<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog</title>
  
  <subtitle>My Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wwyf.github.io/"/>
  <updated>2019-07-24T14:28:41.012Z</updated>
  <id>https://wwyf.github.io/</id>
  
  <author>
    <name>wyf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>tracing2</title>
    <link href="https://wwyf.github.io/2019/07/24/2019-07-2019-07-24-tracing2/"/>
    <id>https://wwyf.github.io/2019/07/24/2019-07-2019-07-24-tracing2/</id>
    <published>2019-07-24T14:23:45.000Z</published>
    <updated>2019-07-24T14:28:41.012Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Tracing-Part2-Linux-中的新一代-tracing-技术"><a href="#Tracing-Part2-Linux-中的新一代-tracing-技术" class="headerlink" title="Tracing Part2 | Linux 中的新一代 tracing 技术"></a>Tracing Part2 | Linux 中的新一代 tracing 技术</h1><blockquote><p>翻译自<br><a href="https://vncz.js.org/ebpf2/" target="_blank" rel="noopener">New generation tracing technologies for Linux operating system - part 2</a></p></blockquote><p>本节旨在快速概述我们编写BPF程序的各种方式以及使用BCC开源项目的一些实际示例。</p><p>编写eBPF程序最简单的方法是简单地将伪程序指令列表指定到一个数组中，直接指向托管程序。</p><p>通常，从eBPF程序创建，加载和获取结果的过程是：</p><ol><li>定义伪装配指令数组</li><li>创建（最终）Maps，以便在eBPF程序和用户空间程序之间交换数据。</li><li>加载程序，指定程序类型</li><li>将程序附加到目标（套接字，Kprobe，Uprobe，静态跟踪点）</li><li>收集结果。</li></ol><p>不幸的是，直接使用伪汇编代码可能过于复杂。</p><p>例如，让我们考虑一个简单的程序，它会在被调用时递增内部计数器。 生成的伪汇编代码如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bpf_insn</span> <span class="title">prog</span>[] = &#123;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Put 0 (the map key) on the stack */</span></span><br><span class="line">BPF_ST_MEM(BPF_W, BPF_REG_10, <span class="number">-4</span>, <span class="number">0</span>),</span><br><span class="line"><span class="comment">/* Put frame pointer into R2 */</span></span><br><span class="line">BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),</span><br><span class="line"><span class="comment">/* Decrement pointer by four */</span></span><br><span class="line">BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, <span class="number">-4</span>),</span><br><span class="line"><span class="comment">/* Put map_fd into R1 */</span></span><br><span class="line">BPF_LD_MAP_FD(BPF_REG_1, map_fd),</span><br><span class="line"><span class="comment">/* Load current count from map into R0 */</span></span><br><span class="line">BPF_RAW_INSN(BPF_JMP | BPF_CALL, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, BPF_FUNC_map_lookup_elem),</span><br><span class="line"><span class="comment">/* If returned value NULL, skip two instructions and return */</span></span><br><span class="line">BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, <span class="number">0</span>, <span class="number">2</span>),</span><br><span class="line"><span class="comment">/* Put 1 into R1 */</span></span><br><span class="line">BPF_MOV64_IMM(BPF_REG_1, <span class="number">1</span>),</span><br><span class="line"><span class="comment">/* Increment value by 1 */</span></span><br><span class="line">BPF_RAW_INSN(BPF_STX | BPF_XADD | BPF_DW, BPF_REG_0, BPF_REG_1, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line"><span class="comment">/* Return from program */</span></span><br><span class="line">BPF_EXIT_INSN(),</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>另一方面，如果我们考虑一个可以执行相同操作的C程序，那么就完全不同了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">counter +=<span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>事实证明，直接使用伪汇编代码是可行的，但它很容易搞错。 因此，用高级语言编写代码很重要，因为它更容易推理。</p><p>此外，内核提供的用于处理eBPF的API非常冗长，需要大量的样板代码才能开始使用eBPF程序，</p><p>幸运的是，对于我们来说，编写简单的eBPF指令和处理原始API并不是必需的。 LLVM为BFP程序提供后端：它意味着模块可以直接用C语言编写，并利用更高级库提供的功能，以及使用函数调用约定来指示程序如何操作以及在何处连接。</p><h2 id="BCC"><a href="#BCC" class="headerlink" title="BCC"></a>BCC</h2><p>BCC（BPF编译器集合）是一个旨在使BPF程序更易于编写的工具包。 它隐藏了为了将BPF与您的应用程序集成而必须遵循的冗长而冗长的工作流程，也避免了有时也需要在Linux源代码树中直接编译的麻烦。</p><p>该工具包提供：</p><ol><li>用于简化eBPF工作流程的共享库</li><li>多种编程语言的绑定（Python，Lua，Go）</li><li>用于跟踪正在运行的系统的单用途和多用途工具（也可作为编写BPF程序的介绍）</li><li>C语言后端（由LLVM提供支持），可将代码转换为eBPF汇编指令</li></ol><p>基本上，我们的意思是插入一些约定，以便编写更简单的程序，并尝试尽可能地跳过处理真实的基础指令。</p><p>例如，为了在特定的内核函数上附加Kprobe，我们可以简单地声明一个具有相同目标函数和kprobe<strong>前缀的函数。 换句话说，如果我们想在tcp_v4_connect上附加一个探针，我们所要做的就是声明一个名为kprobe</strong>tcp_v4_connect的函数</p><p>底层编译器基础结构将负责确定要做什么（附加Kprobe）以及在何处执行（tcp_v4_connect）。 Uprobes也是如此，或者附加到跟踪点等等。</p><p>它还提供处理Map和在BPF程序和用户空间之间交换数据的工具。</p><p>BCC背后的整个概念是确保开发人员可以专注于编写实际的BPF程序，而不必花费太多时间来确定如何与Maps交换数据或如何确保程序正确加载到内核以及试图尽快得到真相（检测无法运行的程序并提前告知它而不是等待验证者拒绝它）。</p><p>现在是一个BCC程序的基本示例，它跟踪所有IPv4连接尝试，即使它们最终失败。 读者应该很容易注意到程序的结构分为两部分：第一部分是BPF代码本身，以字符串的形式写在C中。第二部分是使用Python从程序中收集的结果 向最终用户显示数据。 用于Python的BCC库提供了许多有用的工具来显示数据并从中生成统计数据。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;uapi/linux/ptrace.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;net/sock.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bcc/proto.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">BPF_HASH(currsock, u32, struct sock *);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kprobe__tcp_v4_connect</span><span class="params">(struct pt_regs *ctx, struct sock *sk)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  u32 pid = bpf_get_current_pid_tgid();</span><br><span class="line">  currsock.update(&amp;pid, &amp;sk);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kretprobe__tcp_v4_connect</span><span class="params">(struct pt_regs *ctx)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> ret = PT_REGS_RC(ctx);</span><br><span class="line">  u32 pid = bpf_get_current_pid_tgid();</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">sock</span> **<span class="title">skpp</span>;</span></span><br><span class="line">  skpp = currsock.lookup(&amp;pid);</span><br><span class="line">  <span class="keyword">if</span> (skpp == <span class="number">0</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// missed entry</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (ret != <span class="number">0</span>) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// failed to send SYNC packet, may not have populated</span></span><br><span class="line">  <span class="comment">// socket __sk_common.&#123;skc_rcv_saddr, ...&#125;</span></span><br><span class="line"></span><br><span class="line">  currsock.<span class="keyword">delete</span>(&amp;pid);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// pull in details</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sock</span> *<span class="title">skp</span> = *<span class="title">skpp</span>;</span></span><br><span class="line">u32 saddr = <span class="number">0</span>, daddr = <span class="number">0</span>;</span><br><span class="line">u16 dport = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">bpf_probe_read(&amp;saddr, <span class="keyword">sizeof</span>(saddr), &amp;skp-&gt;__sk_common.skc_rcv_saddr);</span><br><span class="line">bpf_probe_read(&amp;daddr, <span class="keyword">sizeof</span>(daddr), &amp;skp-&gt;__sk_common.skc_daddr);</span><br><span class="line">bpf_probe_read(&amp;dport, <span class="keyword">sizeof</span>(dport), &amp;skp-&gt;__sk_common.skc_dport);</span><br><span class="line"></span><br><span class="line"><span class="comment">// output</span></span><br><span class="line">bpf_trace_printk(<span class="string">"trace_tcp4connect %x %x %d\\n"</span>, saddr, daddr, ntohs(dport));</span><br><span class="line">currsock.<span class="keyword">delete</span>(&amp;pid);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> bcc <span class="keyword">import</span> BPF</span><br><span class="line"><span class="comment"># define BPF program</span></span><br><span class="line">bpf_text = <span class="string">"""</span></span><br><span class="line"><span class="string"># 如前面的c程序所示</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># initialize BPF</span></span><br><span class="line">b = BPF(text=bpf_text)</span><br><span class="line"><span class="comment"># header</span></span><br><span class="line">print(<span class="string">"%-6s %-12s %-16s %-16s %-4s"</span> % (<span class="string">"PID"</span>, <span class="string">"COMM"</span>, <span class="string">"SADDR"</span>, <span class="string">"DADDR"</span>,<span class="string">"DPORT"</span>))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inet_ntoa</span><span class="params">(addr)</span>:</span></span><br><span class="line">    dq = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">4</span>):</span><br><span class="line">      dq = dq + str(addr &amp; <span class="number">0xff</span>)</span><br><span class="line">    <span class="keyword">if</span> (i != <span class="number">3</span>):</span><br><span class="line">      dq = dq + <span class="string">'.'</span></span><br><span class="line">      addr = addr &gt;&gt; <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> dq</span><br><span class="line"><span class="comment"># filter and format output</span></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    <span class="comment"># Read messages from kernel pipe</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        (task, pid, cpu, flags, ts, msg) = b.trace_fields()</span><br><span class="line">        (_tag, saddr_hs, daddr_hs, dport_s) = msg.split(<span class="string">" "</span>)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">    <span class="comment"># Ignore messages from other tracers</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># Ignore messages from other tracers</span></span><br><span class="line">    <span class="keyword">if</span> _tag != <span class="string">"trace_tcp4connect"</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    print(<span class="string">"%-6d %-12.12s %-16s %-16s %-4s"</span> % (pid, task, inet_ntoa(int(saddr_hs, <span class="number">16</span>)), inet_ntoa(int(daddr_hs, <span class="number">16</span>)), dport_s))</span><br></pre></td></tr></table></figure><h2 id="Use-case-hardware-offload"><a href="#Use-case-hardware-offload" class="headerlink" title="Use case: hardware offload"></a>Use case: hardware offload</h2><p>eBPF开辟了许多新的可能性。 然而，eBPF所获得的改进（特别是成为有状态机器的能力）也可以应用并反向移植到网络使用，提供新的有趣用例：其中我们将花费几段时间来解决附加负载到硬件上的问题。</p><p>最初TCP是为不可靠的低速网络而设计的，但随着互联网在骨干传输速度方面的增长（使用光纤载波，千兆以太网和万兆以太网链路）以及更快，更可靠的接入机制（如DSL和电缆调制解调器） 每秒处理的数据量增长令人难以置信，并将继续增加。</p><p>从本质上讲，网络已经成为一种应用程序总线，尽管它不是构建一个应用程序总线的理想场所。 今天的网络包含数百万个端点，物联网带来了大量的新设备。 互联网巨大且嘈杂：可能在10Gb网络上，每秒可以飞行1400万个数据包。 这应该让我们知道在不阻塞网络的情况下处理单个数据包需要多少毫秒。</p><p>而且，网络的内在不可靠性使事情更加复杂化。 TCP正在为我们提供有关数据包状态的绝佳保证，但这种可靠性感会带来复杂性和开销方面的成本。指出我们进行TCP对话时背景中发生的一些事情：</p><ol><li>3路握手连接建立</li><li>显式确认数据包</li><li>校验和和序列号计算</li><li>用于拥塞控制的滑动窗口</li><li>连接终止</li></ol><p>事实证明，主机系统上的TCP软件实现需要大量的计算能力。 虽然这在消费者方面不是问题（终端用户真的不可能通过其网络活动使整个CPU和内存饱和），但这是骨干提供商目前面临的问题。</p><p>多年来，人们一直都很感兴趣，研究以及尝试创建能够将对数据包的处理下放到单独的硬件的系统，实际上有两个主要原因：</p><ol><li>性能：要处理的数据包数量不断增加，这会使内存和CPU饱和。 迫切需要使用专用硬件进行数据包处理。</li><li>网络演进：即使我们 - 作为最终用户 - 没有真正实现它，网络也在不断发展。一个很好的例子是Tcp Fast Open技术。它是由Google和其他一些人开发的，旨在大幅缩短获取网站的时间。对于大多数操作系统，TCP / IP堆栈耦合在内核中，因此工作组将TFO实现推送到上游内核。问题在于说服所有软件和硬件供应商在当前内核版本上重新设置他们的所有软件，这是他们通常尽可能避免的事情，因为突破性变化的数量可能很高。内核和TCP / IP堆栈之间的这种耦合也可能带来安全问题。有许多软件在多年的内核上运行，其中一些甚至可能在TCP / IP堆栈中存在安全问题（如TCP解析器中的某些内容），这使得这些系统非常容易受到攻击。这个问题迫使Google和Facebook等大公司提出在用户空间中移动整个TCP / IP堆栈的想法，而不是在内核中。</li></ol><p>之前曾尝试在Linux内核中推广通用的网络负载下放 - 但是唯一成功的网络可下放的范围非常有限。</p><p>第一次尝试是TOE（TCP offload 引擎） - 一种使用内核补丁允许系统将部分TCP处理（特别是标头）offload到专用硬件的提议。 然而，内核开发人员反对这项技术有几个原因，包括：</p><ol><li>硬件的局限性：有时候，即使专用硬件加快了数据包处理速度，实际上PCI总线并不像今天这么快，导致新的瓶颈令人沮丧</li><li>安全性：专用硬件中的错误可能会危及整个系统，并且它打破了内核始终可以访问所有资源的假设</li><li>复杂性：启用此技术后，内核提供的某些重要服务（如服务质量）不起作用</li><li>专有：为了启用此引擎，仍然需要一个与硬件供应商配合使用的自定义网络驱动程序，并且大部分时间都是封闭源。</li></ol><p>eBPF在桌面上带来了新的可能性，提供了一个标准的统一框架，可以为内核提供一般的卸载机制，原因多种多样; 特别是其中：</p><ol><li>它是一个定义良好的语言和机器，具有受限的资源，寄存器和指令集。 它的功能是众所周知的，所以有一种标准化的方法。</li><li>它是数据包处理中不同工具的构建块（例如tf和XDP，它们正是系统中我们可能希望卸载处理的点）</li><li>eBPF旨在并行运行</li></ol><p>编程模型通过验证器几乎遵循与普通BFP程序相同的路径，唯一改变的是JIT，因为编译的代码应该适合将要执行它的设备。</p><p>许多验证者基础设施通常在翻译过程中重新使用; 这个原因激发了将内部验证器数据结构暴露给外部分析器的想法。 鉴于内核是开源的，很容易找到发生这种分离的提交SHA。</p><p>但是，大多数情况下内置验证程序是不够的，因为您可能需要进行自定义验证，例如验证当前网卡是否能够执行代码。 此时，供应商通常会扩展验证程序，从网卡收集数据（此过程称为大写读取）并检查支持的指令集以及可以加载的最大图像大小。</p><p>如果由于某种原因，网卡无法处理特定的BPF程序，最好的办法是回退到CPU上的常规软件处理。</p><p>您可以对数据包执行的操作和操作范围是扩展的，它取决于卡，但统一正在进行中。 最常见的包括</p><ol><li>ALU指令</li><li>数据包修改（在元数据字段，标头和有效负载上）</li><li>重定向/删除/通行证</li><li>基本地图（用于统计和信息收集）</li><li>结合上面列出的所有操作。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;Tracing-Part2-Linux-中的新一代-tracing
      
    
    </summary>
    
      <category term="Tracing" scheme="https://wwyf.github.io/categories/Tracing/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPF" scheme="https://wwyf.github.io/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>tracing1</title>
    <link href="https://wwyf.github.io/2019/07/24/2019-07-2019-07-24-tracing1/"/>
    <id>https://wwyf.github.io/2019/07/24/2019-07-2019-07-24-tracing1/</id>
    <published>2019-07-24T13:46:48.000Z</published>
    <updated>2019-07-24T14:28:41.012Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Tracing-Part1-Linux-中的新一代-tracing-技术"><a href="#Tracing-Part1-Linux-中的新一代-tracing-技术" class="headerlink" title="Tracing Part1 | Linux 中的新一代 tracing 技术"></a>Tracing Part1 | Linux 中的新一代 tracing 技术</h1><blockquote><p>翻译自<br><a href="https://vncz.js.org/ebpf/" target="_blank" rel="noopener">New generation tracing technologies for Linux operating system</a></p></blockquote><p>在软件工程中，跟踪是通过将程序附加到受控系统中的各种探测点并收集信息来检查和记录有关软件执行的信息的能力。 此信息通常由软件开发人员用于调试目的，以及系统管理员用于保持对系统本身的控制。</p><p>在系统的不同级别上存在许多探测点：它们可以在我能深入检查的函数执行，例如，调用某个函数的参数; 它们可以放在内核中，例如，进入系统并由系统处理的网络数据包; 我们可以检查正在创建/暂停/终止的进程; 但它们也可以是应用程序级事件，如垃圾收集器的调用（如果由运行时环境提供），方法调用和依赖于运行时的事件（如NodeJS的http请求）。</p><p>无论来源如何，每当出现上述有趣事件之一时，跟踪工具允许我们执行某些有用的操作，例如在控制台上打印消息，检查事件的上下文，收集一些统计信息（系统需要多长时间处理 一个网络数据包或运行垃圾收集器），以便我们可以清楚地知道发生了什么。</p><p>所有跟踪工具最重要的要求之一是对系统的低开销。 如果跟踪工具使得系统速度减慢，那么获得的指标可能会产生误导。 此外，跟踪工具意味着在生产和开发模式下连续运行 。因此我们必须在系统上具有非常低开销的tracing工具。</p><p>多年来，很多跟踪工具和技术已经为Linux开发出来。 在增加的开销，易用性，他们能够提取的信息水平以及提供的功能以及最重要的限制方面，有些人比其他人更好; 所以 - 在进入eBPF之前（并理解为什么需要另外的跟踪技术），对Linux中的跟踪环境进行高级概述是有益的。</p><h2 id="Kernel-level-tracing-technologies-overview"><a href="#Kernel-level-tracing-technologies-overview" class="headerlink" title="Kernel level tracing technologies overview"></a>Kernel level tracing technologies overview</h2><p>有了某些内核技术，跟踪才得以进行。 最重要的是，我们有一些用户空间跟踪工具，它们使用上述作为构建块从系统中提取信息并收集有用的数据。</p><h3 id="Trace-points"><a href="#Trace-points" class="headerlink" title="Trace points"></a>Trace points</h3><p>Linux内核中有一种机制已经存在至少10年，称为静态跟踪点。 跟踪点是一个驻留在内核代码中的静态占位符，内核的特定部分的开发人员认为它可以作为挂钩点用于调试代码。</p><p>静态指的是它是一个固定点。 跟踪点的数量及其位置实际上取决于内核版本，更重要的是取决于内核开发人员对该特定区域的看法。 截至今天，当前内核版本有超过700个跟踪点，当然，所有这些都是无操作（即 - 没有执行任何操作）。</p><p>跟踪点真的是多种多样的，包括调度程序事件（新进程创建，进程切换，进程分支），网络事件（进入数据包，数据包出去），文件系统和阻塞IO事件（读，写）等内容。 每个内核系统调用甚至都有跟踪点（这是程序从内核请求服务的程序化方式，形成进程和操作系统之间的基本接口）。 所有内核版本都在其文档中包含可用跟踪点列表。</p><p>内核提供API（通过一组头文件）以便于使用这些跟踪点。 这些头包含一组宏，可用于设置内核模块以响应特定事件。 也可以根据我们的需要定义一个事件类（基本上是一组事件），并为整个类指定一个唯一的处理程序（将要执行的函数）。</p><p>目前几乎所有可用的跟踪工具都可以使用跟踪点附加到所需事件，收集信息并执行有用的统计和分析。</p><p>此外，Trace Point概念也到了系统的更高层次。 各种运行时环境实现了我们可以附加到其中并从中收集信息的详细跟踪点。 例如，在NodeJS中，您可以跟踪何时调用垃圾收集器，何时调用函数，或何时创建类对象，或何时发生IO阻塞操作。</p><p>静态跟踪点的流行和易用性导致它们被放置在许多常见的服务器应用程序中，包括MySQL和PostgreSQL等数据库，您可以使用query<strong>start和query</strong>done跟踪点检查查询执行时间。</p><p>Trace Point的最大限制是，正如其名称所示，它们的静态特性。 如果我们有兴趣跟踪原始开发人员在跟踪点放置期间没有真正考虑的软件的特定区域，我们唯一的可能性是分叉源代码，放置所需的跟踪点并运行fork来收集数据。 希望应该可以回馈主分支，但这可能是一个漫长的过程。</p><p>如果软件是封闭源代码，我们的可能性更小：唯一的方法是联系供应商并开始交易以获得软件的自定义构建，或等待更新。</p><h3 id="Dynamic-Probes"><a href="#Dynamic-Probes" class="headerlink" title="Dynamic Probes"></a>Dynamic Probes</h3><p>Kprobes和Uprobes是内核中内置的另一种机制。 这些已经存在了一段时间，可用于动态探测系统。</p><p>Kprobes和Uprobes不是将静态挂钩点放入内核或编程语言运行时环境或服务器应用程序中，而是允许我们在开发过程中随意选择函数，并在它之上附加程序，而无需在软件中进行任何准备或预置代码。 它既可以是用户空间功能（Uprobes），也可以是内核模块功能（Kprobes）。</p><p>它的工作方式与调试器断点非常相似：每当遇到探测时，都会抛出异常; 一个特殊的异常处理程序将捕获异常并执行与我们附加的探测相关的操作。</p><p>上面有一种替代实现方式更有效：不是抛出导致从内核空间到用户空间的上下文切换的异常（如果谈论Kprobe），只需用提供处理程序的跳转指令替换探测器。</p><p>Kprobes和Uprobes共享许多基础架构和功能集。 但是，由于它们在用户或内核空间中工作，因此存在一些小差异：</p><ol><li>Kprobes是全局性的，而Uprobes是本地的。 Uprobe专门附加在正在创建的进程上，不会影响其他正在运行的进程。 另一方面，Kprobes是全局的，因为它们直接附加在内核函数上，通常，不能保证获得进程句柄。</li><li>Uprobes支持动作和过滤的条件执行 - 此外，在用户空间上附加多个探测是一种预期的方案。</li></ol><h2 id="User-Level-Tracing-Tools"><a href="#User-Level-Tracing-Tools" class="headerlink" title="User Level Tracing Tools"></a>User Level Tracing Tools</h2><p>由于跟踪点和探测都是内核级技术，因此利用这些技术需要编写一个内核模块，该模块将附加到所选事件并以某种方式将其导出到最终用户应用程序 - 或最终在模块本身中收集数据。</p><p>显然，编写内核模块通常不是一个好主意，必须认真对待：即使是最小的错误也可能导致内核panic（这意味着系统停止），而且，处理内核模块意味着大多数隔离过程模型提供的保证可能不可用。</p><p>因此，当您编写内核模块时，您获得的所有跟踪信息不仅限于您当前的进程或shell：相反，您将获得可能不感兴趣的进程和子系统的事件。</p><p>此外，内核跟踪路径是全局的：如果另一个程序使用上面列出的某种内核技术启动跟踪过程，它最终可能会覆盖您的跟踪例程。</p><p>幸运的是，这种内核级技术并不是由用户直接使用。 这绝对是可能的，但其背后的目的是提供构建块来创建更精确和复杂的通用工具，能够从系统收集信息，而无需编写任何代码并保留完全从用户空间工作的可能性。</p><p>我们将快速浏览两个最着名的，但是，正如您在上一张图片中可能已经注意到的那样，跟踪工具还有很多。</p><h3 id="perf"><a href="#perf" class="headerlink" title="perf"></a>perf</h3><p> perf是Linux用户的主要跟踪工具。 它的源代码在Linux内核中，因此您可以通过基本安装获得它。 它最初被设想为从系统性能计数器收集信息的简单工具，但它的功能集一点一点地增加并成为通用的跟踪工具。 它以相对有效的方式将所有收集的数据转储到文件（perf.data），最终可以在以后发布。</p><p> 它错过了一些高级功能（例如，它不能执行功能流程，因为它具有更好的安全性/错误检查功能，因此不那么容易破解）。 它仍然可以进行分析（采样），CPU性能计数器，用户级堆栈转换，并且它可以使用debuginfo进行本地变量的行跟踪。 它还支持多个并发用户。</p><h3 id="ftrace"><a href="#ftrace" class="headerlink" title="ftrace"></a>ftrace</h3><p>ftrace是一个内核跟踪器，允许您监视内核的许多不同区域和活动。 即使它随内核一起提供，它也是独立开发的，其发布周期比内核本身更快。 实际上，每两到三个周期就会将新版本拉入内核树。</p><p>此工具从驻留在/sys/kernel/debug/tracing中的特殊文件系统读取数据。此目录包含多个文件，这些文件表示我们要跟踪的系统部分。 阅读该文件的内容是我们检查系统并弄清楚发生了什么所需要的全部内容。</p><p>还有一个更高级别的工具trace-cmd为您打开ftrace的输出文件，并找出我们可以使用命令行参数查询的有趣事件。</p><h3 id="Performance-limitations"><a href="#Performance-limitations" class="headerlink" title="Performance limitations"></a>Performance limitations</h3><p>这些工具（以及其他工具）都基于将收集的信息直接写入文件的概念。 为了提取我们需要的信息，我们必须将所有这些文件加载到后处理应用程序中（或最终传输这些文件），解析当前行，更新统计信息，然后移动到下一行。 不幸的是，如果所需的统计信息非常具体，您可能需要编写我们自己的后期处理应用程序。</p><p>只要后处理在一台单独的机器上进行就可以了（最好不要在生产中 - 或者至少在单独的过程中），但是如果我们想要收集实时数据，那么它实际上效率很低，所以完全不适用于 实时场景。</p><h2 id="eBPF"><a href="#eBPF" class="headerlink" title="eBPF"></a>eBPF</h2><p>eBPF（代表扩展的Berkley数据包过滤器）是一种相对较新的内核技术（它自3.15起正式成为内核的一部分，但其大多数功能都是在以下内核版本中引入的），旨在提供统一的跟踪解决方案以及克服所有问题 和当前跟踪工具的限制。</p><p>BPF代表Berkley Packet Filtering  -  eBPF诞生的原始技术，它比Linux内核本身存在的时间更长。</p><p>BPF背后的想法是提供一种分析和过滤网络数据包的方法，以便通过用户空间程序提供的简单无状态表达式进行监控。 此表达式一旦附加到目标套接字，将确保通过该套接字的每个数据包将针对它进行测试。</p><p>根据表达式求值返回的（布尔值），可以执行多个动作：丢弃数据包，记录数据包或让数据包继续处理管道。</p><p>不同的工具可以直接使用BPF表达式（tcpdump，wireshark），但是当然任何用户程序都可能使用套接字API附加自定义BPF程序。 由于这种机制，开发起来非常简单，例如，在最终应用程序甚至可以看到它们之前，每个应用程序防火墙消除了数据包。</p><p>最初的BFP发行版以用户空间库的形式出现，但由于性能原因，很快决定将其移入内核：网络数据包处理必须非常高效。</p><p>当网络流量很高时，在将不需要的数据包发送到用户空间之前过滤掉有很多潜在的性能提升：移动通用数据结构（不仅限于套接字，它也可以是文件描述符或内存） 从内核空间到用户空间不仅仅是复制一些内存区域的问题。 它还需要从数据结构本身修剪无用/无法访问的信息，更新进程的资源引用计数器以及使资源通过整个操作系统安全管道。 在内核空间中丢弃数据包（一般来说，避免将内容发送到用户空间），特别是当负载很高时，可以带来显着的性能提升。</p><p>显然，BPF程序运行起来非常重要，因为在高流量情况下，每个开销都会在很大程度上影响性能。</p><p>由于这种“移动”，BPF现在也在内核内部的多个区域内使用（内部数据包过滤，用于流量控制的数据包分类器等）。</p><p>幸运的是，BPF被定义为虚拟机，它几乎是图灵完整且兼容的，只有两个寄存器：累加器和索引。 该机器还有一个小内存区域，隐含地包含正在处理的数据包和有限的指令集。</p><p>这意味着每条BPF指令都可以轻松映射到x86指令序列，并且两个寄存器可以直接映射到CPU寄存器上 - 这表明不是解析表达式并在运行时对其进行评估，而是从BPF生成本机指令 计划是一种可行的方式。</p><p>的确，那件事发生了。 多年来，内核维护人员开始考虑将过滤表达式编译为最流行的体系结构（X86，X64，ARM，PowerPC）的高度优化的机器代码，而不是在运行时解析和执行它们。这是是一个好主意：BFP将成为 基本上很少的本机程序将被加载到内核并以机器速度执行的程序了。</p><p>这需要开发一个JIT编译器，该编译器最终在2011年作为内核补丁登陆，并且最初只适用于x86-64架构。 （公平地说，这不是一场特别的革命，因为自2005年以来FreeBSD一直在使用JIT进行BPF计划）</p><p>回到跟踪工具：虽然这些工具继续发展很大，但是内核仍然缺乏可编写脚本的动态跟踪系统，而是存在于其他系统上：DTrace（一个可编写脚本的跟踪工具）是最令人羡慕的，它可用 在Solaris，MacOS，NetBSD和FreeBSD上。 它允许系统分析业内无法比拟的范围和精度，以及大量的仪器供应商。</p><p>尽管Oracle在许可许可下发布了它，但将DTrace移植到Linux仍然存在问题：</p><ol><li>技术问题：DTrace具有内核中的一些功能，特别是处理无效内存访问的代码和一些基本的检测提供程序。 根据原作者的说法，它不到1500行代码，但是Linux和类UNIX操作系统家族之间的深刻差异使这件事变得微不足道，几乎无法克服，但无论如何都是可行的。</li></ol><ol><li>许可问题：虽然DTrace是在CCDL许可下发布的，但Oracle仍然拥有该软件。 CDDL有一些GPL中没有的限制：因此，将GPL代码（Linux内核）与CDDL代码（DTrace）相结合将导致工作在许可证不一致且无法合法分发。 Oracle希望将DTrace用于Linux，但将其直接集成到内核中显然会导致法律问题，并且最终的补丁会被拒绝，因此他们将其实现为双层内核模块。不幸的是，内核模块的版权有点不清楚。 GPL涵盖了衍生作品，但衍生作品的定义仍然是个人的，没有明确定义。利用明确导出的API可能不足以构成衍生作品 - 另一方面，它可能。 Oracle似乎认为它们是合法的，因此添加了足够的内核代码（并在GPL术语下发布）以支持DTrace，同时保持DTrace的CCDL核心分离。内核实际上有两级暴露（非用户空间）API - 通过EXPORT_SYMBOL（）导出的API和通过EXPORT_SYMBOL_GPL（）导出的API。通过EXPORT_SYMBOL_GPL（）导出的符号只能由声称为GPL的模块使用，否则内核拒绝加载它们。当然，作为DTrace的版权所有者，Oracle可以通过在GPL和CDDL下双重许可DTrace来解决问题。事实上，他们并没有暗示他们认为将其保持在不兼容的许可证下有足够的价值。</li></ol><p>虽然一些开发人员正在考虑向内核添加LUA解释器和虚拟机的想法，但事情却朝着不同的方向发展.3.15内核版本带来了eBPF的第一个版本。 基本上，语言分为两种变体：经典BPF和内部BPF。 后者是现有基础设施的改进和扩展版本，将寄存器数量从2扩展到10，提供对内核功能的有限访问，并添加真正接近真实CPU提供的指令，更重要的是 - 更容易 使用像GCC和LLVM这样的编译器工具链来生成。</p><p>最初，内部BPF，正如名称所声称的那样，并没有暴露，因为开发人员担心这种实现会随着时间的推移而改变，因此他们倾向于从经典BPF程序到内部BPF指令进行内部转换，至少最初是这样。</p><p>在3.16 BPF之后，当经典BPF被证明是稳定的并且所有关于实现变化的担忧消失时，决定将其重命名为扩展BPF并将其暴露给一般用途。</p><p>跟踪是首次使用eBPF进行测试的用例之一，因为乍一看它似乎能够解决不同的痛点，其中缺乏可编写脚本的系统以及快速探测处理。</p><p>在跟踪子系统内（独立于跟踪工具），给定的过滤器表达式通常被解析并表示为一个简单的树，每个内部节点代表一个运算符。 每次遇到跟踪点时，将走这棵树以评估当前存在的特定数据值的每个操作; 如果结果在树的顶部为真，则会触发跟踪点并发出相关信息。 换句话说，大多数跟踪工具都包含一个自己的小解析器和解释器，用于这个特定目的。</p><p>使用扩展的BPF，在另一个头上，将解析器留在原位，但使用JIT编译器删除解释器。 结果令人印象深刻，这表明值得继续以这种方式进行挖掘。</p><p>对于记录，一旦开发人员决定向用户空间公开和改进内部BPF，eBPF的用例就会爆炸。 使用eBPF而不是仅仅过滤数据包，您可以创建虚拟网络，根据您的偏好路由数据包，您可以允许或禁止特定系统调用特定进程，但更重要的是显着改进当前跟踪子系统。 eBPF在功能方面（克服静态跟踪点的限制或简化U / Kprobes的数据收集）和性能（它是一种以机器速度运行的可编程内核技术）开辟了新的可能性。</p><p>此外，无论技术和性能如何改进，具有可编写脚本的跟踪环境的能力都改变了一个重要的事实：到目前为止，度量标准是供应商选择的，封闭源和不完整的。 这迫使所有系统工程师开发推理技术 - 将来自多个工具的源和数据结合起来，试图弄清楚系统中发生了什么。 使用BPF，最终可以编写一个程序，能够准确地收集您正在寻找的信息。</p><h2 id="eBPF-anatomy"><a href="#eBPF-anatomy" class="headerlink" title="eBPF anatomy"></a>eBPF anatomy</h2><h3 id="Verifier"><a href="#Verifier" class="headerlink" title="Verifier"></a>Verifier</h3><p>BPF程序被加载并直接执行到内核中。 这意味着它正在跳过系统在用户空间中自动进行的大量安全检查。 例如，BPF程序中的错误可能会导致内核崩溃（可能会停止整个系统），或者循环情况会冻结整个系统（调度程序无法停止程序，因为我们不在 我们在用户空间中的流程抽象）。</p><p>因此，确保加载的程序是“安全的”绝对至关重要。 验证器完成此检查 - 该软件对正在加载的字节代码执行2阶段静态代码分析。 特别是：</p><ol><li>每个程序加载的指令不超过4096个：eBPF可能会处理大量数据，因此加载的程序很小并且不会成为系统的瓶颈非常重要。</li><li>检查循环和循环流：这些是不允许的，因为它们是不可预测的，并且可能在计算时间方面爆炸并成为系统的瓶颈。</li><li>无法访问的指令：这是为了确保BPF程序很小，加载速度快，执行速度快。 BPF程序应该具有运行所必需的功能。</li><li>跳转错误：验证程序确保跳转发生在程序边界内，而不是任何任意内存位置。这是至关重要的，因为BPF程序不应该损害系统，移动控制流或写入属于其他进程的内存</li><li>路径和流量评估：验证程序正在遍历程序并保持寄存器和堆栈状态的跟踪。如果有任何机会出现堆栈溢出或注册表溢出/下溢，验证程序将拒绝执行代码。同样，这是为了确保BPF程序不会损害系统。</li><li>参数有效性：这是为了确保程序试图在只读寄存器中写入，或者将一大块数据写入较小的寄存器，访问不存在的寄存器，调用未授权的内核函数。</li></ol><p>这些检查以及此处未列出的许多检查，它为我们提供了任何BPF程序的绝佳保证：它是沙箱。 它既不会伤害也不会减慢系统的速度。 这意味着生产安全。</p><p>如果您是软件供应商，并且您想向一家大公司提出您的软件，请说“请在您的计算机上运行此仪器软件”，或者您又是一家安全公司 - 您希望客户端安装特定的内核模块 在他们的生产机器上，公司的安全政策和担忧可能会减慢首次运行的时间。</p><p>通常，如果您是一家公司并且必须安装第三方内核模块，那么您必须承担风险。 您可能需要分析，分解，甚至可能需要手动检查源代码，以确保模块不会嗅探数据或在系统上运行恶意代码。</p><p>BPF正在改变规则。 如果您提供的BPF程序能够实现相同的功能，那么我现在有一套由验证程序提供的保证，因为它是一个带有一组有限指令的沙盒程序，默认情况下它不会损害 系统。 这是BPF计划获得大量支持的原因之一。</p><h3 id="Maps"><a href="#Maps" class="headerlink" title="Maps"></a>Maps</h3><p>BPF程序在内核中运行，但它们仍然必须以某种方式与用户空间程序进行通信，以便随时发回收集的信息以及最终累积的数据。 Maps用于此目的。</p><p>Maps是分配的通用内存区域（确切地说，它被声明为不透明的数据结构），可用于将数据从用户空间传输到内核，反之亦然 - 以及作为多个BPF程序之间的共享内存区域。 它最初被设想为哈希表，但是后续的内核版本也支持数组映射和其他数据结构。</p><p>这可能看起来只是一个小的补充（它实际上只是一个读/写内存区域），但它正在显着改变跟踪场景，特别是在实时用例中。</p><p>正如我们之前所探讨的，我们提到的所有跟踪工具都有一个特定的限制，它们已经遭受了多年的困扰：收集的数据必须以工具相关的格式写在磁盘上，然后，为了收集所需的统计信息， 我们不得不在我们的应用程序中再次加载该文件，解析它并提取所需的信息。</p><p>另一方面，使用Maps不需要存储数据，也不需要将数据解析回来进行后期处理：您只需将自己的结构直接从BPF程序返回到用户应用程序，就像您希望的那样 很容易为您的目的消耗，并最终直接从BPF程序收集统计数据（如递增计数器）。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;Tracing-Part1-Linux-中的新一代-tracing
      
    
    </summary>
    
      <category term="Tracing" scheme="https://wwyf.github.io/categories/Tracing/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPF" scheme="https://wwyf.github.io/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>k8s初部署</title>
    <link href="https://wwyf.github.io/2019/07/22/2019-07-2019-07-22-k8s%E5%88%9D%E9%83%A8%E7%BD%B2/"/>
    <id>https://wwyf.github.io/2019/07/22/2019-07-2019-07-22-k8s初部署/</id>
    <published>2019-07-22T05:58:53.000Z</published>
    <updated>2019-07-23T08:19:07.001Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="在kubernete上部署服务"><a href="#在kubernete上部署服务" class="headerlink" title="在kubernete上部署服务"></a>在kubernete上部署服务</h1><ol><li>部署kubernetes dashboard</li><li>部署sockshop</li><li>部署拓扑关系的那个服务</li><li>部署docker版的bbc（或eBPF）</li></ol><p>[toc]</p><h2 id="关于国内源"><a href="#关于国内源" class="headerlink" title="关于国内源"></a>关于国内源</h2><ol><li>dockerhub速度很低，可使用该方式解决：<ol><li><a href="https://www.daocloud.io/mirror" target="_blank" rel="noopener">daocloud</a></li><li><code>curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io</code></li><li>一条命令，让docker的镜像源设置为daocloud</li></ol></li><li>kubernetes的各种镜像源的替代选择，参考 <a href="https://xuxinkun.github.io/2019/06/11/cn-registry/" target="_blank" rel="noopener">link</a> <a href="https://github.com/Azure/container-service-for-azure-china/tree/master/aks#22-container-registry-proxy" target="_blank" rel="noopener">Azure</a></li></ol><table><thead><tr><th style="text-align:left">global</th><th style="text-align:left">proxy in China</th><th style="text-align:left">format</th><th style="text-align:left">example</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://xuxinkun.github.io/2019/06/11/cn-registry/hub.docker.com" target="_blank" rel="noopener">dockerhub</a>(docker.io)</td><td style="text-align:left"><a href="http://mirror.azk8s.cn/help/docker-registry-proxy-cache.html" target="_blank" rel="noopener">dockerhub.azk8s.cn</a></td><td style="text-align:left"><code>dockerhub.azk8s.cn/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;version&gt;</code></td><td style="text-align:left"><code>dockerhub.azk8s.cn/microsoft/azure-cli:2.0.61``dockerhub.azk8s.cn/library/nginx:1.15</code></td></tr><tr><td style="text-align:left">gcr.io</td><td style="text-align:left"><a href="http://mirror.azk8s.cn/help/gcr-proxy-cache.html" target="_blank" rel="noopener">gcr.azk8s.cn</a></td><td style="text-align:left"><code>gcr.azk8s.cn/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;version&gt;</code></td><td style="text-align:left"><code>gcr.azk8s.cn/google_containers/hyperkube-amd64:v1.13.5</code></td></tr><tr><td style="text-align:left">quay.io</td><td style="text-align:left"><a href="http://mirror.azk8s.cn/help/quay-proxy-cache.html" target="_blank" rel="noopener">quay.azk8s.cn</a></td><td style="text-align:left"><code>quay.azk8s.cn/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;version&gt;</code></td><td style="text-align:left"><code>quay.azk8s.c</code></td></tr></tbody></table><blockquote><p>Note: k8s.gcr.io would redirect to <code>gcr.io/google-containers</code>, following image urls are identical:<br><code>k8s.gcr.io/XXX</code> -&gt; <code>gcr.azk8s.cn/google-containers/XXXXX</code></p></blockquote><h2 id="部署kubernetes-dashboard"><a href="#部署kubernetes-dashboard" class="headerlink" title="部署kubernetes dashboard"></a>部署kubernetes dashboard</h2><p><a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">link</a></p><p>官网教程是这个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><p>其实kubeasz默认就部署好了。不过我就是一直访问不了，没想到踩坑了。</p><p>坑点：</p><ol><li>镜像不要用k8s.grc.io，连不上的</li><li>安全机制似乎做得很好，我必须在集群里才能够访问，集群外的话就访问不了<br>注意这个accept-hosts选项， 我以前没有设置，就一直访问不上去。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl proxy --address=&apos;0.0.0.0&apos; --accept-hosts=&apos;^*$&apos;</span><br></pre></td></tr></table></figure></li></ol><p>然后有一个issue，注意一下</p><p><a href="https://github.com/kubernetes/dashboard/issues/2735" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/issues/2735</a></p><p>在本地做一个代理过去，然后就好了！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -L 8001:localhost:8001 &lt;user@server-ip&gt;</span><br></pre></td></tr></table></figure><p>由此，终于打开了kubernetes-dashboard!!</p><h2 id="部署-Weave"><a href="#部署-Weave" class="headerlink" title="部署 Weave"></a>部署 Weave</h2><p><a href="https://www.weave.works/docs/scope/latest/installing/#k8s" target="_blank" rel="noopener">link</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">kubectl apply -f &quot;https://cloud.weave.works/k8s/scope.yaml?k8s-version=$(kubectl version | base64 | tr -d &apos;\n&apos;)&quot;</span><br></pre></td></tr></table></figure><h2 id="部署sockshop"><a href="#部署sockshop" class="headerlink" title="部署sockshop"></a>部署sockshop</h2><p><a href="https://github.com/microservices-demo/microservices-demo" target="_blank" rel="noopener">https://github.com/microservices-demo/microservices-demo</a><br><a href="https://microservices-demo.github.io/deployment/kubernetes-start.html" target="_blank" rel="noopener">https://microservices-demo.github.io/deployment/kubernetes-start.html</a></p><p>Deploy Sock ShopClone the microservices-demo repositoryGo to the deploy/kubernetes folder</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace sock-shop</span><br><span class="line">kubectl apply -f complete-demo.yaml</span><br></pre></td></tr></table></figure><p>还需要使用这条指令看看端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get service -n sock-shop</span><br></pre></td></tr></table></figure><p>能够看到以下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@v0:~/microservices-demo/deploy/kubernetes# kubectl get service -n sock-shop</span><br><span class="line">NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">carts          ClusterIP   10.68.94.55     &lt;none&gt;        80/TCP         5d14h</span><br><span class="line">carts-db       ClusterIP   10.68.180.121   &lt;none&gt;        27017/TCP      5d14h</span><br><span class="line">catalogue      ClusterIP   10.68.231.124   &lt;none&gt;        80/TCP         5d14h</span><br><span class="line">catalogue-db   ClusterIP   10.68.156.86    &lt;none&gt;        3306/TCP       5d14h</span><br><span class="line">front-end      NodePort    10.68.65.34     &lt;none&gt;        80:30001/TCP   5d14h</span><br><span class="line">orders         ClusterIP   10.68.228.228   &lt;none&gt;        80/TCP         5d14h</span><br><span class="line">orders-db      ClusterIP   10.68.86.56     &lt;none&gt;        27017/TCP      5d14h</span><br><span class="line">payment        ClusterIP   10.68.171.122   &lt;none&gt;        80/TCP         5d14h</span><br><span class="line">queue-master   ClusterIP   10.68.50.241    &lt;none&gt;        80/TCP         5d14h</span><br><span class="line">rabbitmq       ClusterIP   10.68.253.8     &lt;none&gt;        5672/TCP       5d14h</span><br><span class="line">shipping       ClusterIP   10.68.24.98     &lt;none&gt;        80/TCP         5d14h</span><br><span class="line">user           ClusterIP   10.68.151.220   &lt;none&gt;        80/TCP         5d14h</span><br><span class="line">user-db        ClusterIP   10.68.67.241    &lt;none&gt;        27017/TCP      5d14h</span><br><span class="line">root@v0:~/microservices-demo/deploy/kubernetes#</span><br></pre></td></tr></table></figure><p>可以看到前端使用NodePort的方式对外展示。端口为30001</p><p>等待部署完成还需要一点时间，大概机器比较菜吧，等了10多分钟才部署完。</p><h2 id="排查问题：coreDNS"><a href="#排查问题：coreDNS" class="headerlink" title="排查问题：coreDNS"></a>排查问题：coreDNS</h2><p>发现coreDNS老是OOMKilled ?????</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit -n kube-system deployment.apps/coredns</span><br><span class="line">kubectl edit -n kube-system replicaset.apps/coredns-55f46dd959</span><br></pre></td></tr></table></figure><p>尝试修改了内存上限。</p><p>未果，尚待解决</p><p>解决了！！</p><p>参考链接</p><p><a href="https://coredns.io/plugins/loop/#troubleshooting" target="_blank" rel="noopener">link</a><br><a href="https://blog.csdn.net/Fear_w/article/details/88242170" target="_blank" rel="noopener">link2</a></p><p>修改<code>/etc/resolv.conf</code> 就好了。</p><p>然后终于正常了。</p><h2 id="部署测试"><a href="#部署测试" class="headerlink" title="部署测试"></a>部署测试</h2><p>有针对sockshop的<a href="https://microservices-demo.github.io/docs/load-test.html" target="_blank" rel="noopener">模拟测试</a>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run   weaveworksdemos/load-test -h 192.168.199.144:30001 -r 100 -c 50</span><br></pre></td></tr></table></figure><p>就可以了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">user@v4:~/loadtest$ sudo docker run   weaveworksdemos/load-test -h 192.168.199.148:30001 -r 5000 -c 5</span><br><span class="line">Locust file: /config/locustfile.py</span><br><span class="line">Will run /config/locustfile.py against 192.168.199.148:30001. Spawning 5 clients and 5000 total requests.</span><br><span class="line">[2019-07-22 09:41:21,077] 66d812777967/INFO/locust.main: Starting Locust 0.7.5</span><br><span class="line">[2019-07-22 09:41:21,077] 66d812777967/INFO/locust.runners: Hatching and swarming 5 clients at the rate 5 clients/s...</span><br><span class="line">[2019-07-22 09:41:22,096] 66d812777967/INFO/locust.runners: All locusts hatched: Web: 5</span><br><span class="line">[2019-07-22 09:41:22,097] 66d812777967/INFO/locust.runners: Resetting stats</span><br><span class="line"></span><br><span class="line">[2019-07-22 09:43:17,836] 66d812777967/INFO/locust.runners: All locusts dead</span><br><span class="line"></span><br><span class="line">[2019-07-22 09:43:17,836] 66d812777967/INFO/locust.main: Shutting down (exit code 1), bye.</span><br><span class="line"> Name                                                          # reqs      # fails     Avg     Min     Max  |  Median   req/s</span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> GET /                                                            555     0(0.00%)      36       2    5662  |       6    8.00</span><br><span class="line"> GET /basket.html                                                 556     0(0.00%)      19       2     607  |       5    7.80</span><br><span class="line"> DELETE /cart                                                     555     0(0.00%)      76       6    2511  |      21    8.00</span><br><span class="line"> POST /cart                                                       555     1(0.18%)     145      11    3784  |      60    7.80</span><br><span class="line"> GET /catalogue                                                   555     0(0.00%)     109       5    5641  |      24    8.00</span><br><span class="line"> GET /category.html                                               556     0(0.00%)      40       3    3258  |       6    8.00</span><br><span class="line"> GET /detail.html?id=03fef6ac-1896-4ce8-bd69-b798f85c6e0b          55     0(0.00%)      14       3     150  |       5    0.80</span><br><span class="line"> GET /detail.html?id=3395a43e-2d88-40de-b95f-e00e1502085b          70     0(0.00%)      17       2     320  |       6    1.10</span><br><span class="line"> GET /detail.html?id=510a0d7e-8e83-4193-b483-e27e09ddc34d          62     0(0.00%)       9       2      73  |       5    0.40</span><br><span class="line"> GET /detail.html?id=808a2de1-1aaa-4c25-a9b9-6612e8f29a38          44     0(0.00%)      18       2     241  |       6    0.70</span><br><span class="line"> GET /detail.html?id=819e1fbf-8b7e-4f6d-811f-693534916a8b          68     0(0.00%)      21       2     268  |       6    0.90</span><br><span class="line"> GET /detail.html?id=837ab141-399e-4c1f-9abc-bace40296bac          59     0(0.00%)      19       2     699  |       5    1.20</span><br><span class="line"> GET /detail.html?id=a0a4f044-b040-410d-8ead-4de0446aec7e          65     0(0.00%)      17       2     253  |       5    1.00</span><br><span class="line"> GET /detail.html?id=d3588630-ad8e-49df-bbd7-3167f7efb246          68     0(0.00%)      13       2     286  |       6    0.70</span><br><span class="line"> GET /detail.html?id=zzz4f044-b040-410d-8ead-4de0446aec7e          65     0(0.00%)      17       2     538  |       6    1.20</span><br><span class="line"> GET /login                                                       556     0(0.00%)     195      41    7056  |      87    8.00</span><br><span class="line"> POST /orders                                                     490   65(11.71%)     402      72    7311  |     220    7.40</span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> Total                                                           4934    66(1.34%)                                      71.00</span><br><span class="line"></span><br><span class="line">Percentage of the requests completed within given times</span><br><span class="line"> Name                                                           # reqs    50%    66%    75%    80%    90%    95%    98%    99%   100%</span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> GET /                                                             555      6      8     11     15     30     79    240    720   5662</span><br><span class="line"> GET /basket.html                                                  556      5      7      8      9     20     61    240    460    607</span><br><span class="line"> DELETE /cart                                                      555     21     40     59     74    120    240    710   1400   2511</span><br><span class="line"> POST /cart                                                        555     60    100    150    180    280    460    840   1700   3784</span><br><span class="line"> GET /catalogue                                                    555     24     54     88    120    220    360    650   1600   5641</span><br><span class="line"> GET /category.html                                                556      6      9     11     14     45    100    300   1200   3258</span><br><span class="line"> GET /detail.html?id=03fef6ac-1896-4ce8-bd69-b798f85c6e0b           55      5      8     12     17     32     71     74    150    150</span><br><span class="line"> GET /detail.html?id=3395a43e-2d88-40de-b95f-e00e1502085b           70      6      7      8     11     25     83    220    320    320</span><br><span class="line"> GET /detail.html?id=510a0d7e-8e83-4193-b483-e27e09ddc34d           62      5      7     11     11     16     31     58     73     73</span><br><span class="line"> GET /detail.html?id=808a2de1-1aaa-4c25-a9b9-6612e8f29a38           44      6      8     10     11     18     77    240    240    241</span><br><span class="line"> GET /detail.html?id=819e1fbf-8b7e-4f6d-811f-693534916a8b           68      6      9     14     18     59     90    240    270    268</span><br><span class="line"> GET /detail.html?id=837ab141-399e-4c1f-9abc-bace40296bac           59      5      7      9     10     13     38     49    700    699</span><br><span class="line"> GET /detail.html?id=a0a4f044-b040-410d-8ead-4de0446aec7e           65      5      7      8     10     16    110    190    250    253</span><br><span class="line"> GET /detail.html?id=d3588630-ad8e-49df-bbd7-3167f7efb246           68      6      8     10     11     26     30     54    290    286</span><br><span class="line"> GET /detail.html?id=zzz4f044-b040-410d-8ead-4de0446aec7e           65      6      7      9      9     11     20    160    540    538</span><br><span class="line"> GET /login                                                        556     87    120    150    180    290    470   1600   3400   7056</span><br><span class="line"> POST /orders                                                      490    220    330    420    510    840   1500   2400   3000   7311</span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Error report</span><br><span class="line"> # occurences       Error                                                                                               </span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"> 65                 POST /orders: &quot;HTTPError(u&apos;406 Client Error: Not Acceptable for url: http://192.168.199.148:30001/orders&apos;,)&quot;</span><br><span class="line"> 1                  POST /cart: &quot;HTTPError(u&apos;500 Server Error: Internal Server Error for url: http://192.168.199.148:30001/cart&apos;,)&quot;</span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line">user@v4:~/loadtest$ ls</span><br></pre></td></tr></table></figure><h2 id="部署monitoring"><a href="#部署monitoring" class="headerlink" title="部署monitoring"></a>部署monitoring</h2><p>sockshop自带了一些monitoring服务，我打算部署一下。</p><p><a href="https://microservices-demo.github.io/deployment/monitoring-kubernetes.html" target="_blank" rel="noopener">link</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f ./deploy/kubernetes/manifests-monitoring</span><br></pre></td></tr></table></figure><h3 id="坑1"><a href="#坑1" class="headerlink" title="坑1"></a>坑1</h3><p>pod kube-state-metrics-deployment-848b6c67c-clphr 卡在了pull image 上。</p><p>通过describe命令，发现这个pod需要<code>gcr.io</code>的镜像。</p><p>解决（以下方法无法解决）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker pull gcr.azk8s.cn/google_containers/kube-state-metrics:v0.4.1</span><br><span class="line">docker tag gcr.azk8s.cn/google_containers/kube-state-metrics:v0.4.1 gcr.io/google_containers/kube-state-metrics:v0.4.1</span><br><span class="line"># 删除原来的pod，会自动创建新pod的</span><br><span class="line">kubectl delete -n monitoring pod kube-state-metrics-deployment-848b6c67c-clphr</span><br></pre></td></tr></table></figure><p>彻底解决：<br>修改 <code>manifests-monitoring/prometheus-exporter-kube-state-dep.yaml</code></p><p>将里面那个来自 <code>gcr.io</code> 的镜像改成 <code>gcr.azk8s.cn</code> 。</p><h3 id="坑2"><a href="#坑2" class="headerlink" title="坑2"></a>坑2</h3><p>我集群好像不支持LoadBalancer??</p><p>那改一下 <code>grafana-svc.yaml</code>，改一下svc类型就好，改成NodePort。</p><p>然后是弄好了，不过有一些指标暂时无法获取，emmmm不清楚为什么。</p><h2 id="一些奇怪的地方"><a href="#一些奇怪的地方" class="headerlink" title="一些奇怪的地方"></a>一些奇怪的地方</h2><p>pod 删除的时候卡住，可以了解一下这个：</p><p><a href="https://stackoverflow.com/questions/35453792/pods-stuck-in-terminating-status" target="_blank" rel="noopener">https://stackoverflow.com/questions/35453792/pods-stuck-in-terminating-status</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;在kubernete上部署服务&quot;&gt;&lt;a href=&quot;#在kuber
      
    
    </summary>
    
      <category term="K8s" scheme="https://wwyf.github.io/categories/K8s/"/>
    
    
      <category term="K8s" scheme="https://wwyf.github.io/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>eBPF 入门3 | 了解BCC与bpftrace</title>
    <link href="https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF3/"/>
    <id>https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF3/</id>
    <published>2019-07-21T08:05:52.000Z</published>
    <updated>2019-07-21T08:19:46.212Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="eBPF-入门3-了解BCC与bpftrace"><a href="#eBPF-入门3-了解BCC与bpftrace" class="headerlink" title="eBPF 入门3 | 了解BCC与bpftrace"></a>eBPF 入门3 | 了解BCC与bpftrace</h1><p>[toc]</p><h2 id="What"><a href="#What" class="headerlink" title="What?"></a>What?</h2><h3 id="BPF-Compiler-Collection-BCC"><a href="#BPF-Compiler-Collection-BCC" class="headerlink" title="BPF Compiler Collection (BCC)"></a>BPF Compiler Collection (BCC)</h3><blockquote><p>BCC is a toolkit for creating efficient kernel tracing and manipulation programs, and includes several useful tools and examples. It makes use of extended BPF (Berkeley Packet Filters), formally known as eBPF, a new feature that was first added to Linux 3.15. Much of what BCC uses requires Linux 4.1 and above.</p></blockquote><p>BCC是用于创建高效内核跟踪和操作程序的工具包，包括一些有用的工具和示例。 它利用了扩展的BPF（Berkeley Packet Filters），正式名称为eBPF，这是一种新功能，最初被添加到Linux 3.15中。 BCC使用的大部分内容都需要Linux 4.1及更高版本。</p><h3 id="bpftrace"><a href="#bpftrace" class="headerlink" title="bpftrace"></a>bpftrace</h3><blockquote><p>bpftrace is a high-level tracing language for Linux enhanced Berkeley Packet Filter (eBPF) available in recent Linux kernels (4.x). bpftrace uses LLVM as a backend to compile scripts to BPF-bytecode and makes use of BCC for interacting with the Linux BPF system, as well as existing Linux tracing capabilities: kernel dynamic tracing (kprobes), user-level dynamic tracing (uprobes), and tracepoints. The bpftrace language is inspired by awk and C, and predecessor tracers such as DTrace and SystemTap. bpftrace was created by Alastair Robertson.</p></blockquote><p>bpftrace是最新Linux内核（4.x）中提供的Linux增强型Berkeley Packet Filter（eBPF）的高级跟踪语言。 bpftrace使用LLVM作为后端将脚本编译为BPF字节码，并利用BCC与Linux BPF系统进行交互，以及现有的Linux跟踪功能：内核动态跟踪（kprobes），用户级动态跟踪（uprobes）， 和跟踪点。 bpftrace语言的灵感来自awk和C，以及DTrace和SystemTap等前身跟踪器。 bpftrace由Alastair Robertson创建。</p><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p><a href="https://github.com/iovisor/bcc/blob/master/INSTALL.md" target="_blank" rel="noopener">安装BCC</a></p><p><a href="https://github.com/iovisor/bpftrace/blob/master/INSTALL.md" target="_blank" rel="noopener">安装bpftrace</a></p><h3 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h3><p>安装bcc （无论从源码安装还是从包管理器都是可以的）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD</span><br><span class="line">echo "deb https://repo.iovisor.org/apt/$(lsb_release -cs) $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/iovisor.list</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install bcc-tools libbcc-examples linux-headers-$(uname -r)</span><br></pre></td></tr></table></figure><p>安装 bpftrace，我从源码装好了（听说snap上装的有bug）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y bison cmake flex g++ git libelf-dev zlib1g-dev libfl-dev systemtap-sdt-dev</span><br><span class="line">sudo apt-get install llvm-7-dev llvm-7-runtime libclang-7-dev clang-7</span><br><span class="line">git clone https://github.com/iovisor/bpftrace</span><br><span class="line">mkdir bpftrace/build; cd bpftrace/build;</span><br><span class="line">cmake -DCMAKE_BUILD_TYPE=Release ..</span><br><span class="line">make -j8</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h3 id="Arch"><a href="#Arch" class="headerlink" title="Arch"></a>Arch</h3><p>在Arch Linux上可以这样安装。</p><p><a href="https://nanxiao.me/en/install-bcc-on-archlinux/" target="_blank" rel="noopener">link</a></p><ol><li>安装aur助手（<a href="https://linux.cn/article-9925-1.html）" target="_blank" rel="noopener">https://linux.cn/article-9925-1.html）</a></li></ol><p>我安装的是yay</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://aur.archlinux.org/yay.git</span><br><span class="line">cd yay</span><br><span class="line">makepkg -si</span><br></pre></td></tr></table></figure><ol><li>使用yay安装bcc和bpftrace</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yay -S bcc</span><br><span class="line">yay -S bcc-tools</span><br><span class="line">yay -S python-bcc</span><br><span class="line">yay -S brftrace</span><br></pre></td></tr></table></figure><blockquote><p>可以编译安装，流程可见github仓库中的相关说明。<br>方便起见，我就使用了包管理器。</p></blockquote><h2 id="使用BCC"><a href="#使用BCC" class="headerlink" title="使用BCC"></a>使用BCC</h2><p>一个简单的测试是使用BCC仓库自带的example。</p><p>这是一个跟踪磁盘 I/O内核函数的例子。其中bpf程序如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;uapi/linux/ptrace.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/blkdev.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">BPF_HISTOGRAM(dist);</span><br><span class="line">BPF_HISTOGRAM(dist_linear);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kprobe__blk_account_io_completion</span><span class="params">(struct pt_regs *ctx, struct request *req)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        dist.increment(bpf_log2l(req-&gt;__data_len / <span class="number">1024</span>));</span><br><span class="line">        dist_linear.increment(req-&gt;__data_len / <span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>BCC让我们可以调用py接口，很方便的将这个BPF程序注入内核。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bcc <span class="keyword">import</span> BPF</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="comment"># load BPF program</span></span><br><span class="line">b = BPF(text=<span class="string">"""</span></span><br><span class="line"><span class="string">#include &lt;uapi/linux/ptrace.h&gt;</span></span><br><span class="line"><span class="string">#include &lt;linux/blkdev.h&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">BPF_HISTOGRAM(dist);</span></span><br><span class="line"><span class="string">BPF_HISTOGRAM(dist_linear);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">int kprobe__blk_account_io_completion(struct pt_regs *ctx, struct request *req)</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">        dist.increment(bpf_log2l(req-&gt;__data_len / 1024));</span></span><br><span class="line"><span class="string">        dist_linear.increment(req-&gt;__data_len / 1024);</span></span><br><span class="line"><span class="string">        return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">"""</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># header</span></span><br><span class="line">print(<span class="string">"Tracing... Hit Ctrl-C to end."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># trace until Ctrl-C</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">        sleep(<span class="number">99999999</span>)</span><br><span class="line"><span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">print(<span class="string">"log2 histogram"</span>)</span><br><span class="line">print(<span class="string">"~~~~~~~~~~~~~~"</span>)</span><br><span class="line">b[<span class="string">"dist"</span>].print_log2_hist(<span class="string">"kbytes"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\nlinear histogram"</span>)</span><br><span class="line">print(<span class="string">"~~~~~~~~~~~~~~~~"</span>)</span><br><span class="line">b[<span class="string">"dist_linear"</span>].print_linear_hist(<span class="string">"kbytes"</span>)</span><br><span class="line"></span><br><span class="line">`</span><br></pre></td></tr></table></figure><p>最终的执行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">user@v4:~/bpftrace/bcc/examples/tracing$ sudo ./bitehist.py </span><br><span class="line">Tracing... Hit Ctrl-C to end.</span><br><span class="line">^C</span><br><span class="line">log2 histogram</span><br><span class="line">~~~~~~~~~~~~~~</span><br><span class="line">     kbytes              : count     distribution</span><br><span class="line">         0 -&gt; 1          : 55       |**                                      |</span><br><span class="line">         2 -&gt; 3          : 0        |                                        |</span><br><span class="line">         4 -&gt; 7          : 904      |****************************************|</span><br><span class="line">         8 -&gt; 15         : 301      |*************                           |</span><br><span class="line">        16 -&gt; 31         : 132      |*****                                   |</span><br><span class="line">        32 -&gt; 63         : 42       |*                                       |</span><br><span class="line">        64 -&gt; 127        : 35       |*                                       |</span><br><span class="line">       128 -&gt; 255        : 17       |                                        |</span><br><span class="line">       256 -&gt; 511        : 17       |                                        |</span><br><span class="line"></span><br><span class="line">linear histogram</span><br><span class="line">~~~~~~~~~~~~~~~~</span><br><span class="line">     kbytes        : count     distribution</span><br><span class="line">        0          : 55       |**                                      |</span><br><span class="line">        1          : 0        |                                        |</span><br><span class="line">        2          : 0        |                                        |</span><br><span class="line">        3          : 0        |                                        |</span><br><span class="line">        4          : 904      |****************************************|</span><br><span class="line">        5          : 0        |                                        |</span><br><span class="line">        6          : 0        |                                        |</span><br><span class="line">        7          : 0        |                                        |</span><br></pre></td></tr></table></figure><p>这个所表示的含义便是，目前系统中IO系统调用中，数据大小的分布。</p><h2 id="使用bpftrace"><a href="#使用bpftrace" class="headerlink" title="使用bpftrace"></a>使用bpftrace</h2><p>bpftrace这是一种新定义的高层语言。文档细节可见<a href="https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md" target="_blank" rel="noopener">这里</a>。下面举几个例子让自己对这个能干嘛有个感性的认识。</p><h3 id="对do-sys-open系统调用进行监控"><a href="#对do-sys-open系统调用进行监控" class="headerlink" title="对do_sys_open系统调用进行监控"></a>对<code>do_sys_open</code>系统调用进行监控</h3><p>我使用这样一条命令监控do_sys_open系统调用，并获得进程名与open的文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bpftrace -e &apos;kprobe:do_sys_open &#123; printf(&quot;%s: %s\n&quot;, comm, str(arg1)) &#125;&apos;</span><br></pre></td></tr></table></figure><p>然后我使用vim打开一个文件 <code>bench.sh</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">[wyf@wyf-room ~]$ sudo bpftrace -e &apos;kprobe:do_sys_open &#123; printf(&quot;%s: %s\n&quot;, comm, str(arg1)) &#125;&apos;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/tls/x86_64/x86_64/libm.so.6</span><br><span class="line">...</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/x86_64/libm.so.6</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/libm.so.6</span><br><span class="line">vim: /etc/ld.so.cache</span><br><span class="line">vim: /usr/lib/libm.so.6</span><br><span class="line">...</span><br><span class="line">vim: /usr/share/vim/vim81/lang/en.utf8/LC_MESSAGES/vim.mo</span><br><span class="line">vim: /usr/share/vim/vim81/lang/en/LC_MESSAGES/vim.mo</span><br><span class="line">vim: /usr/share/terminfo/x/xterm</span><br><span class="line">vim: .</span><br><span class="line">vim: /etc/vimrc</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vimfiles/archlinux.vim</span><br><span class="line">vim: .</span><br><span class="line">vim: /home/wyf/.vimrc</span><br><span class="line">vim: .</span><br><span class="line">...</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vim81/filetype.vim</span><br><span class="line">vim: /home/wyf/.vim/ftdetect/</span><br><span class="line">vim: /usr/share/vim/vimfiles/ftdetect/</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vimfiles/ftdetect/dockerfile.vim</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vimfiles/ftdetect/nginx.vim</span><br><span class="line">vim: /usr/share/vim/vim81/ftdetect/</span><br><span class="line">...</span><br><span class="line">vim: /usr/share/vim/vim81/plugin/vimballPlugin.vim/</span><br><span class="line">...</span><br><span class="line">vim: /usr/share/vim/vim81/plugin/zipPlugin.vim</span><br><span class="line">vim: /home/wyf/.vim/pack/</span><br><span class="line">vim: /usr/share/vim/vimfiles/pack/</span><br><span class="line">vim: /usr/share/vim/vim81/pack/</span><br><span class="line">vim: /usr/share/vim/vim81/pack/dist/start/</span><br><span class="line">vim: /usr/share/vim/vimfiles/after/pack/</span><br><span class="line">vim: /home/wyf/.vim/after/pack/</span><br><span class="line">...</span><br><span class="line">vim: /home/wyf/.viminfo</span><br><span class="line">vim: /etc/nsswitch.conf</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/libnss_files.so.2</span><br><span class="line">vim: /etc/ld.so.cache</span><br><span class="line">vim: /usr/lib/libnss_files.so.2</span><br><span class="line">vim: /etc/passwd</span><br><span class="line">vim: bench.sh</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swp</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swp</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swx</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swx</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swp</span><br><span class="line">vim: bench.sh</span><br><span class="line">vim: /home/wyf/.viminfo</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vim81/autoload/dist/ft.vim</span><br><span class="line">vim: /home/wyf/.vim/syntax/sh/</span><br><span class="line">vim: /usr/share/vim/vimfiles/syntax/sh/</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vim81/syntax/sh.vim</span><br><span class="line">vim: /usr/share/vim/vim81/syntax/sh/</span><br><span class="line">vim: /usr/share/vim/vimfiles/after/syntax/sh/</span><br><span class="line">vim: /home/wyf/.vim/after/syntax/sh/</span><br></pre></td></tr></table></figure><p>嗯，清清楚楚得看到了vim进程在我打开一个文件的过程里，对多少个配置文件执行了读操作……。</p><p>如果在kubernetes集群里呢？能看到这些内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">kubelet: /var/lib/kubelet/pods/3b55cfed-a57c-11e9-ad37-5254005a02d0/volu</span><br><span class="line">kubelet: /var/lib/kubelet/pods/3b55cfed-a57c-11e9-ad37-5254005a02d0/volu</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/memory/kubepods/besteffort/podd8c5dfe5-a580-11e9</span><br><span class="line">kubelet: /sys/fs/cgroup/cpu,cpuacct/kubepods/besteffort/podd8c5dfe5-a580</span><br><span class="line">kubelet: /sys/fs/cgroup/cpu,cpuacct/kubepods/besteffort/podd8c5dfe5-a580</span><br><span class="line">kubelet: /sys/fs/cgroup/cpu,cpuacct/kubepods/besteffort/podd8c5dfe5-a580</span><br><span class="line">kubelet: /sys/fs/cgroup/blkio/kubepods/besteffort/podd8c5dfe5-a580-11e9-</span><br><span class="line">kubelet: /sys/fs/cgroup/blkio/kubepods/besteffort/podd8c5dfe5-a580-11e9-</span><br><span class="line">kubelet: /sys/fs/cgroup/blkio/kubepods/besteffort/podd8c5dfe5-a580-11e9-</span><br><span class="line">kubelet: /sys/fs/cgroup/cpu,cpuacct/kubepods/besteffort/podd8c5dfe5-a580</span><br><span class="line">kubelet: /proc/19074/net/dev</span><br><span class="line">kubelet: /var/lib/dockershim/sandbox</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/da86e6ba6</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/da86e6ba6</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/metadata/sha256/da86e6ba</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/da86e6ba6</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/da86e6ba6</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/metadata/sha256/da86e6ba</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/da86e6ba6</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/da86e6ba6</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/metadata/sha256/da86e6ba</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/72d68eecf</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/72d68eecf</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/metadata/sha256/72d68eec</span><br><span class="line">dockerd: /var/lib/docker/image/overlay2/imagedb/content/sha256/ff281650a</span><br></pre></td></tr></table></figure><h3 id="对系统调用sys-exit-read进行监控"><a href="#对系统调用sys-exit-read进行监控" class="headerlink" title="对系统调用sys_exit_read进行监控"></a>对系统调用<code>sys_exit_read</code>进行监控</h3><p>监控<code>sys_exit_read</code>系统调用，看看不同进程read size的分布。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[wyf@wyf-room ~]$ sudo bpftrace -e &apos;tracepoint:syscalls:sys_exit_read /args-&gt;ret/ &#123; @[comm] = sum(args-&gt;ret); &#125;&apos;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">^C</span><br><span class="line"></span><br><span class="line">@[sudo]: 1</span><br><span class="line">@[sshd]: 108</span><br><span class="line">@[containerd]: 1286</span><br><span class="line">@[dockerd]: 1456</span><br><span class="line">@[systemd-journal]: 4190</span><br></pre></td></tr></table></figure><p>在一个跑着kubernetes的虚拟机上跑，结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">user@v1:~/bpftrace/build$ sudo bpftrace -e &apos;tracepoint:syscalls:sys_exit_read /args-&gt;ret/ &#123; @[comm] = sum(args-&gt;ret); &#125;&apos;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">^C</span><br><span class="line"></span><br><span class="line">@[systemd-journal]: 8</span><br><span class="line">@[containerd]: 572</span><br><span class="line">@[kube-proxy]: 2329</span><br><span class="line">@[sshd]: 3827</span><br><span class="line">@[iptables]: 23040</span><br><span class="line">@[htop]: 182071</span><br><span class="line">@[kubelet]: 187173</span><br><span class="line">@[dockerd]: 231754</span><br><span class="line">@[flanneld]: 18446744073709551561</span><br><span class="line">@[sudo]: 18446744073709551606</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今日体验到此结束。感觉如果要更加熟练的使用这些工具的话，还需要对各种系统调用的接口有一个比较全面的理解。知道每个系统调用的参数具体有什么作用，这样子才能够让自己更好的观察这个系统。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;eBPF-入门3-了解BCC与bpftrace&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="eBPF" scheme="https://wwyf.github.io/categories/eBPF/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPF" scheme="https://wwyf.github.io/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>eBPF 入门2 | eBPF 介绍 + 捕获系统调用实例</title>
    <link href="https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF2/"/>
    <id>https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF2/</id>
    <published>2019-07-21T04:11:14.000Z</published>
    <updated>2019-07-21T04:13:23.155Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="eBPF-入门2-eBPF-介绍-捕获系统调用实例"><a href="#eBPF-入门2-eBPF-介绍-捕获系统调用实例" class="headerlink" title="eBPF 入门2 | eBPF 介绍 + 捕获系统调用实例"></a>eBPF 入门2 | eBPF 介绍 + 捕获系统调用实例</h1><blockquote><p>翻译博文<br><a href="https://sematext.com/blog/linux-kernel-observability-ebpf/" target="_blank" rel="noopener">https://sematext.com/blog/linux-kernel-observability-ebpf/</a></p></blockquote><p>最新的Linux内核版本配备了强大的Linux监控框架，用于内核检测。 它源于历史上被称为BPF的东西。</p><h2 id="What-is-BPF"><a href="#What-is-BPF" class="headerlink" title="What is BPF?"></a>What is BPF?</h2><p>BPF（Berkeley Packet Filter）是一种非常有效的网络数据包过滤机制，旨在避免不必要的用户空间分配。 它直接在内核域中对网络分组数据进行操作。 最熟悉的BPF功能应用与tcpdump工具中使用的过滤器表达式有关。 在引擎盖下，表达式被编译并透明地转换为BPF字节码。 然后将该字节码加载到内核中并应用于原始网络数据包流(raw socket)，从而有效地将那些满足过滤条件的数据包传递给用户空间。</p><h2 id="What-is-eBPF"><a href="#What-is-eBPF" class="headerlink" title="What is eBPF?"></a>What is eBPF?</h2><p>eBPF是BPF Linux可观察性系统的扩展和增强版本。将其视为加强版的BPF。使用eBPF，可以将自定义沙盒字节码附加到几乎每个通过内核符号表导出的函数，而不必担心破坏内核。事实上，eBPF强调跨越用户空间边界时安全的重要性。如果检测到无效指针解引用或达到最大堆栈大小限制，则内核验证程序将拒绝加载任何eBPF程序。不允许循环（除了在编译时已知常量上限的循环），并且只允许在生成的字节码中调用特定eBPF辅助函数的一小部分子集。 eBPF程序保证在某个时间点终止，并且永远不会耗尽系统资源，而内核模块不会导致系统不稳定或导致可怕的内核恐慌。相反，与“自由”内核模块提供的相比，有些人可能会发现eBPF限制性太强，但权衡可能更有利于eBPF而不是“面向模块”的工具，这主要是因为eBPF程序不能损害内核的保证。然而，这不是唯一的好处。</p><h2 id="Why-use-eBPF-for-Linux-monitoring"><a href="#Why-use-eBPF-for-Linux-monitoring" class="headerlink" title="Why use eBPF for Linux monitoring?"></a>Why use eBPF for Linux monitoring?</h2><p>作为Linux内核的核心部分，eBPF不依赖于任何第三方模块或外部依赖项。 它强加了一个稳定的ABI（应用程序二进制接口），使得在较旧的内核上构建的程序可以在较新的内核版本上运行。 eBPF引起的性能开销通常可以忽略不计，因此非常适合应用程序监控和跟踪重载系统。 Windows用户没有eBPF，但他们可以使用Windows事件跟踪。</p><p>eBPF非常灵活，能够跟踪所有主要Linux子系统的几乎任何方面，包括CPU调度程序，内存管理器，网络，系统调用，块设备请求等。 几乎没有极限。</p><p>您可以通过终端运行此命令找到可跟踪符号的完整列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/kallsyms</span><br></pre></td></tr></table></figure><p>上面的命令会产生巨大的输出。 如果我们只对系统调用接口感兴趣，那么一些grep magic将帮助过滤掉不需要的符号名称：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@wyf-room wyf]# cat /proc/kallsyms | grep -w -E &quot;sys_.*&quot;</span><br><span class="line">ffffffff8d8afc20 T sys_ni_syscall</span><br><span class="line">ffffffff8def39e0 t sys_dmi_field_show</span><br><span class="line">ffffffff8def3b90 t sys_dmi_modalias_show</span><br><span class="line">ffffffff8e6001c0 R sys_call_table</span><br><span class="line">ffffffff8ea9a280 d sys_table</span><br><span class="line">ffffffff8eaf0ac0 d sys_dmi_attribute_groups</span><br><span class="line">ffffffff8eaf0ae0 d sys_dmi_attribute_group</span><br><span class="line">ffffffff8eaf0b20 d sys_dmi_modalias_attr</span><br><span class="line">ffffffff8eaf0b40 d sys_dmi_chassis_asset_tag_attr</span><br><span class="line">ffffffff8eaf0b80 d sys_dmi_chassis_serial_attr</span><br><span class="line">ffffffff8eaf0bc0 d sys_dmi_chassis_version_attr</span><br><span class="line">ffffffff8eaf0c00 d sys_dmi_chassis_type_attr</span><br><span class="line">ffffffff8eaf0c40 d sys_dmi_chassis_vendor_attr</span><br><span class="line">ffffffff8eaf0c80 d sys_dmi_board_asset_tag_attr</span><br><span class="line">ffffffff8eaf0cc0 d sys_dmi_board_serial_attr</span><br><span class="line">ffffffff8eaf0d00 d sys_dmi_board_version_attr</span><br><span class="line">ffffffff8eaf0d40 d sys_dmi_board_name_attr</span><br><span class="line">ffffffff8eaf0d80 d sys_dmi_board_vendor_attr</span><br><span class="line">ffffffff8eaf0dc0 d sys_dmi_product_family_attr</span><br><span class="line">ffffffff8eaf0e00 d sys_dmi_product_sku_attr</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>不同类型的挂钩点负责对内核中触发的不同事件做出反应。 在特定存储器地址处执行内核例程，数据包的到达或用户空间代码的调用都是通过将eBPF程序分别附加到kprobes，XDP程序到分组入口路径以及分别将用户空间进程附加到用户空间进程而可捕获的事件的示例。</p><blockquote><p>(上面那段不是很会翻译，放上原文) Different types of hook points are responsible for reacting to events being triggered inside the kernel. The execution of the kernel routine at specific memory address, arrival of a network packet or invocation of user space code are all examples of events trappable by attaching eBPF programs to kprobes, XDP programs to packet ingress paths and uprobes to user space processes respectively.</p></blockquote><p>在Sematext，我们对eBPF非常兴奋，并正在探索在服务器监控和容器可见性的背景下利用其功能的方法。 继续阅读。</p><p>让我们深入一点，看看如何构建eBPF程序并将其加载到内核中。</p><h2 id="Anatomy-of-a-Linux-eBPF-Program"><a href="#Anatomy-of-a-Linux-eBPF-Program" class="headerlink" title="Anatomy of a Linux eBPF Program"></a>Anatomy of a Linux eBPF Program</h2><p>在我们开始进一步解释eBPF程序的结构之前，值得一提的是BCC（BPF编译器集合） - 一个抽象字节码加载的工具包，并提供Python和Lua语言的绑定以与底层的eBPF基础设施互操作。 它还包含许多有用的工具，可以让您大概了解通过eBPF能够实现的功能。</p><p>过去，BPF程序是通过原始BPF指令集指令手工生成生成的字节码。 幸运的是，clang编译器（LLVM前端的一部分）可以将C转换为eBPF字节码，并使我们免于使用BPF指令。 截至今天，它是唯一可以产生 eBPF字节码的编译器，尽管也可以从<a href="https://unhandledexpression.com/general/rust/2018/02/02/poc-compiling-to-ebpf-from-rust.html" target="_blank" rel="noopener">Rust生成eBPF字节码</a>。</p><p>成功编译eBPF程序并生成目标文件后，我们就可以将其注入内核。 为此，引入了新的bpf系统调用。 除了加载eBPF字节码之外，这个看似简单的系统调用还有很多功能。 它创建和操作内核映射（稍后将详细介绍Map），这是eBPF基础架构最引人注目的功能之一。 你可以通过阅读bpf手册页（man 2 bpf）来了解更多。</p><p>当用户空间进程决定通过调用bpf系统调用来推送eBPF字节码时，内核将对其进行验证，然后将JIT（转换为机器代码）指令转换为等效的目标体系结构指令集。 结果代码将非常快！ 如果由于任何原因JIT编译器不可用，内核将回退到不具备上述裸机性能的解释器。</p><h2 id="Linux-eBPF-Example"><a href="#Linux-eBPF-Example" class="headerlink" title="Linux eBPF Example"></a>Linux eBPF Example</h2><p>我们现在看一个Linux eBPF程序的例子。 我们的目标是将<strong>捕获setns系统调用</strong>。 进程在希望加入一个新的隔离命名空间时调用此系统调用，该命名空间是在构建子进程描述符之后创建的（子进程可以通过在clone syscall参数中指定标志的位掩码来控制它应该从父进程取消链接的命名空间）。 此系统调用通常用于为进程提供系统资源的隔离概述，例如TCP堆栈，挂载点，PID编号空间等。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/kconfig.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/version.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/bpf.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SEC</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SEC(NAME)                  </span></span><br><span class="line">  __attribute__((section(NAME), used))</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">SEC(<span class="string">"kprobe/sys_setns"</span>)</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kprobe__sys_setns</span><span class="params">(struct pt_regs *ctx)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">char</span> _license[] SEC(<span class="string">"license"</span>) = <span class="string">"GPL"</span>;</span><br><span class="line">__u32 _<span class="function">version <span class="title">SEC</span><span class="params">(<span class="string">"version"</span>)</span> </span>= <span class="number">0xFFFFFFFE</span>;</span><br></pre></td></tr></table></figure><p>以上是最小的eBPF程序。 它由不同的部分组成。 首先，我们包含各种内核头文件，其中包含多种数据类型的定义。 我们还声明了用于在对象文件中生成section的SEC宏，这些section将会稍后由ELF BPF加载器解释。 如果加载程序找不到许可证和版本部分，则会抱怨，因此我们需要提供这两个部分。</p><p>现在是我们的eBPF程序中最有趣的部分 - setns系统调用的实际挂钩点。 通过使用kprobe__前缀启动函数名并绑定相应的SEC宏，我们指示内核虚拟机将检测回调附加到sys_setns符号，该符号将触发我们的eBPF程序，并在每次调度syscall时执行函数体内的代码。 每个eBPF程序都有一个执行上下文。 对于内核探测器，这是处理器寄存器（pt_regs结构）的当前状态，它包含libc在从用户到内核空间转换时放置的函数参数。 要编译程序（llvm和clang应该安装并正确配置），我们可以使用以下命令（请注意你需要通过LINUX_HEADERS env变量指定内核头的路径）其中clang将生成我们的中间LLVM表示 程序和LLVM编译器将生成最终的eBPF字节码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ clang -D__KERNEL__ -D__ASM_SYSREG_H</span><br><span class="line">         -Wunused</span><br><span class="line">         -Wall</span><br><span class="line">         -Wno-compare-distinct-pointer-types</span><br><span class="line">         -Wno-pointer-sign</span><br><span class="line">         -O2 -S -emit-llvm ns.c</span><br><span class="line">         -I $LINUX_HEADERS/source/include</span><br><span class="line">         -I $LINUX_HEADERS/source/include/generated/uapi</span><br><span class="line">         -I $LINUX_HEADERS/source/arch/x86/include</span><br><span class="line">         -I $LINUX_HEADERS/build/include</span><br><span class="line">         -I $LINUX_HEADERS/build/arch/x86/include</span><br><span class="line">         -I $LINUX_HEADERS/build/include/uapi</span><br><span class="line">         -I $LINUX_HEADERS/build/include/generated/uapi</span><br><span class="line">         -I $LINUX_HEADERS/build/arch/x86/include/generated</span><br><span class="line">         -o - | llc -march=bpf -filetype=obj -o ns.o</span><br></pre></td></tr></table></figure><p>您可以使用readelf工具来查看ELF部分和目标文件的符号表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ readelf -a -S ns.o</span><br><span class="line">…</span><br><span class="line"> 2: 0000000000000000         0 NOTYPE  GLOBAL DEFAULT        4 _license</span><br><span class="line"> 3: 0000000000000000         0 NOTYPE  GLOBAL DEFAULT        5 _version</span><br><span class="line"> 4: 0000000000000000         0 NOTYPE  GLOBAL DEFAULT        3 kprobe__sys_setns</span><br></pre></td></tr></table></figure><p>上面的输出证明符号表是按预期构建的。 我们有一个有效的eBPF目标文件，现在是时候将它加载到内核中并看到魔术发生了。</p><h2 id="Attaching-eBPF-Programs-with-Go"><a href="#Attaching-eBPF-Programs-with-Go" class="headerlink" title="Attaching eBPF Programs with Go"></a>Attaching eBPF Programs with Go</h2><p>我们已经提到了BCC以及如何在为eBPF提供好用的接口的同时完成繁重的工作。 为了构建和运行eBPF程序，BCC需要在目标节点上安装LLVM和内核头文件，有时我们可能无法进行权衡。 在这种情况下，如果我们可以运送在二进制文件的数据段中的结果ELF对象并最大化跨机器的可移植性，那将是理想的。</p><p>除了为libbcc提供绑定外，gobpf包还能够从预编译的字节码加载eBPF程序。 如果我们将它与可以在Go应用程序中嵌入blob的packr等工具结合起来，我们就拥有了所有需要的成分来分配我们的二进制文件，并且运行时依赖性为零。</p><p>我们将略微修改eBPF程序，以便在触发kprobe时将其打印到内核跟踪管道。 为简洁起见，我们不会包含printt宏的定义以及其他eBPF辅助函数，但您可以在此头文件中找到它们。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SEC(<span class="string">"kprobe/sys_setns"</span>)</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kprobe__sys_setns</span><span class="params">(struct pt_regs *ctx)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> fd = (<span class="keyword">int</span>)PT_REGS_PARM1(ctx);</span><br><span class="line">  <span class="keyword">int</span> pid = bpf_get_current_pid_tgid() &gt;&gt; <span class="number">32</span>;</span><br><span class="line">  printt(<span class="string">"process with pid %d joined ns through fd %d"</span>, pid, fd);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在我们可以开始编写处理eBPF字节码加载的Go代码。 我们将在gobpf上实现一个小抽象（KprobeTracer）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"bytes"</span></span><br><span class="line">  <span class="string">"errors"</span></span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line">  bpflib <span class="string">"github.com/iovisor/gobpf/elf"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> KprobeTracer <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// bytecode is the byte stream with embedded eBPF program</span></span><br><span class="line">  bytecode []<span class="keyword">byte</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// eBPF module associated with this tracer. The module is a  collection of maps, probes, etc.</span></span><br><span class="line">  mod *bpflib.Module</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewKprobeTracer</span><span class="params">(bytecode []<span class="keyword">byte</span>)</span> <span class="params">(*KprobeTracer, error)</span></span> &#123;</span><br><span class="line">   mod := bpflib.NewModuleFromReader(bytes.NewReader(bytecode))</span><br><span class="line">   <span class="keyword">if</span> mod == <span class="literal">nil</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">"ebpf is not supported"</span>)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> KprobeTracer&#123;mod: mod, bytecode: bytecode&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// EnableAllKprobes enables all kprobes/kretprobes in the module. The argument</span></span><br><span class="line"><span class="comment">// determines the maximum number of instances of the probed functions the can</span></span><br><span class="line"><span class="comment">// be handled simultaneously.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *KprobeTracer)</span> <span class="title">EnableAllKprobes</span><span class="params">(maxActive <span class="keyword">int</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"></span><br><span class="line">  params := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]*bpflib.PerfMap)</span><br><span class="line"></span><br><span class="line">  err := t.mod.Load(params)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">     <span class="keyword">return</span> fmt.Errorf(<span class="string">"unable to load module: %v"</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  err = t.mod.EnableKprobes(maxActive)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">     <span class="keyword">return</span> fmt.Errorf(<span class="string">"cannot initialize kprobes: %v"</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们准备引导内核探针跟踪器:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"log"</span></span><br><span class="line">  <span class="string">"github.com/gobuffalo/packr"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  box := packr.NewBox(<span class="string">"/directory/to/your/object/files"</span>)</span><br><span class="line">  bytecode, err := box.Find(<span class="string">"ns.o"</span>)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">      log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ktracer, err := NewKprobeTracer(bytecode)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">     log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> err := ktracer.EnableAllKprobes(<span class="number">10</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">     log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>sudo cat /sys/kernel/debug/tracing/trace_pipe</code>  读取推送到管道的调试信息。 测试eBPF程序的最简单方法是将其附加到正在运行的Docker容器中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it nginx /bin/bash</span><br></pre></td></tr></table></figure><p>在幕后，容器运行时将bash进程重新关联到nginx容器的命名空间。 我们通过PT_REGS_PARM1宏捕获的第一个参数是命名空间的文件描述符，该文件描述符用<code>/proc/&lt;pid&gt;/ns</code>目录中的符号链接表示。 好极了！ 因此，我们可以在每次进程加入命名空间时进行监视。 它可能不是非常有用的东西，但它说明了捕获系统调用执行并访问其参数是多么容易。</p><h2 id="Using-eBPF-Maps"><a href="#Using-eBPF-Maps" class="headerlink" title="Using eBPF Maps"></a>Using eBPF Maps</h2><p>将结果写入跟踪管道有利于调试，但对于生产环境，我们肯定需要一种更复杂的机制来在用户和内核空间之间共享状态。 这就是eBPF的Map有用的地方。 它们代表了用于数据聚合的非常有效的内核键/值存储，并且可以从用户空间异步访问。 有许多类型的eBPF MAP，但对于这个特定的用例，我们将依赖BPF_MAP_TYPE_PERF_EVENT_ARRAY地图。 它可以存储通过perf事件环缓冲区推送的自定义结构，并广播到用户空间进程。</p><p>Go-bpf允许将perf MAP创建和事件流传输到提供的Go通道。 我们可以添加以下代码来将C结构传输到我们的程序中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">rxChan := <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="keyword">byte</span>)</span><br><span class="line">lostChan := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">uint64</span>)</span><br><span class="line">pmap, err := bpflib.InitPerfMap(</span><br><span class="line">  t.mod,</span><br><span class="line">  mapName,</span><br><span class="line">  rxChan,</span><br><span class="line">  lostChan,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> quit, err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> _, found := t.maps[mapName]; !found &#123;</span><br><span class="line">  t.maps[mapName] = pmap</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">     <span class="keyword">select</span> &#123;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> pe := &lt;-rxChan:</span><br><span class="line">        nsJoin := (*C.struct_ns_evt_t)(unsafe.Pointer(&amp;(*pe)[<span class="number">0</span>]))</span><br><span class="line">        log.Info(nsJoin)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> l := &lt;-lostChan:</span><br><span class="line">        <span class="keyword">if</span> lost != <span class="literal">nil</span> &#123;</span><br><span class="line">           lost(l)</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">pmap.PollStart()</span><br></pre></td></tr></table></figure><p>我们初始化接收器和丢失事件通道，并将它们与模块引用和我们应该使用的事件的perf映射的名称一起传递给<code>InitPerfMap</code>函数。 每次在接收器通道上推送新事件时，我们将原始指针转换为我们的eBPF程序中定义的C struct（ns_evt_t）。 我们还需要声明一个perf map并通过bpf_perf_event_output helper生成结构：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> bpf_map_def SEC(<span class="string">"maps/ns"</span>) ns_map = &#123;</span><br><span class="line">  .<span class="keyword">type</span> = BPF_MAP_TYPE_HASH,</span><br><span class="line">  .key_size = sizeof(u32),</span><br><span class="line">  .value_size = sizeof(<span class="keyword">struct</span> ns_evt_t),</span><br><span class="line">  .max_entries = <span class="number">1024</span>,</span><br><span class="line">  .pinning = <span class="number">0</span>,</span><br><span class="line">  .namespace = <span class="string">""</span>,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> ns_evt_t evt = &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Initialize structure fields.*/</span></span><br><span class="line">u32 cpu = bpf_get_smp_processor_id();</span><br><span class="line">bpf_perf_event_output(ctx, &amp;ns_map,</span><br><span class="line">                     cpu,</span><br><span class="line">                     &amp;evt, sizeof(evt));</span><br></pre></td></tr></table></figure><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>eBPF不断发展并得到更广泛的采用。 随着每个内核的发布，新功能和改进正在得到解决。 低开销和本机可编程性支持使其对各种用例非常有吸引力。 例如，Suricata入侵检测系统使用它在Linux网络堆栈的早期阶段实现高级套接字负载平衡策略和数据包过滤。 Cilium严重依赖eBPF来为容器提供复杂的安全策略。 Sematext Agent利用eBPF精确定位有趣的事件，例如杀死信号广播或用于Docker和Kubernetes监控的OOM通知，以及定期服务器监控。 它还通过使用eBPF捕获TCP / UDP流量统计信息，为网络监控提供了有效的网络跟踪器。 看来eBPF的目标是通过Linux内核工具成为Linux监控的事实标准。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;eBPF-入门2-eBPF-介绍-捕获系统调用实例&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="eBPF" scheme="https://wwyf.github.io/categories/eBPF/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPF" scheme="https://wwyf.github.io/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>eBPF 入门1 | Introduction to xdp and eBPF</title>
    <link href="https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF1/"/>
    <id>https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF1/</id>
    <published>2019-07-21T02:34:46.000Z</published>
    <updated>2019-07-21T04:13:23.155Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="eBPF-入门1-Introduction-to-xdp-and-eBPF"><a href="#eBPF-入门1-Introduction-to-xdp-and-eBPF" class="headerlink" title="eBPF 入门1 | Introduction to xdp and eBPF"></a>eBPF 入门1 | Introduction to xdp and eBPF</h1><blockquote><p>翻译博文<br><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/" target="_blank" rel="noopener">https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/</a></p></blockquote><p>在过去几年中，我们已经看到了编程工具包和技术的升级，以克服Linux内核在进行高性能数据包处理时的局限性。 最流行的技术之一是内核旁路（kernel bypass），这意味着跳过内核的网络层并从用户空间进行所有数据包处理。 内核旁路还涉及从用户空间管理NIC，换句话说，依赖于用户空间驱动程序来处理NIC。</p><p>通过使用用户空间程序对NIC完全控制，我们可以减少内核引入的开销（上下文切换，网络层处理，中断等），这在10Gbps或更高速度下工作时更为重要。 内核旁路加上其他功能（批量数据包处理）和性能调整调整（NUMA感知，CPU隔离等）的组合符合高性能用户空间网络的基础。 也许这种新的数据包处理方法的典型代表是英特尔的DPDK（Data Plane Development Kit），尽管其他众所周知的工具包和技术是思科的VPP（Vector Packet Processing），PF_Ring，当然还有 Snabb。</p><p>用户空间网络的缺点有几个：</p><ol><li>OS的内核是硬件资源的抽象层。 由于用户空间程序需要直接管理其资源，因此他们还需要管理其硬件。 用户空间驱动程序可能正常运行，但通常不如OS内核提供的驱动程序那样经过良好测试且可重用性较差。（内核为了简化硬件的管理，已经抽象了硬件资源的管理。但对于用户空间的驱动程序而言，如果不使用内核的抽象层进行管理，而是自己进行管理，可靠性成为问题）</li><li>由于完全跳过了内核空间，因此也会跳过内核提供的所有网络功能。 用户空间程序需要重新实现内核或操作系统可能已提供的功能。</li><li>程序作为沙盒工作，严重限制了它们与操作系统其他部分集成和交互的能力。</li><li>内核也提供了一个安全层，在用户空间网络的情况下不存在。</li></ol><p>从本质上讲，用户空间网络通过将数据包处理从内核领域转移到用户空间来实现高速性能。 事实上，XDP实际上恰恰相反：它将用户空间网络程序（过滤器，映射器，路由等）移动到内核的领域。 XDP允许我们在数据包到达NIC时，并且在它开始向上移动到内核的网络层之前执行我们的网络功能，这让数据包的处理速度得到显着提高。 但是内核如何使用户能够在内核的领域内执行他们的程序呢？ 在回答这个问题之前，我们需要看一下BPF。</p><h2 id="BPF-and-eBPF"><a href="#BPF-and-eBPF" class="headerlink" title="BPF and eBPF"></a>BPF and eBPF</h2><p>尽管名称有些误导，但BPF（Berkeley Packet Filtering）实际上是一个虚拟机模型。 这个VM最初是为包过滤处理而设计的，因此就是它的名字。</p><p>BPF最突出的用户之一是工具tcpdump。 使用tcpdump捕获数据包时，用户可以定义数据包过滤表达式。 实际上只捕获与该表达式匹配的数据包。 例如，表达式“tcp dst port 80”捕获目标端口等于80的所有TCP数据包。此表达式可以通过编译器转成BPF字节码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@wyf-room wyf]# tcpdump -d &quot;tcp dst port 80&quot;</span><br><span class="line">(000) ldh      [12]</span><br><span class="line">(001) jeq      #0x86dd          jt 2jf 6</span><br><span class="line">(002) ldb      [20]</span><br><span class="line">(003) jeq      #0x6             jt 4jf 15</span><br><span class="line">(004) ldh      [56]</span><br><span class="line">(005) jeq      #0x50            jt 14jf 15</span><br><span class="line">(006) jeq      #0x800           jt 7jf 15</span><br><span class="line">(007) ldb      [23]</span><br><span class="line">(008) jeq      #0x6             jt 9jf 15</span><br><span class="line">(009) ldh      [20]</span><br><span class="line">(010) jset     #0x1fff          jt 15jf 11</span><br><span class="line">(011) ldxb     4*([14]&amp;0xf)</span><br><span class="line">(012) ldh      [x + 16]</span><br><span class="line">(013) jeq      #0x50            jt 14jf 15</span><br><span class="line">(014) ret      #262144</span><br><span class="line">(015) ret      #0</span><br><span class="line">[root@wyf-room wyf]#</span><br></pre></td></tr></table></figure><p>上面这个程序做的一些事情是：</p><ol><li>指令（000）：将数据包的偏移量12作为16位字加载到累加器中。 偏移12表示数据包的以太网类型。<ol><li><img src="https://i.imgur.com/2YSVgMT.png" alt=""></li></ol></li><li>指令（001）：将累加器的值与0x86dd进行比较，后者是IPv6的以太网类型值。 如果结果为真，则程序计数器跳转到指令（002），否则跳转到（006）。</li><li>指令（006）：将值与0x800（IPv4的以太网类型值）进行比较。 如果是，则跳转到（007），如果不是（015）。</li></ol><p>依此类推，直到包过滤程序返回结果。 这个结果通常是一个布尔值。 返回非零值（指令（014））意味着数据包匹配，而返回零值（指令（015））意味着数据包不匹配。</p><p>BPF VM及其字节码由Steve McCane和Van Jacobson于1992年末在他们的论文<a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf" target="_blank" rel="noopener">“BSD数据包过滤器：用户级数据包捕获的新架构”</a>中引入，并且它首次在Usenix Conference Winter ‘93上展示。</p><p>由于BPF是VM，因此它定义了执行程序的环境。 除字节码外，它还定义了基于数据包的存储器模型（加载指令在处理数据包上隐式完成），寄存器（A和X;累加器Accumulator和索引寄存器 Index register），暂存存储器和隐式程序计数器（Program Counter）。 有趣的是，BPF的字节码是在摩托罗拉6502 ISA之后建模的。 正如Steve McCane在他的<a href="https://sharkfestus.wireshark.org/sharkfest.11/presentations/McCanne-Sharkfest&#39;11_Keynote_Address.pdf" target="_blank" rel="noopener">Sharkfest ‘11</a>主题演讲中所回忆的那样，由于他初中高中时在Apple II上编程的日子，他熟悉6502汇编，这在设计BPF字节码时影响了他。</p><p>Linux内核自v2.5起支持BPF，主要由Jay Schullist添加。 直到2011年，当Eric Edmazet将BPF解释器转换为JIT（用于数据包过滤器的JIT）时，BPF代码没有发生重大变化。 现在内核能够将BPF程序直接转换为目标体系结构，而不是解释BPF字节码：x86，ARM，MIPS等。</p><p>后来，2014年，Alexei Starovoitov推出了新的BPF JIT。 这个新的JIT实际上是一个基于BPF的新架构，称为eBPF。 我认为这两个虚拟机共存已有一段时间了，但现在在eBPF之上实现了数据包过滤。 事实上，很多文档现在将eBPF称为BPF，而经典BPF称为cBPF。</p><p>eBPF以多种方式扩展了经典的BPF虚拟机：</p><ol><li>与x86-64类似的架构。 eBPF使用64位寄存器，并将可用寄存器的数量从2（累加器Accumulator 和X寄存器）增加到10.eBPF还扩展了操作码的数量。</li><li>与网络子系统分离。 BPF受限于基于数据包的数据模型。由于它用于包过滤，因此其代码存在于网络子系统中。但是，eBPF VM不再受限于数据模型，它可以用于任何目的。现在可以将eBPF程序附加到跟踪点或kprobe。这为eBPF打开了仪表，性能分析以及其他内核子系统中的更多用途的大门。 eBPF代码现在位于自己的路径：kernel / bpf。</li><li>全局数据存储称为Maps。Maps是一种通用数据结构，以键值对的形式存储不同类型的数据。它们允许在eBPF内核程序之间以及内核和用户空间应用程序之间共享数据。</li><li>助手功能。如数据包重写，校验和计算或数据包克隆。与用户空间编程不同，这些函数在内核中执行。此外，还可以从eBPF程序执行系统调用。</li><li>尾调用。 eBPF程序限制为4096字节。尾部调用功能允许eBPF程序通过控制新的eBPF程序，克服此限制。</li></ol><h2 id="eBPF-an-example"><a href="#eBPF-an-example" class="headerlink" title="eBPF: an example"></a>eBPF: an example</h2><p>Linux内核源代码包含几个eBPF示例。 它们可以 <a href="https://github.com/torvalds/linux/tree/v4.19/samples/bpf" target="_blank" rel="noopener">samples/bpf/</a>获得。 要编译这些示例，只需键入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo make samples/bpf/</span><br></pre></td></tr></table></figure><p>我将重新使用 samples/bpf/中可用的一个例子，而不是编写新的eBPF示例。 我将介绍代码的某些部分并解释它是如何工作的。 我选择的例子是tracex4程序。</p><p>通常，<code>samples/bpf/</code>的所有示例都包含2个文件。 这是一个例子：</p><ol><li><code>tracex4_kern.c</code>，包含要在内核中作为eBPF字节码执行的源代码。</li><li><code>tracex4_user.c</code>，包含用户空间程序。</li></ol><p>我们需要将tracex4_kern.c编译为eBPF字节码。 此时，gcc缺少eBPF的后端。 幸运的是，clang可以产生eBPF字节码。 Makefile使用clang将tracex4_kern.c编译为目标文件。</p><p>我之前评论过，eBPF最有趣的功能之一是Maps。 Maps是键/值存储，允许在用户空间和内核空间程序之间交换数据。 tracex4_kern定义了一个Maps：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct pair &#123;</span><br><span class="line">    u64 val;</span><br><span class="line">    u64 ip;</span><br><span class="line">&#125;;  </span><br><span class="line"></span><br><span class="line">struct bpf_map_def SEC(&quot;maps&quot;) my_map = &#123;</span><br><span class="line">    .type = BPF_MAP_TYPE_HASH,</span><br><span class="line">    .key_size = sizeof(long),</span><br><span class="line">    .value_size = sizeof(struct pair),</span><br><span class="line">    .max_entries = 1000000,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>BPF_MAP_TYPE_HASH是eBPF提供的众多Maps类型之一。 在这种情况下，它只是一个哈希表。 您可能也注意到<code>SEC(&quot;Maps&quot;)</code>声明。 SEC是一个用于在二进制文件中创建新section的宏。 实际上tracex4_kern示例还定义了两个section：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">SEC(&quot;kprobe/kmem_cache_free&quot;)</span><br><span class="line">int bpf_prog1(struct pt_regs *ctx)</span><br><span class="line">&#123;   </span><br><span class="line">    long ptr = PT_REGS_PARM2(ctx);</span><br><span class="line"></span><br><span class="line">    bpf_map_delete_elem(&amp;my_map, &amp;ptr); </span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">SEC(&quot;kretprobe/kmem_cache_alloc_node&quot;) </span><br><span class="line">int bpf_prog2(struct pt_regs *ctx)</span><br><span class="line">&#123;</span><br><span class="line">    long ptr = PT_REGS_RC(ctx);</span><br><span class="line">    long ip = 0;</span><br><span class="line"></span><br><span class="line">    // get ip address of kmem_cache_alloc_node() caller</span><br><span class="line">    BPF_KRETPROBE_READ_RET_IP(ip, ctx);</span><br><span class="line"></span><br><span class="line">    struct pair v = &#123;</span><br><span class="line">        .val = bpf_ktime_get_ns(),</span><br><span class="line">        .ip = ip,</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    bpf_map_update_elem(&amp;my_map, &amp;ptr, &amp;v, BPF_ANY);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这两个函数将允许我们从Map中删除一个条目(kprobe/kmem_cache_free) 并向Map添加一个新条目(kretprobe/kmem_cache_alloc_node)。 所有以大写字母表示的函数调用实际上都是在bpf_helpers.h中定义的宏。</p><p>如果我转储目标文件的部分，我应该能够看到定义的这些新部分：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ objdump -h tracex4_kern.o</span><br><span class="line"></span><br><span class="line">tracex4_kern.o:     file format elf64-little</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA               LMA               File off  Algn</span><br><span class="line">  0 .text         00000000  0000000000000000  0000000000000000  00000040  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 kprobe/kmem_cache_free 00000048  0000000000000000  0000000000000000  00000040  2**3</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE</span><br><span class="line">  2 kretprobe/kmem_cache_alloc_node 000000c0  0000000000000000  0000000000000000  00000088  2**3</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE</span><br><span class="line">  3 maps          0000001c  0000000000000000  0000000000000000  00000148  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  4 license       00000004  0000000000000000  0000000000000000  00000164  2**0</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  5 version       00000004  0000000000000000  0000000000000000  00000168  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  6 .eh_frame     00000050  0000000000000000  0000000000000000  00000170  2**3</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA</span><br></pre></td></tr></table></figure><p>然后是主程序tracex4_user.c。 基本上，程序所做的是监听kmem_cache_alloc_node事件。 当该事件发生时，执行相应的eBPF代码。 代码将对象的IP属性存储到Map中，该地图在主程序中循环打印。 例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ./tracex4</span><br><span class="line">obj 0xffff8d6430f60a00 is  2sec old was allocated at ip ffffffff9891ad90</span><br><span class="line">obj 0xffff8d6062ca5e00 is 23sec old was allocated at ip ffffffff98090e8f</span><br><span class="line">obj 0xffff8d5f80161780 is  6sec old was allocated at ip ffffffff98090e8f</span><br></pre></td></tr></table></figure><p>用户空间程序和eBPF程序是如何连接的？ 在初始化时，tracex4_user.c使用load_bpf_file函数加载tracex4_kern.o对象文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">int main(int ac, char **argv)</span><br><span class="line">&#123;</span><br><span class="line">    struct rlimit r = &#123;RLIM_INFINITY, RLIM_INFINITY&#125;;</span><br><span class="line">    char filename[256];</span><br><span class="line">    int i;</span><br><span class="line"></span><br><span class="line">    snprintf(filename, sizeof(filename), &quot;%s_kern.o&quot;, argv[0]);</span><br><span class="line"></span><br><span class="line">    if (setrlimit(RLIMIT_MEMLOCK, &amp;r)) &#123;</span><br><span class="line">        perror(&quot;setrlimit(RLIMIT_MEMLOCK, RLIM_INFINITY)&quot;);</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (load_bpf_file(filename)) &#123;</span><br><span class="line">        printf(&quot;%s&quot;, bpf_log_buf);</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (i = 0; ; i++) &#123;</span><br><span class="line">        print_old_objects(map_fd[1]);</span><br><span class="line">        sleep(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行load_bpf_file时，eBPF文件中定义的探针将添加/sys/kernel/debug/tracing/kprobe_eventskprobe_events。 我们现在正在听那些事件，我们的程序可以在它们发生时做点什么。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cat /sys/kernel/debug/tracing/kprobe_events</span><br><span class="line">p:kprobes/kmem_cache_free kmem_cache_free</span><br><span class="line">r:kprobes/kmem_cache_alloc_node kmem_cache_alloc_node</span><br></pre></td></tr></table></figure><p>sample/bpf/ 中的所有其他程序都遵循类似的结构。 总有两个文件：</p><ol><li>XXX_kern.c: the eBPF program.</li><li>XXX_user.c: the main program.</li></ol><p>eBPF程序定义了连接到二进制部分的Maps和函数。 当内核发出某种类型的事件（例如，一个跟踪点）时，我们的钩子(hooks)将被执行。 Maps用于在内核程序和用户空间程序之间交换数据。</p><p>在本文中，我从高级视图中介绍了BPF和eBPF。 我知道现在有很多关于eBPF的资源和信息，但我觉得我需要用自己的话来解释它（查看建议读数列表以获取更多信息）。 在下一篇文章中，我将介绍XDP及其与eBPF的关系。</p><p>Recommended readings:</p><ul><li><a href="https://lwn.net/Articles/599755/" target="_blank" rel="noopener">BPF: the universal in-kernel virtual machine</a> by Jonathan Corbet. An introduction to BPF and its evolution towards eBPF.</li><li><a href="https://lwn.net/Articles/740157/" target="_blank" rel="noopener">A thorough introduction to eBPF</a> by Brendan Gregg. Article by LWN.net. Brendan tweets often about eBPF and maintains a list of resources in his <a href="http://www.brendangregg.com/" target="_blank" rel="noopener">personal blog</a>.</li><li><a href="https://jvns.ca/blog/2017/06/28/notes-on-bpf---ebpf/" target="_blank" rel="noopener">Notes on BPF &amp; eBPF</a> by Julia Evans. Notes on Suchakra Sharma’s presentation “The BSD Packet Filter: A New Architecture for User-level Packet Capture”. The notes are of good quality and really helpful to digest the slides.</li><li><a href="https://ferrisellis.com/posts/ebpf_past_present_future/" target="_blank" rel="noopener">eBPF, part1: Past, Present and Future</a> by Ferris Ellis. A long read, with a <a href="https://ferrisellis.com/posts/ebpf_syscall_and_maps/" target="_blank" rel="noopener">follow-up</a>, but time worth invested. One of the best articles I’ve read so far about eBPF.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;eBPF-入门1-Introduction-to-xdp-and-
      
    
    </summary>
    
      <category term="eBPF" scheme="https://wwyf.github.io/categories/eBPF/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPG" scheme="https://wwyf.github.io/tags/eBPG/"/>
    
  </entry>
  
  <entry>
    <title>docker 配置nextcloud 并配置泛域名证书</title>
    <link href="https://wwyf.github.io/2019/07/19/2019-07-2019-07-19-%E9%85%8D%E7%BD%AEnextcloud/"/>
    <id>https://wwyf.github.io/2019/07/19/2019-07-2019-07-19-配置nextcloud/</id>
    <published>2019-07-19T03:11:44.000Z</published>
    <updated>2019-07-19T03:11:52.461Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="docker-配置nextcloud-并配置泛域名证书"><a href="#docker-配置nextcloud-并配置泛域名证书" class="headerlink" title="docker 配置nextcloud 并配置泛域名证书"></a>docker 配置nextcloud 并配置泛域名证书</h1><p>总结一下，配一个网站真的费时费力。不过说真的，用了docker已经好很多了……</p><p>配了一晚上，我完成了以下工作：</p><ol><li>使用docker安装了nginx，mysql，nextcloud。</li><li>三个容器间可使用容器名直接连接，避免了重启后容器ip可能改变的问题。</li><li>配置泛域名证书，并每个月自动更新，给nextcloud启动https。</li></ol><h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><p>这里挑选了旧版的mysql，是因为我发现用新版的话，可能由于mysql默认身份验证方式的改变而无法与nextcloud连接上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">docker run \</span><br><span class="line">-v /data/docker/mysql:/var/lib/mysql \</span><br><span class="line">--name wyf-mysql \</span><br><span class="line">-e MYSQL_ROOT_PASSWORD="XXXXXXXX" \</span><br><span class="line">-e MYSQL_USER="username" \</span><br><span class="line">-e MYSQL_PASSWORD="XXXXXXXX" \</span><br><span class="line">-p 3306  -d mysql:5</span><br></pre></td></tr></table></figure><h2 id="安装nextcloud"><a href="#安装nextcloud" class="headerlink" title="安装nextcloud"></a>安装nextcloud</h2><p>说实在的，有了docker，真的给服务部署简化了不少。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">docker run -d \</span><br><span class="line">-v /data/docker/nextcloud:/var/www/html \</span><br><span class="line">--name wyf-nextcloud \</span><br><span class="line">-p 80 \</span><br><span class="line">--link wyf-mysql:wyf-mysql \</span><br><span class="line">nextcloud</span><br></pre></td></tr></table></figure><p>这个时候使用docker ps 命令看看目前nextcloud的端口是哪一个，然后去访问即可。</p><p>初始页面中设置管理员账户还有数据库信息，注意这里数据库的host直接写 wyf-mysql 就可以了。</p><p>这里我发现好像只能用root账户？nextcloud需要创建数据库的权限，想来，一个更好的操作可能是在mysql中创建一个nextcloud的专用账户会更好。</p><p>emmm我为了方便直接就使用了root账户来初始化。</p><h2 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h2><p>本来nginx直接在物理机装就好，弄成docker的原因是我想在nginx.conf里面能够直接写容器名，而不写易变的容器IP。这样子我就不用经常修改nginx.conf</p><p>注意到我这里挂在了两个目录，并且设置为只读。<br>nginx目录就是放置nginx的配置文件的。<br>letsencrypt目录用于certbot存放https证书，后面会说明怎么生成https证书。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">docker run --name wyf-nginx \</span><br><span class="line">-v /etc/nginx:/etc/nginx:ro \</span><br><span class="line">-v /etc/letsencrypt:/etc/letsencrypt:ro \</span><br><span class="line">-d \</span><br><span class="line">-p 80:80 \</span><br><span class="line">-p 443:443 \</span><br><span class="line">--link wyf-mysql:wyf-mysql \</span><br><span class="line">--link wyf-nextcloud:wyf-nextcloud \</span><br><span class="line">nginx</span><br></pre></td></tr></table></figure><h2 id="配置泛域名证书与自动更新"><a href="#配置泛域名证书与自动更新" class="headerlink" title="配置泛域名证书与自动更新"></a>配置泛域名证书与自动更新</h2><p>安装如下包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S certbot certbot-nginx certbot-dns-cloudflare</span><br></pre></td></tr></table></figure><p>在arch安装的时候会莫名发现几个包找不到，在arch官网的包仓库里找到然后离线安装即可，例子如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#pacman -U /home/wyf/python-pbr-5.4.1-1-any.pkg.tar.xz</span><br></pre></td></tr></table></figure><p>然后我使用的是cloudflare的DNS，因此就在cloudflare上获取一个global api key 准备之后的操作。</p><p>创建文件  “/etc/certbot/certbot-dns-cloudflare/dns.ini”，里面填入以下信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dns_cloudflare_email = #cloudfalre的注册邮箱</span><br><span class="line">dns_cloudflare_api_key = #XXXX global api key</span><br></pre></td></tr></table></figure><p>安全起见，将该文件权限设置为 700</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 700 /etc/certbot/certbot-dns-cloudflare/dns.ini</span><br></pre></td></tr></table></figure><p>配置好这一个之后，certbot就具备了自动完成DNS验证的能力，我们就不需要手动在DNS上增加TXT条目了，为之后的自动更新做准备。</p><p>然后获取泛域名证书</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">certbot certonly  \</span><br><span class="line">--dns-cloudflare  \</span><br><span class="line">--dns-cloudflare-credentials /etc/certbot/certbot-dns-cloudflare/dns.ini   \ # 刚刚设置的配置文件路径</span><br><span class="line">--dns-cloudflare-propagation-seconds 60 \ # 等待60秒，等DNS记录更新上来</span><br><span class="line">-d *.sysu.wangyf.top # 泛域名</span><br></pre></td></tr></table></figure><p>此时泛域名证书会存放到 /etc/letsencrypt 下。</p><p>测试一下能否自动更新？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">certbot renew --dry-run</span><br></pre></td></tr></table></figure><p>如果这个操作没有问题的话，那就可以配置crontab自动更新了。<br>pacman -S cronie，安装crontab，使用crontab -e 命令，填入以下信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 3 1 * * /usr/bin/certbot renew</span><br></pre></td></tr></table></figure><p>这样子泛域名证书还有证书的自动更新就完成了，证书会在每个月1号的凌晨3点更新。</p><h2 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h2><p>最后就是配好nginx的代理还有ssl证书。以下是我的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    #listen       80;</span><br><span class="line">    server_name  pan.sysu.wangyf.top;</span><br><span class="line">    location / &#123;</span><br><span class="line">                  proxy_pass http://wyf-nextcloud:80/;</span><br><span class="line">                  proxy_http_version 1.1;</span><br><span class="line">                  proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">                  proxy_set_header Connection &apos;upgrade&apos;;</span><br><span class="line">                  proxy_set_header Host $host;</span><br><span class="line">                  proxy_cache_bypass $http_upgrade;</span><br><span class="line">        &#125;</span><br><span class="line">    listen 443 ssl; # managed by Certbot</span><br><span class="line">    # 泛域名证书</span><br><span class="line">    ssl_certificate /etc/letsencrypt/live/sysu.wangyf.top/fullchain.pem; # managed by Certbot</span><br><span class="line">    ssl_certificate_key /etc/letsencrypt/live/sysu.wangyf.top/privkey.pem; # managed by Certbot</span><br><span class="line">    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot</span><br><span class="line">    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot</span><br><span class="line">    # HSTS</span><br><span class="line">    add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains&quot; always;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">     if ($host = pan.sysu.wangyf.top) &#123;</span><br><span class="line">          return 301 https://$host$request_uri;</span><br><span class="line">     &#125; # managed by Certbot</span><br><span class="line">     listen       80;</span><br><span class="line">     server_name pan.sysu.wangyf.top;</span><br><span class="line">     return 404;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后重启一下nginx</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart wyf-nginx</span><br></pre></td></tr></table></figure><p>一切大功告成！</p><h2 id="可能存在的问题"><a href="#可能存在的问题" class="headerlink" title="可能存在的问题"></a>可能存在的问题</h2><p>nextcloud可能会不认识我们自己设置的域名，这个时候需要进入容器中修改 /var/www/html/config/config.php 文件。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;docker-配置nextcloud-并配置泛域名证书&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="try" scheme="https://wwyf.github.io/categories/try/"/>
    
    
      <category term="try" scheme="https://wwyf.github.io/tags/try/"/>
    
  </entry>
  
  <entry>
    <title>Travis CI 初入门</title>
    <link href="https://wwyf.github.io/2019/05/13/2019-05-2019-05-13-Travis-CI/"/>
    <id>https://wwyf.github.io/2019/05/13/2019-05-2019-05-13-Travis-CI/</id>
    <published>2019-05-13T13:41:44.000Z</published>
    <updated>2019-05-14T01:32:45.212Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Travis-CI-初入门"><a href="#Travis-CI-初入门" class="headerlink" title="Travis CI 初入门"></a>Travis CI 初入门</h1><p>准备做软工项目了！我和队友准备实现一个前后端分离的系统，今儿了解到Travis CI这个好东西，便马上来试用了！</p><p>我使用Travis CI的目的主要是：</p><ol><li>当我push代码后，Travis CI可以帮我自动配置环境，并运行脚本进行测试</li><li>还可以通过一些方法，在测试通过后帮我部署到真实服务器上</li></ol><p>也就是说，之后的开发中，我只需要一个push指令，就可以将测试，部署等东东全部自动完成！正所谓持续集成便是如此。</p><p>事不宜迟，马上来用。</p><h2 id="一个最简单的-例子"><a href="#一个最简单的-例子" class="headerlink" title="一个最简单的 例子"></a>一个最简单的 例子</h2><p>在我即将开始的项目中，我打算使用flask写一个后端，后端还没写，先把持续集成安排一下？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">language: python</span><br><span class="line">install:</span><br><span class="line">  - pip3 install flask</span><br><span class="line">script: </span><br><span class="line">  - python tests/test.py</span><br></pre></td></tr></table></figure><p>install：安装步骤，准备运行所需环境。</p><p>script：运行自己的测试脚本完成单元测试。</p><p>在 Travis CI 上看到这个build过程还是很开心的！</p><p><img src="https://i.imgur.com/VOW4zTe.png" alt=""></p><h2 id="自动部署"><a href="#自动部署" class="headerlink" title="自动部署"></a>自动部署</h2><p>TODO：</p><p>参考链接</p><p><a href="https://zhuanlan.zhihu.com/p/25066056" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25066056</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;Travis-CI-初入门&quot;&gt;&lt;a href=&quot;#Travis-C
      
    
    </summary>
    
      <category term="try" scheme="https://wwyf.github.io/categories/try/"/>
    
    
      <category term="try" scheme="https://wwyf.github.io/tags/try/"/>
    
  </entry>
  
  <entry>
    <title>Pinpoint-Problem Determination in Large, Dynamic Internet Services</title>
    <link href="https://wwyf.github.io/2019/02/19/2019-02-2019-02-19-Pinpoint/"/>
    <id>https://wwyf.github.io/2019/02/19/2019-02-2019-02-19-Pinpoint/</id>
    <published>2019-02-19T02:36:44.000Z</published>
    <updated>2019-02-19T03:22:52.152Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Pinpoint-Problem-Determination-in-Large-Dynamic-Internet-Services"><a href="#Pinpoint-Problem-Determination-in-Large-Dynamic-Internet-Services" class="headerlink" title="Pinpoint: Problem Determination in Large, Dynamic Internet Services"></a>Pinpoint: Problem Determination in Large, Dynamic Internet Services</h1><p>年份：2002</p><p>会议/期刊：IPDS</p><h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><ol><li><p>背景：在大规模，分布式且动态变化的系统中，依靠<strong>静态依赖关系</strong>来进行问题定位的方法已经遇到了瓶颈：</p><ol><li>is difficulty of generating and maintaining an accurate model of a constantly evolving Internet service.</li><li>only model a logical system, do not distinguish among replicated components.</li></ol></li><li><p>主要贡献</p><ol><li><p>提出了一种可行的，可动态分析系统中问题的方法</p></li><li><p>提出了一个可以分离错误检测和问题分析的框架</p></li><li><blockquote><p>1) a dynamic analysis approach to problem determination that works well and<br>2) a framework that enables separation of fault detection<br>and problem determination from application-level components.</p></blockquote></li></ol></li><li><p>In this paper, we present a dynamic analysis methodology that automates problem determination in these environments by </p><p>1) coarse-grained(粗粒度) tagging of numerous real client requests as they travel through the system</p><p>2) using <strong>data mining techniques</strong> to correlate the believed failures and successes of these requests to determine which components are most likely to be at fault.</p></li></ol><h2 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h2><p>Pinpoing的框架主要包含三个部件：</p><p><img src="https://i.imgur.com/ckM3ZEW.png" alt=""></p><ol><li>Client Request Traces<ol><li>在通讯层以及中间件中处理</li><li>目的：追踪某请求用到的所有部件</li></ol></li><li>Failure Detection<ol><li>Internal failure detection<ol><li>might be masked before becoming visible to users</li><li>assertions and exceptions</li></ol></li><li>External failure detection<ol><li>detect faults that will be bisible to the user</li></ol></li><li>detection subsystem logs this along with the ID of the client request</li></ol></li><li>Data Clustering Analysis<ol><li><img src="https://i.imgur.com/R0d5RI9.png" alt=""></li></ol></li></ol><h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><p>在论文3.3节中，作者提到了该框架中的聚类算法。</p><blockquote><p>In our implementation of Pinpoint, we use a hierarchical clustering method, an unweighted pair-group method using arithmetic averages (UPGMA), and calculate distances between components using the Jaccard similarity coefficient.</p></blockquote><p>该算法可以在维基百科<a href="https://en.wikipedia.org/wiki/UPGMA" target="_blank" rel="noopener">wiki</a>上找到相应介绍。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>实验结果的话主要分为两部分</p><ol><li><p>问题定位的准确性</p><ol><li>比另外两种方法准确（Simple Dependency Analysis， Detection Analysis）</li></ol></li><li><p>该系统对性能的影响</p><ol><li><blockquote><p>We measured a cold server with a warm file cache for three 5-minute runs, and found that the online overhead of Pinpoint to be 8.4%.</p></blockquote></li></ol></li></ol><h2 id="我的想法"><a href="#我的想法" class="headerlink" title="我的想法"></a>我的想法</h2><p>这一种tracing的方法在现在看起来，tracing的信息少之又少，在追踪的过程中，系统只需要获取两种信息：该请求调用过的所有部件，以及该请求成功/失败与否。</p><p>这种方法虽然简单，不过在一些特定的系统中我想是行之有效的，并且这种方法也的确比以前的方法有了很大的进步。</p><p>这种通过聚类找到问题根因的思想，了解一下吧。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>Pinpoint: Problem Determination in Large, Dynamic Internet Services</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;Pinpoint-Problem-Determination-in
      
    
    </summary>
    
      <category term="Paper" scheme="https://wwyf.github.io/categories/Paper/"/>
    
    
      <category term="Paper" scheme="https://wwyf.github.io/tags/Paper/"/>
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习4-OpenMP</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A04-OpenMP/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习4-OpenMP/</id>
    <published>2019-01-15T13:44:24.000Z</published>
    <updated>2019-01-15T13:48:00.257Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习4-OpenMP"><a href="#HPC复习4-OpenMP" class="headerlink" title="HPC复习4-OpenMP"></a>HPC复习4-OpenMP</h1><ol><li>OpenMP简介</li><li>OpenMP编译制导</li><li>OpenMP库函数</li><li>OpenMP环境变量</li><li>OpenMP示例–性能改善</li></ol><a id="more"></a><h2 id="OpenMP简介"><a href="#OpenMP简介" class="headerlink" title="OpenMP简介"></a>OpenMP简介</h2><ol><li>是一种基于线程的并行编程模型<ol><li>编译制导</li><li>运行库函数</li><li>环境变量</li></ol></li><li>采用<strong>Fork-Join</strong>并行执行方式<ol><li>OpenMP程序开始于一个单独的主线程（Master Thread），然后主线程一直串行执行，直到遇见第一个并行域(Parallel Region)，然后开始并行执行并行域。并行域代码执行完后再回到主线程，直到遇到下一个并行域，以此类推，直至程序运行结束。</li><li><img src="https://lh3.googleusercontent.com/-2y771w5Yl0Y/XD3UJrbnJDI/AAAAAAAAN1A/sj3jk-OsMMYb-x7sjX6OEqeoPdSZ0EmaACHMYCw/s0/Acrobat_2019-01-15_20-37-57.png" alt=""></li></ol></li></ol><h2 id="OpenMP-编译制导"><a href="#OpenMP-编译制导" class="headerlink" title="OpenMP 编译制导"></a>OpenMP 编译制导</h2><p>编译制导语句格式：<strong>制导标识符 制导名称 [Cluase,…]</strong></p><h3 id="并行域制导"><a href="#并行域制导" class="headerlink" title="并行域制导"></a>并行域制导</h3><blockquote><p>一个并行域就是一个能被多个线程并行执行的程序段</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> ompparallel [clauses]</span></span><br><span class="line">&#123;</span><br><span class="line">BLOCK</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>在并行域结尾有一个隐式同步（barrier）。</li><li>子句（clause）用来说明并行域的附加信息。</li><li>在C/C++中，子句间用空格分开。（Fortran语言中，子句间用逗号或空格分隔）</li></ol><p><img src="https://lh3.googleusercontent.com/-CvLoMA9lHL0/XD3h6muXSmI/AAAAAAAAN1M/mu9RelbjSocH1CzKVCmrsuxTsTSGf9mpACHMYCw/s0/Acrobat_2019-01-15_21-36-40.png" alt=""></p><h3 id="数据访问相关子句"><a href="#数据访问相关子句" class="headerlink" title="数据访问相关子句"></a>数据访问相关子句</h3><p><img src="https://lh3.googleusercontent.com/-0QjMf3-Fjjk/XD3iFQgDyrI/AAAAAAAAN1Q/5yFImqC7IDkjChF_xy5GmiZ227IFTUtcwCHMYCw/s0/Acrobat_2019-01-15_21-37-20.png" alt=""></p><blockquote><p>如何决定哪些变量是共享哪些是私有？</p><ol><li>通常循环变量、临时变量、写变量一般是私有的；</li><li>数组变量、仅用于读的变量通常是共享的。默认时为公有</li></ol></blockquote><h3 id="并行域结构：reduction子句"><a href="#并行域结构：reduction子句" class="headerlink" title="并行域结构：reduction子句"></a>并行域结构：reduction子句</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">inti,myid,n; <span class="keyword">double</span> a[][];</span><br><span class="line"><span class="keyword">double</span> sum;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel reduction(+: sum), private(i, myid)</span></span><br><span class="line">&#123;</span><br><span class="line">    myid=omp_get_thread_num();</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;n;i++)</span><br><span class="line">    sum=sum+a[i][myid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>特别说明：要理解reduction操作</p><ol><li>在reduction子句中，编译器为每个线程创建变量sum的私有副本。当循环完成后，将这些值加在一起并把结果放到原始的变量sum中;</li><li>Reduction中的op操作必须满足算术结合律和交换律。</li></ol></blockquote><p>剩下的，详细可见总结或文档。</p><h3 id="任务划分并行制导"><a href="#任务划分并行制导" class="headerlink" title="任务划分并行制导"></a>任务划分并行制导</h3><ol><li>并行for循环制导<ol><li>schedule 调度子句<ol><li>static</li><li>dynamic</li><li>guided</li><li>runtime</li></ol></li></ol></li><li>并行sections制导</li><li>single和master制导</li><li>其他制导</li></ol><h3 id="同步制导"><a href="#同步制导" class="headerlink" title="同步制导"></a>同步制导</h3><ol><li>barrier制导</li><li>nowait制导</li><li>critical制导</li><li>atomic制导</li><li>lock例程</li><li>flush制导：高速缓存会刷新恢复到内存，影响性能</li></ol><h2 id="OpenMP库函数"><a href="#OpenMP库函数" class="headerlink" title="OpenMP库函数"></a>OpenMP库函数</h2><table><thead><tr><th>函数名</th><th>作用</th></tr></thead><tbody><tr><td><code>int omp_get_num_threads()</code></td><td>得到线程队列中的线程数</td></tr><tr><td><code>int omp_get_thread_num()</code></td><td>得到执行线程的线程号：</td></tr><tr><td><code>void omp_set_num_threads(4)</code></td><td>设定执行线程的数量为4</td></tr><tr><td><code>double omp_get_wtime(void)</code></td><td>返回挂钟“自过去任意时刻以来”经过的时间（秒）</td></tr><tr><td><code>double omp_get_wtick(void);</code></td><td>返回连续时钟滴答声之间的秒数。</td></tr></tbody></table><h2 id="OpenMP环境变量"><a href="#OpenMP环境变量" class="headerlink" title="OpenMP环境变量"></a>OpenMP环境变量</h2><table><thead><tr><th>环境变量名称</th><th>作用</th></tr></thead><tbody><tr><td>OMP_NUM_THREADS</td><td>设定最大线程数</td></tr><tr><td>OMP_SCHEDULE</td><td>调度方式 “DYNAMIC,4”</td></tr><tr><td>OMP_DYNAMIC</td><td>是否动态设定并行域执行的线程数</td></tr><tr><td>OMP_NESTED</td><td>确定是否可以并行嵌套</td></tr></tbody></table><h2 id="OpenMP示例–性能改善"><a href="#OpenMP示例–性能改善" class="headerlink" title="OpenMP示例–性能改善"></a>OpenMP示例–性能改善</h2><h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><p>如何处理循环中存在的依赖关系？例子如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)</span><br><span class="line"><span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">a[i][j]=<span class="number">2.0</span>*a[i<span class="number">-1</span>][j];</span><br></pre></td></tr></table></figure><p>可以变为(交换循环位置)；</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)</span><br><span class="line">a[i][j]=<span class="number">2.0</span>*a[i<span class="number">-1</span>][j];</span><br></pre></td></tr></table></figure><h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><p>下面这一个循环是存在循环依赖的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">2</span>;i&lt;<span class="number">20</span>;i++)</span><br><span class="line">a[i]=a[i<span class="number">-2</span>]+<span class="number">4</span> ;</span><br></pre></td></tr></table></figure><p>不过我们可以将这一个循环分解为多个循环，这多个循环间不存在依赖关系</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">2</span>;i&lt;<span class="number">20</span>;i=i+<span class="number">2</span>)</span><br><span class="line">a[i]=a[i<span class="number">-2</span>]+<span class="number">4</span> ;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">3</span>;i&lt;<span class="number">20</span>;i=i+<span class="number">2</span>)</span><br><span class="line">a[i]=a[i<span class="number">-2</span>]+<span class="number">4</span> ;</span><br></pre></td></tr></table></figure><h2 id="制导指令总结"><a href="#制导指令总结" class="headerlink" title="制导指令总结"></a>制导指令总结</h2><h3 id="并行域指令"><a href="#并行域指令" class="headerlink" title="并行域指令"></a>并行域指令</h3><p><img src="https://lh3.googleusercontent.com/-Qq6sgKD2ji0/XD3i5oH9VvI/AAAAAAAAN1c/Ry8Ay8PLx0ICJfQERdUhafUk00ta3cIZwCHMYCw/s0/Acrobat_2019-01-15_21-40-53.png" alt=""></p><h3 id="工作共享指令"><a href="#工作共享指令" class="headerlink" title="工作共享指令"></a>工作共享指令</h3><p><img src="https://lh3.googleusercontent.com/-JhjPfP392W0/XD3i8nOBkoI/AAAAAAAAN1g/b0rFfhaRdXE7qo4bSY36EMmF0PoL8DCDQCHMYCw/s0/Acrobat_2019-01-15_21-41-06.png" alt=""></p><h3 id="并行域与工作共享指令的结合"><a href="#并行域与工作共享指令的结合" class="headerlink" title="并行域与工作共享指令的结合"></a>并行域与工作共享指令的结合</h3><p><img src="https://lh3.googleusercontent.com/-y7KBSiWaDl4/XD3i_TPH8OI/AAAAAAAAN1k/Q3pjVu3MC-YArhkz1VxhLnJFlenauZjhgCHMYCw/s0/Acrobat_2019-01-15_21-41-17.png" alt=""></p><h3 id="同步指令"><a href="#同步指令" class="headerlink" title="同步指令"></a>同步指令</h3><p><img src="https://lh3.googleusercontent.com/-y7KBSiWaDl4/XD3i_TPH8OI/AAAAAAAAN1k/Q3pjVu3MC-YArhkz1VxhLnJFlenauZjhgCHMYCw/s0/Acrobat_2019-01-15_21-41-17.png" alt=""></p><h3 id="数据环境指令"><a href="#数据环境指令" class="headerlink" title="数据环境指令"></a>数据环境指令</h3><p><img src="https://lh3.googleusercontent.com/-Ccf5agIIOL8/XD3jFewuXmI/AAAAAAAAN1s/825ZKEyguzkYXD8gA7sOIZjctwbZf9CdwCHMYCw/s0/Acrobat_2019-01-15_21-41-39.png" alt=""></p><h2 id="OpenMP子句总结"><a href="#OpenMP子句总结" class="headerlink" title="OpenMP子句总结"></a>OpenMP子句总结</h2><h3 id="数据作用域属性子句"><a href="#数据作用域属性子句" class="headerlink" title="数据作用域属性子句"></a>数据作用域属性子句</h3><p><img src="https://lh3.googleusercontent.com/-JQovoZ2MIzk/XD3jWTZcajI/AAAAAAAAN2A/jrZd8dFECb4lNtCWV3poWFlnx2709pZOACHMYCw/s0/Acrobat_2019-01-15_21-42-48.png" alt=""></p><p><img src="https://lh3.googleusercontent.com/-RY1UDZes6Q4/XD3jZY1-7PI/AAAAAAAAN2E/1-F2Y4dXSngZLhY54tNDClmQt-uVcFF-ACHMYCw/s0/Acrobat_2019-01-15_21-43-01.png" alt=""></p><h3 id="其他子句"><a href="#其他子句" class="headerlink" title="其他子句"></a>其他子句</h3><p><img src="https://lh3.googleusercontent.com/-sfXhe5-b9qg/XD3jcESZ9CI/AAAAAAAAN2I/tN-9ENQk29AezWKTJLkPA9IcBcboBEHHQCHMYCw/s0/Acrobat_2019-01-15_21-43-12.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习4-OpenMP&quot;&gt;&lt;a href=&quot;#HPC复习4-OpenMP&quot; class=&quot;headerlink&quot; title=&quot;HPC复习4-OpenMP&quot;&gt;&lt;/a&gt;HPC复习4-OpenMP&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;OpenMP简介&lt;/li&gt;
&lt;li&gt;OpenMP编译制导&lt;/li&gt;
&lt;li&gt;OpenMP库函数&lt;/li&gt;
&lt;li&gt;OpenMP环境变量&lt;/li&gt;
&lt;li&gt;OpenMP示例–性能改善&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.4-归约操作优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-4-%E5%BD%92%E7%BA%A6%E6%93%8D%E4%BD%9C%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-4-归约操作优化/</id>
    <published>2019-01-15T12:02:10.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-4-并行归约优化"><a href="#HPC复习7-4-并行归约优化" class="headerlink" title="HPC复习7.4-并行归约优化"></a>HPC复习7.4-并行归约优化</h1><p>这里会有归约操作的7种优化版本。</p><p><img src="https://lh3.googleusercontent.com/-8rV-AMsd_Rw/XD2sO0WhFPI/AAAAAAAANzs/dR5OQxmXKt4l3HpoRmnq4Oh9VAf-hN7twCHMYCw/s0/Acrobat_2019-01-15_17-47-39.png" alt=""></p><p>7种方法的加速情况如下：</p><p><img src="https://lh3.googleusercontent.com/-ZARtsyKmBik/XD2s_jh4RUI/AAAAAAAANz0/ZVLxWOhn41MEkuP9fTrLlLwKSkEGc22awCHMYCw/s0/Acrobat_2019-01-15_17-50-54.png" alt=""></p><a id="more"></a><h2 id="Interleaved-Addressing-with-divergent-branching"><a href="#Interleaved-Addressing-with-divergent-branching" class="headerlink" title="Interleaved Addressing with divergent branching"></a>Interleaved Addressing with divergent branching</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reduce0</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata)</span> </span>&#123;</span><br><span class="line"><span class="keyword">extern</span> __shared__ <span class="keyword">int</span> sdata[];</span><br><span class="line">    <span class="comment">// each thread loads one element from global to shared mem</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">    sdata[tid] = g_idata[i]; <span class="comment">// 合并访存，读取一个block的数据到share memory中</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="comment">// do reduction in shared mem</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> s=<span class="number">1</span>; s &lt; blockDim.x; s *= <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid % (<span class="number">2</span>*s) == <span class="number">0</span>) &#123;</span><br><span class="line">            sdata[tid] += sdata[tid + s];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// write result for this block to global mem</span></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) g_odata[blockIdx.x] = sdata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://lh3.googleusercontent.com/-hfUJjKZ4Ksw/XD2vIHV9BzI/AAAAAAAAN0A/gLS3oE0NzqEKGI1O8hjvAI_0jFSTe3wKQCHMYCw/s0/Acrobat_2019-01-15_17-59-59.png" alt=""></p><h3 id="存在的问题："><a href="#存在的问题：" class="headerlink" title="存在的问题："></a>存在的问题：</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> s=<span class="number">1</span>; s &lt; blockDim.x; s *= <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (tid % (<span class="number">2</span>*s) == <span class="number">0</span>) &#123; <span class="comment">// 以warp的运行想一想，就会发现，这个是发散的</span></span><br><span class="line">        sdata[tid] += sdata[tid + s];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Interleaved-address-with-bank-conflict"><a href="#Interleaved-address-with-bank-conflict" class="headerlink" title="Interleaved address with bank conflict"></a>Interleaved address with bank conflict</h2><p>对上面的问题进行优化，将对应的for循环改成下面的循环：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">unsigned</span> <span class="keyword">int</span> s=<span class="number">1</span>; s &lt; blockDim.x; s *= <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> index = <span class="number">2</span> * s * tid;</span><br><span class="line">    <span class="keyword">if</span> (index &lt; blockDim.x) &#123;</span><br><span class="line">    sdata[index] += sdata[index + s];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看了老半天终于看懂了</p><p>第一次循环：</p><p>indexs:0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32，取其中的</p><p>0,2,4,6,8,10,12,14，也就是前8个线程去计算</p><p>第二次循环</p><p>indexs:0,4,8,12,16,….，取前四个线程去计算</p><p><img src="https://lh3.googleusercontent.com/-mB5VGBUtzb4/XD2w5t6nmEI/AAAAAAAAN0M/dzqs-ASHP2syD1k7QFzuprgHYpv0fHjwACHMYCw/s0/Acrobat_2019-01-15_18-07-34.png" alt=""></p><h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><p>数组可能是很大的，考虑到有16个bank，这里在归约的时候，都是以2的倍数在增加，及其容易发生bank冲突。</p><p>如，在第二次循环中，会去读取这些index对应的数据</p><p>0,4,8,12,16,20,24,28,32，。。。就会发生bank冲突了。</p><h2 id="Sequential-Addressing"><a href="#Sequential-Addressing" class="headerlink" title="Sequential Addressing"></a>Sequential Addressing</h2><p>这一个优化就好多啦,不会发生bank冲突，因为一定是顺序写shared memory，看一看示意图，很容易懂！</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">unsigned</span> <span class="keyword">int</span> s=blockDim.x/<span class="number">2</span>; s&gt;<span class="number">0</span>; s&gt;&gt;=<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; s) &#123;</span><br><span class="line">        sdata[tid] += sdata[tid + s];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://lh3.googleusercontent.com/-fIBj8uEKW8I/XD2yyRsUFcI/AAAAAAAAN0c/xi3CeNJWtXs9Uvgg14Yrsxhx228gx3LcQCHMYCw/s0/Acrobat_2019-01-15_18-15-38.png" alt=""></p><h2 id="First-Add-During-Load"><a href="#First-Add-During-Load" class="headerlink" title="First Add During Load"></a>First Add During Load</h2><p>关键：在装入shared memory时做第一次加法</p><p>从代码中可以看出思路：在读取数组中的值时，原本是以一个blockDim.x为单位读取，每个block读取与blockDim.x相当的元素，放到shared memory中，现在每个block会读取两个blockDim.x大小的数组，然后在写进shared memory的时候就做一次加法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// perform first level of reduction,</span></span><br><span class="line"><span class="comment">// reading from global memory, writing to shared memory</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*(blockDim.x*<span class="number">2</span>) + threadIdx.x;</span><br><span class="line">sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure><h3 id="存在的问题：-1"><a href="#存在的问题：-1" class="headerlink" title="存在的问题："></a>存在的问题：</h3><p>可能在指令的吞吐量上，有瓶颈：</p><p>尝试循环展开</p><h2 id="Unrolling-the-Last-Warp"><a href="#Unrolling-the-Last-Warp" class="headerlink" title="Unrolling the Last Warp"></a>Unrolling the Last Warp</h2><p>这里主要尝试这样的做法：</p><ol><li>当归约到只剩下32个线程需要计算的时候（也就是说只剩下一个warp了）</li><li>显式的将剩下的32个线程所需要做的事情通过循环展开的方式来完成</li></ol><p>优化主要体现在两点：</p><ol><li>节省了所有的warp的额外开销<ol><li>想想其他的warp怎么会有开销呢？当只剩下一个warp需要进行实质的工作的时候，其他warp仍然在执行循环。</li><li>这个额外开销指的是维护循环变量，检查循环条件等</li></ol></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">unsigned</span> <span class="keyword">int</span> s=blockDim.x/<span class="number">2</span>; s&gt;<span class="number">32</span>; s&gt;&gt;=<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; s)</span><br><span class="line">        sdata[tid] += sdata[tid + s];</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">32</span>)</span><br><span class="line">&#123;</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">32</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">16</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">8</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">4</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">2</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="存在的问题-1"><a href="#存在的问题-1" class="headerlink" title="存在的问题"></a>存在的问题</h3><p>这里仅仅展开了最后的一个warp，能否完全展开呢？</p><h2 id="Completely-Unrolled"><a href="#Completely-Unrolled" class="headerlink" title="Completely Unrolled"></a>Completely Unrolled</h2><p>由于编译期就可以知道迭代的<code>blockDim.x</code>，因此可以通过模板的方式生成循环展开的相关代码</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (blockSize &gt;= <span class="number">512</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">256</span>) &#123; sdata[tid] += sdata[tid + <span class="number">256</span>]; &#125; __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (blockSize &gt;= <span class="number">256</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">128</span>) &#123; sdata[tid] += sdata[tid + <span class="number">128</span>]; &#125; __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (blockSize &gt;= <span class="number">128</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">64</span>) &#123; sdata[tid] += sdata[tid + <span class="number">64</span>]; &#125; __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">32</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">64</span>) sdata[tid] += sdata[tid + <span class="number">32</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>) sdata[tid] += sdata[tid + <span class="number">16</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>) sdata[tid] += sdata[tid + <span class="number">8</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>) sdata[tid] += sdata[tid + <span class="number">4</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>) sdata[tid] += sdata[tid + <span class="number">2</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>) sdata[tid] += sdata[tid + <span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的blockSize是个模板参数</p><h2 id="Multiple-Adds-Thread"><a href="#Multiple-Adds-Thread" class="headerlink" title="Multiple Adds/Thread"></a>Multiple Adds/Thread</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>combine sequential and parallel reduction</p><p>原理有点不懂。</p><p>Algorithm Cascading（算法级联）</p><p>它具体的做法是这样子的（我猜）：</p><ol><li>申请的线程可以少一些，推荐申请$O(N/logN)$个线程</li><li>在算法开始的时候，先使用串行求和，（也就是下面那一串代码），这样子就可以将问题规模缩小到与线程数的情况</li><li>后面都一样</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*(blockSize*<span class="number">2</span>) + threadIdx.x;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> gridSize = blockSize*<span class="number">2</span>*gridDim.x;</span><br><span class="line">sdata[tid] = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; n) &#123;</span><br><span class="line">    sdata[tid] += g_idata[i] + g_idata[i+blockSize];</span><br><span class="line">    i += gridSize;</span><br><span class="line">&#125;</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>前面的优化都其实特别有意思，特别是最后一个</p><p>最后一个优化应该说在理论层面的推导会稍微多一点，所以就不容易发现。</p><p>而正因为此吧，我觉得我需要弄清楚什么是“算法级联”，如何计算并行算法的复杂度。</p><p>如何推导出来怎样的“算法级联”能够给程序加速。</p><p>最后优化的程序如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">unsigned</span> <span class="keyword">int</span> blockSize&gt;</span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reduce6</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata, <span class="keyword">unsigned</span> <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">int</span> sdata[];</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*(blockSize*<span class="number">2</span>) + tid;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> gridSize = blockSize*<span class="number">2</span>*gridDim.x;</span><br><span class="line">    sdata[tid] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">do</span> &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize; &#125; <span class="keyword">while</span> (i &lt; n);</span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">512</span>) &#123; </span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">256</span>) &#123; sdata[tid] += sdata[tid + <span class="number">256</span>]; &#125; __syncthreads(); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">256</span>) &#123; </span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">128</span>) &#123; sdata[tid] += sdata[tid + <span class="number">128</span>]; &#125; __syncthreads(); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">128</span>) &#123; </span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">64</span>) &#123; sdata[tid] += sdata[tid + <span class="number">64</span>]; &#125; __syncthreads(); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; <span class="number">32</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">64</span>) sdata[tid] += sdata[tid + <span class="number">32</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>) sdata[tid] += sdata[tid + <span class="number">16</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>) sdata[tid] += sdata[tid + <span class="number">8</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>) sdata[tid] += sdata[tid + <span class="number">4</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>) sdata[tid] += sdata[tid + <span class="number">2</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>) sdata[tid] += sdata[tid + <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) g_odata[blockIdx.x] = sdata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>优化的结果可见：</p><p><img src="https://lh3.googleusercontent.com/-bnSz_ewThXc/XD3KsyUzD9I/AAAAAAAAN0w/cTjEcJ9zFb4k_SKLLmMwUIPyAh1TANfDgCHMYCw/s0/Acrobat_2019-01-15_19-57-36.png" alt=""></p><h2 id="相关博客"><a href="#相关博客" class="headerlink" title="相关博客"></a>相关博客</h2><ol><li><a href="http://wattlebird.github.io/2013/07/20/%E5%85%B3%E4%BA%8E-CUDA-%E4%B8%AD-reduction-%E8%BF%90%E7%AE%97%E7%9A%84%E4%BC%98%E5%8C%96/" target="_blank" rel="noopener">关于 CUDA 中 reduction 运算的优化</a></li><li><a href="https://en.wikipedia.org/wiki/Analysis_of_parallel_algorithms" target="_blank" rel="noopener">Brent’s theorem</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习7-4-并行归约优化&quot;&gt;&lt;a href=&quot;#HPC复习7-4-并行归约优化&quot; class=&quot;headerlink&quot; title=&quot;HPC复习7.4-并行归约优化&quot;&gt;&lt;/a&gt;HPC复习7.4-并行归约优化&lt;/h1&gt;&lt;p&gt;这里会有归约操作的7种优化版本。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-8rV-AMsd_Rw/XD2sO0WhFPI/AAAAAAAANzs/dR5OQxmXKt4l3HpoRmnq4Oh9VAf-hN7twCHMYCw/s0/Acrobat_2019-01-15_17-47-39.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;7种方法的加速情况如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-ZARtsyKmBik/XD2s_jh4RUI/AAAAAAAANz0/ZVLxWOhn41MEkuP9fTrLlLwKSkEGc22awCHMYCw/s0/Acrobat_2019-01-15_17-50-54.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.3-矩阵转置优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-3-%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-3-矩阵转置优化/</id>
    <published>2019-01-15T12:01:04.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-3-矩阵转置优化"><a href="#HPC复习7-3-矩阵转置优化" class="headerlink" title="HPC复习7.3-矩阵转置优化"></a>HPC复习7.3-矩阵转置优化</h1><p>这一个例子使用了以下几种技巧优化了矩阵转置：</p><ol><li><p>合并访问</p></li><li><p>避免共享内存的bank conflict</p><p><img src="https://lh3.googleusercontent.com/-KenoHV2uZck/XD2rzKYgx9I/AAAAAAAANzk/fSipGdSUZRgZEL5HDX_I0JVWik5ZZOfnwCHMYCw/s0/Acrobat_2019-01-15_17-45-49.png" alt=""></p></li></ol><a id="more"></a><h2 id="NAIVE"><a href="#NAIVE" class="headerlink" title="NAIVE"></a>NAIVE</h2><p>原始的矩阵转置可见</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">transpose_naive</span><span class="params">(<span class="keyword">float</span> *odata, <span class="keyword">float</span> *idata, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> xIndex = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> yIndex = blockDim.y * blockIdx.y + threadIdx.y;</span><br><span class="line">    <span class="comment">// //这里xIndex对应矩阵的列号，yIndex对应矩阵的行号</span></span><br><span class="line">    <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_in = xIndex + width * yIndex;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_out = yIndex + height * xIndex;</span><br><span class="line">        odata[index_out] = idata[index_in];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// //warp的排列：按threadIdx.x优先的次序</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="合并访存优化"><a href="#合并访存优化" class="headerlink" title="合并访存优化"></a>合并访存优化</h2><p>在原始的版本里，关键问题在于：</p><p><code>odata[index_out]</code>写的时候，无法合并访存：</p><p><img src="https://lh3.googleusercontent.com/-Ji3U1csOcqw/XD2mimdstWI/AAAAAAAANzA/2Ssh9Fc9_W4LrIp9VCK0KkxurBf5Q5IOgCHMYCw/s0/Acrobat_2019-01-15_17-23-22.png" alt=""></p><h3 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h3><ol><li>关键思想：使用合并访存技巧，读取一个块到shared memory中<ol><li><img src="https://lh3.googleusercontent.com/-e2xir8DtlLw/XD2rL1J5cgI/AAAAAAAANzM/IRKaftgFzF4yk62GpzPVBY_Yb7F_BEfoACHMYCw/s0/Acrobat_2019-01-15_17-43-10.png" alt=""></li></ol></li><li>在shared memory中，通过调换读取的索引，实现合并访存写回内存中<ol><li><img src="https://lh3.googleusercontent.com/-NPJTmLUBZio/XD2rWEhYLmI/AAAAAAAANzQ/je5sVWS75IIU8RL0rfLO0uHNNIzN_q02wCHMYCw/s0/Acrobat_2019-01-15_17-43-52.png" alt=""></li></ol></li></ol><h2 id="解决bank冲突"><a href="#解决bank冲突" class="headerlink" title="解决bank冲突"></a>解决bank冲突</h2><p>在上面读取shared memory中，会发生bank冲突导致读取串行化的问题。</p><p><img src="https://lh3.googleusercontent.com/-MM2-kYkf_qI/XD2rfV1YaBI/AAAAAAAANzY/8wKHxHvatQ8iPcHgw34uhA30DSJJoCXAgCHMYCw/s0/Acrobat_2019-01-15_17-44-29.png" alt=""></p><h2 id="代码实现："><a href="#代码实现：" class="headerlink" title="代码实现："></a>代码实现：</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">transpose</span><span class="params">(<span class="keyword">float</span> *odata, <span class="keyword">float</span> *idata, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __shared__ <span class="keyword">float</span> block[(BLOCK_DIM+<span class="number">1</span>)*BLOCK_DIM];</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> xBlock = __mul24(blockDim.x, blockIdx.x);</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> yBlock = __mul24(blockDim.y, blockIdx.y);</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> xIndex = xBlock + threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> yIndex = yBlock + threadIdx.y;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> index_out, index_transpose;</span><br><span class="line">    <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_in = __mul24(width, yIndex) + xIndex;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_block = __mul24(threadIdx.y, BLOCK_DIM+<span class="number">1</span>) + threadIdx.x;</span><br><span class="line">        block[index_block] = idata[index_in];</span><br><span class="line">        index_transpose = __mul24(threadIdx.x, BLOCK_DIM+<span class="number">1</span>) + threadIdx.y;</span><br><span class="line">        index_out = __mul24(height, xBlock + threadIdx.y) + yBlock + threadIdx.x;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">    odata[index_out] = block[index_transpose];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习7-3-矩阵转置优化&quot;&gt;&lt;a href=&quot;#HPC复习7-3-矩阵转置优化&quot; class=&quot;headerlink&quot; title=&quot;HPC复习7.3-矩阵转置优化&quot;&gt;&lt;/a&gt;HPC复习7.3-矩阵转置优化&lt;/h1&gt;&lt;p&gt;这一个例子使用了以下几种技巧优化了矩阵转置：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;合并访问&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;避免共享内存的bank conflict&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-KenoHV2uZck/XD2rzKYgx9I/AAAAAAAANzk/fSipGdSUZRgZEL5HDX_I0JVWik5ZZOfnwCHMYCw/s0/Acrobat_2019-01-15_17-45-49.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.2-cuda矩阵向量乘法优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-2-cuda%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-2-cuda矩阵向量乘法优化/</id>
    <published>2019-01-15T11:59:38.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-2-矩阵向量乘法优化"><a href="#HPC复习7-2-矩阵向量乘法优化" class="headerlink" title="HPC复习7.2-矩阵向量乘法优化"></a>HPC复习7.2-矩阵向量乘法优化</h1><blockquote><p>这里描述了从CPU到GPU的优化步骤，步步渐进，最终收敛于使用cuda的标准数学库。</p></blockquote><p>对于CUDA程序开发来说，优化往往是整个开发过程的核心，不同算法，不同存储器组织的程序性能往往差几十倍，本讲通过一个简单的例子来展示CUDA开发中一些重要的因素对性能的影响。</p><p>最后的优化结果可见</p><p><img src="https://lh3.googleusercontent.com/-eO3K2LRIf3Q/XD2cyoaQgII/AAAAAAAANyo/CwokcPDNYRkX3mZo8UqcINMGXtAgpmxOwCHMYCw/s0/Acrobat_2019-01-15_16-41-45.png" alt=""></p><h2 id="原始版本：串行C版本"><a href="#原始版本：串行C版本" class="headerlink" title="原始版本：串行C版本"></a>原始版本：串行C版本</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mxv</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> rowSize, <span class="keyword">const</span> <span class="keyword">int</span> columnSize,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">float</span> *matrix, <span class="keyword">const</span> <span class="keyword">float</span> *v, <span class="keyword">float</span> *r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)&#123;</span><br><span class="line">        <span class="keyword">float</span> re = <span class="number">0.0f</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columnSize; j++)&#123;</span><br><span class="line">        re += matrix[i*columnSize+j]*v[j];</span><br><span class="line">        &#125;</span><br><span class="line">        r[i] = re;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="CPU上的优化"><a href="#CPU上的优化" class="headerlink" title="CPU上的优化"></a>CPU上的优化</h2><p>在cpu上的优化我就不详细说了吧</p><ol><li><p>使用sse指令来计算</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mxvSSE</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> rowSize, <span class="keyword">const</span> <span class="keyword">int</span> columnSize, <span class="keyword">const</span> <span class="keyword">float</span> *matrix, <span class="keyword">const</span> <span class="keyword">float</span> *v, <span class="keyword">float</span> *r)</span></span>&#123;</span><br><span class="line">    __m128 *mv = (__m128*)v;</span><br><span class="line">    __m128 *mm = (__m128*)matrix;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)&#123;</span><br><span class="line">        __m128 re = _mm_set_ps(<span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columnSize/<span class="number">4</span>; j++)&#123;</span><br><span class="line">            re = _mm_add_ps(re, _mm_mul_ps(mm[i*columnSize/<span class="number">4</span>+j], mv[j]));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">float</span> __attribute((aligned(<span class="number">16</span>))) a[<span class="number">4</span>];</span><br><span class="line">        _mm_store_ps(a, re);</span><br><span class="line">        r[i] = a[<span class="number">0</span>] + a[<span class="number">1</span>] + a[<span class="number">2</span>] + a[<span class="number">3</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>使用sse+openmp来优化</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mxvSSEOpenmp</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> rowSize, <span class="keyword">const</span> <span class="keyword">int</span> columnSize, <span class="keyword">float</span> *matrix, <span class="keyword">float</span> *vec, <span class="keyword">float</span> *r)</span></span>&#123;</span><br><span class="line">    __m128 *mv = (__m128*)v;</span><br><span class="line">    __m128 *mm = (__m128*)matrix;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for num_threads(2)</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)&#123;</span><br><span class="line">        __m128 re = _mm_set_ps(<span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columnSize/<span class="number">4</span>; j++)&#123;</span><br><span class="line">        re = _mm_add_ps(re, _mm_mul_ps(mm[i*columnSize/<span class="number">4</span>+j], mv[j]));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">float</span> __attribute((aligned(<span class="number">16</span>))) a[<span class="number">4</span>];</span><br><span class="line">    _mm_store_ps(a, re);</span><br><span class="line">    r[i] = a[<span class="number">0</span>] + a[<span class="number">1</span>] + a[<span class="number">2</span>] + a[<span class="number">3</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol><h2 id="使用CUDA的注意事项"><a href="#使用CUDA的注意事项" class="headerlink" title="使用CUDA的注意事项"></a>使用CUDA的注意事项</h2><p>几个原则需要尽可能保证</p><ol><li>保持SM尽可能忙碌<ol><li>加大数据量或者减小线程块大小</li></ol></li><li>优化存储器的使用<ol><li>全局存储器合并访问</li><li>使用constant或shared memory</li></ol></li><li>对齐分配空间<ol><li>关于<a href="https://www.ibm.com/developerworks/library/pa-dalign/" target="_blank" rel="noopener">为什么</a></li></ol></li></ol><h2 id="CUDA-naive的优化"><a href="#CUDA-naive的优化" class="headerlink" title="CUDA naive的优化"></a>CUDA naive的优化</h2><p>关键在于：理解这里为什么要使用转置矩阵来达到合并访存的目的</p><h3 id="第一步-cuda-naive"><a href="#第一步-cuda-naive" class="headerlink" title="第一步-cuda naive"></a>第一步-cuda naive</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvNaive</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> columnPitch, <span class="keyword">const</span> <span class="keyword">float</span> *d_matrix, <span class="keyword">const</span> <span class="keyword">float</span> *d_vec, <span class="keyword">float</span> *d_r)</span></span>&#123;</span><br><span class="line">    uint id = blockDim.x*blockIdx.x+ threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(rowSize&lt;= id) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i= <span class="number">0</span>; i&lt; columnSize; i++)&#123;</span><br><span class="line">    temp += d_matrix[id*columnPitch+i]*d_vec[i]; </span><br><span class="line">        <span class="comment">// d_matrix[id*columnPitch+i]这里存在不能合并访存的问题</span></span><br><span class="line">    &#125;</span><br><span class="line">    d_r[id] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="第二步-发现合并访存的问题"><a href="#第二步-发现合并访存的问题" class="headerlink" title="第二步-发现合并访存的问题"></a>第二步-发现合并访存的问题</h3><p><img src="https://lh3.googleusercontent.com/-hTGicVs9O-g/XD2gvBT9DHI/AAAAAAAANy0/OecalPhUJ9Al47t8fZrVLgkejFgThupkQCHMYCw/s0/Acrobat_2019-01-15_16-58-36.png" alt=""></p><p>解决方法：先将矩阵转置，就可以达到合并访存的要求了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 转置后的for循环</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i= <span class="number">0</span>; i&lt; rowSize; i++)&#123;</span><br><span class="line">temp += d_matrix[i*columnPitch+id]*d_vec[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="访存优化"><a href="#访存优化" class="headerlink" title="访存优化"></a>访存优化</h2><p>关注到<code>d_vec</code>数组是不会改变的，因此考虑使用constant或者shared memory进行优化</p><h3 id="使用constant-memory优化"><a href="#使用constant-memory优化" class="headerlink" title="使用constant memory优化"></a>使用constant memory优化</h3><ol><li><p>将一整个向量都放进constant memory中，得到以下代码：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvNaiveTransposeConstant</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> columnPitch, <span class="keyword">const</span> <span class="keyword">float</span> *d_matrix, <span class="keyword">const</span> <span class="keyword">int</span> start, <span class="keyword">float</span> *d_r)</span></span>&#123;</span><br><span class="line">    uint id = blockDim.x*blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(columnSize &lt;= id) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">int</span> end = start+CONSTANTSIZE &gt; rowSize ? rowSize : start+CONSTANTSIZE;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = start; i &lt; end; i++)&#123;</span><br><span class="line">    temp += d_matrix[i*columnPitch+id]*c_v[i-start];</span><br><span class="line">    &#125;</span><br><span class="line">d_r[id] += temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>如果向量超过了constant memory的上限，那就</p><ol><li>分批，多次传输，启动内核。</li></ol></li></ol><h3 id="使用shared-memory优化"><a href="#使用shared-memory优化" class="headerlink" title="使用shared memory优化"></a>使用shared memory优化</h3><ol><li><p>关注到：可以在一个block内共享向量$v$，考虑使用shared memory</p></li><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvNaiveTransposeShared</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> columnPitch, <span class="keyword">const</span> <span class="keyword">float</span> *d_matrix, <span class="keyword">const</span> <span class="keyword">float</span> *d_v, <span class="keyword">const</span> <span class="keyword">int</span> sharedSize, <span class="keyword">float</span> *d_r)</span></span>&#123;</span><br><span class="line">    uint id = blockDim.x*blockIdx.x+ threadIdx.x;</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">float</span> s_v[];</span><br><span class="line">    <span class="comment">// 外层循环，每次加载一段大小为sharedsize的向量v进行计算</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> start = <span class="number">0</span>; start &lt; rowSize; start += sharedSize)&#123;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        <span class="meta">#<span class="meta-keyword">pragma</span> unroll 4</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i= threadIdx.x; i&lt; sharedSize&amp;&amp;i+start&lt;rowSize; i+= blockDim.x)&#123;</span><br><span class="line">        s_v[i] = d_v[start+i]; <span class="comment">// 关键在于这里加载shared memory</span></span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        <span class="keyword">if</span>(columnSize&lt;= id) <span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">int</span> end = start+sharedSize&gt; rowSize? rowSize: start+sharedSize;</span><br><span class="line">        <span class="meta">#<span class="meta-keyword">pragma</span> unroll 8</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = start; i &lt; end; i++)&#123;</span><br><span class="line">            <span class="comment">// 使用shared memory 访存得到极大提升</span></span><br><span class="line">        temp += d_matrix[i*columnPitch+id]*s_v[i-start];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(id &lt; columnSize)</span><br><span class="line">    d_r[id] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="block模式与warp模式"><a href="#block模式与warp模式" class="headerlink" title="block模式与warp模式"></a>block模式与warp模式</h2><p>问题：如果不转置矩阵如何计算？</p><h3 id="block模式"><a href="#block模式" class="headerlink" title="block模式"></a>block模式</h3><p>关键：一个block处理矩阵的一行和向量乘积，其中block中的每个线程处理该行中的一个与对应向量元素的乘积,然后归约。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvBlock</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> pitchItem, <span class="keyword">const</span> <span class="keyword">float</span>* __restrict__ d_matrix,constfloat* __restrict__ d_vec, <span class="keyword">float</span>* __restrict__ d_r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tid= threadIdx.x;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">float</span> s_r[];</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i= tid; i&lt; columnSize; i+= blockDim.x)&#123;</span><br><span class="line">    temp += d_matrix[blockIdx.x*pitchItem+i]*d_vec[i];</span><br><span class="line">    &#125;</span><br><span class="line">    s_r[tid] = temp; __syncthreads();</span><br><span class="line">    ……<span class="comment">//省略归约代码</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="warp模式"><a href="#warp模式" class="headerlink" title="warp模式"></a>warp模式</h3><p>具体的计算和block模式差不多,只是使用一个warp线程计算矩阵的一行与向量的乘积,在我的测试中发现,这个算法对于行数大于列数的矩阵效果很好,很多时候性能是block的两倍以上。</p><h2 id="使用cuBlas包"><a href="#使用cuBlas包" class="headerlink" title="使用cuBlas包"></a>使用cuBlas包</h2><p>成为调包侠：</p><p>函数: cublasSgemv——cuBlas包的矩阵向量乘法</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后的优化结果可见</p><p><img src="https://lh3.googleusercontent.com/-eO3K2LRIf3Q/XD2cyoaQgII/AAAAAAAANyo/CwokcPDNYRkX3mZo8UqcINMGXtAgpmxOwCHMYCw/s0/Acrobat_2019-01-15_16-41-45.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;HPC复习7-2-矩阵向量乘法优化&quot;&gt;&lt;a href=&quot;#HPC复
      
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.1-cuda矩阵乘法优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-1-cuda%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-1-cuda矩阵乘法优化/</id>
    <published>2019-01-15T11:58:43.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-1-矩阵乘法优化"><a href="#HPC复习7-1-矩阵乘法优化" class="headerlink" title="HPC复习7.1-矩阵乘法优化"></a>HPC复习7.1-矩阵乘法优化</h1><h2 id="naive实现"><a href="#naive实现" class="headerlink" title="naive实现"></a>naive实现</h2><p>具体思路就很简单了，仅使用一个块，然后块中每一个线程计算矩阵的一个元素。</p><p>算法图示可见<img src="https://lh3.googleusercontent.com/-hk3rnSa5zm4/XD2a5NgdiSI/AAAAAAAANyc/HDkg-4FY4icQgSXBtHLzhZ7XQ8PliUd3gCHMYCw/s0/Snipaste_2019-01-15_16-33-36.png" alt=""></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 矩阵乘法的内核函数——每个线程都要执行的代码</span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">MatrixMulKernel</span><span class="params">(<span class="keyword">float</span>* Md, <span class="keyword">float</span>* Nd, <span class="keyword">float</span>* Pd, intWidth)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 2维的线程ID号</span></span><br><span class="line">    inttx= threadIdx.x;</span><br><span class="line">    intty= threadIdx.y;</span><br><span class="line">    <span class="comment">// Pvalue用来保存被每个线程计算完成后的矩阵的元素</span></span><br><span class="line">    <span class="keyword">float</span> Pvalue= <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//每个线程计算一个元素</span></span><br><span class="line">    <span class="keyword">for</span> (intk = <span class="number">0</span>; k &lt; Width; ++k)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">float</span> Melement= Md[ty* Width + k];</span><br><span class="line">        <span class="keyword">float</span> Nelement= Nd[k * Width + tx];</span><br><span class="line">        Pvalue += Melement* Nelement;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将计算结果写入设备存储器中</span></span><br><span class="line">    Pd[ty* Width + tx] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>这样的实现是有问题的：</p><ol><li>计算的时间与访存时间比例相当，受存储器延迟的影响很大。</li><li>矩阵的大小收到线程块所能容纳的最大线程数的限制。</li></ol></blockquote><h2 id="处理任意大小的方形矩阵"><a href="#处理任意大小的方形矩阵" class="headerlink" title="处理任意大小的方形矩阵"></a>处理任意大小的方形矩阵</h2><p>解决了在上面的实现中，无法处理任意大小的方形矩阵的问题。</p><p>关键思想：</p><ol><li>将矩阵分块，每一个线程块block计算其中的一个子矩阵</li><li>如果矩阵块的数量大于最大的上限时，需要在内核附近设置一个循环（一个已经用过的技巧，我会的啦）</li></ol><blockquote><p>问题：每一个线程都要访问global memory获取矩阵的一整行和一整列元素</p><p>访存带宽成为了计算的瓶颈</p></blockquote><h2 id="分片矩阵乘法"><a href="#分片矩阵乘法" class="headerlink" title="分片矩阵乘法"></a>分片矩阵乘法</h2><p>使用高带宽的片上存储器”shared memory”缓解了访存瓶颈</p><p>关键思想：重用数据，原来的矩阵乘法实现中，每一个区域都有多个线程多次访问，如果数据可以重用，可以大大降低计算所需的带宽。</p><p>分片矩阵乘法-算法关键：</p><ol><li>代价估计：<code>浮点操作：全局存储器读出操作＝16: 1</code>，说明访存代价占比不高</li><li><img src="figure/1545275255554.png" alt="1545275255554"></li><li>算法细节<ol><li>逐个子矩阵块，依次计算，求和到结果矩阵上</li><li>进行子矩阵块的运算前，先将子矩阵块复制到<code>shared memory</code>上<ol><li>一个合并访存(访问global memory)的技巧：每一个线程读取一个值，然后使用同步原语保证同步</li></ol></li><li>每一个线程计算完子矩阵块的一个结果后，合并访存的技巧依然使用，写位于global memory的矩阵<ol><li>每一个线程仅写回自己计算的值，合并访存，然后使用同步原语</li></ol></li></ol></li></ol><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//每个线程块有TILE_WIDTH2个线程</span></span><br><span class="line"><span class="function">dim3 <span class="title">dimBlock</span><span class="params">(TILE_WIDTH, TILE_WIDTH)</span></span>;</span><br><span class="line"><span class="comment">//有(Width/TILE_WIDTH)2个线程块</span></span><br><span class="line"><span class="function">dim3 <span class="title">dimGrid</span><span class="params">(Width/TILE_WIDTH, Width/TILE_WIDTH)</span></span>;</span><br><span class="line"><span class="comment">//调用内核函数</span></span><br><span class="line">MatrixMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(Md, Nd, Pd，Width);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下是内核函数</span></span><br><span class="line"><span class="comment">// part 1 将数据从global memory加载到shared memory上</span></span><br><span class="line"><span class="comment">//获得线程块号</span></span><br><span class="line">intbx= blockIdx.x;</span><br><span class="line">intby = blockIdx.y;</span><br><span class="line"><span class="comment">//获得块内的线程号</span></span><br><span class="line">inttx= threadIdx.x;</span><br><span class="line">intty= threadIdx.y;</span><br><span class="line"><span class="comment">//Pvalue：线程计算完成后的子矩阵元素——自动变量</span></span><br><span class="line"><span class="keyword">float</span> Pvalue= <span class="number">0</span>;</span><br><span class="line"><span class="comment">//循环，遍历M和N的所有子矩阵</span></span><br><span class="line"><span class="keyword">for</span> (intm = <span class="number">0</span>; m &lt; Width/TILE_WIDTH; ++m) &#123;</span><br><span class="line">    <span class="comment">// 获取指向当前矩阵M子矩阵的指针Msub</span></span><br><span class="line">    Float* Mdsub= GetSubMatrix(Md, m, by, Width);</span><br><span class="line">    <span class="comment">//获取指向当前矩阵N的子矩阵的指针Nsub</span></span><br><span class="line">    Float* Ndsub= GetSubMatrix(Nd, bx, m, Width);</span><br><span class="line">    <span class="comment">//共享存储器空间声明</span></span><br><span class="line">    __shared__floatMds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    __shared__floatNds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    <span class="comment">// 每个线程载入M的子矩阵的一个元素</span></span><br><span class="line">    Mds[ty][tx] = GetMatrixElement(Mdsub, tx, ty);</span><br><span class="line">    <span class="comment">//每个线程载入N的子矩阵的一个元素</span></span><br><span class="line">    Nds[ty][tx] = GetMatrixElement(Ndsub, tx, ty);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// part 2 每个线程计算一个值结果</span></span><br><span class="line"><span class="comment">//同步，在计算之前，确保子矩阵所有的元素都已载入共享存储器中</span></span><br><span class="line">__syncthreads();</span><br><span class="line"><span class="comment">//每个线程计算线程块内子矩阵中的一个元素</span></span><br><span class="line"><span class="keyword">for</span> (intk = <span class="number">0</span>; k &lt; TILE_WIDTH; ++k)</span><br><span class="line">Pvalue+= Mds[ty][k] * Nds[k][tx];</span><br><span class="line"><span class="comment">//同步，确保重新载入新的M和N子矩阵数据前，上述计算操作已全部完成</span></span><br><span class="line">__syncthreads();</span><br><span class="line"></span><br><span class="line"><span class="comment">// part 3 合并访存 写回</span></span><br><span class="line"><span class="comment">// 获取指向矩阵P的子矩阵的指针</span></span><br><span class="line">Matrix Psub= GetSubMatrix(P, bx, by);</span><br><span class="line"><span class="comment">//向全局存储器写入线程块计算后的结果子矩阵</span></span><br><span class="line"><span class="comment">//每个线程写入一个元素</span></span><br><span class="line">SetMatrixElement(Psub, tx, ty, Pvalue);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;HPC复习7-1-矩阵乘法优化&quot;&gt;&lt;a href=&quot;#HPC复习7
      
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习6-CUDA优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A06-CUDA%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习6-CUDA优化/</id>
    <published>2019-01-15T08:13:09.000Z</published>
    <updated>2019-01-15T08:13:49.733Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习6-cuda优化"><a href="#HPC复习6-cuda优化" class="headerlink" title="HPC复习6-cuda优化"></a>HPC复习6-cuda优化</h1><p>在cuda程序的优化中，需要考虑以下几个问题</p><ol><li>了解SM核中所提供的资源，并合理分配。</li><li>确定kernel的启动参数，以尽可能提高cuda程序的性能。</li><li>理解warp隐藏延时的作用，知道为什么warp越多越能隐藏延时。</li><li>通过数据预读取隐藏访存延时。</li><li>了解不同指令的吞吐量，并优化之。</li></ol><a id="more"></a><h2 id="SM资源分割"><a href="#SM资源分割" class="headerlink" title="SM资源分割"></a>SM资源分割</h2><h3 id="需要确定的值"><a href="#需要确定的值" class="headerlink" title="需要确定的值"></a>需要确定的值</h3><ol><li>block的数量</li><li>thread的数量</li></ol><h3 id="与分配资源有关的参数"><a href="#与分配资源有关的参数" class="headerlink" title="与分配资源有关的参数"></a>与分配资源有关的参数</h3><ol><li>线程块槽数量（thread block slot）：block数量的上限</li><li>线程槽数量（thread slot）</li><li>寄存器的数量</li><li>shared memory的大小</li></ol><h3 id="分配资源的数量，与哪些因素有关"><a href="#分配资源的数量，与哪些因素有关" class="headerlink" title="分配资源的数量，与哪些因素有关"></a>分配资源的数量，与哪些因素有关</h3><ol><li>原则一：单个SM核上分配的线程数（block*每个block具有的线程数）越大，线程级别的并行越大（前提与sm核实际运行的状况有关，需要想清楚）<ol><li>线程越多，warp越多，可运行的用来隐藏访存时间的warp就越多，因此就可以尽可能让GPU达到满负荷工作，不会由于访存延迟使得gpu空闲。</li></ol></li><li>原则二：单个SM核上的所有寄存器，平均分配给各个线程，因此，线程数量越多，单个线程可用的寄存器越少<ol><li>性能悬崖警惕：减少1/3的线程（并行度），仅仅让每一个线程增加了1个寄存器，除非由于寄存器不足导致了较大的访存开销，否则小心调整。</li></ol></li><li>原则三：对block的数量需要注意，尽量让每一个SM核上都具有多个block，这样子如果一个block在等待同步，可以启动另一个block<ol><li>需要知道SM核的数量</li></ol></li><li>原则五：『关于shared memory』<ol><li>shared memory按block分割，block过多可能会让单个block所具有的shared memory脱销</li></ol></li></ol><h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><p>对G80而言，与分配相关的参数可见：</p><p><img src="https://lh3.googleusercontent.com/-kTJQHo2890Y/XD2P6Ak0g2I/AAAAAAAANx4/HmgaxgQefeAXjfCrvVLuaHq1WeG4QGtAwCHMYCw/s0/Acrobat_2019-01-15_15-46-48.png" alt=""></p><p>有这样的一个情景，在每个block都含256个线程的情况下，一个SM核可能有以下两种情况：</p><p><img src="https://lh3.googleusercontent.com/-lbe-eNMWhP0/XD2PuXTO_aI/AAAAAAAANx0/Z0Grw8p5d0sLkhYhQM5eEafxGO_6aMF8ACHMYCw/s0/Acrobat_2019-01-15_15-46-01.png" alt=""></p><p>这里就可以发现，每个线程多了一个寄存器，但是带来的影响是，总的可以运行的线程的数量变为原来的2/3，也就是说，并行度是原来的2/3了。</p><p>这个可以给我一个启示：除非为了隐藏global memory访存延迟，否则尽可能不要为了增加寄存器数量而降低并行性。</p><h2 id="Kernel启动参数配置"><a href="#Kernel启动参数配置" class="headerlink" title="Kernel启动参数配置"></a>Kernel启动参数配置</h2><h3 id="需要确定以下参数"><a href="#需要确定以下参数" class="headerlink" title="需要确定以下参数"></a>需要确定以下参数</h3><ol><li><p>grid（block的数量）：主要看$\frac{blocks}{sm}$</p><ol><li>大于1：每个SM至少有一个block在执行</li><li>大于2：多个block可以在SM核上并发执行，如果一个block在等待同步，可以启动另一个block</li><li>大于100：对未来设备有很好的伸缩性</li></ol></li><li><p>block（thread的数量）</p><ol><li><p>块大小必须为32的倍数</p></li><li><p>warp尽可能多，隐藏延时</p></li><li><p>64,128,256 等等，试一下，经验成分比较多</p></li></ol></li></ol><h2 id="隐藏延时-相关计算"><a href="#隐藏延时-相关计算" class="headerlink" title="隐藏延时-相关计算"></a>隐藏延时-相关计算</h2><p>问题：需要使用多少个warp来隐藏某操作的延时，此时占用率多大？</p><blockquote><p>占用率：激活warp与最大可容纳warp数目的比值</p><p>最大warp数目: 32 in Tesla, 48 in Fermi</p></blockquote><h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><p><img src="https://lh3.googleusercontent.com/-_DlX9mCbLX8/XD2Sz8Y7WRI/AAAAAAAANyI/clacnlWedsAqyV5mozO0HiLdBlBAskVVwCHMYCw/s0/Acrobat_2019-01-15_15-59-11.png" alt=""></p><h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><p><img src="https://lh3.googleusercontent.com/-pgQYXjs0hrU/XD2S4yZQCiI/AAAAAAAANyM/rwa9BCsy02EMvIOUSQZmUg4dURBSj05LACHMYCw/s0/Acrobat_2019-01-15_15-59-31.png" alt=""></p><h2 id="数据预读"><a href="#数据预读" class="headerlink" title="数据预读"></a>数据预读</h2><blockquote><p>数据预读：在某global memroy变量的读操作，与该变量的实际使用语句之间，插入与该数据无关的独立指令，可以隐藏访存延迟</p></blockquote><p>例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> m = Md[i];</span><br><span class="line"><span class="keyword">float</span> f = a*b + c*d; <span class="comment">// 无关指令，隐藏访存延时</span></span><br><span class="line"><span class="keyword">float</span> f2 = m * f;</span><br></pre></td></tr></table></figure><h3 id="如何在矩阵乘法中使用预读操作进行优化"><a href="#如何在矩阵乘法中使用预读操作进行优化" class="headerlink" title="如何在矩阵乘法中使用预读操作进行优化"></a>如何在矩阵乘法中使用预读操作进行优化</h3><p>代码模板如下，</p><p>注意到中间的预读在计算点积前面，这样子中间的点积在运算时便可以隐藏预读内存产生的误差了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Load first tile into registers</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="comment">/* ... */</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// Deposit registers into shared memory</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Load next tile into registers</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Accumulate dot product</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="指令吞吐量优化"><a href="#指令吞吐量优化" class="headerlink" title="指令吞吐量优化"></a>指令吞吐量优化</h2><p>了解每一种指令的吞吐量，减少使用昂贵的指令。</p><h3 id="一些指令的吞吐量"><a href="#一些指令的吞吐量" class="headerlink" title="一些指令的吞吐量"></a>一些指令的吞吐量</h3><table><thead><tr><th>int &amp; fp32</th><th>2 cycles</th></tr></thead><tbody><tr><td>fp64:</td><td>2 cycles</td></tr><tr><td>fp32 transendental</td><td>8 cycles</td></tr><tr><td>int devide/modulo</td><td>expensive</td></tr></tbody></table><blockquote><p>优化建议：</p><ol><li>与<code>2^n</code>运算，尽量使用位运算，如<code>&gt;&gt; n``&lt;&lt; n</code></li><li>在float常量中添加f，（缺省是double，会导致隐式的类型转换）</li></ol></blockquote><h3 id="数学函数的吞吐量提高"><a href="#数学函数的吞吐量提高" class="headerlink" title="数学函数的吞吐量提高"></a>数学函数的吞吐量提高</h3><ol><li>cuda中两种类型的运行时数学函数<ol><li>func()</li><li>__func()：使用硬件加速，SFU，精度低</li></ol></li><li><code>--use-fast-math</code>编译指令，强制使用硬件加速的数学函数</li></ol><h3 id="循环展开"><a href="#循环展开" class="headerlink" title="循环展开"></a>循环展开</h3><blockquote><p>原理：循环中除了循环体，还有更新计数器，判断条件，计算地址等指令，减少这些无关指令的运算可以加速</p></blockquote><p>例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k =<span class="number">0</span>;k &lt; <span class="number">16</span>;++k)</span><br><span class="line">&#123;</span><br><span class="line">Pvalue +=Ms[ty][k]*Ns[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这其中含有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2条浮点运算</span><br><span class="line">1条循环分支</span><br><span class="line">2条地址运算</span><br><span class="line">1条循环计数器自增</span><br></pre></td></tr></table></figure><p><strong>仅1/3是浮点计算！！！</strong></p><p>做以下改动：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Pvalue += </span><br><span class="line">    Ms[ty][<span class="number">0</span>] * Ns[<span class="number">0</span>][tx] + </span><br><span class="line">    Ms[ty][<span class="number">1</span>] * Ns[<span class="number">1</span>][tx] + </span><br><span class="line">    ...</span><br><span class="line">    Ms[ty][<span class="number">15</span>] * Ns[<span class="number">15</span>][tx];</span><br></pre></td></tr></table></figure><p>从而减少了循环分支，自增，同时地址运算也可以减少。</p><p>自动完成循环展开：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> unroll 16</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k =<span class="number">0</span>;k &lt; <span class="number">16</span>;++k)</span><br><span class="line">&#123;</span><br><span class="line">Pvalue +=Ms[ty][k]*Ns[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>由于展开能够消除分支以及一些管理归纳变量的代码，因此可以摊销一些分支开销。<br>展开可以积极调度（或管道化）循环以掩盖一些延迟。如果有足够的空闲寄存器使变量保持活动状态，因为通过展开相关性链展露了关键路径，这将非常有用。</p></blockquote><p>但</p><blockquote><p>展开过度或展开非常大的循环时，可能导致代码篇幅增加。如果展开后的循环不能再放入跟踪缓存 (TC)，这将有害无益。</p><p>展开循环体中包含分支的循环时，会增加对 BTB 容量的需求。如果展开后循环的迭代次数是 16 或更少，则分支预测应该能正确预测循环体中改变方向的分支。</p></blockquote><h2 id="课上提醒"><a href="#课上提醒" class="headerlink" title="课上提醒"></a>课上提醒</h2><ol><li>如果一整个warp没有指令要执行，不会占住SP，一上来就下去，但只要warp中有一个线程要执行，那就一定会占住SP</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习6-cuda优化&quot;&gt;&lt;a href=&quot;#HPC复习6-cuda优化&quot; class=&quot;headerlink&quot; title=&quot;HPC复习6-cuda优化&quot;&gt;&lt;/a&gt;HPC复习6-cuda优化&lt;/h1&gt;&lt;p&gt;在cuda程序的优化中，需要考虑以下几个问题&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;了解SM核中所提供的资源，并合理分配。&lt;/li&gt;
&lt;li&gt;确定kernel的启动参数，以尽可能提高cuda程序的性能。&lt;/li&gt;
&lt;li&gt;理解warp隐藏延时的作用，知道为什么warp越多越能隐藏延时。&lt;/li&gt;
&lt;li&gt;通过数据预读取隐藏访存延时。&lt;/li&gt;
&lt;li&gt;了解不同指令的吞吐量，并优化之。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.3-CUDA线程</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-3-CUDA%E7%BA%BF%E7%A8%8B/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-3-CUDA线程/</id>
    <published>2019-01-15T07:21:22.000Z</published>
    <updated>2019-01-17T07:19:21.240Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-3-CUDA线程"><a href="#HPC复习5-3-CUDA线程" class="headerlink" title="HPC复习5.3-CUDA线程"></a>HPC复习5.3-CUDA线程</h1><p>这里主要想想明白一个事：</p><p>已知的是，会有多个block，分配到SM核上来执行。</p><p>也知道，单一时间上，SM核仅有一个warp在运行。</p><p>问题是：</p><ol><li>SM核内部的结构是如何的？</li><li>warp的实际执行情况是如何的？</li><li>warp的并发执行是否会引发一些问题？如何解决？</li></ol><a id="more"></a><h2 id="SM核架构"><a href="#SM核架构" class="headerlink" title="SM核架构"></a>SM核架构</h2><p>对SM核的架构该如何理解？</p><ol><li>2个warp调度器与2个指令分派单元能够将2个warp同时进行发射和执行:</li><li>双warp调度器先选择两个warp，然后从每个warp发射一条指令到一个十六核心的组，或是十六个读写单元或是四个SFU。</li></ol><p><img src="figure/Acrobat_2019-01-15_15-18-20.png" alt=""></p><h2 id="Single-Warp"><a href="#Single-Warp" class="headerlink" title="Single Warp"></a>Single Warp</h2><p>对于单个warp内部的并行执行，可能会遇到以下的一些问题：</p><h3 id="单个warp上可能发生的访存冲突"><a href="#单个warp上可能发生的访存冲突" class="headerlink" title="单个warp上可能发生的访存冲突"></a>单个warp上可能发生的访存冲突</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (warpIdx == <span class="number">0</span>) &#123;</span><br><span class="line">    __shared__ <span class="keyword">int</span> v;</span><br><span class="line">    v = <span class="number">0</span>;</span><br><span class="line">    ++v;</span><br><span class="line">    v == ?</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>注意到share memory在一个block内是能够共享的，因此这一段代码由于会导致错误。</li><li>解决这一个问题可以使用<code>atomicAdd(&amp;v, 1);</code>来实现。</li><li>注意到CUDA不支持临界区。</li></ol><p><img src="https://lh3.googleusercontent.com/-nSO5ewSSqtw/XD15aShcuWI/AAAAAAAANvw/b4Vgwb5THG0NvN8vTR011C3KATyKXZ1IgCHMYCw/s0/Acrobat_2019-01-15_14-10-49.png" alt=""></p><h3 id="warp如何处理分支指令？"><a href="#warp如何处理分支指令？" class="headerlink" title="warp如何处理分支指令？"></a>warp如何处理分支指令？</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> warpIdx = threadIdx.x / <span class="number">32</span>;</span><br><span class="line"><span class="keyword">int</span> laneIdx = threadIdx.x % <span class="number">32</span>;</span><br><span class="line"><span class="keyword">if</span> (warpIdx == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (laneIdx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">    doA();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    doB();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>事实上，warp线程在执行上面代码的时候，图示可见如下：</p><p><img src="https://lh3.googleusercontent.com/-iMVFZM74Hxk/XD16kGp5FmI/AAAAAAAANv4/A4cKphyGtmAWbN00g02kvXHckXrIUbW8ACHMYCw/s0/Acrobat_2019-01-15_14-15-43.png" alt=""></p><ol><li>有很多branch的代码是低效的。</li><li>复杂的控制流，如break，continue，会导致代码低效，可能会出现bug。</li></ol><h3 id="Warp-functions"><a href="#Warp-functions" class="headerlink" title="Warp functions"></a>Warp functions</h3><ol><li><code>__all(predicate);</code><ol><li>return 1 if and only if predicate evaluates to non-zero for all of them.</li></ol></li><li><code>__any(predicate);</code><ol><li>return 1 if and only if predicate evaluates to non-zero for any of them.</li></ol></li><li><img src="https://lh3.googleusercontent.com/-vw2oRXY0li8/XD176bbVsSI/AAAAAAAANwE/YbZ0jpSYt-sFHT40WYokkHGAJeXx60SkACHMYCw/s0/Acrobat_2019-01-15_14-21-29.png" alt=""></li><li><code>__ballot(predicate);</code><ol><li>return an integer whose Nth bit is set if and only if predicate evaluates to non-zero for the Nth thread of the warp and the Nth thread is active.</li><li><img src="https://lh3.googleusercontent.com/-ueHU6gtByjg/XD18A5HFrwI/AAAAAAAANwI/p8mfYDejS8ch_4Uv6nWAmGBPhbzYTmPawCHMYCw/s0/Acrobat_2019-01-15_14-21-56.png" alt=""></li></ol></li></ol><h2 id="Multi-Warp"><a href="#Multi-Warp" class="headerlink" title="Multi Warp"></a>Multi Warp</h2><p>多个warp并发执行，可能会导致一些问题。</p><ol><li>多个warp之间的并发执行顺序不定，这会带来一些问题（联想：多线程可能会带来的问题）</li><li>warp内分支也可能会带来问题，导致性能损失。</li></ol><h3 id="warp之间无序的并发执行会带来哪些问题？"><a href="#warp之间无序的并发执行会带来哪些问题？" class="headerlink" title="warp之间无序的并发执行会带来哪些问题？"></a>warp之间无序的并发执行会带来哪些问题？</h3><ol><li>RaW（read after write）<ol><li>如果先写后读，由于后面读的时候，不知道其他warp写了没，可能会导致问题。</li><li><img src="https://lh3.googleusercontent.com/-uZj9SMP3wek/XD2FvMI87DI/AAAAAAAANwY/Q9uTD9MADB8MWDfVfsvAa2TUKIudidUWQCHMYCw/s0/Acrobat_2019-01-15_15-03-24.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-yt2kMUSQDq0/XD2FySx5pXI/AAAAAAAANwc/LeaX4scfJho6PhzfKyFJdsdAx5BbvfUrwCHMYCw/s0/Acrobat_2019-01-15_15-03-38.png" alt=""></li></ol></li><li>WaR（write after read）<ol><li>读后写，同样的写的时候，不知道前面读的值是否是最新的</li><li><img src="https://lh3.googleusercontent.com/-VJn672ZJxe8/XD2F4RJLBHI/AAAAAAAANwg/9y8nqyw1vE4Mge5Z4juJzuFSQK_7nu1FwCHMYCw/s0/Acrobat_2019-01-15_15-04-01.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-iV8FnRM_3eU/XD2F8DrVM9I/AAAAAAAANwk/Ym3R5o17uIMJglDNqYgX1uN--2SU0ikaQCHMYCw/s0/Acrobat_2019-01-15_15-04-17.png" alt=""></li></ol></li><li>WaW（write after write）<ol><li>写后写，同样的，不同的warp之间的写语句，可能运行的相对顺序不一样。</li><li><img src="https://lh3.googleusercontent.com/-yOpBk_JMEj4/XD2GCgXNvkI/AAAAAAAANws/C2i1Fn7EUSga1XeiHh0QbVy7RsPI_ck2ACHMYCw/s0/Acrobat_2019-01-15_15-04-42.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-b3Q1lYpBoVY/XD2GHe4prVI/AAAAAAAANww/iU36UTs-t5ARlM2uFWfZGrQFYgP2SCl2wCHMYCw/s0/Acrobat_2019-01-15_15-05-01.png" alt=""></li></ol></li><li>如何解决：使用<code>__syncthreads()</code>函数<ol><li><img src="https://lh3.googleusercontent.com/-iEnKp2ahX90/XD2GqKA7g6I/AAAAAAAANxA/1TkcMbml8LkK_9l9UVX-HesqNxjL-3O5gCHMYCw/s0/Acrobat_2019-01-15_15-07-20.png" alt=""></li></ol></li></ol><h3 id="branch如何影响多个warp运行的性能？"><a href="#branch如何影响多个warp运行的性能？" class="headerlink" title="branch如何影响多个warp运行的性能？"></a>branch如何影响多个warp运行的性能？</h3><p>对代码段：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (laneIdx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">doA();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">doB();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>结论：</p><ol><li>如果一个warp内的线程有的运行<code>doA</code>，有的运行<code>doB</code>，那么这一个warp必须两部分都运行</li><li>如果一个warp内的线程仅运行其中一个函数，那么该分支语句就不会带来影响</li></ol></li><li><p>以下分三种情况分别观察情况</p><ol><li>（warp-divergent）一个warp内，有的需要运行<code>doA</code>，有的需要运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-G68TmtaLlMA/XD2Hc6NgCPI/AAAAAAAANxM/VwoZls0KjzMr-s9XCHH451eYMx3XBRKVQCHMYCw/s0/Acrobat_2019-01-15_15-10-43.png" alt=""></li></ol></li><li>(warp-uniform)在同一个block内，有的warp运行<code>doA</code>，有的warp运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-1kdv3JnV8eg/XD2Hj5fN6JI/AAAAAAAANxQ/pLe-5ghYggQ70bhXCeU5ips2MG02p_8WwCHMYCw/s0/Acrobat_2019-01-15_15-11-11.png" alt=""></li></ol></li><li>(block-uniform)不同的block，有的block运行<code>doA</code>，有的block运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-441QzpylRK0/XD2HowdmwLI/AAAAAAAANxU/0nkBL7fTwycSth6o5VV7swq4K9JT_RXUQCHMYCw/s0/Acrobat_2019-01-15_15-11-32.png" alt=""></li></ol></li><li>总结：block-uniform方式能够更好的减少性能损失</li></ol></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这幅图我觉得很好地将之前讲过的很多东西都联系了在一起，那就放上来慢慢观赏吧。</p><p><img src="https://lh3.googleusercontent.com/-8wO_TbAmW08/XD2IhLEAcTI/AAAAAAAANxg/vga83BRrlc4Nk8ebfYTnoOy1FLbJIA6zACHMYCw/s0/Acrobat_2019-01-15_15-15-16.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-3-CUDA线程&quot;&gt;&lt;a href=&quot;#HPC复习5-3-CUDA线程&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.3-CUDA线程&quot;&gt;&lt;/a&gt;HPC复习5.3-CUDA线程&lt;/h1&gt;&lt;p&gt;这里主要想想明白一个事：&lt;/p&gt;
&lt;p&gt;已知的是，会有多个block，分配到SM核上来执行。&lt;/p&gt;
&lt;p&gt;也知道，单一时间上，SM核仅有一个warp在运行。&lt;/p&gt;
&lt;p&gt;问题是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SM核内部的结构是如何的？&lt;/li&gt;
&lt;li&gt;warp的实际执行情况是如何的？&lt;/li&gt;
&lt;li&gt;warp的并发执行是否会引发一些问题？如何解决？&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.2-CUDA访存</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-2-CUDA%E8%AE%BF%E5%AD%98/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-2-CUDA访存/</id>
    <published>2019-01-15T05:30:18.000Z</published>
    <updated>2019-01-15T05:33:09.302Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-2-CUDA访存"><a href="#HPC复习5-2-CUDA访存" class="headerlink" title="HPC复习5.2-CUDA访存"></a>HPC复习5.2-CUDA访存</h1><p>这里就主要对cuda中的访存模式进行比较详细地说明吧。</p><ol><li>GPU中，5种不同存储部件的特性及使用方式</li><li>GPU中，如何使用合并访存加速</li><li>下图是GPU中的存储设备的大图</li></ol><p><img src="https://lh3.googleusercontent.com/-FME8Iu_B5cI/XD1D5vIEeaI/AAAAAAAANsE/9ObTV12e34ArBzh9o90oEjCsNBJ_X1LZQCHMYCw/s0/Acrobat_2019-01-15_10-22-29.png" alt=""></p><a id="more"></a><h2 id="GPU中的存储部件"><a href="#GPU中的存储部件" class="headerlink" title="GPU中的存储部件"></a>GPU中的存储部件</h2><h3 id="如何使用global-memory"><a href="#如何使用global-memory" class="headerlink" title="如何使用global memory?"></a>如何使用global memory?</h3><p>有两种方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="title">add4f</span><span class="params">(<span class="keyword">float</span>* u, <span class="keyword">float</span>* v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i=threadIdx.x;</span><br><span class="line">    u[i]+=v[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> hostU[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span> hostV[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span>* devU, devV;</span><br><span class="line">    <span class="keyword">size_t</span> size = <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*<span class="number">4</span>;</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;devU, size);</span><br><span class="line">    cudaMalloc(&amp;devV, size);</span><br><span class="line">    </span><br><span class="line">    cudaMemcpy(devU, hostU, size, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(devV, hostV, size, cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    add4f&lt;&lt;&lt;<span class="number">1</span>,<span class="number">4</span>&gt;&gt;&gt;(devU, devV);</span><br><span class="line">    cudaMemcpy(hostU, devU, size, cudaMemcpyDeviceToHost);</span><br><span class="line">    </span><br><span class="line">    cudaFree(devV);</span><br><span class="line">    cudaFree(devU);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二种方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__device__ <span class="keyword">float</span> devU[<span class="number">4</span>];</span><br><span class="line">__device__ <span class="keyword">float</span> devV[<span class="number">4</span>];</span><br><span class="line">__<span class="function">global__ <span class="title">addUV</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i=threadIdx.x;</span><br><span class="line">    devU[i]+=devV[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> hostU[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span> hostV[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">size_t</span> size = <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*<span class="number">4</span>;</span><br><span class="line">    cudaMemcpyToSymbol(devU, hostU, size, <span class="number">0</span>, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpyToSymbol(devV, hostV, size, <span class="number">0</span>, cudaMemcpyHostToDevice);</span><br><span class="line">    addUV&lt;&lt;&lt;<span class="number">1</span>,<span class="number">4</span>&gt;&gt;&gt;();</span><br><span class="line">    cudaMemcpyFromSymbol(hostU, devU, size, <span class="number">0</span>, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>一点点小疑问</p><p>cudaMemcpyToSymbol和cudaMemcpy的区别，可见<a href="https://blog.csdn.net/litdaguang/article/details/45047015" target="_blank" rel="noopener">link</a></p></blockquote><h3 id="如何使用constant-cache？该种存储空间有什么特点？"><a href="#如何使用constant-cache？该种存储空间有什么特点？" class="headerlink" title="如何使用constant cache？该种存储空间有什么特点？"></a>如何使用constant cache？该种存储空间有什么特点？</h3><ol><li><p>这样使用：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">__constant__ <span class="keyword">int</span> devVar</span><br><span class="line"></span><br><span class="line">cudaMemcpyToSymbol(</span><br><span class="line">    devVar, &amp;hostVar, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), <span class="number">0</span>,</span><br><span class="line">    cudaMemcpyHostToDevice</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cudaMemcpyFromSymbol(</span><br><span class="line">    &amp;hostVar, devVar, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), <span class="number">0</span>,</span><br><span class="line">    cudaMemcpyDeviceToHost</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>注意到，这种类型的使用，不需要显式的free</p></li></ol></li><li><p>constant cache的特点？</p><ol><li>空间大小上限为4KB</li><li>不依赖于threadIdx</li></ol></li></ol><h3 id="如何使用shared-memory？"><a href="#如何使用shared-memory？" class="headerlink" title="如何使用shared memory？"></a>如何使用shared memory？</h3><ol><li><p>有两种方式来使用：静态分配与动态分配</p><ol><li><p>静态分配如下设置：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="keyword">int</span> shArr[<span class="number">4</span>];</span><br></pre></td></tr></table></figure></li></ol></li><li><p>动态分配可以这样设置：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="keyword">int</span> shArr[];</span><br><span class="line">kernel&lt;&lt;&lt;grid,block,<span class="keyword">sizeof</span>(<span class="keyword">int</span>)*<span class="number">4</span>&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure></li></ol></li></ol></li><li><p>这种memory 的特点？</p><ol><li><img src="https://lh3.googleusercontent.com/-0wOJ6oyRp14/XD1KCIF0C8I/AAAAAAAANsQ/Q44B4ty6zoce_X5HtgdGZDs48e8oKGE6wCHMYCw/s0/Acrobat_2019-01-15_10-48-40.png" alt=""></li><li>L1cache与shared Memory共用一块存储空间（直接说明速度很快）</li><li>大小有限制</li></ol></li></ol><h3 id="什么是local-memory？在什么情况下变量会存在local-memory中？"><a href="#什么是local-memory？在什么情况下变量会存在local-memory中？" class="headerlink" title="什么是local memory？在什么情况下变量会存在local memory中？"></a>什么是local memory？在什么情况下变量会存在local memory中？</h3><ol><li>local memory是线程中某些变量存储的空间，实质上是global memory中分配给线程的一块内存空间。<ol><li>实质上就是global memory</li></ol></li><li>local memory的特点：<ol><li>线程内私有</li><li>速度很慢（在global memory中）</li></ol></li><li>在这些情况下变量会存在local memory而不存在寄存器中<ol><li>当单个线程中的寄存器不够用的情况下，需要使用local memory存储变量。<ol><li>需要了解单个线程中能够使用的寄存器数量。</li><li><img src="https://lh3.googleusercontent.com/-qquc9S_qCr0/XD1LBKycwvI/AAAAAAAANsc/0QbLFST183gUhJI2FWFgp_d42NWb0dZxACHMYCw/s0/Acrobat_2019-01-15_10-52-52.png" alt=""></li></ol></li><li>如果变量使用到了地址，变量就会存在local memory中。<ol><li><img src="https://lh3.googleusercontent.com/-ZWqsNGN9Kn4/XD1LTH5bTjI/AAAAAAAANso/p4HIh0AdS_ktdH3vwk9rnbb0AAMcY294gCHMYCw/s0/Acrobat_2019-01-15_10-54-05.png" alt=""></li></ol></li><li>使用了递归函数，寄存器显然不够用，当然也会使用local memory</li></ol></li></ol><h3 id="texture-cache"><a href="#texture-cache" class="headerlink" title="texture cache"></a>texture cache</h3><p>TODO:</p><p>对这个没有什么兴趣，就先不看吧。</p><h2 id="GPU中的存储访问模式"><a href="#GPU中的存储访问模式" class="headerlink" title="GPU中的存储访问模式"></a>GPU中的存储访问模式</h2><p>问题：怎样的存储访问模式，效率更高？</p><h3 id="如何确定访问过程中对Global-Memory的访问长度"><a href="#如何确定访问过程中对Global-Memory的访问长度" class="headerlink" title="如何确定访问过程中对Global Memory的访问长度"></a>如何确定访问过程中对Global Memory的访问长度</h3><ol><li><p>基于这样的特性：</p><ol><li>对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节</li></ol></li><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>找出最小编号活动线程寻址的存储器片段。段的长度由线程访问的字的长度决定：</span><br><span class="line">    * <span class="number">1</span>字节的字<span class="number">32</span>字节</span><br><span class="line">    * <span class="number">2</span>字节的字<span class="number">64</span>字节</span><br><span class="line">    * <span class="number">4</span>，<span class="number">8</span>，<span class="number">16</span>字节的字<span class="number">128</span>字节</span><br><span class="line"><span class="number">2.</span>找出其它地址在同一段内的活动线程</span><br><span class="line"><span class="number">3.</span>减小事务长度，如果可能：</span><br><span class="line">    * 如果事务是<span class="number">128</span>字节且只有下半部分或上半部分被使用，减小事务到<span class="number">64</span>字节；</span><br><span class="line">    * 如果事务是<span class="number">64</span>字节（原始的或者从<span class="number">128</span>字节减小后的）且只有上半部分或下</span><br><span class="line"><span class="number">4.</span>执行事务且标记已访问数据的线程为非活动的。</span><br></pre></td></tr></table></figure></li></ol><h3 id="Global-Memory中，怎样访存效率更高？"><a href="#Global-Memory中，怎样访存效率更高？" class="headerlink" title="Global Memory中，怎样访存效率更高？"></a>Global Memory中，怎样访存效率更高？</h3><ol><li>cuda访存的特性<ol><li>对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节</li></ol></li><li>根据特性，判断不同访存方式的效率区别(<ol><li>图中例子为：遍历访问数组的32个int元素（32*Bytes=128Bytes）。</li><li>对齐且顺序：<ol><li><img src="https://lh3.googleusercontent.com/-hivZZjGGfi8/XD1PT_H5jRI/AAAAAAAANtA/Jyp5zvfIxyou6Epbh3d0XFTV0Fta6mDCgCHMYCw/s0/Acrobat_2019-01-15_11-11-11.png" alt=""></li></ol></li><li>对齐，但交叉次序访问，注意到对该情况的优化在不同的计算能力下不同。<ol><li>发现1.0的时候，完全不支持交叉次序访问的并行<ol><li>每个int读取一次，32次读取每次读取单位为32B</li></ol></li><li><img src="https://lh3.googleusercontent.com/-8do7xPatAfQ/XD1PgsjTPuI/AAAAAAAANtE/ywf_tP6vUiYlChN0xGN1pzx99kevZeBbQCHMYCw/s0/Acrobat_2019-01-15_11-12-02.png" alt=""></li></ol></li><li>未对齐，但顺序访问<ol><li><img src="https://lh3.googleusercontent.com/-UDvD96XD-Vw/XD1Qa2WOBBI/AAAAAAAANtQ/KiFbNr6zvto_TO4hnaahHwZpzwSHEISxACHMYCw/s0/Acrobat_2019-01-15_11-15-55.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-wuvaBvFBL04/XD1ST3z6tkI/AAAAAAAANts/LLtskN0255wkfZopm6VnnbL2EvdgPm_iQCHMYCw/s0/Acrobat_2019-01-15_11-23-58.png" alt=""></li></ol></li><li>即使对齐了，但是如果乘上一个系数<ol><li><img src="https://lh3.googleusercontent.com/-yGL6OLkxFsA/XD1QfeEWqFI/AAAAAAAANtU/3xmBtQvVAxMfOlW-EA_UxqEoiWl0aKA2ACHMYCw/s0/Acrobat_2019-01-15_11-16-14.png" alt=""></li></ol></li><li>随机访问<ol><li><img src="https://lh3.googleusercontent.com/-rCGJm6lllIs/XD1Qrdz7GbI/AAAAAAAANtc/EyEVB2TTgko4nkQ0ciJ35v3VjZfYNNE7wCHMYCw/s0/Acrobat_2019-01-15_11-17-01.png" alt=""></li></ol></li></ol></li><li>结论：尽可能对齐且顺序访问</li></ol><h3 id="Constant-Memory中，如何访存效率更高？"><a href="#Constant-Memory中，如何访存效率更高？" class="headerlink" title="Constant Memory中，如何访存效率更高？"></a>Constant Memory中，如何访存效率更高？</h3><ol><li>特点：<ol><li>片外存储器，速度虽然比shared满，但是具有缓存</li><li>只读</li><li>无需考虑冲突问题</li></ol></li><li>访问优化：<ol><li>关键：如果half-warp中的线程访问的不是同一个地址，那么各个线程的访问将会串行化。<img src="https://lh3.googleusercontent.com/-yYJUOX-zNgk/XD1TgLgRnyI/AAAAAAAANt4/jB6R5v6BWuA3RcIbegH_yCq33uPjxdJPACHMYCw/s0/Acrobat_2019-01-15_11-29-05.png" alt=""></li><li>例子：<img src="https://lh3.googleusercontent.com/-cXQbxBAYxWA/XD1TdHGWvJI/AAAAAAAANt0/i-ImhB4Jn98B3IPZObx9llbtihPgvRZdQCHMYCw/s0/Acrobat_2019-01-15_11-28-52.png" alt=""></li></ol></li></ol><h3 id="Shared-Memory中如何访存效率更高？"><a href="#Shared-Memory中如何访存效率更高？" class="headerlink" title="Shared Memory中如何访存效率更高？"></a>Shared Memory中如何访存效率更高？</h3><ol><li><p>特点：</p><ol><li>速度极快（毕竟在L1 cache上）</li><li>如果发生bank冲突，可能会使访存串行化</li></ol></li><li><p>shared memory的硬件结构特点与bank</p><ol><li>参考下图<ol><li>线性编址</li></ol></li><li>（以下图为例的话），地址<code>0008</code>，<code>0048</code>，<code>0088</code>在同一个bank上，无法在一个时钟周期内访问，必须串行访问。例如下图：同一个时间里，half-warp发出的访存请求，如果访问同一个bank上的地址，会导致访存串行化<ol><li><img src="https://lh3.googleusercontent.com/-SA4qmGTqTyM/XD1VSMTUETI/AAAAAAAANuI/FDzh1lkWp04cF8K-eT_yKmE2CKOI3K7xQCHMYCw/s0/Acrobat_2019-01-15_11-36-35.png" alt=""></li></ol></li><li>地址<code>0000</code>，<code>0004</code>，<code>0008</code>，等，在同一个bank上，多个线程可以在同一个时钟周期访问，因此实现了并行访存<ol><li><img src="https://lh3.googleusercontent.com/-Njk-efGNx5M/XD1Vb6wjVtI/AAAAAAAANuM/G6tcHtm7i8cz0KITIjuWuOOH07q2eGaBQCHMYCw/s0/Acrobat_2019-01-15_11-37-17.png" alt=""></li></ol></li></ol></li><li><p>关键优化需要特性</p><ol><li>一个half-warp中的线程，在没有发生bank冲突的情况下，可以在一个时钟周期内访问16个不同的地址。</li><li>一个half-warp中的所有线程如果都访问同一个地址，通过广播机制，可以在同一个时钟周期内完成访问。<img src="https://lh3.googleusercontent.com/-whTB6O25Bz8/XD1Ww8ozsKI/AAAAAAAANuc/I7fX9lzV3ioWMGs93a3-w3-P51tgUgalACHMYCw/s0/Acrobat_2019-01-15_11-42-59.png" alt=""></li></ol></li><li><p>访存例子：</p><ol><li><p><code>v = arr[ threadIdx.x ]</code></p><ol><li>连续的16个元素可以通过一个时钟周期一次访问。</li><li><img src="https://lh3.googleusercontent.com/-d7AP5GuL2ns/XD1YgQ30h5I/AAAAAAAANuo/jGCLvbPigYQHcNE9eJ2h9mMBS9b5K3IJQCHMYCw/s0/Acrobat_2019-01-15_11-50-25.png" alt=""></li></ol></li><li><p><code>v = arr[ threadIdx.x+2 ]</code></p><ol><li>没有发生bank冲突，连续的16个值依然可以通过一个时钟周期一次完成访问。</li><li><img src="https://lh3.googleusercontent.com/-NwTzxZl9Nbc/XD1YsH6m5WI/AAAAAAAANus/fAW7EWnFt2EaKdavF_-lrcCNJ5AFqi1IgCHMYCw/s0/Acrobat_2019-01-15_11-51-13.png" alt=""></li></ol></li><li><code>v = arr[2*threadIdx.x]</code>      <ol><li>连续的16个值，前8个可以一次访问，后8个由于与前8个发生了bank冲突，需要等到下一个时钟周期，需要两个时钟周期</li><li><img src="https://lh3.googleusercontent.com/-XH1ZOdJzB4Y/XD1ZBpizwpI/AAAAAAAANu4/WX7e_gTepj8a7_sWcTEKN69YVmUgWUwjwCHMYCw/s0/Acrobat_2019-01-15_11-52-39.png" alt=""></li></ol></li><li><code>v = arr2[threadIdx.x].x</code><ol><li>注意到arr2数组是由int2类型的结构体（int x, int y）组成的，因此在实际访存中，这个语句有着与上面那个类似的效果。</li><li><img src="https://lh3.googleusercontent.com/-PSr-FTdqRlw/XD1Zqeo80mI/AAAAAAAANvA/HyZcNu2u-mM5N_8ugMuuqYKzpFGKejdhACHMYCw/s0/Acrobat_2019-01-15_11-55-21.png" alt=""></li></ol></li><li><code>v = arr[3*threadIdx.x]</code><ol><li>发现很神奇的是，乘上3，就不会发生冲突了。<ol><li>(3与16互素，x $\in [0,15]$是16的一个剩余系，那么3*x能够遍历16的剩余系)</li></ol></li><li><img src="https://lh3.googleusercontent.com/-UBKhzjGNwco/XD1Z2oL1nZI/AAAAAAAANvE/ZIoh-iVj6ms5LXzrq_jD8Dj1IuzuxXQhwCHMYCw/s0/Acrobat_2019-01-15_11-56-10.png" alt=""></li></ol></li><li><code>v = arr[random]</code><ol><li><img src="https://lh3.googleusercontent.com/-_YfC9QLNbVA/XD1rxZMXNII/AAAAAAAANvY/kp120Lh9CnMiCuAP-wbwn44bSi_QYiVywCHMYCw/s0/Acrobat_2019-01-15_13-12-36.png" alt=""></li></ol></li></ol></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://lh3.googleusercontent.com/-hXWKX0lEAvM/XD1wcULablI/AAAAAAAANvk/auzOo_Af5dAKzdR5htukmRwdnKq15TYyQCHMYCw/s0/Acrobat_2019-01-15_13-32-33.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-2-CUDA访存&quot;&gt;&lt;a href=&quot;#HPC复习5-2-CUDA访存&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.2-CUDA访存&quot;&gt;&lt;/a&gt;HPC复习5.2-CUDA访存&lt;/h1&gt;&lt;p&gt;这里就主要对cuda中的访存模式进行比较详细地说明吧。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;GPU中，5种不同存储部件的特性及使用方式&lt;/li&gt;
&lt;li&gt;GPU中，如何使用合并访存加速&lt;/li&gt;
&lt;li&gt;下图是GPU中的存储设备的大图&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-FME8Iu_B5cI/XD1D5vIEeaI/AAAAAAAANsE/9ObTV12e34ArBzh9o90oEjCsNBJ_X1LZQCHMYCw/s0/Acrobat_2019-01-15_10-22-29.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.1-CUDA基础</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-1-CUDA%E5%9F%BA%E7%A1%80/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-1-CUDA基础/</id>
    <published>2019-01-15T02:03:26.000Z</published>
    <updated>2019-01-15T02:04:25.938Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-1-CUDA基础"><a href="#HPC复习5-1-CUDA基础" class="headerlink" title="HPC复习5.1-CUDA基础"></a>HPC复习5.1-CUDA基础</h1><p>复习了一下cuda，主要以自问自答的方式，整理了一下知识点。</p><ol><li>相关背景：前言</li><li>逻辑上的cuda架构大概是怎样的？</li><li>gpu上实际的硬件情况</li><li>cuda架构与硬件之间的关系</li><li>一个简单实例：矩阵相乘的简单实现</li></ol><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="为什么需要gpu？"><a href="#为什么需要gpu？" class="headerlink" title="为什么需要gpu？"></a>为什么需要gpu？</h3><ol><li>CPU处理能力不断强大，但在进入3D时代后，人们发现庞大的3D图像处理数据计算使得CPU越来越不堪重荷，并且远远超出其计算能力；</li><li>图形计算需求日益增多，作为计算机的显示芯片也飞速发展。图形，图像计算等计算的功能被脱离出来，单独设计为一块芯片——GPU （也就是显卡）。</li></ol><h3 id="gpu与cpu的主要区别在？"><a href="#gpu与cpu的主要区别在？" class="headerlink" title="gpu与cpu的主要区别在？"></a>gpu与cpu的主要区别在？</h3><ol><li>gpu采用了大量的执行单元，并且一个控制单元可以同时控制多个执行单元进行计算，实现类似于SIMD的加速。</li><li><img src="https://lh3.googleusercontent.com/-U6dLqQSsc_U/XD0vGdcz0oI/AAAAAAAANqg/skeMgQgw4NMZnsCU87OTm8bNWqoBnac0ACHMYCw/s0/Acrobat_2019-01-15_08-53-44.png" alt=""></li></ol><h3 id="cuda是什么？"><a href="#cuda是什么？" class="headerlink" title="cuda是什么？"></a>cuda是什么？</h3><ol><li>是一种专门针对GPU的开发工具，可以使用类C语言进行通用计算。</li><li>用于编写host+device异构并行C应用程序</li><li><img src="https://lh3.googleusercontent.com/-FlqXBhfrtAQ/XD0vjzixC7I/AAAAAAAANqo/F_57eojX4nAF3CnPqXjbN-gl2nDc0mk0wCHMYCw/s0/Acrobat_2019-01-15_08-55-43.png" alt=""></li></ol><h2 id="CUDA-架构（逻辑上）"><a href="#CUDA-架构（逻辑上）" class="headerlink" title="CUDA 架构（逻辑上）"></a>CUDA 架构（逻辑上）</h2><h3 id="CUDA中线程的组织方式？"><a href="#CUDA中线程的组织方式？" class="headerlink" title="CUDA中线程的组织方式？"></a>CUDA中线程的组织方式？</h3><ol><li>三级：Grid-Block-Thread<ol><li>Thread ：单个线程，是并行的基本单位</li><li>Block：互相合作的线程组</li><li>Grid：一组Block</li></ol></li><li>需要关注到，一个kernel对应一个Grid</li><li><img src="https://lh3.googleusercontent.com/-4LwbA1Aj2MQ/XD0v2jCDuHI/AAAAAAAANq0/64pcOu7Onqc837_4Q79DnfvvoSzWXocaQCHMYCw/s0/Acrobat_2019-01-15_08-56-58.png" alt=""></li></ol><h3 id="CUDA中的访存模式？"><a href="#CUDA中的访存模式？" class="headerlink" title="CUDA中的访存模式？"></a>CUDA中的访存模式？</h3><p>线程可以访问以下空间</p><ol><li>以线程为单位的<ol><li>线程有内部的<strong>寄存器</strong></li><li>在寄存器不够用的情况下，可以在<strong>Global Memory</strong>中申请一块内存空间作为<strong>Local Memory</strong></li></ol></li><li>以Block为单位的<ol><li>单个block中的线程共享<strong>Shared Memory</strong></li></ol></li><li>以Grid为单位的<ol><li>一个Grid中的所有线程共享<strong>Glocal Memory</strong></li><li>特殊的，一个Grid中的所有线程共享<strong>只读的</strong> <strong>constant memory</strong>(常量存储器),<strong>texture memory</strong>(纹理存储器)</li></ol></li><li>图示如下：<img src="https://lh3.googleusercontent.com/-7Id_bAjJjD4/XD0xXYp4HTI/AAAAAAAANrA/g7kkEfzz_Zgxa6JaHZhGRdDckKAqbXEfACHMYCw/s0/Acrobat_2019-01-15_09-03-24.png" alt=""></li></ol><h2 id="cuda与硬件的关系"><a href="#cuda与硬件的关系" class="headerlink" title="cuda与硬件的关系"></a>cuda与硬件的关系</h2><h3 id="cuda中有哪些硬件？是如何组织的？"><a href="#cuda中有哪些硬件？是如何组织的？" class="headerlink" title="cuda中有哪些硬件？是如何组织的？"></a>cuda中有哪些硬件？是如何组织的？</h3><p>由低到高分别是：</p><ol><li>SP：流处理器</li><li>SM：流多处理器</li><li>TPC：线程处理集群</li><li>SPA：流处理器阵列</li></ol><p><img src="https://lh3.googleusercontent.com/-qmYboKb3JQM/XD0xsCp_K6I/AAAAAAAANrI/Hkgu4X-fusoYYnf2q3B-DWv1BcjVEPLYQCHMYCw/s0/Acrobat_2019-01-15_09-04-49.png" alt=""></p><h3 id="cuda架构与实际硬件的关系？"><a href="#cuda架构与实际硬件的关系？" class="headerlink" title="cuda架构与实际硬件的关系？"></a>cuda架构与实际硬件的关系？</h3><ol><li>Grid：运行在SPA上</li><li>Block的执行方式：<ol><li>一般的cuda应用程序具有多个Block组成的线程组，这些Block会分配到多个SM核上分别执行。</li><li>怎么分配？见下图：<img src="https://lh3.googleusercontent.com/-Plh4mq88QdE/XD0y2ywS9aI/AAAAAAAANrU/w50XC5epme4HVSkv4vKG0C-aRc06ujnmwCHMYCw/s0/Acrobat_2019-01-15_09-09-46.png" alt=""></li><li>注意到这里的分配，会受到以下两个限制的影响：<ol><li>一个SM核上分配的Blcok数量是有限制，G80中的SM核最多8个block</li><li>G80中的SM核最多768个线程。</li></ol></li></ol></li><li>SM核上具有多个Block需要运行后，这些线程更具体的，是如何执行的呢？<ol><li>一个SM核上的多个Block，每个block会分成多个Warp（32个线程）</li><li>这些Warp会在SM核上并发地执行，由于一个Warp有32个线程，而一个SM核上仅有8个SP，因此一个Warp运行4个Clock cycles</li></ol></li></ol><h3 id="Warp的调度具有开销吗？"><a href="#Warp的调度具有开销吗？" class="headerlink" title="Warp的调度具有开销吗？"></a>Warp的调度具有开销吗？</h3><ol><li>（联想）cpu中的硬件多线程之间的调度是几乎没有开销的，原因？是因为CPU中已经有了多个可以用于存储线程context的区域，每次调度切换线程的时候，切换context是在CPU硬件内完成的，不是由操作系统完成的，不需要访存，因此几乎0开销。</li><li>GPU中的warp调度，类似的，也是0开销的。</li></ol><h3 id="怎样的Warp会被调度出来执行？"><a href="#怎样的Warp会被调度出来执行？" class="headerlink" title="怎样的Warp会被调度出来执行？"></a>怎样的Warp会被调度出来执行？</h3><ol><li>很明显的，每一个时刻，都会有很多个Warp在等待被GPU调度执行，那么问题是：满足什么条件的Warp，会被调度出来执行？<ol><li>Warp中没有线程被阻塞的（如访存等）</li><li>合适的Warp挑出来优先执行。</li></ol></li></ol><h3 id="为什么要设计成warp的并发执行？"><a href="#为什么要设计成warp的并发执行？" class="headerlink" title="为什么要设计成warp的并发执行？"></a>为什么要设计成warp的并发执行？</h3><ol><li>结论：Warp的并发执行，能够很好的隐藏访存时间（原理类似于cpu中的硬件多线程）</li><li>简单例子：<ol><li><img src="https://lh3.googleusercontent.com/-M9QwhzmB0pI/XD02cA_ftZI/AAAAAAAANrg/NpkbQH9Eo2I7kq1FcXk2uzkxt10DuWbUgCHMYCw/s0/Acrobat_2019-01-15_09-25-04.png" alt=""></li><li>上图中，一个单位长度为一个warp的执行（实际上其实是4个时钟周期，这里简化成了1个）。</li><li>可以发现，每当一个Warp由于访存阻塞了，GPU会马上从调度其他可用的Warp来执行，从而保证GPU中的计算负载保持在100%，这个Warp的访存时间就被别的Warp的执行隐藏掉了</li></ol></li><li>复杂例子：如何计算完全隐藏访存时间所需要的Warp的数量。<ol><li>假设：<ol><li>运行一次一个Warp中的所有线程需要4个clock cycles</li><li>每n个指令需要一次全局内存访问（200个时钟周期）</li></ol></li><li>解答：<ol><li>假设每个指令都需要访存，访存的这一段时间里，可以使用$200/4=50$个warp的执行来隐藏。<ol><li>隐藏假设：单个Warp一次运行仅使用了4个clock cycles就被阻塞了</li></ol></li><li>由于是每n个指令访存一次，因此实际上，单个warp执行了$4*n$后才会被阻塞</li><li>因此，需要$200/(4*n)+1$个warp。</li></ol></li></ol></li></ol><h3 id="SM核上具有的存储空间及分配情况？"><a href="#SM核上具有的存储空间及分配情况？" class="headerlink" title="SM核上具有的存储空间及分配情况？"></a>SM核上具有的存储空间及分配情况？</h3><ol><li>SM核上拥有16KB的shared memory(有些GPU是48KB)</li><li>基于前面，一个SM核上分配多个Block的前提<ol><li>多个block分享一个SM核上的shared memory。</li></ol></li><li>由于单个block可能会要求shared memory至少多大，而一个SM核上的shared memory是有限制的，所以，block要看情况，不能分配太多，不然shared memory就不够用了。<ol><li>Shared Memory也会限制Block的分配</li></ol></li></ol><h2 id="cuda的软件接口"><a href="#cuda的软件接口" class="headerlink" title="cuda的软件接口"></a>cuda的软件接口</h2><p>写了这么多，终于写到要写一个真正的cuda程序了。</p><h3 id="cuda编程中的函数声明"><a href="#cuda编程中的函数声明" class="headerlink" title="cuda编程中的函数声明"></a>cuda编程中的函数声明</h3><ol><li>在cuda编程中，当然既要写在gpu上运行的函数又要写在cpu上运行的函数了，那么如何区分呢？</li><li><img src="https://lh3.googleusercontent.com/-Frw4biWiTdw/XD063lkpXrI/AAAAAAAANrs/2FySYbhR3EsgK3TcHH6cPOlsy7x_zxzTQCHMYCw/s0/Acrobat_2019-01-15_09-43-58.png" alt=""></li><li>好吧，之前我没有好好想<code>__device__</code>还有<code>__global__</code>的区别，所以这里要特地给自己强调一下。</li></ol><h3 id="cuda中的5个内建设备变量"><a href="#cuda中的5个内建设备变量" class="headerlink" title="cuda中的5个内建设备变量"></a>cuda中的5个内建设备变量</h3><ol><li><code>gridDim</code></li><li><code>blockDim</code></li><li><code>blockIdx</code></li><li><code>threadIdx</code></li><li><code>warpSize</code></li></ol><h3 id="cuda中的各种各样的内存操作"><a href="#cuda中的各种各样的内存操作" class="headerlink" title="cuda中的各种各样的内存操作"></a>cuda中的各种各样的内存操作</h3><p><code>cudaMemcpy(void * dst, void * src, size_t nbytes, enum cudaMemcpyType direction);</code></p><p><code>cudaMalloc</code></p><p><code>cudaFree</code></p><h3 id="cuda中的同步操作"><a href="#cuda中的同步操作" class="headerlink" title="cuda中的同步操作"></a>cuda中的同步操作</h3><p><code>__syncThreads()</code>：同步一个block里面的所有线程，作用相当于一个Barrier</p><h2 id="实例：very-simple的矩阵相乘"><a href="#实例：very-simple的矩阵相乘" class="headerlink" title="实例：very simple的矩阵相乘"></a>实例：very simple的矩阵相乘</h2><p>可以看我的<a href="https://gitee.com/wwyf/class_hpc/blob/master/e6/code/multi.cu" target="_blank" rel="noopener">git仓库</a>（我具体的实现可能没有这么naive）</p><p>具体思路是：</p><p><img src="https://lh3.googleusercontent.com/-3jJ-qYk5SD8/XD09D8JLBTI/AAAAAAAANr4/HjWn0Aj36A4S0xuZEoZ70EqhyJ6waYYGwCHMYCw/s0/Acrobat_2019-01-15_09-53-19.png" alt=""></p><p>对该程序优化的思考</p><ol><li>性能问题：<ol><li>每计算一次，访问两次内存（如从矩阵Md中取一个数，以及从Nd中取一个数，然后只做了一次加法）</li><li>访存限制</li></ol></li><li>矩阵的大小受到一个block大小的限制。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-1-CUDA基础&quot;&gt;&lt;a href=&quot;#HPC复习5-1-CUDA基础&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.1-CUDA基础&quot;&gt;&lt;/a&gt;HPC复习5.1-CUDA基础&lt;/h1&gt;&lt;p&gt;复习了一下cuda，主要以自问自答的方式，整理了一下知识点。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;相关背景：前言&lt;/li&gt;
&lt;li&gt;逻辑上的cuda架构大概是怎样的？&lt;/li&gt;
&lt;li&gt;gpu上实际的硬件情况&lt;/li&gt;
&lt;li&gt;cuda架构与硬件之间的关系&lt;/li&gt;
&lt;li&gt;一个简单实例：矩阵相乘的简单实现&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习3-pthread</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A03-pthread/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习3-pthread/</id>
    <published>2019-01-14T13:38:29.000Z</published>
    <updated>2019-01-16T01:15:19.718Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习3-pthread"><a href="#HPC复习3-pthread" class="headerlink" title="HPC复习3-pthread"></a>HPC复习3-pthread</h1><p><a href="https://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html" target="_blank" rel="noopener">toturial</a></p><p>这里是高性能计算课程-pthread部分的复习笔记，大概会有以下内容：</p><ol><li>pthread中的hello,world</li><li>pthread中的临界区</li><li>忙等待</li><li>互斥量</li><li>生产者-消费者同步与信号量</li><li>实现路障</li><li>读写锁与链表</li><li>pthread中的缓存一致性</li></ol><a id="more"></a><h2 id="进程、线程和pthread"><a href="#进程、线程和pthread" class="headerlink" title="进程、线程和pthread"></a>进程、线程和pthread</h2><ol><li>pthread:一种共享内存编程模型</li></ol><h2 id="Hello-world"><a href="#Hello-world" class="headerlink" title="Hello,world"></a>Hello,world</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">print_message_function</span><span class="params">( <span class="keyword">void</span> *ptr )</span></span>;</span><br><span class="line"></span><br><span class="line">main()</span><br><span class="line">&#123;</span><br><span class="line">     <span class="keyword">pthread_t</span> thread1, thread2;</span><br><span class="line">     <span class="keyword">char</span> *message1 = <span class="string">"Thread 1"</span>;</span><br><span class="line">     <span class="keyword">char</span> *message2 = <span class="string">"Thread 2"</span>;</span><br><span class="line">     <span class="keyword">int</span>  iret1, iret2;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Create independent threads each of which will execute function */</span></span><br><span class="line"></span><br><span class="line">     iret1 = pthread_create( &amp;thread1, <span class="literal">NULL</span>, print_message_function, (<span class="keyword">void</span>*) message1);</span><br><span class="line">     iret2 = pthread_create( &amp;thread2, <span class="literal">NULL</span>, print_message_function, (<span class="keyword">void</span>*) message2);</span><br><span class="line"></span><br><span class="line">     <span class="comment">/* Wait till threads are complete before main continues. Unless we  */</span></span><br><span class="line">     <span class="comment">/* wait we run the risk of executing an exit which will terminate   */</span></span><br><span class="line">     <span class="comment">/* the process and all threads before the threads have completed.   */</span></span><br><span class="line"></span><br><span class="line">     pthread_join( thread1, <span class="literal">NULL</span>);</span><br><span class="line">     pthread_join( thread2, <span class="literal">NULL</span>); </span><br><span class="line"></span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Thread 1 returns: %d\n"</span>,iret1);</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Thread 2 returns: %d\n"</span>,iret2);</span><br><span class="line">     <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">print_message_function</span><span class="params">( <span class="keyword">void</span> *ptr )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="keyword">char</span> *message;</span><br><span class="line">     message = (<span class="keyword">char</span> *) ptr;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"%s \n"</span>, message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="pthread中的临界区"><a href="#pthread中的临界区" class="headerlink" title="pthread中的临界区"></a>pthread中的临界区</h2><ol><li>课本上使用多个线程并行计算$\pi$会出问题<ol><li>多个线程尝试更新同一个共享变量时，会出问题。</li></ol></li><li>多个线程尝试更新一个共享资源，结果可能是无法预测的，这些访问可能会导致某种错误，我们称之为<strong>竞争条件</strong></li><li><strong>临界区</strong>：更新共享资源的代码段</li></ol><h2 id="忙等待"><a href="#忙等待" class="headerlink" title="忙等待"></a>忙等待</h2><ol><li>可以使用忙等待实现“严格按照线程号，单个线程进入临界区”。</li><li>注意，可能会由于发生了编译优化导致该忙等待失效（该忙等待语句可能会调度到其他指令前后）<ol><li>可以通过<code>volitile</code>关键字来解决</li></ol></li><li>缺点：<ol><li>忙等待：浪费CPU周期</li></ol></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initialize</span></span><br><span class="line">flag = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// .... some code</span></span><br><span class="line"><span class="keyword">while</span>(flag != my_rank);</span><br><span class="line"><span class="comment">// critical area</span></span><br><span class="line">flag = (flag + <span class="number">1</span>)% thread_count;<span class="comment">// 保证在所有进程都已到达后，flag恢复成0</span></span><br></pre></td></tr></table></figure><h2 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h2><ol><li>改善忙等待的缺点：互斥量，互斥锁</li><li>设计函数接口<ol><li><code>pthread_mutex_init( pthread_mutex_t *, const pthread_mutexattr_t *)</code></li><li><code>int pthread_mutex_destroy(pthread_mutex_t* )</code></li><li><code>int pthread_mutex_lock(pthread_mutex_t *)</code></li><li><code>int pthread_mutex_unlock(pthread_mutex_t *)</code></li></ol></li></ol><h2 id="生产者-消费者同步和信号量"><a href="#生产者-消费者同步和信号量" class="headerlink" title="生产者-消费者同步和信号量"></a>生产者-消费者同步和信号量</h2><p>TODO:</p><h2 id="路障和条件变量"><a href="#路障和条件变量" class="headerlink" title="路障和条件变量"></a>路障和条件变量</h2><ol><li><p>问题：如何保证所有线程在程序中处于同一位置来同步线程（即实现路障）</p></li><li><p>忙等待和互斥量实现路障</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> counter;</span><br><span class="line"><span class="keyword">int</span> thread_count;</span><br><span class="line"><span class="keyword">pthread_mutex_t</span> barier_mutex;</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> * <span class="title">Threa_word</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    pthread_mutex_lock(&amp;barier_mutex);</span><br><span class="line">    counter++；</span><br><span class="line">    pthread_mutex_unlock(&amp;barrier_mutex);</span><br><span class="line">    <span class="keyword">while</span>(counter &lt; thread_count);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>信号量实现路障</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> counter;</span><br><span class="line"><span class="keyword">sem_t</span> count_sem;</span><br><span class="line"><span class="keyword">sem_t</span> barrier_sem;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">Thread_work</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    <span class="comment">// 先获得计数器的信号量</span></span><br><span class="line">    sem_wait(&amp;count_sem);</span><br><span class="line">    <span class="keyword">if</span> (counter == thread_count<span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="comment">// 最后一个到达路障的线程负责初始化counter以及释放其他线程</span></span><br><span class="line">        counter = <span class="number">0</span>;</span><br><span class="line">        sem_post(&amp;count_sem);</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; thread_count<span class="number">-1</span>; j++)</span><br><span class="line">            sem_post(&amp;barrier_sem);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        counter++;</span><br><span class="line">        sem_postq(&amp;count_sem);</span><br><span class="line">        sem_wait(&amp;barrier_sem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>该路障的重用可能会导致竞争条件</p></li></ol></li><li><p>使用条件变量实现路障</p><ol><li><p>条件变量是：允许线程在某个特定条件或事前发生前都处于挂起状态。当事件发生时，另一个线程可以通过信号来唤醒挂起的线程。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> * <span class="title">Thread_work</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ....</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    counter++;</span><br><span class="line">    <span class="keyword">if</span> (counter == thread_count)&#123;</span><br><span class="line">        counter = <span class="number">0</span>;</span><br><span class="line">        pthread_cond_broadcast(&amp;cond_var);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">while</span>(pthread_cond_wait(&amp;cond_var, &amp;mutex) != <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);    </span><br><span class="line">    ....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol><h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>使用读写锁，实现多线程共享的链表怎么实现？不难。</p><p><img src="https://lh3.googleusercontent.com/-jm61UeXUUc4/XD6AbNTejpI/AAAAAAAAN2k/AHGevmv9O5kY5oRH6DnqEail-W6a8NiIgCHMYCw/s0/Acrobat_2019-01-16_08-53-00.png" alt=""></p><p>一个结论：在Insert，Delete操作十分少的时候，使用读写锁的性能更好。</p><p><img src="https://lh3.googleusercontent.com/-BgLlpcl5A-k/XD6ATQaRnAI/AAAAAAAAN2g/DlvaYc1Cp5kLj6O4rNPIOQtAL_rVe-nigCHMYCw/s0/Acrobat_2019-01-16_08-52-27.png" alt=""></p><h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><p>书本拿了矩阵-向量乘法的例子，说明了缓存对程序性能的影响</p><ol><li>对于8*8000000的矩阵，伪共享带来了很大的影响<ol><li>关键：$y[0]-y[7]$在同一个缓存行中</li></ol></li></ol><p><img src="https://lh3.googleusercontent.com/-LJMIfdNhooo/XDyQgxv4XJI/AAAAAAAANqI/8lBb1o5SPBUV1Gn6uK0sRuGp0bH87hCJQCHMYCw/s0/Typora_2019-01-14_21-37-07.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习3-pthread&quot;&gt;&lt;a href=&quot;#HPC复习3-pthread&quot; class=&quot;headerlink&quot; title=&quot;HPC复习3-pthread&quot;&gt;&lt;/a&gt;HPC复习3-pthread&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;toturial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里是高性能计算课程-pthread部分的复习笔记，大概会有以下内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pthread中的hello,world&lt;/li&gt;
&lt;li&gt;pthread中的临界区&lt;/li&gt;
&lt;li&gt;忙等待&lt;/li&gt;
&lt;li&gt;互斥量&lt;/li&gt;
&lt;li&gt;生产者-消费者同步与信号量&lt;/li&gt;
&lt;li&gt;实现路障&lt;/li&gt;
&lt;li&gt;读写锁与链表&lt;/li&gt;
&lt;li&gt;pthread中的缓存一致性&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习2-MPI</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A02-MPI/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习2-MPI/</id>
    <published>2019-01-14T12:26:23.000Z</published>
    <updated>2019-01-14T13:39:25.530Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习2-MPI"><a href="#HPC复习2-MPI" class="headerlink" title="HPC复习2-MPI"></a>HPC复习2-MPI</h1><p><a href="https://www.open-mpi.org/doc/current/" target="_blank" rel="noopener">OpenMPI 官方文档</a></p><p><a href="http://www.mpich.org/static/docs/latest/" target="_blank" rel="noopener">mpich官方文档</a></p><p>这里是高性能计算课程-MPI部分的复习笔记，大概会有以下内容：</p><ol><li>MPI中的Hello world</li><li>常见的MPI函数</li><li>使用MPI实现梯形积分法</li><li>中级：MPI中的集合通信</li><li>中级：MPI中的派生数据类型</li><li>中级：MPI中的计时方法</li><li>算法：奇偶并行排序算法</li><li>算法：并行正则采样排序</li></ol><a id="more"></a><h2 id="MPI中的hello-world"><a href="#MPI中的hello-world" class="headerlink" title="MPI中的hello world"></a>MPI中的hello world</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_STRING = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> greeting[MAX_STRING];</span><br><span class="line">    <span class="keyword">int</span> comm_sz;</span><br><span class="line">    <span class="keyword">int</span> my_rank;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Initialize the MPI environment</span></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">// Get the number of processes</span></span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line">    <span class="comment">// Get the rank of the process</span></span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (my_rank != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">sprintf</span>(greeting, <span class="string">"Greetings from process %d of %d!"</span>, my_rank, comm_sz);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Hello world from ank %d\n"</span>,my_rank);</span><br><span class="line">        MPI_Send(</span><br><span class="line">            greeting,</span><br><span class="line">            <span class="comment">// strlen(greeting)+1,</span></span><br><span class="line">            <span class="comment">// strlen(greeting),</span></span><br><span class="line">            MAX_STRING,</span><br><span class="line">            MPI_CHAR,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            MPI_COMM_WORLD</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Greetings from process %d of %d!\n"</span>, my_rank, comm_sz);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> q = <span class="number">1</span>; q &lt; comm_sz; q++)&#123;</span><br><span class="line">            MPI_Recv(</span><br><span class="line">                greeting,</span><br><span class="line">                MAX_STRING,</span><br><span class="line">                MPI_CHAR,</span><br><span class="line">                q,</span><br><span class="line">                <span class="number">0</span>,</span><br><span class="line">                MPI_COMM_WORLD,</span><br><span class="line">                MPI_STATUS_IGNORE</span><br><span class="line">            );</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%s in %d\n"</span>, greeting, my_rank);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Finalize the MPI environment.</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见的MPI函数"><a href="#常见的MPI函数" class="headerlink" title="常见的MPI函数"></a>常见的MPI函数</h2><p>这6个MPI函数，可以完成一切任务</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Init</span><span class="params">(<span class="keyword">int</span> *argc, <span class="keyword">char</span> **argv[])</span></span>;</span><br><span class="line"><span class="comment">// 进入MPI环境并完成所有的初始化工作</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Finalize</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="comment">// 从MPI环境中退出</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_rank</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *rank)</span></span>;</span><br><span class="line"><span class="comment">// 获得当前进程在指定通信域中的编号</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_size</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *size)</span></span>;</span><br><span class="line"><span class="comment">// 获得指定通信域中的进程数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> dest, <span class="keyword">int</span> tag, MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 发送消息到目标进程</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Recv</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> source, <span class="keyword">int</span> tag, MPI_Comm comm,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Status * status_p</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 从指定进程接受一个消息</span></span></span><br></pre></td></tr></table></figure><h2 id="使用MPI实现梯形积分法"><a href="#使用MPI实现梯形积分法" class="headerlink" title="使用MPI实现梯形积分法"></a>使用MPI实现梯形积分法</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 对这一个函数进行积分</span></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">f</span><span class="params">(<span class="keyword">double</span> x)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x*x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">Trap</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> left_endpt,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> right_endpt,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> trap_count,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> base_len</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">/**</span></span></span><br><span class="line"><span class="function"><span class="comment"> * @brief 梯形积分法的串行实现</span></span></span><br><span class="line"><span class="function"><span class="comment"> * </span></span></span><br><span class="line"><span class="function"><span class="comment"> * @param base_len 就是left_endpt与right_endpt之间分成trap_count份后，每一份的长度</span></span></span><br><span class="line"><span class="function"><span class="comment"> * </span></span></span><br><span class="line"><span class="function"><span class="comment"> */</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> estimate, x;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    estimate = (f(left_endpt) + f(right_endpt))/<span class="number">2.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= trap_count<span class="number">-1</span>; i++)&#123;</span><br><span class="line">        x = left_endpt + i*base_len;</span><br><span class="line">        estimate += f(x);</span><br><span class="line">    &#125;</span><br><span class="line">    estimate = estimate*base_len;</span><br><span class="line">    <span class="keyword">return</span> estimate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Get_input</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> my_rank,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> comm_sz,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> * a_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> * b_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>* n_p</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> dest;</span><br><span class="line">    <span class="keyword">if</span> (my_rank == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Enter a,b,and n\n"</span>);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%lf %lf %d"</span>, a_p, b_p, n_p);</span><br><span class="line">        <span class="keyword">for</span> (dest = <span class="number">1</span>; dest &lt; comm_sz; dest++)&#123;</span><br><span class="line">            MPI_Send(a_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(b_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(n_p, <span class="number">1</span>, MPI_INT, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        MPI_Recv(a_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(b_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(n_p, <span class="number">1</span>, MPI_INT, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"in trap %lf, %lf, %d\n"</span>, *a_p, *b_p, *n_p);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> my_rank, comm_sz, n=<span class="number">1024</span>, local_n;</span><br><span class="line">    <span class="keyword">double</span> a = <span class="number">0.0</span>, b = <span class="number">3.0</span>, h, local_a, local_b;</span><br><span class="line">    <span class="keyword">double</span> local_int, total_int;</span><br><span class="line">    <span class="keyword">int</span> source;</span><br><span class="line"></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line"></span><br><span class="line">    Get_input(my_rank, comm_sz, &amp;a, &amp;b, &amp;n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"in main %lf, %lf, %d\n"</span>, a, b, n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">    <span class="comment">// 将积分区间分成n份</span></span><br><span class="line">    h = (b-a)/n;</span><br><span class="line">    <span class="comment">// 将n分区间，分到comm_sz个进程里，每个进程分到local_n个区间</span></span><br><span class="line">    local_n = n/comm_sz;</span><br><span class="line"></span><br><span class="line">    local_a = a+my_rank*local_n*h;</span><br><span class="line">    local_b = local_a+local_n*h;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"local_a : %lf, local_b : %lf, local_n : %d"</span>, local_a, local_b, local_n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">    local_int = Trap(local_a, local_b, local_n, h);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (my_rank != <span class="number">0</span>)&#123;</span><br><span class="line">        MPI_Send(&amp;local_int, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        total_int = local_int;</span><br><span class="line">        <span class="keyword">for</span> (source = <span class="number">1</span>; source &lt; comm_sz; source++)&#123;</span><br><span class="line">            MPI_Recv(&amp;local_int, <span class="number">1</span>, MPI_DOUBLE, source, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">            total_int += local_int;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(my_rank == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"With n = %d trapezoids, out estimate\n"</span>, n);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"of the integral from %f to %f = %.15e\n"</span>,a,b,total_int);</span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的阻塞与非阻塞通信"><a href="#中级：MPI中的阻塞与非阻塞通信" class="headerlink" title="中级：MPI中的阻塞与非阻塞通信"></a>中级：MPI中的阻塞与非阻塞通信</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MPI_Send</span><br><span class="line"><span class="comment">// normal send</span></span><br><span class="line">MPI_Isend</span><br><span class="line"><span class="comment">// begin a nonblocking send</span></span><br><span class="line">MPI_Ssend</span><br><span class="line"><span class="comment">// Blocking synchronous send</span></span><br><span class="line"></span><br><span class="line">MPI_Bsend</span><br><span class="line"><span class="comment">// send message wich user-provided buffering</span></span><br><span class="line">MPI_Issend</span><br><span class="line"><span class="comment">// Starts a nonblocking synchronous send</span></span><br><span class="line">MPI_Ibsend</span><br><span class="line"><span class="comment">// Starts a nonblocking buffered send</span></span><br><span class="line">MPI_Rsend</span><br><span class="line"><span class="comment">// Blocking ready send</span></span><br><span class="line">MPI_Irsend</span><br><span class="line"><span class="comment">// Starts a nonblocking ready send</span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Irecv</span><br><span class="line"><span class="comment">// Begins a nonblocking receive</span></span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的集合通信"><a href="#中级：MPI中的集合通信" class="headerlink" title="中级：MPI中的集合通信"></a>中级：MPI中的集合通信</h2><p>涉及通信子中所有进程的通信函数成为集合通信（与点对点通信区分开）</p><p>MPI中的集合通信，在树中介绍的主要有以下几个函数：</p><table><thead><tr><th>函数名</th><th>作用</th></tr></thead><tbody><tr><td>MPI_Reduce</td><td>归约（可以用来求和等等,支持交换律和结合律的运算）</td></tr><tr><td>MPI_Allreduce</td><td>所有进程都可以得到全局求和的结果</td></tr><tr><td>MPI_Bcast</td><td>广播，顾名思义</td></tr><tr><td>MPI_Scatter</td><td>0号进程读入整个向量，但只将分量发送给需要分量的其他进程</td></tr><tr><td>MPI_Gather</td><td>将其他进程的分量都收集到0号进程</td></tr><tr><td>MPI_Allgather</td><td>将每个进程desend_buf_p内容串联起来，存储到每个进程的recv_buf_p参数中</td></tr></tbody></table><p>下面一个一个函数分别说明其参数情况。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Reduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Op op,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allreduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Op op,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Bcast</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buffer, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Scatter</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Gather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allgather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount,  <span class="comment">// local_n</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, <span class="comment">// local_n</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的派生数据类型"><a href="#中级：MPI中的派生数据类型" class="headerlink" title="中级：MPI中的派生数据类型"></a>中级：MPI中的派生数据类型</h2><blockquote><p>在MPI中，通过同时存储数据项的类型以及他们在内存中的相对位置，派生数据类型可以表示内存中数据项的任意集合。</p></blockquote><p>在书本中，派生数据类型用在了，减少通信量上。</p><p>一般创建一个新的派生数据类型，需要进行以下的步骤：</p><ol><li>调用<code>MPI_Type_create_struct</code>函数，创建派生数据类型<ol><li>可使用<code>MPI_Get_address</code>辅助得到相对地址</li></ol></li><li>调用<code>MPI_Type_commit</code>函数，允许MPI实现为了在通信函数内使用这一数据类型，优化数据类型的内部表示</li><li>使用结束后，调用<code>MPI_Type_free</code>函数释放额外的存储空间</li></ol><h3 id="函数原型"><a href="#函数原型" class="headerlink" title="函数原型"></a>函数原型</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_create_struct</span><span class="params">(<span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> <span class="keyword">int</span> array_of_blocklengths[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> MPI_Aint array_of_displacements[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> MPI_Datatype array_of_types[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           MPI_Datatype * newtype</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_commit</span><span class="params">(MPI_Datatype * datatype_p)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_free</span><span class="params">(MPI_Datatype * datatype)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p><img src="https://lh3.googleusercontent.com/-ZQmKH0alUZ4/XDx4AZvqyiI/AAAAAAAANps/UnqSTxTMGJ4OO2Nq86kZFBMXJCN_YKBEQCHMYCw/s0/Acrobat_2019-01-14_19-52-35.png" alt=""></p><h2 id="中级：MPI中的计时方法"><a href="#中级：MPI中的计时方法" class="headerlink" title="中级：MPI中的计时方法"></a>中级：MPI中的计时方法</h2><ol><li><code>MPI_Wtime</code></li><li><code>MPI_Barrier</code></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MPI_Barrier(comm);</span><br><span class="line">local_start = MPI_Wtime();</span><br><span class="line"></span><br><span class="line">....</span><br><span class="line">    </span><br><span class="line">local_finish = MPI_Wtime();</span><br><span class="line">local_elapsed = local_finish - local_start;</span><br></pre></td></tr></table></figure><h2 id="算法：并行奇偶交换排序"><a href="#算法：并行奇偶交换排序" class="headerlink" title="算法：并行奇偶交换排序"></a>算法：并行奇偶交换排序</h2><h3 id="奇偶交换排序"><a href="#奇偶交换排序" class="headerlink" title="奇偶交换排序"></a>奇偶交换排序</h3><p>关键思想：去耦的比较-交换</p><ol><li>偶数阶段：以下数对进行比较-交换<ol><li>$(a[0], a[1]), (a[2],a[3]), (a[4],a[5]),…$</li></ol></li><li>奇数阶段：以下数对进行比较-交换<ol><li>$(a[1], a[2]), (a[3],a[4]), (a[5],a[6]),…$</li></ol></li><li>定理：n个值的列表，经过n个阶段后，该列表一定能够排好序。</li></ol><h3 id="并行化"><a href="#并行化" class="headerlink" title="并行化"></a>并行化</h3><p>步骤：</p><ol><li>将数据分到不同的进程之后，先本地进行一个qsort排个序</li><li>偶数阶段：进程0,1，进程2,3进行比较-交换数据</li><li>奇数阶段：进程1,2， 进程3,4进行比较-交换数据</li></ol><p><img src="https://lh3.googleusercontent.com/-eZA5pXZnybQ/XDx7VnZQdDI/AAAAAAAANp4/DVSafASPAYgRV2LWJXEz1F-a4z06JGiHQCHMYCw/s0/Acrobat_2019-01-14_20-06-48.png" alt=""></p><h2 id="算法：并行正则采样排序"><a href="#算法：并行正则采样排序" class="headerlink" title="算法：并行正则采样排序"></a>算法：并行正则采样排序</h2><ol><li>数据初始化阶段：每个进程根据进程号与数据量，计算得到本进程所读取的数据范围，并从文件中直接读取。由于读取数据的步骤不需要进行通信分发，提高了程序运行的效率。</li><li>每一个进程对其本地的无序数据,长度为$local_n$的$local_buffer$数组进行串行快速排序，从而在每个处理器上都得到一个有序的序列$local_buffer$。</li><li>在每一个处理器上选取代表元素：每一个处理器从局部有序序列中选取第$w$，第$2<em>w$，第$3</em>w$,第$(comm_sz-1)w$共$p-1$个代表元素，其中$w=comm_sz/(p*p)$。</li><li>进程0收集每一个进程中得到的代表元素，从而具有了$(p-1)<em>(p-1)$个代表元素，然后进程0对所有代表元素进行排序，选取第$comm_sz-1$，第$2</em>(comm_sz-1)$，第$3<em>(comm_sz-1)\ \cdots (comm_sz-1)</em>(comm_sz-1)$个元素，这$comm_sz-1$个元素作为主元。</li><li>进程0将上一步中得到的$comm_sz-1$个主元$pivot_values$，分发到其余所有处理器上。</li><li>局部有序序列划分：每一个处理器根据这$comm_sz-1$个主元，将本地的$local_buffer$划分成$comm_sz$段。</li><li>有序序列的分发：在上一个步骤中的$comm_sz$段序列中，每一个处理器将本地的第$i$段发送给第$i$个处理器，最终处理器$i$拥有所有处理器的第$i$段。</li><li>最终排序：每个处理器对上一步中得到的$comm_sz$段有序序列进行排序，即为最终结果。</li></ol><h2 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h2><h3 id="向量求和"><a href="#向量求和" class="headerlink" title="向量求和"></a>向量求和</h3><ol><li>块划分:简单的将连续N个分量所构成的块，分配到每个进程中。</li><li>循环划分:采用轮转的方式去分配向量分量</li><li>块-循环划分:用一个循环来分发向量分量所构成的块，而不是分发单个向量分量。</li></ol><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol><li>在什么场景下必须使用消息标签？<ol><li><img src="https://lh3.googleusercontent.com/-ac7MTJh3T3s/XDxVtBXjiPI/AAAAAAAANpI/VWRc8sgUPlIUJBJHvgJjXZCqcIUp9PzJgCHMYCw/s0/Acrobat_2019-01-14_17-26-13.png" alt=""></li><li>这段代码打算传送A的前32个字节进入X,传送B的前16个字节进入Y.但是,如果消息B尽管后发送但先到达进程Q,就会被第一个recv()接收在X中，使用标签就可以避免这种情况</li><li><img src="https://lh3.googleusercontent.com/-9IwMxoVBf2k/XDxV13-N1SI/AAAAAAAANpM/rZe2IYt1JLIzwqtUtfsiS1QiGPCRFt_qgCHMYCw/s0/Acrobat_2019-01-14_17-26-49.png" alt=""></li></ol></li><li>MPI_Send与MPI_Recv的问题<ol><li>Send的精确行为是由MPI实现决定的，MPI_Send可能有不同大小的缓冲区，在发送消息的时候，是使用缓冲区，还是直接阻塞等待发送完成，由“消息截止大小”决定。</li><li>启示：了解实际执行情况，不要做假设。</li></ol></li><li>关于MPI_Reduce调用顺序<ol><li><img src="https://lh3.googleusercontent.com/-yu7mVk_1EZE/XDxuhZnZycI/AAAAAAAANpg/6efvirvvmQc1TStPAXBgC2ryDgv-cMwHgCHMYCw/s0/Acrobat_2019-01-14_19-12-06.png" alt=""></li><li>内存单元的名字与MPI_Reduce的调用匹配无关，函数调用的顺序决定了匹配方式。</li><li>！！不可预测，可能b中存储的值将是$1+2+1=4$，而d中为$2+1+2=5$</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习2-MPI&quot;&gt;&lt;a href=&quot;#HPC复习2-MPI&quot; class=&quot;headerlink&quot; title=&quot;HPC复习2-MPI&quot;&gt;&lt;/a&gt;HPC复习2-MPI&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.open-mpi.org/doc/current/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;OpenMPI 官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.mpich.org/static/docs/latest/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;mpich官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里是高性能计算课程-MPI部分的复习笔记，大概会有以下内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MPI中的Hello world&lt;/li&gt;
&lt;li&gt;常见的MPI函数&lt;/li&gt;
&lt;li&gt;使用MPI实现梯形积分法&lt;/li&gt;
&lt;li&gt;中级：MPI中的集合通信&lt;/li&gt;
&lt;li&gt;中级：MPI中的派生数据类型&lt;/li&gt;
&lt;li&gt;中级：MPI中的计时方法&lt;/li&gt;
&lt;li&gt;算法：奇偶并行排序算法&lt;/li&gt;
&lt;li&gt;算法：并行正则采样排序&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
</feed>
