<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog</title>
  
  <subtitle>My Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wwyf.github.io/"/>
  <updated>2019-01-15T08:13:49.733Z</updated>
  <id>https://wwyf.github.io/</id>
  
  <author>
    <name>wyf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>高性能计算基础-复习6-CUDA优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A06-CUDA%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习6-CUDA优化/</id>
    <published>2019-01-15T08:13:09.000Z</published>
    <updated>2019-01-15T08:13:49.733Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习6-cuda优化"><a href="#HPC复习6-cuda优化" class="headerlink" title="HPC复习6-cuda优化"></a>HPC复习6-cuda优化</h1><p>在cuda程序的优化中，需要考虑以下几个问题</p><ol><li>了解SM核中所提供的资源，并合理分配。</li><li>确定kernel的启动参数，以尽可能提高cuda程序的性能。</li><li>理解warp隐藏延时的作用，知道为什么warp越多越能隐藏延时。</li><li>通过数据预读取隐藏访存延时。</li><li>了解不同指令的吞吐量，并优化之。</li></ol><a id="more"></a><h2 id="SM资源分割"><a href="#SM资源分割" class="headerlink" title="SM资源分割"></a>SM资源分割</h2><h3 id="需要确定的值"><a href="#需要确定的值" class="headerlink" title="需要确定的值"></a>需要确定的值</h3><ol><li>block的数量</li><li>thread的数量</li></ol><h3 id="与分配资源有关的参数"><a href="#与分配资源有关的参数" class="headerlink" title="与分配资源有关的参数"></a>与分配资源有关的参数</h3><ol><li>线程块槽数量（thread block slot）：block数量的上限</li><li>线程槽数量（thread slot）</li><li>寄存器的数量</li><li>shared memory的大小</li></ol><h3 id="分配资源的数量，与哪些因素有关"><a href="#分配资源的数量，与哪些因素有关" class="headerlink" title="分配资源的数量，与哪些因素有关"></a>分配资源的数量，与哪些因素有关</h3><ol><li>原则一：单个SM核上分配的线程数（block*每个block具有的线程数）越大，线程级别的并行越大（前提与sm核实际运行的状况有关，需要想清楚）<ol><li>线程越多，warp越多，可运行的用来隐藏访存时间的warp就越多，因此就可以尽可能让GPU达到满负荷工作，不会由于访存延迟使得gpu空闲。</li></ol></li><li>原则二：单个SM核上的所有寄存器，平均分配给各个线程，因此，线程数量越多，单个线程可用的寄存器越少<ol><li>性能悬崖警惕：减少1/3的线程（并行度），仅仅让每一个线程增加了1个寄存器，除非由于寄存器不足导致了较大的访存开销，否则小心调整。</li></ol></li><li>原则三：对block的数量需要注意，尽量让每一个SM核上都具有多个block，这样子如果一个block在等待同步，可以启动另一个block<ol><li>需要知道SM核的数量</li></ol></li><li>原则五：『关于shared memory』<ol><li>shared memory按block分割，block过多可能会让单个block所具有的shared memory脱销</li></ol></li></ol><h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><p>对G80而言，与分配相关的参数可见：</p><p><img src="https://lh3.googleusercontent.com/-kTJQHo2890Y/XD2P6Ak0g2I/AAAAAAAANx4/HmgaxgQefeAXjfCrvVLuaHq1WeG4QGtAwCHMYCw/s0/Acrobat_2019-01-15_15-46-48.png" alt=""></p><p>有这样的一个情景，在每个block都含256个线程的情况下，一个SM核可能有以下两种情况：</p><p><img src="https://lh3.googleusercontent.com/-lbe-eNMWhP0/XD2PuXTO_aI/AAAAAAAANx0/Z0Grw8p5d0sLkhYhQM5eEafxGO_6aMF8ACHMYCw/s0/Acrobat_2019-01-15_15-46-01.png" alt=""></p><p>这里就可以发现，每个线程多了一个寄存器，但是带来的影响是，总的可以运行的线程的数量变为原来的2/3，也就是说，并行度是原来的2/3了。</p><p>这个可以给我一个启示：除非为了隐藏global memory访存延迟，否则尽可能不要为了增加寄存器数量而降低并行性。</p><h2 id="Kernel启动参数配置"><a href="#Kernel启动参数配置" class="headerlink" title="Kernel启动参数配置"></a>Kernel启动参数配置</h2><h3 id="需要确定以下参数"><a href="#需要确定以下参数" class="headerlink" title="需要确定以下参数"></a>需要确定以下参数</h3><ol><li><p>grid（block的数量）：主要看$\frac{blocks}{sm}$</p><ol><li>大于1：每个SM至少有一个block在执行</li><li>大于2：多个block可以在SM核上并发执行，如果一个block在等待同步，可以启动另一个block</li><li>大于100：对未来设备有很好的伸缩性</li></ol></li><li><p>block（thread的数量）</p><ol><li><p>块大小必须为32的倍数</p></li><li><p>warp尽可能多，隐藏延时</p></li><li><p>64,128,256 等等，试一下，经验成分比较多</p></li></ol></li></ol><h2 id="隐藏延时-相关计算"><a href="#隐藏延时-相关计算" class="headerlink" title="隐藏延时-相关计算"></a>隐藏延时-相关计算</h2><p>问题：需要使用多少个warp来隐藏某操作的延时，此时占用率多大？</p><blockquote><p>占用率：激活warp与最大可容纳warp数目的比值</p><p>最大warp数目: 32 in Tesla, 48 in Fermi</p></blockquote><h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><p><img src="https://lh3.googleusercontent.com/-_DlX9mCbLX8/XD2Sz8Y7WRI/AAAAAAAANyI/clacnlWedsAqyV5mozO0HiLdBlBAskVVwCHMYCw/s0/Acrobat_2019-01-15_15-59-11.png" alt=""></p><h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><p><img src="https://lh3.googleusercontent.com/-pgQYXjs0hrU/XD2S4yZQCiI/AAAAAAAANyM/rwa9BCsy02EMvIOUSQZmUg4dURBSj05LACHMYCw/s0/Acrobat_2019-01-15_15-59-31.png" alt=""></p><h2 id="数据预读"><a href="#数据预读" class="headerlink" title="数据预读"></a>数据预读</h2><blockquote><p>数据预读：在某global memroy变量的读操作，与该变量的实际使用语句之间，插入与该数据无关的独立指令，可以隐藏访存延迟</p></blockquote><p>例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> m = Md[i];</span><br><span class="line"><span class="keyword">float</span> f = a*b + c*d; <span class="comment">// 无关指令，隐藏访存延时</span></span><br><span class="line"><span class="keyword">float</span> f2 = m * f;</span><br></pre></td></tr></table></figure><h3 id="如何在矩阵乘法中使用预读操作进行优化"><a href="#如何在矩阵乘法中使用预读操作进行优化" class="headerlink" title="如何在矩阵乘法中使用预读操作进行优化"></a>如何在矩阵乘法中使用预读操作进行优化</h3><p>代码模板如下，</p><p>注意到中间的预读在计算点积前面，这样子中间的点积在运算时便可以隐藏预读内存产生的误差了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Load first tile into registers</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="comment">/* ... */</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// Deposit registers into shared memory</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Load next tile into registers</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Accumulate dot product</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="指令吞吐量优化"><a href="#指令吞吐量优化" class="headerlink" title="指令吞吐量优化"></a>指令吞吐量优化</h2><p>了解每一种指令的吞吐量，减少使用昂贵的指令。</p><h3 id="一些指令的吞吐量"><a href="#一些指令的吞吐量" class="headerlink" title="一些指令的吞吐量"></a>一些指令的吞吐量</h3><table><thead><tr><th>int &amp; fp32</th><th>2 cycles</th></tr></thead><tbody><tr><td>fp64:</td><td>2 cycles</td></tr><tr><td>fp32 transendental</td><td>8 cycles</td></tr><tr><td>int devide/modulo</td><td>expensive</td></tr></tbody></table><blockquote><p>优化建议：</p><ol><li>与<code>2^n</code>运算，尽量使用位运算，如<code>&gt;&gt; n``&lt;&lt; n</code></li><li>在float常量中添加f，（缺省是double，会导致隐式的类型转换）</li></ol></blockquote><h3 id="数学函数的吞吐量提高"><a href="#数学函数的吞吐量提高" class="headerlink" title="数学函数的吞吐量提高"></a>数学函数的吞吐量提高</h3><ol><li>cuda中两种类型的运行时数学函数<ol><li>func()</li><li>__func()：使用硬件加速，SFU，精度低</li></ol></li><li><code>--use-fast-math</code>编译指令，强制使用硬件加速的数学函数</li></ol><h3 id="循环展开"><a href="#循环展开" class="headerlink" title="循环展开"></a>循环展开</h3><blockquote><p>原理：循环中除了循环体，还有更新计数器，判断条件，计算地址等指令，减少这些无关指令的运算可以加速</p></blockquote><p>例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k =<span class="number">0</span>;k &lt; <span class="number">16</span>;++k)</span><br><span class="line">&#123;</span><br><span class="line">Pvalue +=Ms[ty][k]*Ns[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这其中含有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2条浮点运算</span><br><span class="line">1条循环分支</span><br><span class="line">2条地址运算</span><br><span class="line">1条循环计数器自增</span><br></pre></td></tr></table></figure><p><strong>仅1/3是浮点计算！！！</strong></p><p>做以下改动：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Pvalue += </span><br><span class="line">    Ms[ty][<span class="number">0</span>] * Ns[<span class="number">0</span>][tx] + </span><br><span class="line">    Ms[ty][<span class="number">1</span>] * Ns[<span class="number">1</span>][tx] + </span><br><span class="line">    ...</span><br><span class="line">    Ms[ty][<span class="number">15</span>] * Ns[<span class="number">15</span>][tx];</span><br></pre></td></tr></table></figure><p>从而减少了循环分支，自增，同时地址运算也可以减少。</p><p>自动完成循环展开：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> unroll 16</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k =<span class="number">0</span>;k &lt; <span class="number">16</span>;++k)</span><br><span class="line">&#123;</span><br><span class="line">Pvalue +=Ms[ty][k]*Ns[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>由于展开能够消除分支以及一些管理归纳变量的代码，因此可以摊销一些分支开销。<br>展开可以积极调度（或管道化）循环以掩盖一些延迟。如果有足够的空闲寄存器使变量保持活动状态，因为通过展开相关性链展露了关键路径，这将非常有用。</p></blockquote><p>但</p><blockquote><p>展开过度或展开非常大的循环时，可能导致代码篇幅增加。如果展开后的循环不能再放入跟踪缓存 (TC)，这将有害无益。</p><p>展开循环体中包含分支的循环时，会增加对 BTB 容量的需求。如果展开后循环的迭代次数是 16 或更少，则分支预测应该能正确预测循环体中改变方向的分支。</p></blockquote><h2 id="课上提醒"><a href="#课上提醒" class="headerlink" title="课上提醒"></a>课上提醒</h2><ol><li>如果一整个warp没有指令要执行，不会占住SP，一上来就下去，但只要warp中有一个线程要执行，那就一定会占住SP</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习6-cuda优化&quot;&gt;&lt;a href=&quot;#HPC复习6-cuda优化&quot; class=&quot;headerlink&quot; title=&quot;HPC复习6-cuda优化&quot;&gt;&lt;/a&gt;HPC复习6-cuda优化&lt;/h1&gt;&lt;p&gt;在cuda程序的优化中，需要考虑以下几个问题&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;了解SM核中所提供的资源，并合理分配。&lt;/li&gt;
&lt;li&gt;确定kernel的启动参数，以尽可能提高cuda程序的性能。&lt;/li&gt;
&lt;li&gt;理解warp隐藏延时的作用，知道为什么warp越多越能隐藏延时。&lt;/li&gt;
&lt;li&gt;通过数据预读取隐藏访存延时。&lt;/li&gt;
&lt;li&gt;了解不同指令的吞吐量，并优化之。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.3-CUDA线程</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-3-CUDA%E7%BA%BF%E7%A8%8B/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-3-CUDA线程/</id>
    <published>2019-01-15T07:21:22.000Z</published>
    <updated>2019-01-15T07:21:49.107Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><hr><h2 id="typora-copy-images-to-figure"><a href="#typora-copy-images-to-figure" class="headerlink" title="typora-copy-images-to: figure"></a>typora-copy-images-to: figure</h2><h1 id="HPC复习5-3-CUDA线程"><a href="#HPC复习5-3-CUDA线程" class="headerlink" title="HPC复习5.3-CUDA线程"></a>HPC复习5.3-CUDA线程</h1><p>这里主要想想明白一个事：</p><p>已知的是，会有多个block，分配到SM核上来执行。</p><p>也知道，单一时间上，SM核仅有一个warp在运行。</p><p>问题是：</p><ol><li>SM核内部的结构是如何的？</li><li>warp的实际执行情况是如何的？</li><li>warp的并发执行是否会引发一些问题？如何解决？</li></ol><a id="more"></a><h2 id="SM核架构"><a href="#SM核架构" class="headerlink" title="SM核架构"></a>SM核架构</h2><p>对SM核的架构该如何理解？</p><ol><li>2个warp调度器与2个指令分派单元能够将2个warp同时进行发射和执行:</li><li>双warp调度器先选择两个warp，然后从每个warp发射一条指令到一个十六核心的组，或是十六个读写单元或是四个SFU。</li></ol><p><img src="figure/Acrobat_2019-01-15_15-18-20.png" alt=""></p><h2 id="Single-Warp"><a href="#Single-Warp" class="headerlink" title="Single Warp"></a>Single Warp</h2><p>对于单个warp内部的并行执行，可能会遇到以下的一些问题：</p><h3 id="单个warp上可能发生的访存冲突"><a href="#单个warp上可能发生的访存冲突" class="headerlink" title="单个warp上可能发生的访存冲突"></a>单个warp上可能发生的访存冲突</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (warpIdx == <span class="number">0</span>) &#123;</span><br><span class="line">    __shared__ <span class="keyword">int</span> v;</span><br><span class="line">    v = <span class="number">0</span>;</span><br><span class="line">    ++v;</span><br><span class="line">    v == ?</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>注意到share memory在一个block内是能够共享的，因此这一段代码由于会导致错误。</li><li>解决这一个问题可以使用<code>atomicAdd(&amp;v, 1);</code>来实现。</li><li>注意到CUDA不支持临界区。</li></ol><p><img src="https://lh3.googleusercontent.com/-nSO5ewSSqtw/XD15aShcuWI/AAAAAAAANvw/b4Vgwb5THG0NvN8vTR011C3KATyKXZ1IgCHMYCw/s0/Acrobat_2019-01-15_14-10-49.png" alt=""></p><h3 id="warp如何处理分支指令？"><a href="#warp如何处理分支指令？" class="headerlink" title="warp如何处理分支指令？"></a>warp如何处理分支指令？</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> warpIdx = threadIdx.x / <span class="number">32</span>;</span><br><span class="line"><span class="keyword">int</span> laneIdx = threadIdx.x % <span class="number">32</span>;</span><br><span class="line"><span class="keyword">if</span> (warpIdx == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (laneIdx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">    doA();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    doB();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>事实上，warp线程在执行上面代码的时候，图示可见如下：</p><p><img src="https://lh3.googleusercontent.com/-iMVFZM74Hxk/XD16kGp5FmI/AAAAAAAANv4/A4cKphyGtmAWbN00g02kvXHckXrIUbW8ACHMYCw/s0/Acrobat_2019-01-15_14-15-43.png" alt=""></p><ol><li>有很多branch的代码是低效的。</li><li>复杂的控制流，如break，continue，会导致代码低效，可能会出现bug。</li></ol><h3 id="Warp-functions"><a href="#Warp-functions" class="headerlink" title="Warp functions"></a>Warp functions</h3><ol><li><code>__all(predicate);</code><ol><li>return 1 if and only if predicate evaluates to non-zero for all of them.</li></ol></li><li><code>__any(predicate);</code><ol><li>return 1 if and only if predicate evaluates to non-zero for any of them.</li></ol></li><li><img src="https://lh3.googleusercontent.com/-vw2oRXY0li8/XD176bbVsSI/AAAAAAAANwE/YbZ0jpSYt-sFHT40WYokkHGAJeXx60SkACHMYCw/s0/Acrobat_2019-01-15_14-21-29.png" alt=""></li><li><code>__ballot(predicate);</code><ol><li>return an integer whose Nth bit is set if and only if predicate evaluates to non-zero for the Nth thread of the warp and the Nth thread is active.</li><li><img src="https://lh3.googleusercontent.com/-ueHU6gtByjg/XD18A5HFrwI/AAAAAAAANwI/p8mfYDejS8ch_4Uv6nWAmGBPhbzYTmPawCHMYCw/s0/Acrobat_2019-01-15_14-21-56.png" alt=""></li></ol></li></ol><h2 id="Multi-Warp"><a href="#Multi-Warp" class="headerlink" title="Multi Warp"></a>Multi Warp</h2><p>多个warp并发执行，可能会导致一些问题。</p><ol><li>多个warp之间的并发执行顺序不定，这会带来一些问题（联想：多线程可能会带来的问题）</li><li>warp内分支也可能会带来问题，导致性能损失。</li></ol><h3 id="warp之间无序的并发执行会带来哪些问题？"><a href="#warp之间无序的并发执行会带来哪些问题？" class="headerlink" title="warp之间无序的并发执行会带来哪些问题？"></a>warp之间无序的并发执行会带来哪些问题？</h3><ol><li>RaW（read after write）<ol><li>如果先写后读，由于后面读的时候，不知道其他warp写了没，可能会导致问题。</li><li><img src="https://lh3.googleusercontent.com/-uZj9SMP3wek/XD2FvMI87DI/AAAAAAAANwY/Q9uTD9MADB8MWDfVfsvAa2TUKIudidUWQCHMYCw/s0/Acrobat_2019-01-15_15-03-24.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-yt2kMUSQDq0/XD2FySx5pXI/AAAAAAAANwc/LeaX4scfJho6PhzfKyFJdsdAx5BbvfUrwCHMYCw/s0/Acrobat_2019-01-15_15-03-38.png" alt=""></li></ol></li><li>WaR（write after read）<ol><li>读后写，同样的写的时候，不知道前面读的值是否是最新的</li><li><img src="https://lh3.googleusercontent.com/-VJn672ZJxe8/XD2F4RJLBHI/AAAAAAAANwg/9y8nqyw1vE4Mge5Z4juJzuFSQK_7nu1FwCHMYCw/s0/Acrobat_2019-01-15_15-04-01.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-iV8FnRM_3eU/XD2F8DrVM9I/AAAAAAAANwk/Ym3R5o17uIMJglDNqYgX1uN--2SU0ikaQCHMYCw/s0/Acrobat_2019-01-15_15-04-17.png" alt=""></li></ol></li><li>WaW（write after write）<ol><li>写后写，同样的，不同的warp之间的写语句，可能运行的相对顺序不一样。</li><li><img src="https://lh3.googleusercontent.com/-yOpBk_JMEj4/XD2GCgXNvkI/AAAAAAAANws/C2i1Fn7EUSga1XeiHh0QbVy7RsPI_ck2ACHMYCw/s0/Acrobat_2019-01-15_15-04-42.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-b3Q1lYpBoVY/XD2GHe4prVI/AAAAAAAANww/iU36UTs-t5ARlM2uFWfZGrQFYgP2SCl2wCHMYCw/s0/Acrobat_2019-01-15_15-05-01.png" alt=""></li></ol></li><li>如何解决：使用<code>__syncthreads()</code>函数<ol><li><img src="https://lh3.googleusercontent.com/-iEnKp2ahX90/XD2GqKA7g6I/AAAAAAAANxA/1TkcMbml8LkK_9l9UVX-HesqNxjL-3O5gCHMYCw/s0/Acrobat_2019-01-15_15-07-20.png" alt=""></li></ol></li></ol><h3 id="branch如何影响多个warp运行的性能？"><a href="#branch如何影响多个warp运行的性能？" class="headerlink" title="branch如何影响多个warp运行的性能？"></a>branch如何影响多个warp运行的性能？</h3><p>对代码段：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (laneIdx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">doA();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">doB();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>结论：</p><ol><li>如果一个warp内的线程有的运行<code>doA</code>，有的运行<code>doB</code>，那么这一个warp必须两部分都运行</li><li>如果一个warp内的线程仅运行其中一个函数，那么该分支语句就不会带来影响</li></ol></li><li><p>以下分三种情况分别观察情况</p><ol><li>（warp-divergent）一个warp内，有的需要运行<code>doA</code>，有的需要运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-G68TmtaLlMA/XD2Hc6NgCPI/AAAAAAAANxM/VwoZls0KjzMr-s9XCHH451eYMx3XBRKVQCHMYCw/s0/Acrobat_2019-01-15_15-10-43.png" alt=""></li></ol></li><li>(warp-uniform)在同一个block内，有的warp运行<code>doA</code>，有的warp运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-1kdv3JnV8eg/XD2Hj5fN6JI/AAAAAAAANxQ/pLe-5ghYggQ70bhXCeU5ips2MG02p_8WwCHMYCw/s0/Acrobat_2019-01-15_15-11-11.png" alt=""></li></ol></li><li>(block-uniform)不同的block，有的block运行<code>doA</code>，有的block运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-441QzpylRK0/XD2HowdmwLI/AAAAAAAANxU/0nkBL7fTwycSth6o5VV7swq4K9JT_RXUQCHMYCw/s0/Acrobat_2019-01-15_15-11-32.png" alt=""></li></ol></li><li>总结：block-uniform方式能够更好的减少性能损失</li></ol></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这幅图我觉得很好地将之前讲过的很多东西都联系了在一起，那就放上来慢慢观赏吧。</p><p><img src="https://lh3.googleusercontent.com/-8wO_TbAmW08/XD2IhLEAcTI/AAAAAAAANxg/vga83BRrlc4Nk8ebfYTnoOy1FLbJIA6zACHMYCw/s0/Acrobat_2019-01-15_15-15-16.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;typora-copy-images-to-figure&quot;&gt;&lt;a href=&quot;#typora-copy-images-to-figure&quot; class=&quot;headerlink&quot; title=&quot;typora-copy-images-to: figure&quot;&gt;&lt;/a&gt;typora-copy-images-to: figure&lt;/h2&gt;&lt;h1 id=&quot;HPC复习5-3-CUDA线程&quot;&gt;&lt;a href=&quot;#HPC复习5-3-CUDA线程&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.3-CUDA线程&quot;&gt;&lt;/a&gt;HPC复习5.3-CUDA线程&lt;/h1&gt;&lt;p&gt;这里主要想想明白一个事：&lt;/p&gt;
&lt;p&gt;已知的是，会有多个block，分配到SM核上来执行。&lt;/p&gt;
&lt;p&gt;也知道，单一时间上，SM核仅有一个warp在运行。&lt;/p&gt;
&lt;p&gt;问题是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SM核内部的结构是如何的？&lt;/li&gt;
&lt;li&gt;warp的实际执行情况是如何的？&lt;/li&gt;
&lt;li&gt;warp的并发执行是否会引发一些问题？如何解决？&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.2-CUDA访存</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-2-CUDA%E8%AE%BF%E5%AD%98/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-2-CUDA访存/</id>
    <published>2019-01-15T05:30:18.000Z</published>
    <updated>2019-01-15T05:33:09.302Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-2-CUDA访存"><a href="#HPC复习5-2-CUDA访存" class="headerlink" title="HPC复习5.2-CUDA访存"></a>HPC复习5.2-CUDA访存</h1><p>这里就主要对cuda中的访存模式进行比较详细地说明吧。</p><ol><li>GPU中，5种不同存储部件的特性及使用方式</li><li>GPU中，如何使用合并访存加速</li><li>下图是GPU中的存储设备的大图</li></ol><p><img src="https://lh3.googleusercontent.com/-FME8Iu_B5cI/XD1D5vIEeaI/AAAAAAAANsE/9ObTV12e34ArBzh9o90oEjCsNBJ_X1LZQCHMYCw/s0/Acrobat_2019-01-15_10-22-29.png" alt=""></p><a id="more"></a><h2 id="GPU中的存储部件"><a href="#GPU中的存储部件" class="headerlink" title="GPU中的存储部件"></a>GPU中的存储部件</h2><h3 id="如何使用global-memory"><a href="#如何使用global-memory" class="headerlink" title="如何使用global memory?"></a>如何使用global memory?</h3><p>有两种方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="title">add4f</span><span class="params">(<span class="keyword">float</span>* u, <span class="keyword">float</span>* v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i=threadIdx.x;</span><br><span class="line">    u[i]+=v[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> hostU[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span> hostV[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span>* devU, devV;</span><br><span class="line">    <span class="keyword">size_t</span> size = <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*<span class="number">4</span>;</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;devU, size);</span><br><span class="line">    cudaMalloc(&amp;devV, size);</span><br><span class="line">    </span><br><span class="line">    cudaMemcpy(devU, hostU, size, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(devV, hostV, size, cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    add4f&lt;&lt;&lt;<span class="number">1</span>,<span class="number">4</span>&gt;&gt;&gt;(devU, devV);</span><br><span class="line">    cudaMemcpy(hostU, devU, size, cudaMemcpyDeviceToHost);</span><br><span class="line">    </span><br><span class="line">    cudaFree(devV);</span><br><span class="line">    cudaFree(devU);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二种方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__device__ <span class="keyword">float</span> devU[<span class="number">4</span>];</span><br><span class="line">__device__ <span class="keyword">float</span> devV[<span class="number">4</span>];</span><br><span class="line">__<span class="function">global__ <span class="title">addUV</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i=threadIdx.x;</span><br><span class="line">    devU[i]+=devV[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> hostU[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span> hostV[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">size_t</span> size = <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*<span class="number">4</span>;</span><br><span class="line">    cudaMemcpyToSymbol(devU, hostU, size, <span class="number">0</span>, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpyToSymbol(devV, hostV, size, <span class="number">0</span>, cudaMemcpyHostToDevice);</span><br><span class="line">    addUV&lt;&lt;&lt;<span class="number">1</span>,<span class="number">4</span>&gt;&gt;&gt;();</span><br><span class="line">    cudaMemcpyFromSymbol(hostU, devU, size, <span class="number">0</span>, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>一点点小疑问</p><p>cudaMemcpyToSymbol和cudaMemcpy的区别，可见<a href="https://blog.csdn.net/litdaguang/article/details/45047015" target="_blank" rel="noopener">link</a></p></blockquote><h3 id="如何使用constant-cache？该种存储空间有什么特点？"><a href="#如何使用constant-cache？该种存储空间有什么特点？" class="headerlink" title="如何使用constant cache？该种存储空间有什么特点？"></a>如何使用constant cache？该种存储空间有什么特点？</h3><ol><li><p>这样使用：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">__constant__ <span class="keyword">int</span> devVar</span><br><span class="line"></span><br><span class="line">cudaMemcpyToSymbol(</span><br><span class="line">    devVar, &amp;hostVar, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), <span class="number">0</span>,</span><br><span class="line">    cudaMemcpyHostToDevice</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cudaMemcpyFromSymbol(</span><br><span class="line">    &amp;hostVar, devVar, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), <span class="number">0</span>,</span><br><span class="line">    cudaMemcpyDeviceToHost</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>注意到，这种类型的使用，不需要显式的free</p></li></ol></li><li><p>constant cache的特点？</p><ol><li>空间大小上限为4KB</li><li>不依赖于threadIdx</li></ol></li></ol><h3 id="如何使用shared-memory？"><a href="#如何使用shared-memory？" class="headerlink" title="如何使用shared memory？"></a>如何使用shared memory？</h3><ol><li><p>有两种方式来使用：静态分配与动态分配</p><ol><li><p>静态分配如下设置：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="keyword">int</span> shArr[<span class="number">4</span>];</span><br></pre></td></tr></table></figure></li></ol></li><li><p>动态分配可以这样设置：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="keyword">int</span> shArr[];</span><br><span class="line">kernel&lt;&lt;&lt;grid,block,<span class="keyword">sizeof</span>(<span class="keyword">int</span>)*<span class="number">4</span>&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure></li></ol></li></ol></li><li><p>这种memory 的特点？</p><ol><li><img src="https://lh3.googleusercontent.com/-0wOJ6oyRp14/XD1KCIF0C8I/AAAAAAAANsQ/Q44B4ty6zoce_X5HtgdGZDs48e8oKGE6wCHMYCw/s0/Acrobat_2019-01-15_10-48-40.png" alt=""></li><li>L1cache与shared Memory共用一块存储空间（直接说明速度很快）</li><li>大小有限制</li></ol></li></ol><h3 id="什么是local-memory？在什么情况下变量会存在local-memory中？"><a href="#什么是local-memory？在什么情况下变量会存在local-memory中？" class="headerlink" title="什么是local memory？在什么情况下变量会存在local memory中？"></a>什么是local memory？在什么情况下变量会存在local memory中？</h3><ol><li>local memory是线程中某些变量存储的空间，实质上是global memory中分配给线程的一块内存空间。<ol><li>实质上就是global memory</li></ol></li><li>local memory的特点：<ol><li>线程内私有</li><li>速度很慢（在global memory中）</li></ol></li><li>在这些情况下变量会存在local memory而不存在寄存器中<ol><li>当单个线程中的寄存器不够用的情况下，需要使用local memory存储变量。<ol><li>需要了解单个线程中能够使用的寄存器数量。</li><li><img src="https://lh3.googleusercontent.com/-qquc9S_qCr0/XD1LBKycwvI/AAAAAAAANsc/0QbLFST183gUhJI2FWFgp_d42NWb0dZxACHMYCw/s0/Acrobat_2019-01-15_10-52-52.png" alt=""></li></ol></li><li>如果变量使用到了地址，变量就会存在local memory中。<ol><li><img src="https://lh3.googleusercontent.com/-ZWqsNGN9Kn4/XD1LTH5bTjI/AAAAAAAANso/p4HIh0AdS_ktdH3vwk9rnbb0AAMcY294gCHMYCw/s0/Acrobat_2019-01-15_10-54-05.png" alt=""></li></ol></li><li>使用了递归函数，寄存器显然不够用，当然也会使用local memory</li></ol></li></ol><h3 id="texture-cache"><a href="#texture-cache" class="headerlink" title="texture cache"></a>texture cache</h3><p>TODO:</p><p>对这个没有什么兴趣，就先不看吧。</p><h2 id="GPU中的存储访问模式"><a href="#GPU中的存储访问模式" class="headerlink" title="GPU中的存储访问模式"></a>GPU中的存储访问模式</h2><p>问题：怎样的存储访问模式，效率更高？</p><h3 id="如何确定访问过程中对Global-Memory的访问长度"><a href="#如何确定访问过程中对Global-Memory的访问长度" class="headerlink" title="如何确定访问过程中对Global Memory的访问长度"></a>如何确定访问过程中对Global Memory的访问长度</h3><ol><li><p>基于这样的特性：</p><ol><li>对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节</li></ol></li><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>找出最小编号活动线程寻址的存储器片段。段的长度由线程访问的字的长度决定：</span><br><span class="line">    * <span class="number">1</span>字节的字<span class="number">32</span>字节</span><br><span class="line">    * <span class="number">2</span>字节的字<span class="number">64</span>字节</span><br><span class="line">    * <span class="number">4</span>，<span class="number">8</span>，<span class="number">16</span>字节的字<span class="number">128</span>字节</span><br><span class="line"><span class="number">2.</span>找出其它地址在同一段内的活动线程</span><br><span class="line"><span class="number">3.</span>减小事务长度，如果可能：</span><br><span class="line">    * 如果事务是<span class="number">128</span>字节且只有下半部分或上半部分被使用，减小事务到<span class="number">64</span>字节；</span><br><span class="line">    * 如果事务是<span class="number">64</span>字节（原始的或者从<span class="number">128</span>字节减小后的）且只有上半部分或下</span><br><span class="line"><span class="number">4.</span>执行事务且标记已访问数据的线程为非活动的。</span><br></pre></td></tr></table></figure></li></ol><h3 id="Global-Memory中，怎样访存效率更高？"><a href="#Global-Memory中，怎样访存效率更高？" class="headerlink" title="Global Memory中，怎样访存效率更高？"></a>Global Memory中，怎样访存效率更高？</h3><ol><li>cuda访存的特性<ol><li>对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节</li></ol></li><li>根据特性，判断不同访存方式的效率区别(<ol><li>图中例子为：遍历访问数组的32个int元素（32*Bytes=128Bytes）。</li><li>对齐且顺序：<ol><li><img src="https://lh3.googleusercontent.com/-hivZZjGGfi8/XD1PT_H5jRI/AAAAAAAANtA/Jyp5zvfIxyou6Epbh3d0XFTV0Fta6mDCgCHMYCw/s0/Acrobat_2019-01-15_11-11-11.png" alt=""></li></ol></li><li>对齐，但交叉次序访问，注意到对该情况的优化在不同的计算能力下不同。<ol><li>发现1.0的时候，完全不支持交叉次序访问的并行<ol><li>每个int读取一次，32次读取每次读取单位为32B</li></ol></li><li><img src="https://lh3.googleusercontent.com/-8do7xPatAfQ/XD1PgsjTPuI/AAAAAAAANtE/ywf_tP6vUiYlChN0xGN1pzx99kevZeBbQCHMYCw/s0/Acrobat_2019-01-15_11-12-02.png" alt=""></li></ol></li><li>未对齐，但顺序访问<ol><li><img src="https://lh3.googleusercontent.com/-UDvD96XD-Vw/XD1Qa2WOBBI/AAAAAAAANtQ/KiFbNr6zvto_TO4hnaahHwZpzwSHEISxACHMYCw/s0/Acrobat_2019-01-15_11-15-55.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-wuvaBvFBL04/XD1ST3z6tkI/AAAAAAAANts/LLtskN0255wkfZopm6VnnbL2EvdgPm_iQCHMYCw/s0/Acrobat_2019-01-15_11-23-58.png" alt=""></li></ol></li><li>即使对齐了，但是如果乘上一个系数<ol><li><img src="https://lh3.googleusercontent.com/-yGL6OLkxFsA/XD1QfeEWqFI/AAAAAAAANtU/3xmBtQvVAxMfOlW-EA_UxqEoiWl0aKA2ACHMYCw/s0/Acrobat_2019-01-15_11-16-14.png" alt=""></li></ol></li><li>随机访问<ol><li><img src="https://lh3.googleusercontent.com/-rCGJm6lllIs/XD1Qrdz7GbI/AAAAAAAANtc/EyEVB2TTgko4nkQ0ciJ35v3VjZfYNNE7wCHMYCw/s0/Acrobat_2019-01-15_11-17-01.png" alt=""></li></ol></li></ol></li><li>结论：尽可能对齐且顺序访问</li></ol><h3 id="Constant-Memory中，如何访存效率更高？"><a href="#Constant-Memory中，如何访存效率更高？" class="headerlink" title="Constant Memory中，如何访存效率更高？"></a>Constant Memory中，如何访存效率更高？</h3><ol><li>特点：<ol><li>片外存储器，速度虽然比shared满，但是具有缓存</li><li>只读</li><li>无需考虑冲突问题</li></ol></li><li>访问优化：<ol><li>关键：如果half-warp中的线程访问的不是同一个地址，那么各个线程的访问将会串行化。<img src="https://lh3.googleusercontent.com/-yYJUOX-zNgk/XD1TgLgRnyI/AAAAAAAANt4/jB6R5v6BWuA3RcIbegH_yCq33uPjxdJPACHMYCw/s0/Acrobat_2019-01-15_11-29-05.png" alt=""></li><li>例子：<img src="https://lh3.googleusercontent.com/-cXQbxBAYxWA/XD1TdHGWvJI/AAAAAAAANt0/i-ImhB4Jn98B3IPZObx9llbtihPgvRZdQCHMYCw/s0/Acrobat_2019-01-15_11-28-52.png" alt=""></li></ol></li></ol><h3 id="Shared-Memory中如何访存效率更高？"><a href="#Shared-Memory中如何访存效率更高？" class="headerlink" title="Shared Memory中如何访存效率更高？"></a>Shared Memory中如何访存效率更高？</h3><ol><li><p>特点：</p><ol><li>速度极快（毕竟在L1 cache上）</li><li>如果发生bank冲突，可能会使访存串行化</li></ol></li><li><p>shared memory的硬件结构特点与bank</p><ol><li>参考下图<ol><li>线性编址</li></ol></li><li>（以下图为例的话），地址<code>0008</code>，<code>0048</code>，<code>0088</code>在同一个bank上，无法在一个时钟周期内访问，必须串行访问。例如下图：同一个时间里，half-warp发出的访存请求，如果访问同一个bank上的地址，会导致访存串行化<ol><li><img src="https://lh3.googleusercontent.com/-SA4qmGTqTyM/XD1VSMTUETI/AAAAAAAANuI/FDzh1lkWp04cF8K-eT_yKmE2CKOI3K7xQCHMYCw/s0/Acrobat_2019-01-15_11-36-35.png" alt=""></li></ol></li><li>地址<code>0000</code>，<code>0004</code>，<code>0008</code>，等，在同一个bank上，多个线程可以在同一个时钟周期访问，因此实现了并行访存<ol><li><img src="https://lh3.googleusercontent.com/-Njk-efGNx5M/XD1Vb6wjVtI/AAAAAAAANuM/G6tcHtm7i8cz0KITIjuWuOOH07q2eGaBQCHMYCw/s0/Acrobat_2019-01-15_11-37-17.png" alt=""></li></ol></li></ol></li><li><p>关键优化需要特性</p><ol><li>一个half-warp中的线程，在没有发生bank冲突的情况下，可以在一个时钟周期内访问16个不同的地址。</li><li>一个half-warp中的所有线程如果都访问同一个地址，通过广播机制，可以在同一个时钟周期内完成访问。<img src="https://lh3.googleusercontent.com/-whTB6O25Bz8/XD1Ww8ozsKI/AAAAAAAANuc/I7fX9lzV3ioWMGs93a3-w3-P51tgUgalACHMYCw/s0/Acrobat_2019-01-15_11-42-59.png" alt=""></li></ol></li><li><p>访存例子：</p><ol><li><p><code>v = arr[ threadIdx.x ]</code></p><ol><li>连续的16个元素可以通过一个时钟周期一次访问。</li><li><img src="https://lh3.googleusercontent.com/-d7AP5GuL2ns/XD1YgQ30h5I/AAAAAAAANuo/jGCLvbPigYQHcNE9eJ2h9mMBS9b5K3IJQCHMYCw/s0/Acrobat_2019-01-15_11-50-25.png" alt=""></li></ol></li><li><p><code>v = arr[ threadIdx.x+2 ]</code></p><ol><li>没有发生bank冲突，连续的16个值依然可以通过一个时钟周期一次完成访问。</li><li><img src="https://lh3.googleusercontent.com/-NwTzxZl9Nbc/XD1YsH6m5WI/AAAAAAAANus/fAW7EWnFt2EaKdavF_-lrcCNJ5AFqi1IgCHMYCw/s0/Acrobat_2019-01-15_11-51-13.png" alt=""></li></ol></li><li><code>v = arr[2*threadIdx.x]</code>      <ol><li>连续的16个值，前8个可以一次访问，后8个由于与前8个发生了bank冲突，需要等到下一个时钟周期，需要两个时钟周期</li><li><img src="https://lh3.googleusercontent.com/-XH1ZOdJzB4Y/XD1ZBpizwpI/AAAAAAAANu4/WX7e_gTepj8a7_sWcTEKN69YVmUgWUwjwCHMYCw/s0/Acrobat_2019-01-15_11-52-39.png" alt=""></li></ol></li><li><code>v = arr2[threadIdx.x].x</code><ol><li>注意到arr2数组是由int2类型的结构体（int x, int y）组成的，因此在实际访存中，这个语句有着与上面那个类似的效果。</li><li><img src="https://lh3.googleusercontent.com/-PSr-FTdqRlw/XD1Zqeo80mI/AAAAAAAANvA/HyZcNu2u-mM5N_8ugMuuqYKzpFGKejdhACHMYCw/s0/Acrobat_2019-01-15_11-55-21.png" alt=""></li></ol></li><li><code>v = arr[3*threadIdx.x]</code><ol><li>发现很神奇的是，乘上3，就不会发生冲突了。<ol><li>(3与16互素，x $\in [0,15]$是16的一个剩余系，那么3*x能够遍历16的剩余系)</li></ol></li><li><img src="https://lh3.googleusercontent.com/-UBKhzjGNwco/XD1Z2oL1nZI/AAAAAAAANvE/ZIoh-iVj6ms5LXzrq_jD8Dj1IuzuxXQhwCHMYCw/s0/Acrobat_2019-01-15_11-56-10.png" alt=""></li></ol></li><li><code>v = arr[random]</code><ol><li><img src="https://lh3.googleusercontent.com/-_YfC9QLNbVA/XD1rxZMXNII/AAAAAAAANvY/kp120Lh9CnMiCuAP-wbwn44bSi_QYiVywCHMYCw/s0/Acrobat_2019-01-15_13-12-36.png" alt=""></li></ol></li></ol></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://lh3.googleusercontent.com/-hXWKX0lEAvM/XD1wcULablI/AAAAAAAANvk/auzOo_Af5dAKzdR5htukmRwdnKq15TYyQCHMYCw/s0/Acrobat_2019-01-15_13-32-33.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-2-CUDA访存&quot;&gt;&lt;a href=&quot;#HPC复习5-2-CUDA访存&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.2-CUDA访存&quot;&gt;&lt;/a&gt;HPC复习5.2-CUDA访存&lt;/h1&gt;&lt;p&gt;这里就主要对cuda中的访存模式进行比较详细地说明吧。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;GPU中，5种不同存储部件的特性及使用方式&lt;/li&gt;
&lt;li&gt;GPU中，如何使用合并访存加速&lt;/li&gt;
&lt;li&gt;下图是GPU中的存储设备的大图&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-FME8Iu_B5cI/XD1D5vIEeaI/AAAAAAAANsE/9ObTV12e34ArBzh9o90oEjCsNBJ_X1LZQCHMYCw/s0/Acrobat_2019-01-15_10-22-29.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.1-CUDA基础</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-1-CUDA%E5%9F%BA%E7%A1%80/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-1-CUDA基础/</id>
    <published>2019-01-15T02:03:26.000Z</published>
    <updated>2019-01-15T02:04:25.938Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-1-CUDA基础"><a href="#HPC复习5-1-CUDA基础" class="headerlink" title="HPC复习5.1-CUDA基础"></a>HPC复习5.1-CUDA基础</h1><p>复习了一下cuda，主要以自问自答的方式，整理了一下知识点。</p><ol><li>相关背景：前言</li><li>逻辑上的cuda架构大概是怎样的？</li><li>gpu上实际的硬件情况</li><li>cuda架构与硬件之间的关系</li><li>一个简单实例：矩阵相乘的简单实现</li></ol><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="为什么需要gpu？"><a href="#为什么需要gpu？" class="headerlink" title="为什么需要gpu？"></a>为什么需要gpu？</h3><ol><li>CPU处理能力不断强大，但在进入3D时代后，人们发现庞大的3D图像处理数据计算使得CPU越来越不堪重荷，并且远远超出其计算能力；</li><li>图形计算需求日益增多，作为计算机的显示芯片也飞速发展。图形，图像计算等计算的功能被脱离出来，单独设计为一块芯片——GPU （也就是显卡）。</li></ol><h3 id="gpu与cpu的主要区别在？"><a href="#gpu与cpu的主要区别在？" class="headerlink" title="gpu与cpu的主要区别在？"></a>gpu与cpu的主要区别在？</h3><ol><li>gpu采用了大量的执行单元，并且一个控制单元可以同时控制多个执行单元进行计算，实现类似于SIMD的加速。</li><li><img src="https://lh3.googleusercontent.com/-U6dLqQSsc_U/XD0vGdcz0oI/AAAAAAAANqg/skeMgQgw4NMZnsCU87OTm8bNWqoBnac0ACHMYCw/s0/Acrobat_2019-01-15_08-53-44.png" alt=""></li></ol><h3 id="cuda是什么？"><a href="#cuda是什么？" class="headerlink" title="cuda是什么？"></a>cuda是什么？</h3><ol><li>是一种专门针对GPU的开发工具，可以使用类C语言进行通用计算。</li><li>用于编写host+device异构并行C应用程序</li><li><img src="https://lh3.googleusercontent.com/-FlqXBhfrtAQ/XD0vjzixC7I/AAAAAAAANqo/F_57eojX4nAF3CnPqXjbN-gl2nDc0mk0wCHMYCw/s0/Acrobat_2019-01-15_08-55-43.png" alt=""></li></ol><h2 id="CUDA-架构（逻辑上）"><a href="#CUDA-架构（逻辑上）" class="headerlink" title="CUDA 架构（逻辑上）"></a>CUDA 架构（逻辑上）</h2><h3 id="CUDA中线程的组织方式？"><a href="#CUDA中线程的组织方式？" class="headerlink" title="CUDA中线程的组织方式？"></a>CUDA中线程的组织方式？</h3><ol><li>三级：Grid-Block-Thread<ol><li>Thread ：单个线程，是并行的基本单位</li><li>Block：互相合作的线程组</li><li>Grid：一组Block</li></ol></li><li>需要关注到，一个kernel对应一个Grid</li><li><img src="https://lh3.googleusercontent.com/-4LwbA1Aj2MQ/XD0v2jCDuHI/AAAAAAAANq0/64pcOu7Onqc837_4Q79DnfvvoSzWXocaQCHMYCw/s0/Acrobat_2019-01-15_08-56-58.png" alt=""></li></ol><h3 id="CUDA中的访存模式？"><a href="#CUDA中的访存模式？" class="headerlink" title="CUDA中的访存模式？"></a>CUDA中的访存模式？</h3><p>线程可以访问以下空间</p><ol><li>以线程为单位的<ol><li>线程有内部的<strong>寄存器</strong></li><li>在寄存器不够用的情况下，可以在<strong>Global Memory</strong>中申请一块内存空间作为<strong>Local Memory</strong></li></ol></li><li>以Block为单位的<ol><li>单个block中的线程共享<strong>Shared Memory</strong></li></ol></li><li>以Grid为单位的<ol><li>一个Grid中的所有线程共享<strong>Glocal Memory</strong></li><li>特殊的，一个Grid中的所有线程共享<strong>只读的</strong> <strong>constant memory</strong>(常量存储器),<strong>texture memory</strong>(纹理存储器)</li></ol></li><li>图示如下：<img src="https://lh3.googleusercontent.com/-7Id_bAjJjD4/XD0xXYp4HTI/AAAAAAAANrA/g7kkEfzz_Zgxa6JaHZhGRdDckKAqbXEfACHMYCw/s0/Acrobat_2019-01-15_09-03-24.png" alt=""></li></ol><h2 id="cuda与硬件的关系"><a href="#cuda与硬件的关系" class="headerlink" title="cuda与硬件的关系"></a>cuda与硬件的关系</h2><h3 id="cuda中有哪些硬件？是如何组织的？"><a href="#cuda中有哪些硬件？是如何组织的？" class="headerlink" title="cuda中有哪些硬件？是如何组织的？"></a>cuda中有哪些硬件？是如何组织的？</h3><p>由低到高分别是：</p><ol><li>SP：流处理器</li><li>SM：流多处理器</li><li>TPC：线程处理集群</li><li>SPA：流处理器阵列</li></ol><p><img src="https://lh3.googleusercontent.com/-qmYboKb3JQM/XD0xsCp_K6I/AAAAAAAANrI/Hkgu4X-fusoYYnf2q3B-DWv1BcjVEPLYQCHMYCw/s0/Acrobat_2019-01-15_09-04-49.png" alt=""></p><h3 id="cuda架构与实际硬件的关系？"><a href="#cuda架构与实际硬件的关系？" class="headerlink" title="cuda架构与实际硬件的关系？"></a>cuda架构与实际硬件的关系？</h3><ol><li>Grid：运行在SPA上</li><li>Block的执行方式：<ol><li>一般的cuda应用程序具有多个Block组成的线程组，这些Block会分配到多个SM核上分别执行。</li><li>怎么分配？见下图：<img src="https://lh3.googleusercontent.com/-Plh4mq88QdE/XD0y2ywS9aI/AAAAAAAANrU/w50XC5epme4HVSkv4vKG0C-aRc06ujnmwCHMYCw/s0/Acrobat_2019-01-15_09-09-46.png" alt=""></li><li>注意到这里的分配，会受到以下两个限制的影响：<ol><li>一个SM核上分配的Blcok数量是有限制，G80中的SM核最多8个block</li><li>G80中的SM核最多768个线程。</li></ol></li></ol></li><li>SM核上具有多个Block需要运行后，这些线程更具体的，是如何执行的呢？<ol><li>一个SM核上的多个Block，每个block会分成多个Warp（32个线程）</li><li>这些Warp会在SM核上并发地执行，由于一个Warp有32个线程，而一个SM核上仅有8个SP，因此一个Warp运行4个Clock cycles</li></ol></li></ol><h3 id="Warp的调度具有开销吗？"><a href="#Warp的调度具有开销吗？" class="headerlink" title="Warp的调度具有开销吗？"></a>Warp的调度具有开销吗？</h3><ol><li>（联想）cpu中的硬件多线程之间的调度是几乎没有开销的，原因？是因为CPU中已经有了多个可以用于存储线程context的区域，每次调度切换线程的时候，切换context是在CPU硬件内完成的，不是由操作系统完成的，不需要访存，因此几乎0开销。</li><li>GPU中的warp调度，类似的，也是0开销的。</li></ol><h3 id="怎样的Warp会被调度出来执行？"><a href="#怎样的Warp会被调度出来执行？" class="headerlink" title="怎样的Warp会被调度出来执行？"></a>怎样的Warp会被调度出来执行？</h3><ol><li>很明显的，每一个时刻，都会有很多个Warp在等待被GPU调度执行，那么问题是：满足什么条件的Warp，会被调度出来执行？<ol><li>Warp中没有线程被阻塞的（如访存等）</li><li>合适的Warp挑出来优先执行。</li></ol></li></ol><h3 id="为什么要设计成warp的并发执行？"><a href="#为什么要设计成warp的并发执行？" class="headerlink" title="为什么要设计成warp的并发执行？"></a>为什么要设计成warp的并发执行？</h3><ol><li>结论：Warp的并发执行，能够很好的隐藏访存时间（原理类似于cpu中的硬件多线程）</li><li>简单例子：<ol><li><img src="https://lh3.googleusercontent.com/-M9QwhzmB0pI/XD02cA_ftZI/AAAAAAAANrg/NpkbQH9Eo2I7kq1FcXk2uzkxt10DuWbUgCHMYCw/s0/Acrobat_2019-01-15_09-25-04.png" alt=""></li><li>上图中，一个单位长度为一个warp的执行（实际上其实是4个时钟周期，这里简化成了1个）。</li><li>可以发现，每当一个Warp由于访存阻塞了，GPU会马上从调度其他可用的Warp来执行，从而保证GPU中的计算负载保持在100%，这个Warp的访存时间就被别的Warp的执行隐藏掉了</li></ol></li><li>复杂例子：如何计算完全隐藏访存时间所需要的Warp的数量。<ol><li>假设：<ol><li>运行一次一个Warp中的所有线程需要4个clock cycles</li><li>每n个指令需要一次全局内存访问（200个时钟周期）</li></ol></li><li>解答：<ol><li>假设每个指令都需要访存，访存的这一段时间里，可以使用$200/4=50$个warp的执行来隐藏。<ol><li>隐藏假设：单个Warp一次运行仅使用了4个clock cycles就被阻塞了</li></ol></li><li>由于是每n个指令访存一次，因此实际上，单个warp执行了$4*n$后才会被阻塞</li><li>因此，需要$200/(4*n)+1$个warp。</li></ol></li></ol></li></ol><h3 id="SM核上具有的存储空间及分配情况？"><a href="#SM核上具有的存储空间及分配情况？" class="headerlink" title="SM核上具有的存储空间及分配情况？"></a>SM核上具有的存储空间及分配情况？</h3><ol><li>SM核上拥有16KB的shared memory(有些GPU是48KB)</li><li>基于前面，一个SM核上分配多个Block的前提<ol><li>多个block分享一个SM核上的shared memory。</li></ol></li><li>由于单个block可能会要求shared memory至少多大，而一个SM核上的shared memory是有限制的，所以，block要看情况，不能分配太多，不然shared memory就不够用了。<ol><li>Shared Memory也会限制Block的分配</li></ol></li></ol><h2 id="cuda的软件接口"><a href="#cuda的软件接口" class="headerlink" title="cuda的软件接口"></a>cuda的软件接口</h2><p>写了这么多，终于写到要写一个真正的cuda程序了。</p><h3 id="cuda编程中的函数声明"><a href="#cuda编程中的函数声明" class="headerlink" title="cuda编程中的函数声明"></a>cuda编程中的函数声明</h3><ol><li>在cuda编程中，当然既要写在gpu上运行的函数又要写在cpu上运行的函数了，那么如何区分呢？</li><li><img src="https://lh3.googleusercontent.com/-Frw4biWiTdw/XD063lkpXrI/AAAAAAAANrs/2FySYbhR3EsgK3TcHH6cPOlsy7x_zxzTQCHMYCw/s0/Acrobat_2019-01-15_09-43-58.png" alt=""></li><li>好吧，之前我没有好好想<code>__device__</code>还有<code>__global__</code>的区别，所以这里要特地给自己强调一下。</li></ol><h3 id="cuda中的5个内建设备变量"><a href="#cuda中的5个内建设备变量" class="headerlink" title="cuda中的5个内建设备变量"></a>cuda中的5个内建设备变量</h3><ol><li><code>gridDim</code></li><li><code>blockDim</code></li><li><code>blockIdx</code></li><li><code>threadIdx</code></li><li><code>warpSize</code></li></ol><h3 id="cuda中的各种各样的内存操作"><a href="#cuda中的各种各样的内存操作" class="headerlink" title="cuda中的各种各样的内存操作"></a>cuda中的各种各样的内存操作</h3><p><code>cudaMemcpy(void * dst, void * src, size_t nbytes, enum cudaMemcpyType direction);</code></p><p><code>cudaMalloc</code></p><p><code>cudaFree</code></p><h3 id="cuda中的同步操作"><a href="#cuda中的同步操作" class="headerlink" title="cuda中的同步操作"></a>cuda中的同步操作</h3><p><code>__syncThreads()</code>：同步一个block里面的所有线程，作用相当于一个Barrier</p><h2 id="实例：very-simple的矩阵相乘"><a href="#实例：very-simple的矩阵相乘" class="headerlink" title="实例：very simple的矩阵相乘"></a>实例：very simple的矩阵相乘</h2><p>可以看我的<a href="https://gitee.com/wwyf/class_hpc/blob/master/e6/code/multi.cu" target="_blank" rel="noopener">git仓库</a>（我具体的实现可能没有这么naive）</p><p>具体思路是：</p><p><img src="https://lh3.googleusercontent.com/-3jJ-qYk5SD8/XD09D8JLBTI/AAAAAAAANr4/HjWn0Aj36A4S0xuZEoZ70EqhyJ6waYYGwCHMYCw/s0/Acrobat_2019-01-15_09-53-19.png" alt=""></p><p>对该程序优化的思考</p><ol><li>性能问题：<ol><li>每计算一次，访问两次内存（如从矩阵Md中取一个数，以及从Nd中取一个数，然后只做了一次加法）</li><li>访存限制</li></ol></li><li>矩阵的大小受到一个block大小的限制。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-1-CUDA基础&quot;&gt;&lt;a href=&quot;#HPC复习5-1-CUDA基础&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.1-CUDA基础&quot;&gt;&lt;/a&gt;HPC复习5.1-CUDA基础&lt;/h1&gt;&lt;p&gt;复习了一下cuda，主要以自问自答的方式，整理了一下知识点。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;相关背景：前言&lt;/li&gt;
&lt;li&gt;逻辑上的cuda架构大概是怎样的？&lt;/li&gt;
&lt;li&gt;gpu上实际的硬件情况&lt;/li&gt;
&lt;li&gt;cuda架构与硬件之间的关系&lt;/li&gt;
&lt;li&gt;一个简单实例：矩阵相乘的简单实现&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习3-pthread</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A03-pthread/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习3-pthread/</id>
    <published>2019-01-14T13:38:29.000Z</published>
    <updated>2019-01-14T13:39:25.530Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习3-pthread"><a href="#HPC复习3-pthread" class="headerlink" title="HPC复习3-pthread"></a>HPC复习3-pthread</h1><p><a href="https://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html" target="_blank" rel="noopener">toturial</a></p><p>这里是高性能计算课程-pthread部分的复习笔记，大概会有以下内容：</p><ol><li>pthread中的hello,world</li><li>pthread中的临界区</li><li>忙等待</li><li>互斥量</li><li>生产者-消费者同步与信号量</li><li>实现路障</li><li>读写锁与链表</li><li>pthread中的缓存一致性</li></ol><a id="more"></a><h2 id="进程、线程和pthread"><a href="#进程、线程和pthread" class="headerlink" title="进程、线程和pthread"></a>进程、线程和pthread</h2><ol><li>pthread:一种共享内存编程模型</li></ol><h2 id="Hello-world"><a href="#Hello-world" class="headerlink" title="Hello,world"></a>Hello,world</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">print_message_function</span><span class="params">( <span class="keyword">void</span> *ptr )</span></span>;</span><br><span class="line"></span><br><span class="line">main()</span><br><span class="line">&#123;</span><br><span class="line">     <span class="keyword">pthread_t</span> thread1, thread2;</span><br><span class="line">     <span class="keyword">char</span> *message1 = <span class="string">"Thread 1"</span>;</span><br><span class="line">     <span class="keyword">char</span> *message2 = <span class="string">"Thread 2"</span>;</span><br><span class="line">     <span class="keyword">int</span>  iret1, iret2;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Create independent threads each of which will execute function */</span></span><br><span class="line"></span><br><span class="line">     iret1 = pthread_create( &amp;thread1, <span class="literal">NULL</span>, print_message_function, (<span class="keyword">void</span>*) message1);</span><br><span class="line">     iret2 = pthread_create( &amp;thread2, <span class="literal">NULL</span>, print_message_function, (<span class="keyword">void</span>*) message2);</span><br><span class="line"></span><br><span class="line">     <span class="comment">/* Wait till threads are complete before main continues. Unless we  */</span></span><br><span class="line">     <span class="comment">/* wait we run the risk of executing an exit which will terminate   */</span></span><br><span class="line">     <span class="comment">/* the process and all threads before the threads have completed.   */</span></span><br><span class="line"></span><br><span class="line">     pthread_join( thread1, <span class="literal">NULL</span>);</span><br><span class="line">     pthread_join( thread2, <span class="literal">NULL</span>); </span><br><span class="line"></span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Thread 1 returns: %d\n"</span>,iret1);</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Thread 2 returns: %d\n"</span>,iret2);</span><br><span class="line">     <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">print_message_function</span><span class="params">( <span class="keyword">void</span> *ptr )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="keyword">char</span> *message;</span><br><span class="line">     message = (<span class="keyword">char</span> *) ptr;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"%s \n"</span>, message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="pthread中的临界区"><a href="#pthread中的临界区" class="headerlink" title="pthread中的临界区"></a>pthread中的临界区</h2><ol><li>课本上使用多个线程并行计算$\pi$会出问题<ol><li>多个线程尝试更新同一个共享变量时，会出问题。</li></ol></li><li>多个线程尝试更新一个共享资源，结果可能是无法预测的，这些访问可能会导致某种错误，我们称之为<strong>竞争条件</strong></li><li><strong>临界区</strong>：更新共享资源的代码段</li></ol><h2 id="忙等待"><a href="#忙等待" class="headerlink" title="忙等待"></a>忙等待</h2><ol><li>可以使用忙等待实现“严格按照线程号，单个线程进入临界区”。</li><li>注意，可能会由于发生了编译优化导致该忙等待失效（该忙等待语句可能会调度到其他指令前后）<ol><li>可以通过<code>volitile</code>关键字来解决</li></ol></li><li>缺点：<ol><li>忙等待：浪费CPU周期</li></ol></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initialize</span></span><br><span class="line">flag = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// .... some code</span></span><br><span class="line"><span class="keyword">while</span>(flag != my_rank);</span><br><span class="line"><span class="comment">// critical area</span></span><br><span class="line">flag = (flag + <span class="number">1</span>)% thread_count;<span class="comment">// 保证在所有进程都已到达后，flag恢复成0</span></span><br></pre></td></tr></table></figure><h2 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h2><ol><li>改善忙等待的缺点：互斥量，互斥锁</li><li>设计函数接口<ol><li><code>pthread_mutex_init( pthread_mutex_t *, const pthread_mutexattr_t *)</code></li><li><code>int pthread_mutex_destroy(pthread_mutex_t* )</code></li><li><code>int pthread_mutex_lock(pthread_mutex_t *)</code></li><li><code>int pthread_mutex_unlock(pthread_mutex_t *)</code></li></ol></li></ol><h2 id="生产者-消费者同步和信号量"><a href="#生产者-消费者同步和信号量" class="headerlink" title="生产者-消费者同步和信号量"></a>生产者-消费者同步和信号量</h2><p>TODO:</p><h2 id="路障和条件变量"><a href="#路障和条件变量" class="headerlink" title="路障和条件变量"></a>路障和条件变量</h2><ol><li><p>问题：如何保证所有线程在程序中处于同一位置来同步线程（即实现路障）</p></li><li><p>忙等待和互斥量实现路障</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> counter;</span><br><span class="line"><span class="keyword">int</span> thread_count;</span><br><span class="line"><span class="keyword">pthread_mutex_t</span> barier_mutex;</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> * <span class="title">Threa_word</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    pthread_mutex_lock(&amp;barier_mutex);</span><br><span class="line">    counter++；</span><br><span class="line">    pthread_mutex_unlock(&amp;barrier_mutex);</span><br><span class="line">    <span class="keyword">while</span>(counter &lt; thread_count);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>信号量实现路障</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> counter;</span><br><span class="line"><span class="keyword">sem_t</span> count_sem;</span><br><span class="line"><span class="keyword">sem_t</span> barrier_sem;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">Thread_work</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    <span class="comment">// 先获得计数器的信号量</span></span><br><span class="line">    sem_wait(&amp;count_sem);</span><br><span class="line">    <span class="keyword">if</span> (counter == thread_count<span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="comment">// 最后一个到达路障的线程负责初始化counter以及释放其他线程</span></span><br><span class="line">        counter = <span class="number">0</span>;</span><br><span class="line">        sem_post(&amp;count_sem);</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; thread_count<span class="number">-1</span>; j++)</span><br><span class="line">            sem_post(&amp;barrier_sem);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        counter++;</span><br><span class="line">        sem_post(&amp;count_sem);</span><br><span class="line">        sem_wait(&amp;barrier_sem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>该路障的重用可能会导致竞争条件</p></li></ol></li><li><p>使用条件变量实现路障</p><ol><li>TODO</li></ol></li></ol><h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>使用读写锁，实现多线程共享的链表怎么实现？</p><p>TODO:</p><h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><p>书本拿了矩阵-向量乘法的例子，说明了缓存对程序性能的影响</p><ol><li>对于8*8000000的矩阵，伪共享带来了很大的影响<ol><li>关键：$y[0]-y[7]$在同一个缓存行中</li></ol></li></ol><p><img src="https://lh3.googleusercontent.com/-LJMIfdNhooo/XDyQgxv4XJI/AAAAAAAANqI/8lBb1o5SPBUV1Gn6uK0sRuGp0bH87hCJQCHMYCw/s0/Typora_2019-01-14_21-37-07.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习3-pthread&quot;&gt;&lt;a href=&quot;#HPC复习3-pthread&quot; class=&quot;headerlink&quot; title=&quot;HPC复习3-pthread&quot;&gt;&lt;/a&gt;HPC复习3-pthread&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;toturial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里是高性能计算课程-pthread部分的复习笔记，大概会有以下内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pthread中的hello,world&lt;/li&gt;
&lt;li&gt;pthread中的临界区&lt;/li&gt;
&lt;li&gt;忙等待&lt;/li&gt;
&lt;li&gt;互斥量&lt;/li&gt;
&lt;li&gt;生产者-消费者同步与信号量&lt;/li&gt;
&lt;li&gt;实现路障&lt;/li&gt;
&lt;li&gt;读写锁与链表&lt;/li&gt;
&lt;li&gt;pthread中的缓存一致性&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习2-MPI</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A02-MPI/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习2-MPI/</id>
    <published>2019-01-14T12:26:23.000Z</published>
    <updated>2019-01-14T13:39:25.530Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习2-MPI"><a href="#HPC复习2-MPI" class="headerlink" title="HPC复习2-MPI"></a>HPC复习2-MPI</h1><p><a href="https://www.open-mpi.org/doc/current/" target="_blank" rel="noopener">OpenMPI 官方文档</a></p><p><a href="http://www.mpich.org/static/docs/latest/" target="_blank" rel="noopener">mpich官方文档</a></p><p>这里是高性能计算课程-MPI部分的复习笔记，大概会有以下内容：</p><ol><li>MPI中的Hello world</li><li>常见的MPI函数</li><li>使用MPI实现梯形积分法</li><li>中级：MPI中的集合通信</li><li>中级：MPI中的派生数据类型</li><li>中级：MPI中的计时方法</li><li>算法：奇偶并行排序算法</li><li>算法：并行正则采样排序</li></ol><a id="more"></a><h2 id="MPI中的hello-world"><a href="#MPI中的hello-world" class="headerlink" title="MPI中的hello world"></a>MPI中的hello world</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_STRING = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> greeting[MAX_STRING];</span><br><span class="line">    <span class="keyword">int</span> comm_sz;</span><br><span class="line">    <span class="keyword">int</span> my_rank;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Initialize the MPI environment</span></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">// Get the number of processes</span></span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line">    <span class="comment">// Get the rank of the process</span></span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (my_rank != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">sprintf</span>(greeting, <span class="string">"Greetings from process %d of %d!"</span>, my_rank, comm_sz);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Hello world from ank %d\n"</span>,my_rank);</span><br><span class="line">        MPI_Send(</span><br><span class="line">            greeting,</span><br><span class="line">            <span class="comment">// strlen(greeting)+1,</span></span><br><span class="line">            <span class="comment">// strlen(greeting),</span></span><br><span class="line">            MAX_STRING,</span><br><span class="line">            MPI_CHAR,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            MPI_COMM_WORLD</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Greetings from process %d of %d!\n"</span>, my_rank, comm_sz);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> q = <span class="number">1</span>; q &lt; comm_sz; q++)&#123;</span><br><span class="line">            MPI_Recv(</span><br><span class="line">                greeting,</span><br><span class="line">                MAX_STRING,</span><br><span class="line">                MPI_CHAR,</span><br><span class="line">                q,</span><br><span class="line">                <span class="number">0</span>,</span><br><span class="line">                MPI_COMM_WORLD,</span><br><span class="line">                MPI_STATUS_IGNORE</span><br><span class="line">            );</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%s in %d\n"</span>, greeting, my_rank);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Finalize the MPI environment.</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见的MPI函数"><a href="#常见的MPI函数" class="headerlink" title="常见的MPI函数"></a>常见的MPI函数</h2><p>这6个MPI函数，可以完成一切任务</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Init</span><span class="params">(<span class="keyword">int</span> *argc, <span class="keyword">char</span> **argv[])</span></span>;</span><br><span class="line"><span class="comment">// 进入MPI环境并完成所有的初始化工作</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Finalize</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="comment">// 从MPI环境中退出</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_rank</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *rank)</span></span>;</span><br><span class="line"><span class="comment">// 获得当前进程在指定通信域中的编号</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_size</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *size)</span></span>;</span><br><span class="line"><span class="comment">// 获得指定通信域中的进程数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> dest, <span class="keyword">int</span> tag, MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 发送消息到目标进程</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Recv</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> source, <span class="keyword">int</span> tag, MPI_Comm comm,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Status * status_p</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 从指定进程接受一个消息</span></span></span><br></pre></td></tr></table></figure><h2 id="使用MPI实现梯形积分法"><a href="#使用MPI实现梯形积分法" class="headerlink" title="使用MPI实现梯形积分法"></a>使用MPI实现梯形积分法</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 对这一个函数进行积分</span></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">f</span><span class="params">(<span class="keyword">double</span> x)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x*x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">Trap</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> left_endpt,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> right_endpt,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> trap_count,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> base_len</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">/**</span></span></span><br><span class="line"><span class="function"><span class="comment"> * @brief 梯形积分法的串行实现</span></span></span><br><span class="line"><span class="function"><span class="comment"> * </span></span></span><br><span class="line"><span class="function"><span class="comment"> * @param base_len 就是left_endpt与right_endpt之间分成trap_count份后，每一份的长度</span></span></span><br><span class="line"><span class="function"><span class="comment"> * </span></span></span><br><span class="line"><span class="function"><span class="comment"> */</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> estimate, x;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    estimate = (f(left_endpt) + f(right_endpt))/<span class="number">2.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= trap_count<span class="number">-1</span>; i++)&#123;</span><br><span class="line">        x = left_endpt + i*base_len;</span><br><span class="line">        estimate += f(x);</span><br><span class="line">    &#125;</span><br><span class="line">    estimate = estimate*base_len;</span><br><span class="line">    <span class="keyword">return</span> estimate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Get_input</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> my_rank,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> comm_sz,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> * a_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> * b_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>* n_p</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> dest;</span><br><span class="line">    <span class="keyword">if</span> (my_rank == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Enter a,b,and n\n"</span>);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%lf %lf %d"</span>, a_p, b_p, n_p);</span><br><span class="line">        <span class="keyword">for</span> (dest = <span class="number">1</span>; dest &lt; comm_sz; dest++)&#123;</span><br><span class="line">            MPI_Send(a_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(b_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(n_p, <span class="number">1</span>, MPI_INT, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        MPI_Recv(a_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(b_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(n_p, <span class="number">1</span>, MPI_INT, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"in trap %lf, %lf, %d\n"</span>, *a_p, *b_p, *n_p);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> my_rank, comm_sz, n=<span class="number">1024</span>, local_n;</span><br><span class="line">    <span class="keyword">double</span> a = <span class="number">0.0</span>, b = <span class="number">3.0</span>, h, local_a, local_b;</span><br><span class="line">    <span class="keyword">double</span> local_int, total_int;</span><br><span class="line">    <span class="keyword">int</span> source;</span><br><span class="line"></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line"></span><br><span class="line">    Get_input(my_rank, comm_sz, &amp;a, &amp;b, &amp;n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"in main %lf, %lf, %d\n"</span>, a, b, n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">    <span class="comment">// 将积分区间分成n份</span></span><br><span class="line">    h = (b-a)/n;</span><br><span class="line">    <span class="comment">// 将n分区间，分到comm_sz个进程里，每个进程分到local_n个区间</span></span><br><span class="line">    local_n = n/comm_sz;</span><br><span class="line"></span><br><span class="line">    local_a = a+my_rank*local_n*h;</span><br><span class="line">    local_b = local_a+local_n*h;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"local_a : %lf, local_b : %lf, local_n : %d"</span>, local_a, local_b, local_n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">    local_int = Trap(local_a, local_b, local_n, h);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (my_rank != <span class="number">0</span>)&#123;</span><br><span class="line">        MPI_Send(&amp;local_int, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        total_int = local_int;</span><br><span class="line">        <span class="keyword">for</span> (source = <span class="number">1</span>; source &lt; comm_sz; source++)&#123;</span><br><span class="line">            MPI_Recv(&amp;local_int, <span class="number">1</span>, MPI_DOUBLE, source, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">            total_int += local_int;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(my_rank == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"With n = %d trapezoids, out estimate\n"</span>, n);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"of the integral from %f to %f = %.15e\n"</span>,a,b,total_int);</span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的阻塞与非阻塞通信"><a href="#中级：MPI中的阻塞与非阻塞通信" class="headerlink" title="中级：MPI中的阻塞与非阻塞通信"></a>中级：MPI中的阻塞与非阻塞通信</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MPI_Send</span><br><span class="line"><span class="comment">// normal send</span></span><br><span class="line">MPI_Isend</span><br><span class="line"><span class="comment">// begin a nonblocking send</span></span><br><span class="line">MPI_Ssend</span><br><span class="line"><span class="comment">// Blocking synchronous send</span></span><br><span class="line"></span><br><span class="line">MPI_Bsend</span><br><span class="line"><span class="comment">// send message wich user-provided buffering</span></span><br><span class="line">MPI_Issend</span><br><span class="line"><span class="comment">// Starts a nonblocking synchronous send</span></span><br><span class="line">MPI_Ibsend</span><br><span class="line"><span class="comment">// Starts a nonblocking buffered send</span></span><br><span class="line">MPI_Rsend</span><br><span class="line"><span class="comment">// Blocking ready send</span></span><br><span class="line">MPI_Irsend</span><br><span class="line"><span class="comment">// Starts a nonblocking ready send</span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Irecv</span><br><span class="line"><span class="comment">// Begins a nonblocking receive</span></span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的集合通信"><a href="#中级：MPI中的集合通信" class="headerlink" title="中级：MPI中的集合通信"></a>中级：MPI中的集合通信</h2><p>涉及通信子中所有进程的通信函数成为集合通信（与点对点通信区分开）</p><p>MPI中的集合通信，在树中介绍的主要有以下几个函数：</p><table><thead><tr><th>函数名</th><th>作用</th></tr></thead><tbody><tr><td>MPI_Reduce</td><td>归约（可以用来求和等等,支持交换律和结合律的运算）</td></tr><tr><td>MPI_Allreduce</td><td>所有进程都可以得到全局求和的结果</td></tr><tr><td>MPI_Bcast</td><td>广播，顾名思义</td></tr><tr><td>MPI_Scatter</td><td>0号进程读入整个向量，但只将分量发送给需要分量的其他进程</td></tr><tr><td>MPI_Gather</td><td>将其他进程的分量都收集到0号进程</td></tr><tr><td>MPI_Allgather</td><td>将每个进程desend_buf_p内容串联起来，存储到每个进程的recv_buf_p参数中</td></tr></tbody></table><p>下面一个一个函数分别说明其参数情况。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Reduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Op op,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allreduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Op op,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Bcast</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buffer, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Scatter</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Gather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allgather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount,  <span class="comment">// local_n</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, <span class="comment">// local_n</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的派生数据类型"><a href="#中级：MPI中的派生数据类型" class="headerlink" title="中级：MPI中的派生数据类型"></a>中级：MPI中的派生数据类型</h2><blockquote><p>在MPI中，通过同时存储数据项的类型以及他们在内存中的相对位置，派生数据类型可以表示内存中数据项的任意集合。</p></blockquote><p>在书本中，派生数据类型用在了，减少通信量上。</p><p>一般创建一个新的派生数据类型，需要进行以下的步骤：</p><ol><li>调用<code>MPI_Type_create_struct</code>函数，创建派生数据类型<ol><li>可使用<code>MPI_Get_address</code>辅助得到相对地址</li></ol></li><li>调用<code>MPI_Type_commit</code>函数，允许MPI实现为了在通信函数内使用这一数据类型，优化数据类型的内部表示</li><li>使用结束后，调用<code>MPI_Type_free</code>函数释放额外的存储空间</li></ol><h3 id="函数原型"><a href="#函数原型" class="headerlink" title="函数原型"></a>函数原型</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_create_struct</span><span class="params">(<span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> <span class="keyword">int</span> array_of_blocklengths[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> MPI_Aint array_of_displacements[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> MPI_Datatype array_of_types[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           MPI_Datatype * newtype</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_commit</span><span class="params">(MPI_Datatype * datatype_p)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_free</span><span class="params">(MPI_Datatype * datatype)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p><img src="https://lh3.googleusercontent.com/-ZQmKH0alUZ4/XDx4AZvqyiI/AAAAAAAANps/UnqSTxTMGJ4OO2Nq86kZFBMXJCN_YKBEQCHMYCw/s0/Acrobat_2019-01-14_19-52-35.png" alt=""></p><h2 id="中级：MPI中的计时方法"><a href="#中级：MPI中的计时方法" class="headerlink" title="中级：MPI中的计时方法"></a>中级：MPI中的计时方法</h2><ol><li><code>MPI_Wtime</code></li><li><code>MPI_Barrier</code></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MPI_Barrier(comm);</span><br><span class="line">local_start = MPI_Wtime();</span><br><span class="line"></span><br><span class="line">....</span><br><span class="line">    </span><br><span class="line">local_finish = MPI_Wtime();</span><br><span class="line">local_elapsed = local_finish - local_start;</span><br></pre></td></tr></table></figure><h2 id="算法：并行奇偶交换排序"><a href="#算法：并行奇偶交换排序" class="headerlink" title="算法：并行奇偶交换排序"></a>算法：并行奇偶交换排序</h2><h3 id="奇偶交换排序"><a href="#奇偶交换排序" class="headerlink" title="奇偶交换排序"></a>奇偶交换排序</h3><p>关键思想：去耦的比较-交换</p><ol><li>偶数阶段：以下数对进行比较-交换<ol><li>$(a[0], a[1]), (a[2],a[3]), (a[4],a[5]),…$</li></ol></li><li>奇数阶段：以下数对进行比较-交换<ol><li>$(a[1], a[2]), (a[3],a[4]), (a[5],a[6]),…$</li></ol></li><li>定理：n个值的列表，经过n个阶段后，该列表一定能够排好序。</li></ol><h3 id="并行化"><a href="#并行化" class="headerlink" title="并行化"></a>并行化</h3><p>步骤：</p><ol><li>将数据分到不同的进程之后，先本地进行一个qsort排个序</li><li>偶数阶段：进程0,1，进程2,3进行比较-交换数据</li><li>奇数阶段：进程1,2， 进程3,4进行比较-交换数据</li></ol><p><img src="https://lh3.googleusercontent.com/-eZA5pXZnybQ/XDx7VnZQdDI/AAAAAAAANp4/DVSafASPAYgRV2LWJXEz1F-a4z06JGiHQCHMYCw/s0/Acrobat_2019-01-14_20-06-48.png" alt=""></p><h2 id="算法：并行正则采样排序"><a href="#算法：并行正则采样排序" class="headerlink" title="算法：并行正则采样排序"></a>算法：并行正则采样排序</h2><ol><li>数据初始化阶段：每个进程根据进程号与数据量，计算得到本进程所读取的数据范围，并从文件中直接读取。由于读取数据的步骤不需要进行通信分发，提高了程序运行的效率。</li><li>每一个进程对其本地的无序数据,长度为$local_n$的$local_buffer$数组进行串行快速排序，从而在每个处理器上都得到一个有序的序列$local_buffer$。</li><li>在每一个处理器上选取代表元素：每一个处理器从局部有序序列中选取第$w$，第$2<em>w$，第$3</em>w$,第$(comm_sz-1)w$共$p-1$个代表元素，其中$w=comm_sz/(p*p)$。</li><li>进程0收集每一个进程中得到的代表元素，从而具有了$(p-1)<em>(p-1)$个代表元素，然后进程0对所有代表元素进行排序，选取第$comm_sz-1$，第$2</em>(comm_sz-1)$，第$3<em>(comm_sz-1)\ \cdots (comm_sz-1)</em>(comm_sz-1)$个元素，这$comm_sz-1$个元素作为主元。</li><li>进程0将上一步中得到的$comm_sz-1$个主元$pivot_values$，分发到其余所有处理器上。</li><li>局部有序序列划分：每一个处理器根据这$comm_sz-1$个主元，将本地的$local_buffer$划分成$comm_sz$段。</li><li>有序序列的分发：在上一个步骤中的$comm_sz$段序列中，每一个处理器将本地的第$i$段发送给第$i$个处理器，最终处理器$i$拥有所有处理器的第$i$段。</li><li>最终排序：每个处理器对上一步中得到的$comm_sz$段有序序列进行排序，即为最终结果。</li></ol><h2 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h2><h3 id="向量求和"><a href="#向量求和" class="headerlink" title="向量求和"></a>向量求和</h3><ol><li>块划分:简单的将连续N个分量所构成的块，分配到每个进程中。</li><li>循环划分:采用轮转的方式去分配向量分量</li><li>块-循环划分:用一个循环来分发向量分量所构成的块，而不是分发单个向量分量。</li></ol><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol><li>在什么场景下必须使用消息标签？<ol><li><img src="https://lh3.googleusercontent.com/-ac7MTJh3T3s/XDxVtBXjiPI/AAAAAAAANpI/VWRc8sgUPlIUJBJHvgJjXZCqcIUp9PzJgCHMYCw/s0/Acrobat_2019-01-14_17-26-13.png" alt=""></li><li>这段代码打算传送A的前32个字节进入X,传送B的前16个字节进入Y.但是,如果消息B尽管后发送但先到达进程Q,就会被第一个recv()接收在X中，使用标签就可以避免这种情况</li><li><img src="https://lh3.googleusercontent.com/-9IwMxoVBf2k/XDxV13-N1SI/AAAAAAAANpM/rZe2IYt1JLIzwqtUtfsiS1QiGPCRFt_qgCHMYCw/s0/Acrobat_2019-01-14_17-26-49.png" alt=""></li></ol></li><li>MPI_Send与MPI_Recv的问题<ol><li>Send的精确行为是由MPI实现决定的，MPI_Send可能有不同大小的缓冲区，在发送消息的时候，是使用缓冲区，还是直接阻塞等待发送完成，由“消息截止大小”决定。</li><li>启示：了解实际执行情况，不要做假设。</li></ol></li><li>关于MPI_Reduce调用顺序<ol><li><img src="https://lh3.googleusercontent.com/-yu7mVk_1EZE/XDxuhZnZycI/AAAAAAAANpg/6efvirvvmQc1TStPAXBgC2ryDgv-cMwHgCHMYCw/s0/Acrobat_2019-01-14_19-12-06.png" alt=""></li><li>内存单元的名字与MPI_Reduce的调用匹配无关，函数调用的顺序决定了匹配方式。</li><li>！！不可预测，可能b中存储的值将是$1+2+1=4$，而d中为$2+1+2=5$</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习2-MPI&quot;&gt;&lt;a href=&quot;#HPC复习2-MPI&quot; class=&quot;headerlink&quot; title=&quot;HPC复习2-MPI&quot;&gt;&lt;/a&gt;HPC复习2-MPI&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.open-mpi.org/doc/current/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;OpenMPI 官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.mpich.org/static/docs/latest/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;mpich官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里是高性能计算课程-MPI部分的复习笔记，大概会有以下内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MPI中的Hello world&lt;/li&gt;
&lt;li&gt;常见的MPI函数&lt;/li&gt;
&lt;li&gt;使用MPI实现梯形积分法&lt;/li&gt;
&lt;li&gt;中级：MPI中的集合通信&lt;/li&gt;
&lt;li&gt;中级：MPI中的派生数据类型&lt;/li&gt;
&lt;li&gt;中级：MPI中的计时方法&lt;/li&gt;
&lt;li&gt;算法：奇偶并行排序算法&lt;/li&gt;
&lt;li&gt;算法：并行正则采样排序&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习1-并行硬件与并行软件</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A01-%E5%B9%B6%E8%A1%8C%E7%A1%AC%E4%BB%B6%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%BD%AF%E4%BB%B6/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习1-并行硬件与并行软件/</id>
    <published>2019-01-14T08:33:45.000Z</published>
    <updated>2019-01-15T05:38:38.926Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习1-并行硬件与并行软件"><a href="#HPC复习1-并行硬件与并行软件" class="headerlink" title="HPC复习1-并行硬件与并行软件"></a>HPC复习1-并行硬件与并行软件</h1><p>主要分为四部分：</p><ol><li>背景介绍</li><li>超算硬件</li><li>超算软件</li><li>编写并行程序</li></ol><a id="more"></a><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><ol><li>冯·诺依曼结构</li><li>进程、多任务和线程</li><li>冯·诺依曼结构的发展</li></ol><h3 id="冯·诺依曼结构"><a href="#冯·诺依曼结构" class="headerlink" title="冯·诺依曼结构"></a>冯·诺依曼结构</h3><ol><li>包括主存，中央处理单元（控制单元，算术逻辑单元ALU），以及主存和CPU之间的互连结构</li><li>冯若依曼瓶颈：主存和CPU之间的分离</li></ol><p><img src="https://lh3.googleusercontent.com/-1a3WDll47y4/XDw4ZfJw_RI/AAAAAAAANnw/o5l-qRgC4zwyRuVTEYDXURYwzhuJsKPHQCHMYCw/s0/Acrobat_2019-01-14_15-21-10.png" alt=""></p><h3 id="进程、多任务和线程"><a href="#进程、多任务和线程" class="headerlink" title="进程、多任务和线程"></a>进程、多任务和线程</h3><ol><li><strong>进程</strong>：是运行着的程序的一个实例</li><li><strong>多任务</strong>：对同时运行多个程序的支持，可真并行，也可时间片轮转</li></ol><h3 id="冯诺依曼结构的发展"><a href="#冯诺依曼结构的发展" class="headerlink" title="冯诺依曼结构的发展"></a>冯诺依曼结构的发展</h3><ol><li>高速缓存：<ol><li>是一片读写极快但是空间很小的存储区域</li><li>根据程序执行与数据访问行为的局部性，存储部分数据</li><li>目的：让数据存取的速度适应CPU的处理速度（简而言之就是加快存取速度）</li><li><img src="https://lh3.googleusercontent.com/-ng0exR_kQ68/XDw66GtmfJI/AAAAAAAANn8/FXjZR74AmNI-Jm1AZjYJ4MMw34-zdtOPwCHMYCw/s0/Acrobat_2019-01-14_15-31-52.png" alt=""></li></ol></li><li>虚拟内存<ol><li>是一种内存管理技术</li><li>解决：所需内存超过物理内存下程序无法执行的问题，以及其他直接使用物理内存可能带来的问题</li></ol></li><li>指令集并行：单处理器上的细粒度并行<ol><li>流水线技术</li><li>多发射技术</li></ol></li><li>硬件多线程<ol><li>在处理器中多开辟几仹线程状态，当线程发生切换时，处理器切换到对应的线程状态执行，在瞬间即可完成，这种方式叫做硬件多线程</li><li>多种粒度的硬件多线程，可以了解一下<ol><li>粗粒度：遇到长时间中断，切换线程</li><li>细粒度：逐个CPU周期轮流切换线程</li><li>同时多线程：多个线程的指令能够被同时发射</li><li><img src="https://lh3.googleusercontent.com/-N8o9Xm48f08/XDw73TB4n_I/AAAAAAAANoE/jIAbyujdxncxl4hMJo7yPu8y_Ptch8fzQCHMYCw/s0/Acrobat_2019-01-14_15-35-58.png" alt=""></li></ol></li></ol></li></ol><h2 id="超算硬件"><a href="#超算硬件" class="headerlink" title="超算硬件"></a>超算硬件</h2><p>主要有以下内容：</p><ol><li>两类并行系统：SIMD，MIMD</li><li>互联网络</li><li>缓存一致性</li></ol><h3 id="两类并行系统"><a href="#两类并行系统" class="headerlink" title="两类并行系统"></a>两类并行系统</h3><ol><li>Flynn 分类法<ol><li>根据指令流和数据流的概念对计算机的体系结构进行分类</li><li><img src="https://lh3.googleusercontent.com/-VqI58B-Y0RA/XDw8xAmCI7I/AAAAAAAANoQ/O9qHhKvwSMsZfN3gFs6CzSaKEyQmLNPfACHMYCw/s0/Acrobat_2019-01-14_15-39-48.png" alt=""></li></ol></li><li>SIMD 与MIMD 的最大区别<ol><li>SMID 使用一个控制器来控制多个处理器，而MIMD系统使用多个控制器异步地控制多个处理器</li><li>SIMD 中所有进程/线程执行完全相同的指令操作，而MIMD系统使用不同进程/线程执行不同的指令</li></ol></li><li>MIMD<ol><li>共享内存<ol><li>UMA结构（Uniform Memory Access）</li><li>NUMA结构（Non-Uniform Memory Access）</li><li>COMA结构（Cache-only Memory Access）</li></ol></li><li>分布内存</li></ol></li></ol><h3 id="互联网络"><a href="#互联网络" class="headerlink" title="互联网络"></a>互联网络</h3><ol><li>互联网络是：连接所有节点组成并行计算机的高速网络</li><li>两种互联网络：<ol><li>共享内存的互联网络（CPU通过互联网络与所需的Memory相连）<ol><li>总线（Buses）</li><li>交叉开关（Crossbars）</li></ol></li><li>分布内存的互联网络<ol><li>直接互联网络（两个节点直接相连）<ol><li>环</li><li>环绕网络</li><li>超立方</li></ol></li><li>间接互联网络（由开关网络负责处理节点之间的相连）<ol><li>交叉开关（Crossbars）</li><li>$\Omega$ 网络</li></ol></li></ol></li></ol></li><li>参数：<ol><li>延迟：是消息源开始収送消息到消息目的地接收到第一个字节的时间段。</li><li>带宽：是消息目的地接收第一个字节开始到完成数据接收，接收数据的速率。</li><li>理解：使用水龙头出水的时间来理解<ol><li>延迟：打开水龙头到出水的时延</li><li>带宽：水龙头口的大小</li></ol></li></ol></li></ol><h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><ol><li>概念<ol><li>指在含有多个Cache的并行系统中，数据的多个副本（因为没有同步更新）而造成的丌一致问题。</li></ol></li><li>更新缓存所需协议（二选一）<ol><li>写无效策略</li><li>写更新策略</li></ol></li><li>缓存一致性协议（二选一）<ol><li>监听总线协议</li><li>基于目录的协议</li></ol></li><li>伪共享<ol><li>现象：两个处理器上的线程，分别读取的两个不同的变量在同一个cache line里。</li><li><img src="https://lh3.googleusercontent.com/-KiiHq4K34Go/XDxANFBQAyI/AAAAAAAANoc/coRh3XIr92o-DRICB9c8857nFRItevs6gCHMYCw/s0/Acrobat_2019-01-14_15-54-29.png" alt=""></li></ol></li></ol><h2 id="超算软件"><a href="#超算软件" class="headerlink" title="超算软件"></a>超算软件</h2><p>主要有以下内容：</p><ol><li>共享内存如何协调？</li><li>分布内存如何协调？</li><li>混合编程</li></ol><h3 id="协调共享内存"><a href="#协调共享内存" class="headerlink" title="协调共享内存"></a>协调共享内存</h3><ol><li>动态线程，静态线程</li><li>不确定性</li><li>需要使用一些方法解决不确定性<ol><li>互斥锁</li><li>忙碌等待</li><li>信号量</li><li>等等</li></ol></li><li>线程安全<ol><li>代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。</li><li>例子：<code>strtok</code>函数</li></ol></li></ol><h3 id="协调分布内存"><a href="#协调分布内存" class="headerlink" title="协调分布内存"></a>协调分布内存</h3><ol><li>消息传递<ol><li><img src="https://lh3.googleusercontent.com/-qwebtN8Zvrg/XDxCVtr7avI/AAAAAAAANoo/8SFS1EwYUroyKg8HGGtJxk1UOGVZizb7wCHMYCw/s0/Acrobat_2019-01-14_16-03-35.png" alt=""></li></ol></li><li>单向通信（或称 远程内存访问）<ol><li>消息传递中，一个进程必须调用一个发送函数，并且必须与另一个进程调用的接受函数相匹配</li><li>问题：任何通信都需要两个进程的显式参与</li><li>解决：单向通信中，单个进程调用一个函数，可从其他进程中得到对应的值来更新局部内存，或者使用自己的值更新远端内存。这种通信，只需要一个进程的参与计科。</li><li><img src="https://lh3.googleusercontent.com/-jN2bOlWAYro/XDxC7MdwgiI/AAAAAAAANow/V0-wOHcfsGskmxmjA9dhv1j-Ve7vz3_TwCHMYCw/s0/Acrobat_2019-01-14_16-06-06.png" alt=""></li></ol></li><li>分区的全局地址空间<ol><li><img src="https://lh3.googleusercontent.com/-bSmqC6yOmMo/XDxDOvWazbI/AAAAAAAANo4/kBCUSEZV8PI70uGj9ZB3h7b-5I8gF62-gCHMYCw/s0/Acrobat_2019-01-14_16-07-23.png" alt=""></li></ol></li></ol><h2 id="编写并行程序"><a href="#编写并行程序" class="headerlink" title="编写并行程序"></a>编写并行程序</h2><p>主要有以下内容：</p><ol><li>一般步骤<ol><li>划分：大任务划分为小任务，使小任务可以并行执行。</li><li>通信：确定划分得到的小任务需要的通信。</li><li>集聚：如果小任务间有依赖关系，就把它们合并为一个任务。</li><li>映射：把小任务映射到丌同的迚程中，使得进程通信量最小且负载均衡。</li></ol></li><li>并行程序设计</li><li>编辑运行</li><li>输入输出</li><li>性能</li></ol><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><ol><li>计时<ol><li>需要关注CPU时间与真实运行时间的差异。</li></ol></li><li>加速比，效率<ol><li>加速比：串行计算时间与并行计算时间的比值<ol><li>$ \frac{T<em>{serial}}{T</em>{parallel}} ​$</li><li>线性加速比：计算速度随进程线程数的增加呈线性增长</li></ol></li><li>效率：加速比与进程数的比值<ol><li>$ E = \frac{S}{P} = \frac{T<em>{serial}}{p * T</em>{parallel}} $</li></ol></li><li>需要了解到，并行是有额外开销的</li></ol></li><li>阿姆达尔定律<ol><li>加速比是有上限的，无论如何增大处理器数目，加速比也无法高于某个数</li><li>$T_{serial} = W_s + W_p$</li><li>$T_{parallel} = W_s + W_p/p$</li><li>$S = \frac{W_s + W_p}{W_s + W_p/p}$<ol><li>当$p \rightarrow $正无穷的时候，上式具有极限</li></ol></li></ol></li><li>可扩展性<ol><li>同时增加问题规模和进程/线程数，并行程序的效率能基本保持丌变，就说这个程序是可扩展的。</li><li><strong>强可扩展</strong>：增加进程/线程数，为了维持效率而增加的问题规模不大</li><li><strong>弱可扩展</strong>：问题规模的增加的比率与进程/线程数增加比率一致（为了维持效率不变）</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习1-并行硬件与并行软件&quot;&gt;&lt;a href=&quot;#HPC复习1-并行硬件与并行软件&quot; class=&quot;headerlink&quot; title=&quot;HPC复习1-并行硬件与并行软件&quot;&gt;&lt;/a&gt;HPC复习1-并行硬件与并行软件&lt;/h1&gt;&lt;p&gt;主要分为四部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;背景介绍&lt;/li&gt;
&lt;li&gt;超算硬件&lt;/li&gt;
&lt;li&gt;超算软件&lt;/li&gt;
&lt;li&gt;编写并行程序&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统中的无层次命名</title>
    <link href="https://wwyf.github.io/2019/01/12/2019-01-2019-01-12-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E6%97%A0%E5%B1%82%E6%AC%A1%E5%91%BD%E5%90%8D/"/>
    <id>https://wwyf.github.io/2019/01/12/2019-01-2019-01-12-分布式系统中的无层次命名/</id>
    <published>2019-01-12T09:49:37.000Z</published>
    <updated>2019-01-12T09:57:41.499Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="分布式系统中的无层次命名"><a href="#分布式系统中的无层次命名" class="headerlink" title="分布式系统中的无层次命名"></a>分布式系统中的无层次命名</h1><p>今天整理了一下笔记，打算将无层次命名这一部分的笔记重新编辑一下，放到这里分享给大家。</p><h2 id="命名系统-基本概念"><a href="#命名系统-基本概念" class="headerlink" title="命名系统-基本概念"></a>命名系统-基本概念</h2><p>在分布式系统中，命名系统起着名称解析的作用，即，允许进程访问对应命名的实体。关于命名系统中的一些概念，这里需要弄清楚：</p><ol><li>实体与访问点的关系<ol><li>访问点是一个特殊的实体</li><li>通过访问点访问实体</li><li>实体可能具有多个访问点</li><li>实体的访问点可能会改变</li></ol></li><li><strong>名称</strong>：用于指向一个实体<ol><li><strong>位置无关</strong>的名称：独立于实体地址</li></ol></li><li><strong>地址</strong>：实体对应的某个<strong>访问点</strong>的名称</li><li><strong>标识符</strong>：用于唯一标识实体，实体与标识符是一对一的关系，且不可重用</li><li><strong>用户友好的名称</strong>：一般是字符串</li></ol><p>为了解决：把名称和标识符解析成地址 的问题，需要：</p><p><strong>名称到地址的绑定</strong></p><h2 id="无层次命名"><a href="#无层次命名" class="headerlink" title="无层次命名"></a>无层次命名</h2><blockquote><p>无层次命名是一种与实体空间位置无关的，扁平化的一种命名方法，一般用做实体的<strong>标识符</strong>。</p><p>名称解析：只给定实体的标识符（常用标识符做非结构化或无层次的名称），定位该实体。</p></blockquote><p>大体有四种方法：</p><ol><li><p>简单方法</p><ol><li>广播和多播<ol><li>包含该实体所用标识符的消息会通过广播发送到所有机器上，请求每一套机器检查它是否拥有该实体（实例：ARP 地址解析协议）</li></ol></li><li>转发指针（<strong>移动实体定位</strong>）<ol><li>每个转发指针都已（客户端存根，服务器存根）对的形式实现，当对象从地址空间A移动到地址空间B时，它会将一个客户存根留在A中，并且在B安装一个应用它的服务器存根。移动的细节对客户是透明的，客户可以顺着转发指针形成的链来查找实体对应的当前地址。</li><li>两种策略：<ol><li>直接向起始客户存根发送相应</li><li>按照转发指针的相反方向发送响应</li></ol></li></ol></li></ol></li><li><p>基于宿主位置</p><ol><li>所有与某主机地址的通信一开始都被转发到移动主机的宿主代理中。对移动主机来说，如果要转移到另一个网络，会获得一个新的地址，该<strong>转交地址</strong>要在宿主代理中注册<ol><li><img src="1547286768306.png" alt="1547286768306"></li></ol></li></ol></li><li><p>分布式散列表</p><ol><li><p>主要解决问题：m位的标识符$k$，解析为$succ(k)$的地址</p></li><li><p>如何高效解决：在每一个节点上维护一个指状表</p><ol><li><p><img src="1546940003091.png" alt="1546940003091"></p></li><li><p><img src="1546940017315.png" alt="1546940017315"></p></li></ol></li><li><p>加入与退出：</p><ol><li>节点p加入很简单，只需要请求$succ(p+1)$即可</li><li>更新指状表会比较复杂</li></ol></li></ol></li><li><p>分层方法</p><ol><li>目录节点：维护目录下的域所有实体的位置记录</li><li>低级的只有低级域的位置记录，高级域有多个低级域的位置记录</li><li>查询实体：自底向上，如果目录节点没有某记录，那转发到父节点继续查询</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;分布式系统中的无层次命名&quot;&gt;&lt;a href=&quot;#分布式系统中的无层
      
    
    </summary>
    
      <category term="Distributed System" scheme="https://wwyf.github.io/categories/Distributed-System/"/>
    
    
      <category term="Distributed System" scheme="https://wwyf.github.io/tags/Distributed-System/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://wwyf.github.io/2019/01/12/test-2018-hello-world/"/>
    <id>https://wwyf.github.io/2019/01/12/test-2018-hello-world/</id>
    <published>2019-01-12T07:36:03.302Z</published>
    <updated>2019-01-12T07:36:03.302Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="test"><a href="#test" class="headerlink" title="test"></a>test</h1><h2 id="test-imag"><a href="#test-imag" class="headerlink" title="test imag"></a>test imag</h2><p><img src="https://i.loli.net/2018/01/24/5a6875a4acc53.png" alt="这是使用公共图床上传的图片"></p><!-- ![](figure/2018-04-21-16-26-20.png) --><img src="/2019/01/12/test-2018-hello-world/2018-04-21-16-26-20.png" title="test"><h2 id="test-math"><a href="#test-math" class="headerlink" title="test math"></a>test math</h2><p>$$ a^2 = b $$</p><h2 id="test-chinese"><a href="#test-chinese" class="headerlink" title="test chinese"></a>test chinese</h2><p>这是中文。</p><h2 id="换了个头像"><a href="#换了个头像" class="headerlink" title="换了个头像"></a>换了个头像</h2><p><img src="http://blog.wwyf.top/logo.jpg" alt=""></p><h2 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h2><p>可以在<code>_posts</code>文件夹下创建自己的文件夹，然后hexo是不会管你的文件夹的！<br>继续测试。</p><p><img src="2018-05-05-11-31-29.png" alt="测试文件夹下放图片"></p><p>使用 typora的话，设置图片根目录后可以很方便的复制粘贴图片。</p><p><img src="1525494633350.png" alt="1525494633350"></p><h2 id="写好了一个脚本"><a href="#写好了一个脚本" class="headerlink" title="写好了一个脚本"></a>写好了一个脚本</h2><p>这个脚本用来自动创建一个新页面，并且填写yml模板信息</p><h2 id="测试脚注"><a href="#测试脚注" class="headerlink" title="测试脚注"></a>测试脚注</h2><p>脚注是<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="用来测试的脚注">[1]</span></a></sup></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">用来测试的脚注<a href="#fnref:1" rev="footnote"> ↩</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;test&quot;&gt;&lt;a href=&quot;#test&quot; class=&quot;head
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
  </entry>
  
  <entry>
    <title>配置博客</title>
    <link href="https://wwyf.github.io/2019/01/12/2019-01-2019-01-12-%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2/"/>
    <id>https://wwyf.github.io/2019/01/12/2019-01-2019-01-12-配置博客/</id>
    <published>2019-01-12T04:00:01.000Z</published>
    <updated>2019-01-12T09:40:14.419Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>今天配置了一下博客。</p><ol><li>本地仅维护markdown文件</li><li>通过git push，将markdown文件push到腾讯云服务器</li><li>云服务器中的远程git仓库触发hooks，cd到服务器的博客文件中，拉取最新博客文件，并执行hexo g -d 生成博客文件并发布</li></ol><p>最重要的一个改变在于：本地不需要存储博客的配置文件，仅需维护内容即可，一切配置文件都存放在了云服务器上，而且网页静态文件的生成也放在了云服务器上。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;今天配置了一下博客。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;本地仅维护markdown文
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
  </entry>
  
  <entry>
    <title>hexo配置评论系统</title>
    <link href="https://wwyf.github.io/2019/01/12/2018-05-2018-05-06-hexo%E9%85%8D%E7%BD%AE%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/"/>
    <id>https://wwyf.github.io/2019/01/12/2018-05-2018-05-06-hexo配置评论系统/</id>
    <published>2019-01-12T03:33:37.248Z</published>
    <updated>2019-01-12T03:33:37.248Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="hexo-评论系统"><a href="#hexo-评论系统" class="headerlink" title="hexo 评论系统"></a>hexo 评论系统</h1><p>有这样的想法，为自己的博客弄一个评论系统。</p><p>不过由于时间精力的缘故，还没有去弄。</p><p>先放一下要弄评论系统可能需要的一些资料。</p><p>第三方的评论系统似乎都不太好使，打算自建</p><p><a href="http://www.candura.us/posts/post-348/" target="_blank" rel="noopener">http://www.candura.us/posts/post-348/</a></p><p><a href="https://wzfou.com/hashover/" target="_blank" rel="noopener">https://wzfou.com/hashover/</a></p><p><a href="https://zhuanlan.zhihu.com/p/26955370" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26955370</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;hexo-评论系统&quot;&gt;&lt;a href=&quot;#hexo-评论系统&quot; c
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
      <category term="hexo" scheme="https://wwyf.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>hexo中的评论系统</title>
    <link href="https://wwyf.github.io/2019/01/11/2019-01-2019-01-11-hexo%E4%B8%AD%E7%9A%84%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/"/>
    <id>https://wwyf.github.io/2019/01/11/2019-01-2019-01-11-hexo中的评论系统/</id>
    <published>2019-01-11T13:55:16.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="关于hexo的评论系统"><a href="#关于hexo的评论系统" class="headerlink" title="关于hexo的评论系统"></a>关于hexo的评论系统</h1><p>这里要推荐一个极简无后端的评论系统！！！</p><blockquote><p>Valine 诞生于2017年8月7日，是一款基于Leancloud的快速、简洁且高效的无后端评论系统。<br>理论上支持但不限于静态博客，目前已有Hexo、Jekyll、Typecho、Hugo 等博客程序在使用Valine。</p></blockquote><p>官网是这一个：<a href="https://valine.js.org/" target="_blank" rel="noopener">https://valine.js.org/</a></p><h2 id="使用感受"><a href="#使用感受" class="headerlink" title="使用感受"></a>使用感受</h2><p>到leancloud上创建一个应用，然后找到把appid和appkey填到hexo的config里就好了！别的什么都不用怎么配置，哇比其他的方便多了，特别是之前那一个已经没有人维护的gitment。</p><p>引用几个博客的链接：</p><p><a href="https://blog.csdn.net/esa_dsq/article/details/78626509" target="_blank" rel="noopener">https://blog.csdn.net/esa_dsq/article/details/78626509</a><br><a href="https://xiaotiandi.github.io/publicBlog/2018-09-19-d196c9ad.html" target="_blank" rel="noopener">https://xiaotiandi.github.io/publicBlog/2018-09-19-d196c9ad.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;关于hexo的评论系统&quot;&gt;&lt;a href=&quot;#关于hexo的评论系
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
  </entry>
  
  <entry>
    <title>立一个flag</title>
    <link href="https://wwyf.github.io/2019/01/11/2019-01-2019-01-11-%E7%AB%8B%E4%B8%80%E4%B8%AAflag/"/>
    <id>https://wwyf.github.io/2019/01/11/2019-01-2019-01-11-立一个flag/</id>
    <published>2019-01-11T13:10:01.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>test 目录就是让我用来随便测试的吧。</p><p>吐槽一下，现在考试进度 6/8，加油吧~</p><p>我想测试一个图片</p><p><img src="1547212329062.png" alt="1547212329062"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;test 目录就是让我用来随便测试的吧。&lt;/p&gt;
&lt;p&gt;吐槽一下，现在考试进
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
  </entry>
  
  <entry>
    <title>BCNF与4NF</title>
    <link href="https://wwyf.github.io/2018/11/01/2018-11-2018-11-01-BCNF%E4%B8%8E4NF/"/>
    <id>https://wwyf.github.io/2018/11/01/2018-11-2018-11-01-BCNF与4NF/</id>
    <published>2018-11-01T02:18:23.000Z</published>
    <updated>2019-01-12T09:07:41.134Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="数据库关系模式的BCNF分解与4NF分解"><a href="#数据库关系模式的BCNF分解与4NF分解" class="headerlink" title="数据库关系模式的BCNF分解与4NF分解"></a>数据库关系模式的BCNF分解与4NF分解</h1><p>这两种分解看得我云里雾里，今早好不容易觉得看懂了，觉得要写成一篇blog记下来，不然以后回来再看的时候可能又要看半天才能看懂了o(╥﹏╥)o。</p><p>书本上说的会比较抽象，虽然这保证了定义和方法的准确性，但是要去理解实在是有点困难，我想，将我解答题目的过程放上来能帮助这几种分解的理解。</p><h2 id="BCNF分解实例"><a href="#BCNF分解实例" class="headerlink" title="BCNF分解实例"></a>BCNF分解实例</h2><h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><p>有这样的关系模式$r(A,B,C,D,E,F)$，其中该关系模式需要满足以下函数依赖：</p><p>$ A \rightarrow BCD $</p><p>$ BC \rightarrow DE $</p><p>$ B \rightarrow D $</p><p>$ D \rightarrow A $</p><h3 id="分析原理"><a href="#分析原理" class="headerlink" title="分析原理"></a>分析原理</h3><ol><li>如何判断一个关系模式是否满足BCNF模式<ol><li>书本P196最上面：一个最简单的判定方法，但不可用于分解后的关系模式的判定</li><li>书本P196中间：可用于分解后的关系模式的判定</li></ol></li></ol><p>这两种方法，我觉得后者会相对比较难理解，但是在实际题目中还是的确能够使用上的。</p><p>具体的定义书本上就有，这里也照抄一份：</p><p>第一种方法：</p><p><img src="http://bit.ly/2Oka04m" alt=""></p><p>第二种方法：</p><p><img src="http://bit.ly/2Og6kkd" alt=""></p><h3 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h3><p>就，按顺序一个函数依赖一个函数依赖的看就好了。</p><h4 id="第一步分解"><a href="#第一步分解" class="headerlink" title="第一步分解"></a>第一步分解</h4><p>目前的关系模式$r$还没有分解，就使用第一种方法来进行分析：</p><p>对于函数依赖$A \rightarrow BCD$来说，根据第一种方法，我先计算$A^{+} = ABCDE$，发现$A^{+}$并没有包含关系$r$中的所有属性（$ABCDEF$，少了个$F$），因此$A$不是关系模式$r$的超码。</p><p>这样子，我就根据函数依赖$A \rightarrow BCD$说明了关系模式$r$不属于BCNF，因此将原有的关系模式$r$分解为$ (r-BCD) \cup (A,BCD) $</p><p>因此此步分解得到以下关系模式：</p><blockquote><p>$ r_1(A,B,C,D) $<br>$ r_2(A,E,F) $</p></blockquote><h4 id="检验第一步分解结果"><a href="#检验第一步分解结果" class="headerlink" title="检验第一步分解结果"></a>检验第一步分解结果</h4><p>在第二步分解结果前，需要检验第一步的分解结果是否满足BCNF条件，注意到这两个关系模式是分解后产生的，原先的第一种用来判断关系模式是否属于BCNF的方法不能够再使用，后面均使用第二种方法。</p><p>先看关系模式$r_1(A,B,C,D)$。</p><p>第二种方法要求$r_1$中属性的每一个子集$\alpha$，确保$\alpha^{+}$（F下$\alpha$的属性闭包）要么不包含$r-\alpha$的任何属性，要么包含$r_1$的所有属性。</p><blockquote><p>这里为遍历$r_1$中属性子集的过程<br>对于属性$A$，$A^{+} = ABCDE$，包含了$r_1$的所有属性<br>对于属性$B$，$B^{+} = ABCDE$，包含了$r_1$的所有属性<br>对于属性$C$，$C^{+} = C$，不包含$r_1 - C$的任何属性<br>对于属性$D$，$D^{+} = ABCDE$,包含了$r_1$的所有属性<br>对于属性$E$，$E^{+} = E$，不包含$r_1 - E$的任何属性<br>对于属性子集$AB，AC，AD，AE，BC，BD，BE，CD，DE$，属性闭包均为$ABCDE$，包含了$r_1$的所有属性<br>对于属性子集$CD$，$CD^{+} = CD$，不包含$r_1 - C$的任何属性<br>对于三个属性以上的属性子集，属性闭包均为$ABCDE$，包含了$r_1$的所有属性</p></blockquote><p>综上，$r_1$满足BCNF条件。</p><p>再看关系模式$r_2(A,E,F)$:</p><blockquote><p>这里为遍历$r_2$属性子集的过程<br>对于属性$A$，$A^{+} = ABCDE$，而$r_2 - A = EF$，会发现$A^{+}$包含了$r_2 - A$中的属性$E$，且没有包含$r_2$的所有属性（如属性$F$）</p></blockquote><p>找到了一个属性违反该条件，那么就可以证明有这样的一个函数依赖出现在$F^{+}$中：</p><p>$$A \rightarrow (A^{+} - A) \cap r_2$$</p><p>算一算，$A^{+} - A \cap r_2 = BCDE \cap AEF = E$</p><p>因此便找到了这样的一个函数依赖$A \rightarrow E$，让$r_2$不满足BCNF</p><h4 id="第二步分解"><a href="#第二步分解" class="headerlink" title="第二步分解"></a>第二步分解</h4><p>上面找到了这样的一个函数依赖$A \rightarrow E$，让$r_2(A,E,F)$不满足BCNF，<br>因此$r_2$可以这样子分解：</p><p>$r_3(A, E)$</p><p>$r_4(A, F)$</p><p>此步骤得到的分解结果为</p><blockquote><p>$r_1(A,B,C,D)$<br>$r_3(A, E)$<br>$r_4(A, F)$</p></blockquote><h4 id="检验第二步结果"><a href="#检验第二步结果" class="headerlink" title="检验第二步结果"></a>检验第二步结果</h4><p>$r_1$上面已经检验过了，这里只需要检验$r_3$和$r_4$即可。</p><p>对于关系模式$r_3$：</p><blockquote><p>对于属性$A$， $A^{+} = ABCDE$，包含了$r_3$的所有属性<br>对于属性$E$，$E^{+} = E$，不包含$r_3 - E$的任何属性</p></blockquote><p>对于关系模式$r_4$：</p><blockquote><p>对于属性$A$，$A^{+} = ABCDE$，而$r_4 - A = F$，$A^{+}$不包含$r_4 - A$的所有属性<br>对于属性$F$，$F^{+} = F$，不包含$r_3 - F$的任何属性</p></blockquote><p>综上，关系模式$r_3$,$r_4$，都已经满足BCNF条件</p><h4 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h4><p>已经检验过了，每一个关系模式都满足BCNF条件，因此，最终结果便是：</p><blockquote><p>$r_1(A,B,C,D)$<br>$r_3(A, E)$<br>$r_4(A, F)$</p></blockquote><h2 id="3NF分解实例"><a href="#3NF分解实例" class="headerlink" title="3NF分解实例"></a>3NF分解实例</h2><p>我觉得3NF比BCNF简单很多，不想写了hhh</p><h2 id="4NF分解实例"><a href="#4NF分解实例" class="headerlink" title="4NF分解实例"></a>4NF分解实例</h2><h3 id="分解原理"><a href="#分解原理" class="headerlink" title="分解原理"></a>分解原理</h3><p>关于4NF，其实课本P201上已经说明了检验模式是否满足4NF的方法。</p><p>一种方法便是4NF的定义，定义可以好好看看书本，和BCNF的定义类似，但问题在于这一个定义无法用于分解后的关系模式中。</p><p><img src="http://bit.ly/2OcpJ5v" alt=""></p><p>第二种方法可以用在分解后的关系模式，其实就是找到在分解后的关系模式上的限定$D_i$，然后对于该限定$D_i$里面的每一个依赖，都使用4NF的定义去检查是否满足条件。</p><p><img src="http://bit.ly/2Ohgf95" alt=""></p><h3 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h3><p>$R = (A,B,C,G,H,I)$<br>$F = {$<br>$A \rightarrow\rightarrow B$,<br>$B \rightarrow\rightarrow HI$,<br>$CG \rightarrow\rightarrow H$<br>$}$</p><h3 id="分解流程"><a href="#分解流程" class="headerlink" title="分解流程"></a>分解流程</h3><h4 id="第一步分解-1"><a href="#第一步分解-1" class="headerlink" title="第一步分解"></a>第一步分解</h4><p>使用第一种方法来判断，注意到多值依赖是一种比函数依赖更弱的依赖，因此这里我觉得较难判断关系模式$R$的超码，就暂且认为该关系模式中的每一个属性都不是超码。</p><p>因为$A \rightarrow\rightarrow B$满足，且$A$不是关系模式$R$的超码，因此分解$R$得到</p><blockquote><p>$R_1(A,B)$<br>$R_2(A,C,G,H,I)$</p></blockquote><h4 id="判断第一步分解结果"><a href="#判断第一步分解结果" class="headerlink" title="判断第一步分解结果"></a>判断第一步分解结果</h4><p>判断分解后的关系模式是否满足4NF条件，需要使用第二种方法，这里需要计算函数依赖和多值依赖的集合$D$在$R_1$和$R_2$上的限定。</p><h5 id="判断1"><a href="#判断1" class="headerlink" title="判断1"></a>判断1</h5><p>先判断关系模式$R_1(A,B)$，我通过如下方式寻找函数依赖和多值依赖的集合$D$在$R_1$上的限定$D_1$:</p><blockquote><ol><li>$D^{+}$中所有只含有$R_1$中属性的函数依赖：无</li><li>所有形如$\alpha \rightarrow\rightarrow \beta \cap R_1$的多值依赖，其中$\alpha \in R_1$，且$\alpha \rightarrow\rightarrow \beta$ 属于$D^{+}$:<blockquote><p>当$\alpha = A$，能够找到$A\rightarrow\rightarrow B$，还有$A\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后得到仅有$A\rightarrow\rightarrow B$在限定$D_1$中<br>当$\alpha = B$，能够找到$B\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后发现没有多值依赖在限定$D_1$中</p></blockquote></li></ol></blockquote><p>因此函数依赖和多值依赖的集合$D$在$R_1$上的限定$D_1$为${ (A\rightarrow\rightarrow B) }$。</p><p>接下来判断限定里面的依赖是否能够让关系模式$R_1$满足4NF条件。因为在关系模式$R_1$中仅有两个属性$A,B$，因此多值依赖$A\rightarrow\rightarrow B$是一个平凡的多值依赖。因此满足4NF条件。</p><h5 id="判断2"><a href="#判断2" class="headerlink" title="判断2"></a>判断2</h5><p>判断关系模式$R_2(A,C,G,H,I)$是否满足4NF条件。</p><p>同样是两个步骤，显示找到函数依赖和多值依赖的集合$D$在$R_2$上的限定$D_2$，然后在限定$D_2$中，遍历每一个依赖关系，寻找是否有使得$R_2$不满足条件的依赖关系，若有则不满足4NF条件，若无则该关系模式满足4NF条件。</p><ol><li>在限定$D_2$中，我找到了这样的依赖关系$CG \rightarrow\rightarrow H$</li><li>该依赖关系并不平凡，并且$CG$也不是$R_2$的一个超码</li></ol><p>因此关系模式$R_2$不满足4NF条件，需要分解</p><h4 id="第二步分解-1"><a href="#第二步分解-1" class="headerlink" title="第二步分解"></a>第二步分解</h4><p>前面说到，根据依赖关系$CG \rightarrow\rightarrow H$，$R_2(A,C,G,H,I)$并不满足4NF条件。</p><p>因此进行分解得到以下关系模式</p><p>$R_3(C,G,H)$<br>$R_4(A,C,G,I)$</p><h4 id="判断第二步分解结果是否满足4NF条件"><a href="#判断第二步分解结果是否满足4NF条件" class="headerlink" title="判断第二步分解结果是否满足4NF条件"></a>判断第二步分解结果是否满足4NF条件</h4><p>然后又需要判断$R_3$,$R_4$是否满足4NF条件。</p><h5 id="判断-R-3"><a href="#判断-R-3" class="headerlink" title="判断$R_3$"></a>判断$R_3$</h5><p>判断仍然是两步走，先寻找函数依赖和多值依赖的集合$D$在$R_3$上的限定$D_3$，然后遍历该限定$D_3$中的每一个依赖关系。</p><ol><li>$D_3 = { (CG \rightarrow\rightarrow H) }$</li><li>$D_3$中仅有一个依赖关系，且$CG \rightarrow\rightarrow H$是一个平凡的多值依赖（因为$CG \cap H = R_3$），满足4NF条件</li></ol><p>因此$R_3$满足4NF条件</p><h5 id="判断-R-4"><a href="#判断-R-4" class="headerlink" title="判断$R_4$"></a>判断$R_4$</h5><p>对$R_4(A,C,G,I)$一样的方法，寻找$D_4$,然后遍历$D_4$。这里我会更详细地说明限定$D_4$的计算方法</p><blockquote><ol><li>$D^{+}$中所有只含有$R_4(A,C,H,I)$中属性的函数依赖：无</li><li>所有形如$\alpha \rightarrow\rightarrow \beta \cap R_4$的多值依赖，其中$\alpha \in R_4$，且$\alpha \rightarrow\rightarrow \beta$ 属于$D^{+}$:<blockquote><p>当$\alpha = A$，能够找到$A\rightarrow\rightarrow B$，还有$A\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后得到仅有$A\rightarrow\rightarrow I$在限定$D_4$中<br>当$\alpha = C$，或$\alpha = H$ 或$\alpha = I$，均找不到符合条件的多值依赖<br>当$\alpha = AC$,$\alpha = AH$,$\alpha = AI$,等等等，所有子集都找不到符合条件的多值依赖</p></blockquote></li></ol></blockquote><p>因此$D_4 = { (A \rightarrow\rightarrow I) }$</p><p>对着一个函数依赖我会发现，$A$并不是关系模式$R_4$的主键，因此该关系模式不符合4NF条件。</p><h4 id="第三步分解"><a href="#第三步分解" class="headerlink" title="第三步分解"></a>第三步分解</h4><p>上面找到了$A \rightarrow\rightarrow I$让关系模式$R_4$不满足4NF条件，因此分解成以下两个关系模式</p><p>$R_5(A,I)$</p><p>$R_6(A,C,G)$</p><h4 id="判断第三步结果是否符合4NF条件"><a href="#判断第三步结果是否符合4NF条件" class="headerlink" title="判断第三步结果是否符合4NF条件"></a>判断第三步结果是否符合4NF条件</h4><p>判断的过程依然是两步走</p><h5 id="判断-R-5"><a href="#判断-R-5" class="headerlink" title="判断$R_5$"></a>判断$R_5$</h5><p>计算得到$D_5 = { (A\rightarrow\rightarrow I) }$</p><p>该依赖关系在$R_5$中是平凡的，因为$A \cap I = R_5$</p><p>因此$R_5$满足4NF条件</p><h5 id="判断-R-6"><a href="#判断-R-6" class="headerlink" title="判断$R_6$"></a>判断$R_6$</h5><p>计算$D_6$:</p><blockquote><ol><li>$D^{+}$中所有只含有$R_6(A,C,G)$中属性的函数依赖：无</li><li>所有形如$\alpha \rightarrow\rightarrow \beta \cap R_6$的多值依赖，其中$\alpha \in R_6$，且$\alpha \rightarrow\rightarrow \beta$ 属于$D^{+}$:<blockquote><p>当$\alpha = A$，能够找到$A\rightarrow\rightarrow B$，还有$A\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后得找不到符合条件的多值依赖<br>当$\alpha = C$，或$\alpha = G$均找不到符合条件的多值依赖<br>当$\alpha = AC$,$\alpha = AG$,$\alpha = CG$,等等等，能够找到$CG \rightarrow\rightarrow H$，但是在使用$\beta \cap R_6$后，依然是空集</p></blockquote></li></ol></blockquote><p>因此，$D_6 = \emptyset$。</p><p>这个时候也可以说，对$D_6$中所有依赖，均满足4NF条件。</p><p>因此$R_6$满足4NF条件</p><h4 id="最终分解的结果"><a href="#最终分解的结果" class="headerlink" title="最终分解的结果"></a>最终分解的结果</h4><p>最终分解得到</p><blockquote><p>$R_1(A,B)$<br>$R_3(C,G,H)$<br>$R_5(A,I)$<br>$R_6(A,C,G)$</p></blockquote><h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>总之就是严格按照课本定义，一点一点地推导和证明。</p><p>课本上的定义和方法实在是太过抽象了，我希望自己可以通过对这一些实例的详细探讨，对这一些分解方法有一个比较清晰的认识就好，昨天做作业的时候还是感觉自己迷迷糊糊的，现在就感觉，注意到了一些昨天没有注意到的细节，然后对书本这些理论的自洽性也有了一些比较深的理解，本来一些觉得诶好像证明不了的，回去一看看定义，哦原来是我对定义本身就不清楚……诸如此类的问题还是蛮多的.啊希望以后期末的时候对这一块的内容可以通过这篇博客更好地复习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;数据库关系模式的BCNF分解与4NF分解&quot;&gt;&lt;a href=&quot;#数
      
    
    </summary>
    
      <category term="Datebase" scheme="https://wwyf.github.io/categories/Datebase/"/>
    
    
      <category term="Datebase" scheme="https://wwyf.github.io/tags/Datebase/"/>
    
  </entry>
  
  <entry>
    <title>关于word-embedding的理解</title>
    <link href="https://wwyf.github.io/2018/07/28/2018-07-2018-07-28-%E5%85%B3%E4%BA%8Eword-embedding%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>https://wwyf.github.io/2018/07/28/2018-07-2018-07-28-关于word-embedding的理解/</id>
    <published>2018-07-28T02:00:47.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="关于word-embedding的理解与pytorch实现"><a href="#关于word-embedding的理解与pytorch实现" class="headerlink" title="关于word-embedding的理解与pytorch实现"></a>关于word-embedding的理解与pytorch实现</h1><p>在NLP中，计算机需要一种方法，表示一个单词。我们马上可以想到，可以直接使用ascii来保存呀，计算机也能够识别。</p><p>用ascii并不是不可以，但是，大家都知道，如果能够把单词表示成向量的形式，无论在怎样的数学处理中都会更加方便，即使是用ascii，最终也必须在计算机中有一种数学的方法表达，才能够完成后续的语义识别的工作。这种，为单词寻找到一种在计算机中表示的方法，可以称之为”Word embedding”(这里的定义是不完整的，后面继续补充。)</p><p>那么，什么办法可以表示一个单词呢？一种显而易见的办法是使用“one-hot encoding”,也就是说，每一个单词，在这样的一个向量中，都有一个独一不二的索引。对不同的词，便在不同的位置为1，其余的位置为0.</p><p><img src="http://bit.ly/2mNgfSX" alt=""></p><p>不妨将单词向量化后的那一个向量空间称之为单词空间？那么，对于单词空间中的每一个具有“one-hot encoding”性质的向量，我们都能够找到一个单词一一对应。</p><p>“one-hot encoding”已经解决了单词-单词空间向量的映射问题，但是，似乎不太好呢。大家都知道，每一个单词之间都有着或多或少的关联。<strong>one-hot encoding方法，将单词之间可能具有的关联信息全部都抛弃掉，只留下一一对应的性质</strong>，这样的单词嵌入方法，并不是特别的理想。</p><h2 id="真正的word-embedding的定义"><a href="#真正的word-embedding的定义" class="headerlink" title="真正的word-embedding的定义"></a>真正的word-embedding的定义</h2><p>摘自知乎</p><blockquote><p>Embedding在数学上表示一个maping, f: X -&gt; Y， 也就是一个function，其中该函数是injective（就是我们所说的单射函数，每个Y只有唯一的X对应，反之亦然）和structure-preserving (结构保存，比如在X所属的空间上X1 &lt; X2,那么映射后在Y所属空间上同理 Y1 &lt; Y2)。那么对于word embedding，就是将单词word映射到另外一个空间，其中这个映射具有injective和structure-preserving的特点。</p></blockquote><p>个人觉得这位网友说的还是很不错的。word embedding的关键在于两点</p><ol><li>单射</li><li><strong>结构保存</strong>（原本关联度较大的两个词，在新的向量空间中的相似度也应该较大？）</li></ol><h2 id="word-embedding的输入输出"><a href="#word-embedding的输入输出" class="headerlink" title="word-embedding的输入输出"></a>word-embedding的输入输出</h2><p>输入：一个单词<br>输出：这一个单词对应的向量</p><p>其中为了达到<strong>结构保存</strong>的目的，前期还需要很多的语料库进行训练。</p><h2 id="pytorch中的word-embedding"><a href="#pytorch中的word-embedding" class="headerlink" title="pytorch中的word embedding"></a>pytorch中的word embedding</h2><p>pytorch中预先已经提供了很多可用了“神经元层”，其中有一个<code>nn.Embedding(a,b)</code>就是专门用于完成“word embedding”工作的神经元层。该层的功能是：将一个具有$a$个单词的字典中的所有单词，映射到一个$b$维的向量空间中。</p><p>简单的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line">word_to_ix = &#123;<span class="string">"hello"</span>: <span class="number">0</span>, <span class="string">"world"</span>: <span class="number">1</span>&#125;</span><br><span class="line">embeds = nn.Embedding(<span class="number">2</span>, <span class="number">5</span>)  <span class="comment"># 2 words in vocab, 5 dimensional embeddings</span></span><br><span class="line">lookup_tensor = torch.tensor([word_to_ix[<span class="string">"hello"</span>]], dtype=torch.long)</span><br><span class="line"><span class="comment"># print(lookup_tensor)  # tensor([0])</span></span><br><span class="line">hello_embed = embeds(lookup_tensor) <span class="comment"># 输入单词索引即可</span></span><br><span class="line">print(hello_embed)</span><br></pre></td></tr></table></figure><h2 id="An-Example-N-Gram-Language-Modeling"><a href="#An-Example-N-Gram-Language-Modeling" class="headerlink" title="An Example: N-Gram Language Modeling"></a>An Example: N-Gram Language Modeling</h2><p>([ word_i-2, word_i-1 ], target word)</p><p>官网上提供了一个根据上文预测下一个单词的神经网络以供参考。代码我就不放上来了。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>pytorch官方教程 <a href="https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html</a></li><li>一个知乎的回答：<a href="https://www.zhihu.com/question/32275069/answer/80188672" target="_blank" rel="noopener">https://www.zhihu.com/question/32275069/answer/80188672</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;关于word-embedding的理解与pytorch实现&quot;&gt;&lt;a
      
    
    </summary>
    
      <category term="Machine-Learning" scheme="https://wwyf.github.io/categories/Machine-Learning/"/>
    
    
      <category term="Machine-Learning" scheme="https://wwyf.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>pytorch初学感想</title>
    <link href="https://wwyf.github.io/2018/07/27/2018-07-2018-07-27-pytorch%E5%88%9D%E5%AD%A6%E6%84%9F%E6%83%B3/"/>
    <id>https://wwyf.github.io/2018/07/27/2018-07-2018-07-27-pytorch初学感想/</id>
    <published>2018-07-27T12:03:57.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="pytorch初学感想"><a href="#pytorch初学感想" class="headerlink" title="pytorch初学感想"></a>pytorch初学感想</h1><p>一开始是通过莫烦的python教程来进行学习的。他的教程有一个特点，丰富的样例代码，加上对一些细节的讲解，让我能够很快的上手pytorch。不过，我看完，总觉得还缺点什么？有一些机制我始终没有想的特别明白，就像我对<code>loss.backword()</code> <code>optimizer.step()</code>， 这几个函数的作用始终一知半解，虽然大概知道一点，但是对使用pytorch实现的神经网络，还是有一些没法想清楚的地方。</p><h2 id="官方教程"><a href="#官方教程" class="headerlink" title="官方教程"></a>官方教程</h2><p>pytorch的官方教程，有一篇我觉得写得特别好，可以说是给初学者稍微打开了pytorch背后封装的一些操作，让这一个黑盒，至少看起来不那么黑，自己写起代码来心中也有一些B数。</p><p><a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html</a></p><p>这个教程我最喜欢的一点，是它从一个使用numpy实现的两层神经网络（输入层不算一层）开始， 一点点改造成具有纯正“pytorch”风味的神经网络。这样子的教程，消除了我对pytorch封装的担心，内部的操作顿时清晰了很多。</p><h2 id="使用numpy实现神经网络？"><a href="#使用numpy实现神经网络？" class="headerlink" title="使用numpy实现神经网络？"></a>使用numpy实现神经网络？</h2><p>当然可以了~</p><p>下面把原教程的代码抄了过来，加上了自己的一点点注释。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    <span class="comment"># 这是矩阵相乘，(N行D_in列) * (D_in行H列)，算出来(N行，H列)的矩阵，其中第i行第j列的元素表示，第i个输入对应的第j个隐藏层神经元的输出</span></span><br><span class="line">    h = x.dot(w1)</span><br><span class="line">    <span class="comment"># 这里就是relu函数啦，相比起来我们喜闻乐见的relu函数，这里不过是用矩阵的方式，使用这个函数本身的定义来计算。查一下relu函数就清楚了</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 再一次矩阵线程，算出输出层神经元的输出值</span></span><br><span class="line">    y_pred = h_relu.dot(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    <span class="comment"># 差的平方再求和</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    <span class="comment"># 下面就是具体计算梯度的方法，这个计算方法如何得出来的，大概可以参考《机器学习》周志华书上的数学证明 P102-104</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><h2 id="如何将上面的神经网络pytorch化？"><a href="#如何将上面的神经网络pytorch化？" class="headerlink" title="如何将上面的神经网络pytorch化？"></a>如何将上面的神经网络pytorch化？</h2><p>pytorch为神经网络的编写，提供了一些方便的接口，用以替代上面的部分代码</p><ol><li>numpy中的array不能够跑在GPU上计算，而与之功能类似的<code>torch.tensor</code>可以跑在GPU上</li><li>梯度的计算，pytorch中提供接口能够自动算<ol><li>tensor中有一个grad成员用于存放梯度</li><li>tensor对象在进行运算的时候，会自动建造一张计算图（<strong>computational graph</strong> ）</li><li>在计算损失后，能够调用<code>backwoard()</code>，算出用于计算这个损失涉及到的有关tensor（requires_grad=True）的梯度，并存到对应的tensor的grad成员中。</li></ol></li><li>优化器的选择：pytorch中提供了多种优化器，用以取代显式的使用梯度修改</li><li>神经网络模型的建立，能够通过高层接口，简单的增加层，而不用自己麻烦的定义参数矩阵再进行相乘</li><li>损失的计算：pytorch中同样提供了多种损失函数</li></ol><p>以上每一个点，在原教程中都有对应的代码用来与原代码对比。最终，我们得到了下面的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the nn package to define our model and loss function.</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out),</span><br><span class="line">)</span><br><span class="line">loss_fn = torch.nn.MSELoss(size_average=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the optim package to define an Optimizer that will update the weights of</span></span><br><span class="line"><span class="comment"># the model for us. Here we will use Adam; the optim package contains many other</span></span><br><span class="line"><span class="comment"># optimization algoriths. The first argument to the Adam constructor tells the</span></span><br><span class="line"><span class="comment"># optimizer which Tensors it should update.</span></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y by passing x to the model.</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss.</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Before the backward pass, use the optimizer object to zero all of the</span></span><br><span class="line">    <span class="comment"># gradients for the variables it will update (which are the learnable</span></span><br><span class="line">    <span class="comment"># weights of the model). This is because by default, gradients are</span></span><br><span class="line">    <span class="comment"># accumulated in buffers( i.e, not overwritten) whenever .backward()</span></span><br><span class="line">    <span class="comment"># is called. Checkout docs of torch.autograd.backward for more details.</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradient of the loss with respect to model</span></span><br><span class="line">    <span class="comment"># parameters</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calling the step function on an Optimizer makes an update to its</span></span><br><span class="line">    <span class="comment"># parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><p>代码其实少了很多，通过与原来numpy编写的神经网络对比，也更好的理解各个高层接口的作用。</p><blockquote><p>我个人觉得，编写框架的人总是喜欢把高层接口控制得尽可能优雅，就如同现在我们所使用的pytorch一样，事实上，有了pytorch的优雅的高层接口 ，十多二十行足以编写一个可以玩一玩的神经网络。然而，作为初学者而言，我们总是很难把握高层接口的作用，在使用的时候总是很不踏实，可以说，对高层接口又爱又恨，万一出bug了呢，怎么改呀，高层接口帮我做了啥我也不知道呀。官方教程这样子从底层开始展示细节到使用高层接口替换的教程，恰巧将初学者在学习过程中的不安给打消了。不管怎么说，我觉得官方的教程写的棒棒哒！让我感觉自己在调用高层api的时候心安了不少:joy:。</p></blockquote><h2 id="自定义nn模块还有autograd函数？"><a href="#自定义nn模块还有autograd函数？" class="headerlink" title="自定义nn模块还有autograd函数？"></a>自定义nn模块还有autograd函数？</h2><p>都可以都可以，我建议自己试多几把，这样子对这个框架也能够更加地熟悉。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;pytorch初学感想&quot;&gt;&lt;a href=&quot;#pytorch初学感
      
    
    </summary>
    
      <category term="python" scheme="https://wwyf.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://wwyf.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>pytorch中的unsqueeze函数</title>
    <link href="https://wwyf.github.io/2018/07/27/2018-07-2018-07-27-pytorch%E4%B8%AD%E7%9A%84unsqueeze%E5%87%BD%E6%95%B0/"/>
    <id>https://wwyf.github.io/2018/07/27/2018-07-2018-07-27-pytorch中的unsqueeze函数/</id>
    <published>2018-07-27T07:33:37.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="pytorch中的unsqueeze函数"><a href="#pytorch中的unsqueeze函数" class="headerlink" title="pytorch中的unsqueeze函数"></a>pytorch中的unsqueeze函数</h1><p>一直对pytorch中的<code>unsqueeze</code>不太理解，官方文档的解释是：</p><blockquote><p>Returns a new tensor with a dimension of size one inserted at the specified position.</p><p>The returned tensor shares the same underlying data with this tensor.</p></blockquote><p>其实说的已经很清楚了，但是在我搞懂这个问题前，一直没有看懂这段说明的意思，因此做了一些实验来验证自己的想法。将自己的感想放到博客上，以供以后忘记了再回看复习。</p><h2 id="一句话解释"><a href="#一句话解释" class="headerlink" title="一句话解释"></a>一句话解释</h2><p>这个函数的意思，就是</p><ol><li>往原有的数据中，增加一个维度</li><li>增加的维度值，必须是1</li></ol><h2 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h2><p>随便弄了个这样的矩阵来进行实验</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">arr = array([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>]],</span><br><span class="line"></span><br><span class="line">       [[ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]],</span><br><span class="line"></span><br><span class="line">       [[ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]]])</span><br><span class="line">        </span><br><span class="line"><span class="comment"># In [53]: arr.shape</span></span><br><span class="line"><span class="comment"># Out[53]: (3, 2, 4)</span></span><br></pre></td></tr></table></figure><p>结果见下面的截图</p><p><img src="http://bit.ly/2AaD5gE" alt=""></p><h2 id="对numpy中维度的理解"><a href="#对numpy中维度的理解" class="headerlink" title="对numpy中维度的理解"></a>对numpy中维度的理解</h2><p><a href="https://flat2010.github.io/2017/05/31/Numpy%E6%95%B0%E7%BB%84%E8%A7%A3%E6%83%91/" target="_blank" rel="noopener">https://flat2010.github.io/2017/05/31/Numpy%E6%95%B0%E7%BB%84%E8%A7%A3%E6%83%91/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;pytorch中的unsqueeze函数&quot;&gt;&lt;a href=&quot;#p
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
  </entry>
  
  <entry>
    <title>ftp服务器+内网穿透</title>
    <link href="https://wwyf.github.io/2018/07/26/2018-07-2018-07-26-ftp%E6%9C%8D%E5%8A%A1%E5%99%A8-%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
    <id>https://wwyf.github.io/2018/07/26/2018-07-2018-07-26-ftp服务器-内网穿透/</id>
    <published>2018-07-26T09:22:51.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>花了一下下午时间，做了自己的ftp服务器。</p><ol><li>配置具有多用户多权限多目录的ftp服务器</li><li>内网测试</li><li>买一个域名？绑定到云服务器上</li><li>使用frp完成内网穿透</li><li>几个比较重要的坑<ol><li>必须使用被动模式</li><li>vsftpd的被动模式设置数据端口段，并使用frp进行转发</li></ol></li></ol><p>主要分为两个内容来记录一下这一次的配置。</p><h1 id="配置多用户多权限多目录的ftp服务器"><a href="#配置多用户多权限多目录的ftp服务器" class="headerlink" title="配置多用户多权限多目录的ftp服务器"></a>配置多用户多权限多目录的ftp服务器</h1><p>考虑到自己需要去弄多个用户都可以登录并且还具有不同权限的ftp服务器，我在网上找到了这样的一个教程，然后自己在理解了这个教程的基础上，对一些指令进行了适当的改动。</p><p><a href="http://forum.ubuntu.org.cn/viewtopic.php?t=368282" target="_blank" rel="noopener">http://forum.ubuntu.org.cn/viewtopic.php?t=368282</a></p><p>为了防止该网站gg，我记录一下。</p><p><img src="http://bit.ly/2Ok9k0e" alt=""></p><h2 id="我自己的配置"><a href="#我自己的配置" class="headerlink" title="我自己的配置"></a>我自己的配置</h2><p>我把有关用户的配置都放在了/etc/vsftpd里面，并且把一些重要的文件的权限设置为600，这样的话，就无法查看与数据库对应的用户名密码的文件。</p><h2 id="还有一个坑"><a href="#还有一个坑" class="headerlink" title="还有一个坑"></a>还有一个坑</h2><p>vsftpd-500-oops-cannot-change-directory</p><p>关于这一个错误，可能有好几种原因。</p><p>我见过的有，</p><ol><li>补上这一条指令，可能就可以了（<img src="http://bit.ly/2OhbZrn" alt=""> <code>allow_writeable_chroot=YES</code></li><li>可能是对应的文件夹还没有创建（傻逼错误了这是）</li></ol><h1 id="内网穿透"><a href="#内网穿透" class="headerlink" title="内网穿透"></a>内网穿透</h1><p>大概的配置其实还是挺简单的，frp本身就易用，然后我在这一次的配置中，使用到了supervisor对frp进程进行守护。</p><h2 id="使用supervisor对frp进行守护"><a href="#使用supervisor对frp进行守护" class="headerlink" title="使用supervisor对frp进行守护"></a>使用supervisor对frp进行守护</h2><p><a href="https://diannaobos.com/post/535.html" target="_blank" rel="noopener">https://diannaobos.com/post/535.html</a><br>主要参考了这一篇博客来进行配置，注意到日志文件的输出也是在配置文件里面定义好的。</p><h2 id="配置服务器端"><a href="#配置服务器端" class="headerlink" title="配置服务器端"></a>配置服务器端</h2><p>frps.ini</p><p><img src="http://bit.ly/2A8E1m0" alt=""></p><p>很贴心的提供了token，防止别人偷偷用自己的服务器做内网穿透</p><h2 id="配置客户端"><a href="#配置客户端" class="headerlink" title="配置客户端"></a>配置客户端</h2><p>注意客户端的token要和服务器端的一致就好</p><p><img src="http://bit.ly/2mHzBZs" alt=""></p><h2 id="一个坑点"><a href="#一个坑点" class="headerlink" title="一个坑点"></a>一个坑点</h2><p>在清楚ftp主动模式和被动模式之后，其实我们很容易发现，在使用一台外网服务器去做内网穿透后，我们如果使用主动模式访问ftp服务器，是会出问题的。</p><p><a href="https://github.com/fatedier/frp/issues/219" target="_blank" rel="noopener">https://github.com/fatedier/frp/issues/219</a></p><p>主要参考了这一个issue解决了这个问题。</p><p>不过有一个显示，只能够使用被动模式访问ftp服务器，如果使用主动模式是完全行不通的。</p><h1 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h1><p>注意了，如果使用域名访问的话只能够使用被动模式来访问，在命令行中，linux的ftp命令可以通过passive切换主被动模式，而window下好像没有被动模式？</p><p>注意一点：使用域名的话，必须使用被动模式，而如果使用中大内网ip的话则必须使用主动模式，不能使用被动模式（原因有点复杂），不过中大内网速度飞快啊10mb/s</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;花了一下下午时间，做了自己的ftp服务器。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置具
      
    
    </summary>
    
      <category term="Tools" scheme="https://wwyf.github.io/categories/Tools/"/>
    
    
      <category term="Tools" scheme="https://wwyf.github.io/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>信号量应用实例</title>
    <link href="https://wwyf.github.io/2018/07/13/2018-07-2018-07-13-%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B/"/>
    <id>https://wwyf.github.io/2018/07/13/2018-07-2018-07-13-信号量应用实例/</id>
    <published>2018-07-12T16:20:57.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="使用信号量解决这样的问题"><a href="#使用信号量解决这样的问题" class="headerlink" title="使用信号量解决这样的问题"></a>使用信号量解决这样的问题</h2><blockquote><p>某操作系统支持信号量机制，系统中有一组进程A、B、C、D和E共5个合作进程，它们中各有一个操作，分别记为a, b, c, d和e，这些操作需要按下面的时序推进：操作a完成后才可以开始操作b和操作c；操作b完成后才可以开始操作d，操作c和操作d完成后才能开始操作e。请在这5个进程的程序中描述如何利用信号量实现规定的同步，要求说明用到几个信号量，每个信号量的初值是什么。 </p></blockquote><h2 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a>一些说明</h2><p>使用信号量实现一些进程的按序执行，一般可以按照这样的做法。</p><p>若B进程必须等候A进程的进行，以下是简单的代码说明</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">s a_finished = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">A</span><span class="params">()</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* a */</span></span><br><span class="line"></span><br><span class="line">    V(a_finished);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">B</span><span class="params">()</span></span>&#123;</span><br><span class="line">    P(a_finished);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* b  */</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="这一道题"><a href="#这一道题" class="headerlink" title="这一道题"></a>这一道题</h2><h3 id="使用到的信号量"><a href="#使用到的信号量" class="headerlink" title="使用到的信号量"></a>使用到的信号量</h3><p>注意，使用的都是计数信号量</p><table><thead><tr><th>信号量名称</th><th>信号量作用</th></tr></thead><tbody><tr><td>a_finished</td><td>将“a已完成任务”作为一种信号，给进程B，进程C领取</td></tr><tr><td>b_finished</td><td>“b已完成任务”，告诉d进程</td></tr><tr><td>c_finished</td><td>“c已完成任务”，告诉e进程</td></tr><tr><td>d_finished</td><td>“d已完成任务”，告诉e进程</td></tr></tbody></table><h3 id="代码说明"><a href="#代码说明" class="headerlink" title="代码说明"></a>代码说明</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">s a_finished = <span class="number">0</span>;</span><br><span class="line">s b_finished = <span class="number">0</span>;</span><br><span class="line">s c_finished = <span class="number">0</span>;</span><br><span class="line">s d_finished = <span class="number">0</span>;</span><br><span class="line">s e_finished = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">A</span><span class="params">()</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* a */</span></span><br><span class="line"></span><br><span class="line">    V(a_finished);</span><br><span class="line">    V(a_finished);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">B</span><span class="params">()</span></span>&#123;</span><br><span class="line">    P(a_finished);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* b  */</span></span><br><span class="line"></span><br><span class="line">    V(b_finished);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">C</span><span class="params">()</span></span>&#123;</span><br><span class="line">    P(a_finished);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* c */</span></span><br><span class="line"></span><br><span class="line">    V(c_finished);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">D</span><span class="params">()</span></span>&#123;</span><br><span class="line">    P(b_finished);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* d */</span></span><br><span class="line"></span><br><span class="line">    V(d_finished);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">E</span><span class="params">()</span></span>&#123;</span><br><span class="line">    P(d_finished);</span><br><span class="line">    P(c_finished);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* e */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    parbegin(A(),B(),C(),D(),E());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;使用信号量解决这样的问题&quot;&gt;&lt;a href=&quot;#使用信号量解决这样
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
  </entry>
  
  <entry>
    <title>使用信号量解决互斥问题</title>
    <link href="https://wwyf.github.io/2018/07/08/2018-07-2018-07-08-%E4%BD%BF%E7%94%A8%E4%BF%A1%E5%8F%B7%E9%87%8F%E8%A7%A3%E5%86%B3%E4%BA%92%E6%96%A5%E9%97%AE%E9%A2%98/"/>
    <id>https://wwyf.github.io/2018/07/08/2018-07-2018-07-08-使用信号量解决互斥问题/</id>
    <published>2018-07-08T07:21:47.000Z</published>
    <updated>2019-01-12T03:33:37.284Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="使用信号量解决同步问题"><a href="#使用信号量解决同步问题" class="headerlink" title="使用信号量解决同步问题"></a>使用信号量解决同步问题</h1><h2 id="信号量定义"><a href="#信号量定义" class="headerlink" title="信号量定义"></a>信号量定义</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">semaphore</span>&#123;</span> <span class="comment">//定义结构</span></span><br><span class="line">    <span class="keyword">int</span> count;</span><br><span class="line">    queueType *<span class="built_in">queue</span>;</span><br><span class="line">&#125;s;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>  <span class="title">P</span><span class="params">(semaphore s)</span> </span>&#123; <span class="comment">// P操作</span></span><br><span class="line">    s.count--;</span><br><span class="line">    <span class="keyword">if</span> (s.count&lt;<span class="number">0</span>)  </span><br><span class="line">       Block(CurruntProcess, s.<span class="built_in">queue</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>  <span class="title">V</span><span class="params">(semaphore s)</span> </span>&#123;<span class="comment">// V操作</span></span><br><span class="line">    s.count++;</span><br><span class="line">    <span class="keyword">if</span> (s.count&lt;=<span class="number">0</span>)  </span><br><span class="line">       WakeUp(s.<span class="built_in">queue</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="用信号量实现进程同步"><a href="#用信号量实现进程同步" class="headerlink" title="用信号量实现进程同步"></a>用信号量实现进程同步</h2><p>系统中的一些进程需要相互合作，共同完成一项任务。具体来说，一个进程运行到某一点时，要求另一伙伴进程为它提供消息，在未获得消息之前，该进程处于阻塞状态，获得消息后被唤醒进入就绪状态。</p><p>这里有一个例子是：司机与售票员之间的同步。只有当售票员关门了，司机才可以进行启动汽车，而且只有当司机到站停车了，售票员才能够开门。</p><h3 id="信号量实现进程同步"><a href="#信号量实现进程同步" class="headerlink" title="信号量实现进程同步"></a>信号量实现进程同步</h3><p>进程$P_I$将输入的数据写入缓冲区$B_1$,<br>进程$P_C$读出$B_1$中的数据，完成计算，把结果写入缓冲区$B_2$<br>进程$P_P$读出$B_2$中的结果，打印输出</p><p>这三个进程之间的同步要求有两点</p><ol><li>先写后读（不能读空缓冲区）</li><li>未读完不能写（不能写非空缓冲区）</li></ol><p><img src="https://lh3.googleusercontent.com/-ugfRbGmn9sw/W0HCOZ220uI/AAAAAAAAI2U/CZyBocvneOcYFZ_mQUfiBTp60-J7VECSQCHMYCw/s0/POWERPNT_2018-07-08_15-50-15.png" alt=""></p><p>对于这个问题，使用信号量可以这样解决</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">semaphore empty1 = <span class="number">1</span>;</span><br><span class="line">semaphore full1 = <span class="number">0</span>;</span><br><span class="line">semaphore empry2 = <span class="number">1</span>;</span><br><span class="line">semaphore full2 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对PI进程而言</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>)&#123;</span><br><span class="line">    P(empty1);</span><br><span class="line">    <span class="comment">// 将数据写到B1</span></span><br><span class="line">    V(full1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//对PC进程而言</span></span><br><span class="line"><span class="keyword">while</span> ( <span class="number">1</span> ) &#123;</span><br><span class="line">    P(full1);</span><br><span class="line">    <span class="comment">// 从B1中读取数据;</span></span><br><span class="line">    V(empty1);</span><br><span class="line">    <span class="comment">// 计算;</span></span><br><span class="line">    P(empty2);</span><br><span class="line">    <span class="comment">// 结果写到B2;</span></span><br><span class="line">    V(full2);</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 对PP进程而言</span></span><br><span class="line"><span class="keyword">while</span> ( <span class="number">1</span> ) &#123;</span><br><span class="line">    P(full2);</span><br><span class="line">    <span class="comment">// 读取B2中的结果并输出到打印机;</span></span><br><span class="line">    V(empty2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="生产者-消费者问题"><a href="#生产者-消费者问题" class="headerlink" title="生产者/消费者问题"></a>生产者/消费者问题</h2><p>并发处理的最常见问题类型</p><p>问题描述</p><ol><li>若干进程通过无限/有限的共享缓冲区交换数据</li><li>一组“生产者”进程不断写入</li><li>另一组“消费者”进程不断读出</li><li>共享缓冲区无限/共有N个</li><li>任何时刻只能有一个进程可对共享缓冲区进行操作</li></ol><h3 id="基于计数信号量的正确解决方案"><a href="#基于计数信号量的正确解决方案" class="headerlink" title="基于计数信号量的正确解决方案"></a>基于计数信号量的正确解决方案</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">semaphore n=<span class="number">0</span>; <span class="comment">/*缓冲区中的产品数*/</span></span><br><span class="line">semaphore s=<span class="number">1</span>; <span class="comment">/*互斥*/</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">    produce();</span><br><span class="line"></span><br><span class="line">    semWait(s);</span><br><span class="line">    append();</span><br><span class="line">    semSignal(s);</span><br><span class="line"></span><br><span class="line">    semSignal(n);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;   </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">    semWait(n);</span><br><span class="line"></span><br><span class="line">    semWait(s);</span><br><span class="line">    take();</span><br><span class="line">    semSignal(s);</span><br><span class="line"></span><br><span class="line">    consume();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;   </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">   parbegin(producer, consumer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="基于二元信号量的正确解决方案"><a href="#基于二元信号量的正确解决方案" class="headerlink" title="基于二元信号量的正确解决方案"></a>基于二元信号量的正确解决方案</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line">Binary_semaphore s=<span class="number">1</span>; <span class="comment">// 用于控制缓冲区变量的互斥访问</span></span><br><span class="line">Binary_semaphore delay=<span class="number">0</span>; <span class="comment">// 用于确定能否访问缓冲区，如果缓冲区为空，阻塞消费者</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">    produce();</span><br><span class="line">    semWaitB(s);</span><br><span class="line">    append();</span><br><span class="line">    n++;</span><br><span class="line">    <span class="keyword">if</span> (n==<span class="number">1</span>)  semSignalB(delay);</span><br><span class="line">    semSignalB(s);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;   </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> m;</span><br><span class="line">  semWaitB(delay);</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">    semWaitB(s);</span><br><span class="line">    take();</span><br><span class="line">    n--;</span><br><span class="line">    m=n;</span><br><span class="line">    semSignalB(s);</span><br><span class="line">    consume();</span><br><span class="line">    <span class="keyword">if</span> (m==<span class="number">0</span>)  semWaitB(delay);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="有限循环缓冲区的解决方案"><a href="#有限循环缓冲区的解决方案" class="headerlink" title="有限循环缓冲区的解决方案"></a>有限循环缓冲区的解决方案</h3><p>一种这样的思想：生产者在将产品放入缓冲区前，先申请一个空闲位置（空闲信号量-1），然后在将产品放入到缓冲区中，然后再申请增加一个产品。（感觉是一种比较保守的做法）</p><p>消费者也是采取了一种保守的做法。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> sizebuffer=N</span><br><span class="line">semaphore n=<span class="number">0</span>; <span class="comment">/*产品数*/</span></span><br><span class="line">semaphore s=<span class="number">1</span>;  <span class="comment">/*互斥*/</span></span><br><span class="line">semaphore e=N; <span class="comment">/*空闲数*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">    produce();</span><br><span class="line">    semWait(e);</span><br><span class="line"></span><br><span class="line">    semWait(s);</span><br><span class="line">    append();</span><br><span class="line">    semSignal(s);</span><br><span class="line"></span><br><span class="line">    semSignal(n);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;   </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">    semWait(n);</span><br><span class="line"></span><br><span class="line">    semWait(s);</span><br><span class="line">    take();</span><br><span class="line">    semSignal(s);</span><br><span class="line"></span><br><span class="line">    semSignal(e);</span><br><span class="line">    consume();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;   </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">   parbegin(producer, consumer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="写者-读者问题"><a href="#写者-读者问题" class="headerlink" title="写者/读者问题"></a>写者/读者问题</h2><p>同步与并发机制设计的著名问题<br>问题描述</p><ol><li>有一个多个进程共享的数据区，有一些只读取这个数据区的进程(reader)和一些只往数据区中写数据的进程(writer)</li></ol><p>必须满足下列条件：</p><ol><li>任意多的读进程可以同时读这个数据区</li><li>一次只有一个写进程可以往数据区写</li><li>如果一个写进程正在往数据区中写，禁止任何读进程读数据区</li></ol><h3 id="读者优先信号量方案"><a href="#读者优先信号量方案" class="headerlink" title="读者优先信号量方案"></a>读者优先信号量方案</h3><ol><li>一旦有一个读进程正在读，写进程就一直被阻塞</li><li>直到没有读进程在读了写进程才可以在写。</li><li>读者优先，写者可能饥饿</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/* program reader_and_writer */</span></span><br><span class="line"><span class="keyword">int</span> readcount;  </span><br><span class="line">semaphore x=<span class="number">1</span>; <span class="comment">// 用于保证readcount被正确更新</span></span><br><span class="line">semaphore wsem=<span class="number">1</span>;  <span class="comment">// 用于实现互斥</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reader</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">      P(x);</span><br><span class="line">      readcount++;</span><br><span class="line">      <span class="comment">// 如果本来没有进程在读，这是第一个进程，就需要防止该单元被写</span></span><br><span class="line">      <span class="keyword">if</span> (readcount==<span class="number">1</span>) P(wsem);</span><br><span class="line">      V(x);</span><br><span class="line">      READUNIT();</span><br><span class="line">      P(x);</span><br><span class="line">      readcount--;</span><br><span class="line">      <span class="comment">// 如果没有进程在读了，这是最后一个进程，就需要释放这一个单元</span></span><br><span class="line">      <span class="keyword">if</span> (readcount==<span class="number">0</span>) V(wsem);</span><br><span class="line">      V(x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">writer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">      P(wsem);</span><br><span class="line">      WRITEUNIT();</span><br><span class="line">      V(wsem);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   readcount=<span class="number">0</span>;</span><br><span class="line">   parbegin(reader(), writer());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="写者优先信号量方案"><a href="#写者优先信号量方案" class="headerlink" title="写者优先信号量方案"></a>写者优先信号量方案</h3><p>为了保证写进程优先，写进程声明想写时，不允许新的读进程访问该数据块。</p><p>一旦有一个写者要写，读者就无法读取，读者只能够等待所有写者写完才能够进行读取。</p><ol><li>当写进程声明想写时，不允许有新的进程继续读</li><li>思路<ol><li>读进程在一个队列上进行排队（信号量z）<ol><li>信号量z初值设为1，这就意味着所有想要读的进程想要排队的时候，只有一个能够排到队头去获取读的权力</li><li>概括：通过信号量z，多个读者在队列中排队，并且每次只能够派出一名读者尝试获取读的权力</li></ol></li><li>尝试获取读的权力（信号量rsem）<ol><li>rsem信号量，读者写者都在争取，写者获得了运行权限后，第一个写者会锁住“读的权力”rsem信号量，从而此时的读者无法获得读的权力，阻塞着</li><li>若此时仍有写者要来写，writecount的值会大于1，因此rsem不会被第一个写者立马释放。</li><li>实现了：一旦有一个写者要写，读者就无法读取，读者只能够等待所有写者写完才能够进行读取。</li></ol></li></ol></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* program reader_and_writer */</span></span><br><span class="line"><span class="keyword">int</span> readcount, writecount;  </span><br><span class="line">semaphore x=<span class="number">1</span>, y=<span class="number">1</span>, z=<span class="number">1</span>, rsem=<span class="number">1</span>, wsem=<span class="number">1</span>; </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">信号量z：</span></span><br><span class="line"><span class="comment">信号量x：控制readcount的更新</span></span><br><span class="line"><span class="comment">-------------------------</span></span><br><span class="line"><span class="comment">writecount：控制rsem的设置</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">信号量rsem : 『读的权力』当有写进程准备访问数据区的时候，用于禁止所有的读进程</span></span><br><span class="line"><span class="comment">信号量wsem：『写的权力』</span></span><br><span class="line"><span class="comment">信号量y：控制writecount的更新</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reader</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">       <span class="comment">// rsem表示『读的权力』，应该像一个二元信号量一样</span></span><br><span class="line">       <span class="comment">// 有了z在rsem前面，那么rsem最多被读进程要一次，其他的进程都会在z上排队。</span></span><br><span class="line">      P(z); P(rsem); </span><br><span class="line"> P(x);</span><br><span class="line">      readcount++;</span><br><span class="line">      <span class="keyword">if</span> (readcount==<span class="number">1</span>) P(wsem);</span><br><span class="line">      V(x); </span><br><span class="line"> V(rsem); V(z);</span><br><span class="line"> READUNIT();</span><br><span class="line">      P(x);</span><br><span class="line">      readcount--;</span><br><span class="line">      <span class="keyword">if</span> (readcount==<span class="number">0</span>) V(wsem);</span><br><span class="line">      V(x);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">writer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">      P(y); </span><br><span class="line">      writecount++;</span><br><span class="line">      <span class="keyword">if</span> (writecount==<span class="number">1</span>) P(rsem);</span><br><span class="line">      V(y);</span><br><span class="line">      P(wsem);</span><br><span class="line">      WRITEUNIT();</span><br><span class="line">      V(wsem);</span><br><span class="line">      P(y); </span><br><span class="line">      writecount--;</span><br><span class="line">      <span class="keyword">if</span> (writecount==<span class="number">0</span>) V(rsem);</span><br><span class="line">      V(y);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   readcount = writecount = <span class="number">0</span>;</span><br><span class="line">   parbegin(reader(), writer());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="公平方案"><a href="#公平方案" class="headerlink" title="公平方案"></a>公平方案</h3><p>如何体现公平？</p><p>读者/写者的公平方案是指：无论读者还是写者，都有可能获取到一个锁用以锁住文件访问权限。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">void</span> read-justice()&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    p(q);</span><br><span class="line"></span><br><span class="line">    p(rcountsem)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rcount == <span class="number">0</span>)</span><br><span class="line">      p(fsem)</span><br><span class="line">    rcount++;</span><br><span class="line"></span><br><span class="line">    r(rcountsem)</span><br><span class="line">    </span><br><span class="line">    v(q) ; </span><br><span class="line"></span><br><span class="line">    <span class="comment">// reading... </span></span><br><span class="line"></span><br><span class="line">    p(rcountsem)</span><br><span class="line"></span><br><span class="line">    rcount--;</span><br><span class="line">    <span class="keyword">if</span> (rcount == <span class="number">0</span>)</span><br><span class="line">      v(fsem);</span><br><span class="line"></span><br><span class="line">    v(rcountsem)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write_justice</span><span class="params">()</span></span>&#123; </span><br><span class="line">  p(q) ; </span><br><span class="line">  p(fsem) ; </span><br><span class="line">  v(q); </span><br><span class="line">  <span class="comment">// writing... </span></span><br><span class="line">  v (fsem) ; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="哲学家就餐问题"><a href="#哲学家就餐问题" class="headerlink" title="哲学家就餐问题"></a>哲学家就餐问题</h2><h3 id="信号量解决方案一"><a href="#信号量解决方案一" class="headerlink" title="信号量解决方案一"></a>信号量解决方案一</h3><p>这一种方案有死锁风险</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">semaphore fork[<span class="number">5</span>]=&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">philosopher</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">      think();</span><br><span class="line">      P(fork[i]);</span><br><span class="line">      P(fork[(i+<span class="number">1</span>) mod <span class="number">5</span>]);</span><br><span class="line">      eat();</span><br><span class="line">      V(fork[(i+<span class="number">1</span>) mod <span class="number">5</span>]);</span><br><span class="line">      V(fork[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    parbegin(</span><br><span class="line">       philosopher(<span class="number">1</span>),</span><br><span class="line">       philosopher(<span class="number">2</span>),</span><br><span class="line">       philosopher(<span class="number">3</span>),</span><br><span class="line">       philosopher(<span class="number">4</span>),</span><br><span class="line">       philosopher(<span class="number">5</span>)</span><br><span class="line">     )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="信号量解决方案二"><a href="#信号量解决方案二" class="headerlink" title="信号量解决方案二"></a>信号量解决方案二</h3><p>这里增加了一个服务员，这个服务员只允许四位哲学家同时进入餐厅。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">semaphore fork[<span class="number">5</span>]=&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;;</span><br><span class="line">semaphore room=<span class="number">4</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">philosopher</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">while</span> (<span class="literal">true</span>)  &#123;</span><br><span class="line">      think();</span><br><span class="line">      P(room);</span><br><span class="line">      P(fork[i]);</span><br><span class="line">      P(fork[(i+<span class="number">1</span>) mod <span class="number">5</span>]);</span><br><span class="line">      eat();</span><br><span class="line">      V(fork[(i+<span class="number">1</span>) mod <span class="number">5</span>]);</span><br><span class="line">      V(fork[i]);</span><br><span class="line">      V(room); &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    parbegin(</span><br><span class="line">       philosopher(<span class="number">0</span>),</span><br><span class="line">       philosopher(<span class="number">1</span>),</span><br><span class="line">       philosopher(<span class="number">2</span>),</span><br><span class="line">       philosopher(<span class="number">3</span>),</span><br><span class="line">       philosopher(<span class="number">4</span>)</span><br><span class="line">     )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;使用信号量解决同步问题&quot;&gt;&lt;a href=&quot;#使用信号量解决同步问
      
    
    </summary>
    
      <category term="Operating System" scheme="https://wwyf.github.io/categories/Operating-System/"/>
    
    
      <category term="Operating System" scheme="https://wwyf.github.io/tags/Operating-System/"/>
    
  </entry>
  
</feed>
