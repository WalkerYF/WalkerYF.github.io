<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog</title>
  
  <subtitle>My Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wwyf.github.io/"/>
  <updated>2019-07-21T08:06:40.844Z</updated>
  <id>https://wwyf.github.io/</id>
  
  <author>
    <name>wyf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>eBPF 入门3 | 了解BCC与bpftrace</title>
    <link href="https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF3/"/>
    <id>https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF3/</id>
    <published>2019-07-21T08:05:52.000Z</published>
    <updated>2019-07-21T08:06:40.844Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="eBPF-入门3-了解BCC与bpftrace"><a href="#eBPF-入门3-了解BCC与bpftrace" class="headerlink" title="eBPF 入门3 | 了解BCC与bpftrace"></a>eBPF 入门3 | 了解BCC与bpftrace</h1><h2 id="What"><a href="#What" class="headerlink" title="What?"></a>What?</h2><h3 id="BPF-Compiler-Collection-BCC"><a href="#BPF-Compiler-Collection-BCC" class="headerlink" title="BPF Compiler Collection (BCC)"></a>BPF Compiler Collection (BCC)</h3><blockquote><p>BCC is a toolkit for creating efficient kernel tracing and manipulation programs, and includes several useful tools and examples. It makes use of extended BPF (Berkeley Packet Filters), formally known as eBPF, a new feature that was first added to Linux 3.15. Much of what BCC uses requires Linux 4.1 and above.</p></blockquote><p>BCC是用于创建高效内核跟踪和操作程序的工具包，包括一些有用的工具和示例。 它利用了扩展的BPF（Berkeley Packet Filters），正式名称为eBPF，这是一种新功能，最初被添加到Linux 3.15中。 BCC使用的大部分内容都需要Linux 4.1及更高版本。</p><h3 id="bpftrace"><a href="#bpftrace" class="headerlink" title="bpftrace"></a>bpftrace</h3><blockquote><p>bpftrace is a high-level tracing language for Linux enhanced Berkeley Packet Filter (eBPF) available in recent Linux kernels (4.x). bpftrace uses LLVM as a backend to compile scripts to BPF-bytecode and makes use of BCC for interacting with the Linux BPF system, as well as existing Linux tracing capabilities: kernel dynamic tracing (kprobes), user-level dynamic tracing (uprobes), and tracepoints. The bpftrace language is inspired by awk and C, and predecessor tracers such as DTrace and SystemTap. bpftrace was created by Alastair Robertson.</p></blockquote><p>bpftrace是最新Linux内核（4.x）中提供的Linux增强型Berkeley Packet Filter（eBPF）的高级跟踪语言。 bpftrace使用LLVM作为后端将脚本编译为BPF字节码，并利用BCC与Linux BPF系统进行交互，以及现有的Linux跟踪功能：内核动态跟踪（kprobes），用户级动态跟踪（uprobes）， 和跟踪点。 bpftrace语言的灵感来自awk和C，以及DTrace和SystemTap等前身跟踪器。 bpftrace由Alastair Robertson创建。</p><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p><a href="https://github.com/iovisor/bcc/blob/master/INSTALL.md" target="_blank" rel="noopener">安装BCC</a></p><p><a href="">安装bpftrace</a></p><h3 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h3><p>安装bcc （无论从源码安装还是从包管理器都是可以的）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD</span><br><span class="line">echo &quot;deb https://repo.iovisor.org/apt/$(lsb_release -cs) $(lsb_release -cs) main&quot; | sudo tee /etc/apt/sources.list.d/iovisor.list</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install bcc-tools libbcc-examples linux-headers-$(uname -r)</span><br></pre></td></tr></table></figure><h3 id="Arch"><a href="#Arch" class="headerlink" title="Arch"></a>Arch</h3><p>在Arch Linux上可以这样安装。</p><p><a href="https://nanxiao.me/en/install-bcc-on-archlinux/" target="_blank" rel="noopener">link</a></p><ol><li>安装aur助手（<a href="https://linux.cn/article-9925-1.html）" target="_blank" rel="noopener">https://linux.cn/article-9925-1.html）</a></li></ol><p>我安装的是yay</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://aur.archlinux.org/yay.git</span><br><span class="line">cd yay</span><br><span class="line">makepkg -si</span><br></pre></td></tr></table></figure><ol><li>使用yay安装bcc和bpftrace</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yay -S bcc</span><br><span class="line">yay -S bcc-tools</span><br><span class="line">yay -S python-bcc</span><br><span class="line">yay -S brftrace</span><br></pre></td></tr></table></figure><blockquote><p>可以编译安装，流程可见github仓库中的相关说明。<br>方便起见，我就使用了包管理器。</p></blockquote><h2 id="使用BCC"><a href="#使用BCC" class="headerlink" title="使用BCC"></a>使用BCC</h2><p>一个简单的测试是使用BCC仓库自带的example。</p><p>这是一个跟踪磁盘 I/O内核函数的例子。其中bpf程序如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;uapi/linux/ptrace.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/blkdev.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">BPF_HISTOGRAM(dist);</span><br><span class="line">BPF_HISTOGRAM(dist_linear);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kprobe__blk_account_io_completion</span><span class="params">(struct pt_regs *ctx, struct request *req)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        dist.increment(bpf_log2l(req-&gt;__data_len / <span class="number">1024</span>));</span><br><span class="line">        dist_linear.increment(req-&gt;__data_len / <span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>BCC让我们可以调用py接口，很方便的将这个BPF程序注入内核。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bcc <span class="keyword">import</span> BPF</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="comment"># load BPF program</span></span><br><span class="line">b = BPF(text=<span class="string">"""</span></span><br><span class="line"><span class="string">#include &lt;uapi/linux/ptrace.h&gt;</span></span><br><span class="line"><span class="string">#include &lt;linux/blkdev.h&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">BPF_HISTOGRAM(dist);</span></span><br><span class="line"><span class="string">BPF_HISTOGRAM(dist_linear);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">int kprobe__blk_account_io_completion(struct pt_regs *ctx, struct request *req)</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">        dist.increment(bpf_log2l(req-&gt;__data_len / 1024));</span></span><br><span class="line"><span class="string">        dist_linear.increment(req-&gt;__data_len / 1024);</span></span><br><span class="line"><span class="string">        return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">"""</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># header</span></span><br><span class="line">print(<span class="string">"Tracing... Hit Ctrl-C to end."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># trace until Ctrl-C</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">        sleep(<span class="number">99999999</span>)</span><br><span class="line"><span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">print(<span class="string">"log2 histogram"</span>)</span><br><span class="line">print(<span class="string">"~~~~~~~~~~~~~~"</span>)</span><br><span class="line">b[<span class="string">"dist"</span>].print_log2_hist(<span class="string">"kbytes"</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\nlinear histogram"</span>)</span><br><span class="line">print(<span class="string">"~~~~~~~~~~~~~~~~"</span>)</span><br><span class="line">b[<span class="string">"dist_linear"</span>].print_linear_hist(<span class="string">"kbytes"</span>)</span><br><span class="line"></span><br><span class="line">`</span><br></pre></td></tr></table></figure><p>最终的执行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">user@v4:~/bpftrace/bcc/examples/tracing$ sudo ./bitehist.py </span><br><span class="line">Tracing... Hit Ctrl-C to end.</span><br><span class="line">^C</span><br><span class="line">log2 histogram</span><br><span class="line">~~~~~~~~~~~~~~</span><br><span class="line">     kbytes              : count     distribution</span><br><span class="line">         0 -&gt; 1          : 55       |**                                      |</span><br><span class="line">         2 -&gt; 3          : 0        |                                        |</span><br><span class="line">         4 -&gt; 7          : 904      |****************************************|</span><br><span class="line">         8 -&gt; 15         : 301      |*************                           |</span><br><span class="line">        16 -&gt; 31         : 132      |*****                                   |</span><br><span class="line">        32 -&gt; 63         : 42       |*                                       |</span><br><span class="line">        64 -&gt; 127        : 35       |*                                       |</span><br><span class="line">       128 -&gt; 255        : 17       |                                        |</span><br><span class="line">       256 -&gt; 511        : 17       |                                        |</span><br><span class="line"></span><br><span class="line">linear histogram</span><br><span class="line">~~~~~~~~~~~~~~~~</span><br><span class="line">     kbytes        : count     distribution</span><br><span class="line">        0          : 55       |**                                      |</span><br><span class="line">        1          : 0        |                                        |</span><br><span class="line">        2          : 0        |                                        |</span><br><span class="line">        3          : 0        |                                        |</span><br><span class="line">        4          : 904      |****************************************|</span><br><span class="line">        5          : 0        |                                        |</span><br><span class="line">        6          : 0        |                                        |</span><br><span class="line">        7          : 0        |                                        |</span><br></pre></td></tr></table></figure><p>这个所表示的含义便是，目前系统中IO系统调用中，数据大小的分布。</p><h2 id="使用bpftrace"><a href="#使用bpftrace" class="headerlink" title="使用bpftrace"></a>使用bpftrace</h2><p>bpftrace这是一种新定义的高层语言。文档细节可见<a href="https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md" target="_blank" rel="noopener">这里</a>。下面举几个例子让自己对这个能干嘛有个感性的认识。</p><h3 id="对do-sys-open系统调用进行监控"><a href="#对do-sys-open系统调用进行监控" class="headerlink" title="对do_sys_open系统调用进行监控"></a>对<code>do_sys_open</code>系统调用进行监控</h3><p>我使用这样一条命令监控do_sys_open系统调用，并获得进程名与open的文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bpftrace -e &apos;kprobe:do_sys_open &#123; printf(&quot;%s: %s\n&quot;, comm, str(arg1)) &#125;&apos;</span><br></pre></td></tr></table></figure><p>然后我使用vim打开一个文件 <code>bench.sh</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">[wyf@wyf-room ~]$ sudo bpftrace -e &apos;kprobe:do_sys_open &#123; printf(&quot;%s: %s\n&quot;, comm, str(arg1)) &#125;&apos;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/tls/x86_64/x86_64/libm.so.6</span><br><span class="line">...</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/x86_64/libm.so.6</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/libm.so.6</span><br><span class="line">vim: /etc/ld.so.cache</span><br><span class="line">vim: /usr/lib/libm.so.6</span><br><span class="line">...</span><br><span class="line">vim: /usr/share/vim/vim81/lang/en.utf8/LC_MESSAGES/vim.mo</span><br><span class="line">vim: /usr/share/vim/vim81/lang/en/LC_MESSAGES/vim.mo</span><br><span class="line">vim: /usr/share/terminfo/x/xterm</span><br><span class="line">vim: .</span><br><span class="line">vim: /etc/vimrc</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vimfiles/archlinux.vim</span><br><span class="line">vim: .</span><br><span class="line">vim: /home/wyf/.vimrc</span><br><span class="line">vim: .</span><br><span class="line">...</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vim81/filetype.vim</span><br><span class="line">vim: /home/wyf/.vim/ftdetect/</span><br><span class="line">vim: /usr/share/vim/vimfiles/ftdetect/</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vimfiles/ftdetect/dockerfile.vim</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vimfiles/ftdetect/nginx.vim</span><br><span class="line">vim: /usr/share/vim/vim81/ftdetect/</span><br><span class="line">...</span><br><span class="line">vim: /usr/share/vim/vim81/plugin/vimballPlugin.vim/</span><br><span class="line">...</span><br><span class="line">vim: /usr/share/vim/vim81/plugin/zipPlugin.vim</span><br><span class="line">vim: /home/wyf/.vim/pack/</span><br><span class="line">vim: /usr/share/vim/vimfiles/pack/</span><br><span class="line">vim: /usr/share/vim/vim81/pack/</span><br><span class="line">vim: /usr/share/vim/vim81/pack/dist/start/</span><br><span class="line">vim: /usr/share/vim/vimfiles/after/pack/</span><br><span class="line">vim: /home/wyf/.vim/after/pack/</span><br><span class="line">...</span><br><span class="line">vim: /home/wyf/.viminfo</span><br><span class="line">vim: /etc/nsswitch.conf</span><br><span class="line">vim: /usr/lib/perl5/5.30/core_perl/CORE/libnss_files.so.2</span><br><span class="line">vim: /etc/ld.so.cache</span><br><span class="line">vim: /usr/lib/libnss_files.so.2</span><br><span class="line">vim: /etc/passwd</span><br><span class="line">vim: bench.sh</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swp</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swp</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swx</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swx</span><br><span class="line">vim: /home/wyf/.cache/vim/swap//%home%wyf%bench.sh.swp</span><br><span class="line">vim: bench.sh</span><br><span class="line">vim: /home/wyf/.viminfo</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vim81/autoload/dist/ft.vim</span><br><span class="line">vim: /home/wyf/.vim/syntax/sh/</span><br><span class="line">vim: /usr/share/vim/vimfiles/syntax/sh/</span><br><span class="line">vim: .</span><br><span class="line">vim: /usr/share/vim/vim81/syntax/sh.vim</span><br><span class="line">vim: /usr/share/vim/vim81/syntax/sh/</span><br><span class="line">vim: /usr/share/vim/vimfiles/after/syntax/sh/</span><br><span class="line">vim: /home/wyf/.vim/after/syntax/sh/</span><br></pre></td></tr></table></figure><p>嗯，清清楚楚得看到了vim进程在我打开一个文件的过程里，对多少个配置文件执行了读操作……。</p><h3 id="对系统调用sys-exit-read进行监控"><a href="#对系统调用sys-exit-read进行监控" class="headerlink" title="对系统调用sys_exit_read进行监控"></a>对系统调用<code>sys_exit_read</code>进行监控</h3><p>监控<code>sys_exit_read</code>系统调用，看看不同进程read size的分布。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[wyf@wyf-room ~]$ sudo bpftrace -e &apos;tracepoint:syscalls:sys_exit_read /args-&gt;ret/ &#123; @[comm] = sum(args-&gt;ret); &#125;&apos;</span><br><span class="line">Attaching 1 probe...</span><br><span class="line">^C</span><br><span class="line"></span><br><span class="line">@[sudo]: 1</span><br><span class="line">@[sshd]: 108</span><br><span class="line">@[containerd]: 1286</span><br><span class="line">@[dockerd]: 1456</span><br><span class="line">@[systemd-journal]: 4190</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今日体验到此结束。感觉如果要更加熟练的使用这些工具的话，还需要对各种系统调用的接口有一个比较全面的理解。知道每个系统调用的参数具体有什么作用，这样子才能够让自己更好的观察这个系统。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;eBPF-入门3-了解BCC与bpftrace&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="eBPF" scheme="https://wwyf.github.io/categories/eBPF/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPF" scheme="https://wwyf.github.io/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>eBPF 入门2 | eBPF 介绍 + 捕获系统调用实例</title>
    <link href="https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF2/"/>
    <id>https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF2/</id>
    <published>2019-07-21T04:11:14.000Z</published>
    <updated>2019-07-21T04:13:23.155Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="eBPF-入门2-eBPF-介绍-捕获系统调用实例"><a href="#eBPF-入门2-eBPF-介绍-捕获系统调用实例" class="headerlink" title="eBPF 入门2 | eBPF 介绍 + 捕获系统调用实例"></a>eBPF 入门2 | eBPF 介绍 + 捕获系统调用实例</h1><blockquote><p>翻译博文<br><a href="https://sematext.com/blog/linux-kernel-observability-ebpf/" target="_blank" rel="noopener">https://sematext.com/blog/linux-kernel-observability-ebpf/</a></p></blockquote><p>最新的Linux内核版本配备了强大的Linux监控框架，用于内核检测。 它源于历史上被称为BPF的东西。</p><h2 id="What-is-BPF"><a href="#What-is-BPF" class="headerlink" title="What is BPF?"></a>What is BPF?</h2><p>BPF（Berkeley Packet Filter）是一种非常有效的网络数据包过滤机制，旨在避免不必要的用户空间分配。 它直接在内核域中对网络分组数据进行操作。 最熟悉的BPF功能应用与tcpdump工具中使用的过滤器表达式有关。 在引擎盖下，表达式被编译并透明地转换为BPF字节码。 然后将该字节码加载到内核中并应用于原始网络数据包流(raw socket)，从而有效地将那些满足过滤条件的数据包传递给用户空间。</p><h2 id="What-is-eBPF"><a href="#What-is-eBPF" class="headerlink" title="What is eBPF?"></a>What is eBPF?</h2><p>eBPF是BPF Linux可观察性系统的扩展和增强版本。将其视为加强版的BPF。使用eBPF，可以将自定义沙盒字节码附加到几乎每个通过内核符号表导出的函数，而不必担心破坏内核。事实上，eBPF强调跨越用户空间边界时安全的重要性。如果检测到无效指针解引用或达到最大堆栈大小限制，则内核验证程序将拒绝加载任何eBPF程序。不允许循环（除了在编译时已知常量上限的循环），并且只允许在生成的字节码中调用特定eBPF辅助函数的一小部分子集。 eBPF程序保证在某个时间点终止，并且永远不会耗尽系统资源，而内核模块不会导致系统不稳定或导致可怕的内核恐慌。相反，与“自由”内核模块提供的相比，有些人可能会发现eBPF限制性太强，但权衡可能更有利于eBPF而不是“面向模块”的工具，这主要是因为eBPF程序不能损害内核的保证。然而，这不是唯一的好处。</p><h2 id="Why-use-eBPF-for-Linux-monitoring"><a href="#Why-use-eBPF-for-Linux-monitoring" class="headerlink" title="Why use eBPF for Linux monitoring?"></a>Why use eBPF for Linux monitoring?</h2><p>作为Linux内核的核心部分，eBPF不依赖于任何第三方模块或外部依赖项。 它强加了一个稳定的ABI（应用程序二进制接口），使得在较旧的内核上构建的程序可以在较新的内核版本上运行。 eBPF引起的性能开销通常可以忽略不计，因此非常适合应用程序监控和跟踪重载系统。 Windows用户没有eBPF，但他们可以使用Windows事件跟踪。</p><p>eBPF非常灵活，能够跟踪所有主要Linux子系统的几乎任何方面，包括CPU调度程序，内存管理器，网络，系统调用，块设备请求等。 几乎没有极限。</p><p>您可以通过终端运行此命令找到可跟踪符号的完整列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/kallsyms</span><br></pre></td></tr></table></figure><p>上面的命令会产生巨大的输出。 如果我们只对系统调用接口感兴趣，那么一些grep magic将帮助过滤掉不需要的符号名称：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@wyf-room wyf]# cat /proc/kallsyms | grep -w -E &quot;sys_.*&quot;</span><br><span class="line">ffffffff8d8afc20 T sys_ni_syscall</span><br><span class="line">ffffffff8def39e0 t sys_dmi_field_show</span><br><span class="line">ffffffff8def3b90 t sys_dmi_modalias_show</span><br><span class="line">ffffffff8e6001c0 R sys_call_table</span><br><span class="line">ffffffff8ea9a280 d sys_table</span><br><span class="line">ffffffff8eaf0ac0 d sys_dmi_attribute_groups</span><br><span class="line">ffffffff8eaf0ae0 d sys_dmi_attribute_group</span><br><span class="line">ffffffff8eaf0b20 d sys_dmi_modalias_attr</span><br><span class="line">ffffffff8eaf0b40 d sys_dmi_chassis_asset_tag_attr</span><br><span class="line">ffffffff8eaf0b80 d sys_dmi_chassis_serial_attr</span><br><span class="line">ffffffff8eaf0bc0 d sys_dmi_chassis_version_attr</span><br><span class="line">ffffffff8eaf0c00 d sys_dmi_chassis_type_attr</span><br><span class="line">ffffffff8eaf0c40 d sys_dmi_chassis_vendor_attr</span><br><span class="line">ffffffff8eaf0c80 d sys_dmi_board_asset_tag_attr</span><br><span class="line">ffffffff8eaf0cc0 d sys_dmi_board_serial_attr</span><br><span class="line">ffffffff8eaf0d00 d sys_dmi_board_version_attr</span><br><span class="line">ffffffff8eaf0d40 d sys_dmi_board_name_attr</span><br><span class="line">ffffffff8eaf0d80 d sys_dmi_board_vendor_attr</span><br><span class="line">ffffffff8eaf0dc0 d sys_dmi_product_family_attr</span><br><span class="line">ffffffff8eaf0e00 d sys_dmi_product_sku_attr</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>不同类型的挂钩点负责对内核中触发的不同事件做出反应。 在特定存储器地址处执行内核例程，数据包的到达或用户空间代码的调用都是通过将eBPF程序分别附加到kprobes，XDP程序到分组入口路径以及分别将用户空间进程附加到用户空间进程而可捕获的事件的示例。</p><blockquote><p>(上面那段不是很会翻译，放上原文) Different types of hook points are responsible for reacting to events being triggered inside the kernel. The execution of the kernel routine at specific memory address, arrival of a network packet or invocation of user space code are all examples of events trappable by attaching eBPF programs to kprobes, XDP programs to packet ingress paths and uprobes to user space processes respectively.</p></blockquote><p>在Sematext，我们对eBPF非常兴奋，并正在探索在服务器监控和容器可见性的背景下利用其功能的方法。 继续阅读。</p><p>让我们深入一点，看看如何构建eBPF程序并将其加载到内核中。</p><h2 id="Anatomy-of-a-Linux-eBPF-Program"><a href="#Anatomy-of-a-Linux-eBPF-Program" class="headerlink" title="Anatomy of a Linux eBPF Program"></a>Anatomy of a Linux eBPF Program</h2><p>在我们开始进一步解释eBPF程序的结构之前，值得一提的是BCC（BPF编译器集合） - 一个抽象字节码加载的工具包，并提供Python和Lua语言的绑定以与底层的eBPF基础设施互操作。 它还包含许多有用的工具，可以让您大概了解通过eBPF能够实现的功能。</p><p>过去，BPF程序是通过原始BPF指令集指令手工生成生成的字节码。 幸运的是，clang编译器（LLVM前端的一部分）可以将C转换为eBPF字节码，并使我们免于使用BPF指令。 截至今天，它是唯一可以产生 eBPF字节码的编译器，尽管也可以从<a href="https://unhandledexpression.com/general/rust/2018/02/02/poc-compiling-to-ebpf-from-rust.html" target="_blank" rel="noopener">Rust生成eBPF字节码</a>。</p><p>成功编译eBPF程序并生成目标文件后，我们就可以将其注入内核。 为此，引入了新的bpf系统调用。 除了加载eBPF字节码之外，这个看似简单的系统调用还有很多功能。 它创建和操作内核映射（稍后将详细介绍Map），这是eBPF基础架构最引人注目的功能之一。 你可以通过阅读bpf手册页（man 2 bpf）来了解更多。</p><p>当用户空间进程决定通过调用bpf系统调用来推送eBPF字节码时，内核将对其进行验证，然后将JIT（转换为机器代码）指令转换为等效的目标体系结构指令集。 结果代码将非常快！ 如果由于任何原因JIT编译器不可用，内核将回退到不具备上述裸机性能的解释器。</p><h2 id="Linux-eBPF-Example"><a href="#Linux-eBPF-Example" class="headerlink" title="Linux eBPF Example"></a>Linux eBPF Example</h2><p>我们现在看一个Linux eBPF程序的例子。 我们的目标是将<strong>捕获setns系统调用</strong>。 进程在希望加入一个新的隔离命名空间时调用此系统调用，该命名空间是在构建子进程描述符之后创建的（子进程可以通过在clone syscall参数中指定标志的位掩码来控制它应该从父进程取消链接的命名空间）。 此系统调用通常用于为进程提供系统资源的隔离概述，例如TCP堆栈，挂载点，PID编号空间等。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/kconfig.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/version.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/bpf.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SEC</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SEC(NAME)                  </span></span><br><span class="line">  __attribute__((section(NAME), used))</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">SEC(<span class="string">"kprobe/sys_setns"</span>)</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kprobe__sys_setns</span><span class="params">(struct pt_regs *ctx)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">char</span> _license[] SEC(<span class="string">"license"</span>) = <span class="string">"GPL"</span>;</span><br><span class="line">__u32 _<span class="function">version <span class="title">SEC</span><span class="params">(<span class="string">"version"</span>)</span> </span>= <span class="number">0xFFFFFFFE</span>;</span><br></pre></td></tr></table></figure><p>以上是最小的eBPF程序。 它由不同的部分组成。 首先，我们包含各种内核头文件，其中包含多种数据类型的定义。 我们还声明了用于在对象文件中生成section的SEC宏，这些section将会稍后由ELF BPF加载器解释。 如果加载程序找不到许可证和版本部分，则会抱怨，因此我们需要提供这两个部分。</p><p>现在是我们的eBPF程序中最有趣的部分 - setns系统调用的实际挂钩点。 通过使用kprobe__前缀启动函数名并绑定相应的SEC宏，我们指示内核虚拟机将检测回调附加到sys_setns符号，该符号将触发我们的eBPF程序，并在每次调度syscall时执行函数体内的代码。 每个eBPF程序都有一个执行上下文。 对于内核探测器，这是处理器寄存器（pt_regs结构）的当前状态，它包含libc在从用户到内核空间转换时放置的函数参数。 要编译程序（llvm和clang应该安装并正确配置），我们可以使用以下命令（请注意你需要通过LINUX_HEADERS env变量指定内核头的路径）其中clang将生成我们的中间LLVM表示 程序和LLVM编译器将生成最终的eBPF字节码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ clang -D__KERNEL__ -D__ASM_SYSREG_H</span><br><span class="line">         -Wunused</span><br><span class="line">         -Wall</span><br><span class="line">         -Wno-compare-distinct-pointer-types</span><br><span class="line">         -Wno-pointer-sign</span><br><span class="line">         -O2 -S -emit-llvm ns.c</span><br><span class="line">         -I $LINUX_HEADERS/source/include</span><br><span class="line">         -I $LINUX_HEADERS/source/include/generated/uapi</span><br><span class="line">         -I $LINUX_HEADERS/source/arch/x86/include</span><br><span class="line">         -I $LINUX_HEADERS/build/include</span><br><span class="line">         -I $LINUX_HEADERS/build/arch/x86/include</span><br><span class="line">         -I $LINUX_HEADERS/build/include/uapi</span><br><span class="line">         -I $LINUX_HEADERS/build/include/generated/uapi</span><br><span class="line">         -I $LINUX_HEADERS/build/arch/x86/include/generated</span><br><span class="line">         -o - | llc -march=bpf -filetype=obj -o ns.o</span><br></pre></td></tr></table></figure><p>您可以使用readelf工具来查看ELF部分和目标文件的符号表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ readelf -a -S ns.o</span><br><span class="line">…</span><br><span class="line"> 2: 0000000000000000         0 NOTYPE  GLOBAL DEFAULT        4 _license</span><br><span class="line"> 3: 0000000000000000         0 NOTYPE  GLOBAL DEFAULT        5 _version</span><br><span class="line"> 4: 0000000000000000         0 NOTYPE  GLOBAL DEFAULT        3 kprobe__sys_setns</span><br></pre></td></tr></table></figure><p>上面的输出证明符号表是按预期构建的。 我们有一个有效的eBPF目标文件，现在是时候将它加载到内核中并看到魔术发生了。</p><h2 id="Attaching-eBPF-Programs-with-Go"><a href="#Attaching-eBPF-Programs-with-Go" class="headerlink" title="Attaching eBPF Programs with Go"></a>Attaching eBPF Programs with Go</h2><p>我们已经提到了BCC以及如何在为eBPF提供好用的接口的同时完成繁重的工作。 为了构建和运行eBPF程序，BCC需要在目标节点上安装LLVM和内核头文件，有时我们可能无法进行权衡。 在这种情况下，如果我们可以运送在二进制文件的数据段中的结果ELF对象并最大化跨机器的可移植性，那将是理想的。</p><p>除了为libbcc提供绑定外，gobpf包还能够从预编译的字节码加载eBPF程序。 如果我们将它与可以在Go应用程序中嵌入blob的packr等工具结合起来，我们就拥有了所有需要的成分来分配我们的二进制文件，并且运行时依赖性为零。</p><p>我们将略微修改eBPF程序，以便在触发kprobe时将其打印到内核跟踪管道。 为简洁起见，我们不会包含printt宏的定义以及其他eBPF辅助函数，但您可以在此头文件中找到它们。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SEC(<span class="string">"kprobe/sys_setns"</span>)</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">kprobe__sys_setns</span><span class="params">(struct pt_regs *ctx)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> fd = (<span class="keyword">int</span>)PT_REGS_PARM1(ctx);</span><br><span class="line">  <span class="keyword">int</span> pid = bpf_get_current_pid_tgid() &gt;&gt; <span class="number">32</span>;</span><br><span class="line">  printt(<span class="string">"process with pid %d joined ns through fd %d"</span>, pid, fd);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在我们可以开始编写处理eBPF字节码加载的Go代码。 我们将在gobpf上实现一个小抽象（KprobeTracer）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"bytes"</span></span><br><span class="line">  <span class="string">"errors"</span></span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line">  bpflib <span class="string">"github.com/iovisor/gobpf/elf"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> KprobeTracer <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// bytecode is the byte stream with embedded eBPF program</span></span><br><span class="line">  bytecode []<span class="keyword">byte</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// eBPF module associated with this tracer. The module is a  collection of maps, probes, etc.</span></span><br><span class="line">  mod *bpflib.Module</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewKprobeTracer</span><span class="params">(bytecode []<span class="keyword">byte</span>)</span> <span class="params">(*KprobeTracer, error)</span></span> &#123;</span><br><span class="line">   mod := bpflib.NewModuleFromReader(bytes.NewReader(bytecode))</span><br><span class="line">   <span class="keyword">if</span> mod == <span class="literal">nil</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">"ebpf is not supported"</span>)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> KprobeTracer&#123;mod: mod, bytecode: bytecode&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// EnableAllKprobes enables all kprobes/kretprobes in the module. The argument</span></span><br><span class="line"><span class="comment">// determines the maximum number of instances of the probed functions the can</span></span><br><span class="line"><span class="comment">// be handled simultaneously.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *KprobeTracer)</span> <span class="title">EnableAllKprobes</span><span class="params">(maxActive <span class="keyword">int</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"></span><br><span class="line">  params := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]*bpflib.PerfMap)</span><br><span class="line"></span><br><span class="line">  err := t.mod.Load(params)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">     <span class="keyword">return</span> fmt.Errorf(<span class="string">"unable to load module: %v"</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  err = t.mod.EnableKprobes(maxActive)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">     <span class="keyword">return</span> fmt.Errorf(<span class="string">"cannot initialize kprobes: %v"</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们准备引导内核探针跟踪器:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"log"</span></span><br><span class="line">  <span class="string">"github.com/gobuffalo/packr"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  box := packr.NewBox(<span class="string">"/directory/to/your/object/files"</span>)</span><br><span class="line">  bytecode, err := box.Find(<span class="string">"ns.o"</span>)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">      log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ktracer, err := NewKprobeTracer(bytecode)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">     log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> err := ktracer.EnableAllKprobes(<span class="number">10</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">     log.Fatal(err)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>sudo cat /sys/kernel/debug/tracing/trace_pipe</code>  读取推送到管道的调试信息。 测试eBPF程序的最简单方法是将其附加到正在运行的Docker容器中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it nginx /bin/bash</span><br></pre></td></tr></table></figure><p>在幕后，容器运行时将bash进程重新关联到nginx容器的命名空间。 我们通过PT_REGS_PARM1宏捕获的第一个参数是命名空间的文件描述符，该文件描述符用<code>/proc/&lt;pid&gt;/ns</code>目录中的符号链接表示。 好极了！ 因此，我们可以在每次进程加入命名空间时进行监视。 它可能不是非常有用的东西，但它说明了捕获系统调用执行并访问其参数是多么容易。</p><h2 id="Using-eBPF-Maps"><a href="#Using-eBPF-Maps" class="headerlink" title="Using eBPF Maps"></a>Using eBPF Maps</h2><p>将结果写入跟踪管道有利于调试，但对于生产环境，我们肯定需要一种更复杂的机制来在用户和内核空间之间共享状态。 这就是eBPF的Map有用的地方。 它们代表了用于数据聚合的非常有效的内核键/值存储，并且可以从用户空间异步访问。 有许多类型的eBPF MAP，但对于这个特定的用例，我们将依赖BPF_MAP_TYPE_PERF_EVENT_ARRAY地图。 它可以存储通过perf事件环缓冲区推送的自定义结构，并广播到用户空间进程。</p><p>Go-bpf允许将perf MAP创建和事件流传输到提供的Go通道。 我们可以添加以下代码来将C结构传输到我们的程序中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">rxChan := <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="keyword">byte</span>)</span><br><span class="line">lostChan := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">uint64</span>)</span><br><span class="line">pmap, err := bpflib.InitPerfMap(</span><br><span class="line">  t.mod,</span><br><span class="line">  mapName,</span><br><span class="line">  rxChan,</span><br><span class="line">  lostChan,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> quit, err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> _, found := t.maps[mapName]; !found &#123;</span><br><span class="line">  t.maps[mapName] = pmap</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">     <span class="keyword">select</span> &#123;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> pe := &lt;-rxChan:</span><br><span class="line">        nsJoin := (*C.struct_ns_evt_t)(unsafe.Pointer(&amp;(*pe)[<span class="number">0</span>]))</span><br><span class="line">        log.Info(nsJoin)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">case</span> l := &lt;-lostChan:</span><br><span class="line">        <span class="keyword">if</span> lost != <span class="literal">nil</span> &#123;</span><br><span class="line">           lost(l)</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">pmap.PollStart()</span><br></pre></td></tr></table></figure><p>我们初始化接收器和丢失事件通道，并将它们与模块引用和我们应该使用的事件的perf映射的名称一起传递给<code>InitPerfMap</code>函数。 每次在接收器通道上推送新事件时，我们将原始指针转换为我们的eBPF程序中定义的C struct（ns_evt_t）。 我们还需要声明一个perf map并通过bpf_perf_event_output helper生成结构：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> bpf_map_def SEC(<span class="string">"maps/ns"</span>) ns_map = &#123;</span><br><span class="line">  .<span class="keyword">type</span> = BPF_MAP_TYPE_HASH,</span><br><span class="line">  .key_size = sizeof(u32),</span><br><span class="line">  .value_size = sizeof(<span class="keyword">struct</span> ns_evt_t),</span><br><span class="line">  .max_entries = <span class="number">1024</span>,</span><br><span class="line">  .pinning = <span class="number">0</span>,</span><br><span class="line">  .namespace = <span class="string">""</span>,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> ns_evt_t evt = &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Initialize structure fields.*/</span></span><br><span class="line">u32 cpu = bpf_get_smp_processor_id();</span><br><span class="line">bpf_perf_event_output(ctx, &amp;ns_map,</span><br><span class="line">                     cpu,</span><br><span class="line">                     &amp;evt, sizeof(evt));</span><br></pre></td></tr></table></figure><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>eBPF不断发展并得到更广泛的采用。 随着每个内核的发布，新功能和改进正在得到解决。 低开销和本机可编程性支持使其对各种用例非常有吸引力。 例如，Suricata入侵检测系统使用它在Linux网络堆栈的早期阶段实现高级套接字负载平衡策略和数据包过滤。 Cilium严重依赖eBPF来为容器提供复杂的安全策略。 Sematext Agent利用eBPF精确定位有趣的事件，例如杀死信号广播或用于Docker和Kubernetes监控的OOM通知，以及定期服务器监控。 它还通过使用eBPF捕获TCP / UDP流量统计信息，为网络监控提供了有效的网络跟踪器。 看来eBPF的目标是通过Linux内核工具成为Linux监控的事实标准。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;eBPF-入门2-eBPF-介绍-捕获系统调用实例&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="eBPF" scheme="https://wwyf.github.io/categories/eBPF/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPF" scheme="https://wwyf.github.io/tags/eBPF/"/>
    
  </entry>
  
  <entry>
    <title>eBPF 入门1 | Introduction to xdp and eBPF</title>
    <link href="https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF1/"/>
    <id>https://wwyf.github.io/2019/07/21/2019-07-2019-07-21-eBPF1/</id>
    <published>2019-07-21T02:34:46.000Z</published>
    <updated>2019-07-21T04:13:23.155Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="eBPF-入门1-Introduction-to-xdp-and-eBPF"><a href="#eBPF-入门1-Introduction-to-xdp-and-eBPF" class="headerlink" title="eBPF 入门1 | Introduction to xdp and eBPF"></a>eBPF 入门1 | Introduction to xdp and eBPF</h1><blockquote><p>翻译博文<br><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/" target="_blank" rel="noopener">https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/</a></p></blockquote><p>在过去几年中，我们已经看到了编程工具包和技术的升级，以克服Linux内核在进行高性能数据包处理时的局限性。 最流行的技术之一是内核旁路（kernel bypass），这意味着跳过内核的网络层并从用户空间进行所有数据包处理。 内核旁路还涉及从用户空间管理NIC，换句话说，依赖于用户空间驱动程序来处理NIC。</p><p>通过使用用户空间程序对NIC完全控制，我们可以减少内核引入的开销（上下文切换，网络层处理，中断等），这在10Gbps或更高速度下工作时更为重要。 内核旁路加上其他功能（批量数据包处理）和性能调整调整（NUMA感知，CPU隔离等）的组合符合高性能用户空间网络的基础。 也许这种新的数据包处理方法的典型代表是英特尔的DPDK（Data Plane Development Kit），尽管其他众所周知的工具包和技术是思科的VPP（Vector Packet Processing），PF_Ring，当然还有 Snabb。</p><p>用户空间网络的缺点有几个：</p><ol><li>OS的内核是硬件资源的抽象层。 由于用户空间程序需要直接管理其资源，因此他们还需要管理其硬件。 用户空间驱动程序可能正常运行，但通常不如OS内核提供的驱动程序那样经过良好测试且可重用性较差。（内核为了简化硬件的管理，已经抽象了硬件资源的管理。但对于用户空间的驱动程序而言，如果不使用内核的抽象层进行管理，而是自己进行管理，可靠性成为问题）</li><li>由于完全跳过了内核空间，因此也会跳过内核提供的所有网络功能。 用户空间程序需要重新实现内核或操作系统可能已提供的功能。</li><li>程序作为沙盒工作，严重限制了它们与操作系统其他部分集成和交互的能力。</li><li>内核也提供了一个安全层，在用户空间网络的情况下不存在。</li></ol><p>从本质上讲，用户空间网络通过将数据包处理从内核领域转移到用户空间来实现高速性能。 事实上，XDP实际上恰恰相反：它将用户空间网络程序（过滤器，映射器，路由等）移动到内核的领域。 XDP允许我们在数据包到达NIC时，并且在它开始向上移动到内核的网络层之前执行我们的网络功能，这让数据包的处理速度得到显着提高。 但是内核如何使用户能够在内核的领域内执行他们的程序呢？ 在回答这个问题之前，我们需要看一下BPF。</p><h2 id="BPF-and-eBPF"><a href="#BPF-and-eBPF" class="headerlink" title="BPF and eBPF"></a>BPF and eBPF</h2><p>尽管名称有些误导，但BPF（Berkeley Packet Filtering）实际上是一个虚拟机模型。 这个VM最初是为包过滤处理而设计的，因此就是它的名字。</p><p>BPF最突出的用户之一是工具tcpdump。 使用tcpdump捕获数据包时，用户可以定义数据包过滤表达式。 实际上只捕获与该表达式匹配的数据包。 例如，表达式“tcp dst port 80”捕获目标端口等于80的所有TCP数据包。此表达式可以通过编译器转成BPF字节码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@wyf-room wyf]# tcpdump -d &quot;tcp dst port 80&quot;</span><br><span class="line">(000) ldh      [12]</span><br><span class="line">(001) jeq      #0x86dd          jt 2jf 6</span><br><span class="line">(002) ldb      [20]</span><br><span class="line">(003) jeq      #0x6             jt 4jf 15</span><br><span class="line">(004) ldh      [56]</span><br><span class="line">(005) jeq      #0x50            jt 14jf 15</span><br><span class="line">(006) jeq      #0x800           jt 7jf 15</span><br><span class="line">(007) ldb      [23]</span><br><span class="line">(008) jeq      #0x6             jt 9jf 15</span><br><span class="line">(009) ldh      [20]</span><br><span class="line">(010) jset     #0x1fff          jt 15jf 11</span><br><span class="line">(011) ldxb     4*([14]&amp;0xf)</span><br><span class="line">(012) ldh      [x + 16]</span><br><span class="line">(013) jeq      #0x50            jt 14jf 15</span><br><span class="line">(014) ret      #262144</span><br><span class="line">(015) ret      #0</span><br><span class="line">[root@wyf-room wyf]#</span><br></pre></td></tr></table></figure><p>上面这个程序做的一些事情是：</p><ol><li>指令（000）：将数据包的偏移量12作为16位字加载到累加器中。 偏移12表示数据包的以太网类型。<ol><li><img src="https://i.imgur.com/2YSVgMT.png" alt=""></li></ol></li><li>指令（001）：将累加器的值与0x86dd进行比较，后者是IPv6的以太网类型值。 如果结果为真，则程序计数器跳转到指令（002），否则跳转到（006）。</li><li>指令（006）：将值与0x800（IPv4的以太网类型值）进行比较。 如果是，则跳转到（007），如果不是（015）。</li></ol><p>依此类推，直到包过滤程序返回结果。 这个结果通常是一个布尔值。 返回非零值（指令（014））意味着数据包匹配，而返回零值（指令（015））意味着数据包不匹配。</p><p>BPF VM及其字节码由Steve McCane和Van Jacobson于1992年末在他们的论文<a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf" target="_blank" rel="noopener">“BSD数据包过滤器：用户级数据包捕获的新架构”</a>中引入，并且它首次在Usenix Conference Winter ‘93上展示。</p><p>由于BPF是VM，因此它定义了执行程序的环境。 除字节码外，它还定义了基于数据包的存储器模型（加载指令在处理数据包上隐式完成），寄存器（A和X;累加器Accumulator和索引寄存器 Index register），暂存存储器和隐式程序计数器（Program Counter）。 有趣的是，BPF的字节码是在摩托罗拉6502 ISA之后建模的。 正如Steve McCane在他的<a href="https://sharkfestus.wireshark.org/sharkfest.11/presentations/McCanne-Sharkfest&#39;11_Keynote_Address.pdf" target="_blank" rel="noopener">Sharkfest ‘11</a>主题演讲中所回忆的那样，由于他初中高中时在Apple II上编程的日子，他熟悉6502汇编，这在设计BPF字节码时影响了他。</p><p>Linux内核自v2.5起支持BPF，主要由Jay Schullist添加。 直到2011年，当Eric Edmazet将BPF解释器转换为JIT（用于数据包过滤器的JIT）时，BPF代码没有发生重大变化。 现在内核能够将BPF程序直接转换为目标体系结构，而不是解释BPF字节码：x86，ARM，MIPS等。</p><p>后来，2014年，Alexei Starovoitov推出了新的BPF JIT。 这个新的JIT实际上是一个基于BPF的新架构，称为eBPF。 我认为这两个虚拟机共存已有一段时间了，但现在在eBPF之上实现了数据包过滤。 事实上，很多文档现在将eBPF称为BPF，而经典BPF称为cBPF。</p><p>eBPF以多种方式扩展了经典的BPF虚拟机：</p><ol><li>与x86-64类似的架构。 eBPF使用64位寄存器，并将可用寄存器的数量从2（累加器Accumulator 和X寄存器）增加到10.eBPF还扩展了操作码的数量。</li><li>与网络子系统分离。 BPF受限于基于数据包的数据模型。由于它用于包过滤，因此其代码存在于网络子系统中。但是，eBPF VM不再受限于数据模型，它可以用于任何目的。现在可以将eBPF程序附加到跟踪点或kprobe。这为eBPF打开了仪表，性能分析以及其他内核子系统中的更多用途的大门。 eBPF代码现在位于自己的路径：kernel / bpf。</li><li>全局数据存储称为Maps。Maps是一种通用数据结构，以键值对的形式存储不同类型的数据。它们允许在eBPF内核程序之间以及内核和用户空间应用程序之间共享数据。</li><li>助手功能。如数据包重写，校验和计算或数据包克隆。与用户空间编程不同，这些函数在内核中执行。此外，还可以从eBPF程序执行系统调用。</li><li>尾调用。 eBPF程序限制为4096字节。尾部调用功能允许eBPF程序通过控制新的eBPF程序，克服此限制。</li></ol><h2 id="eBPF-an-example"><a href="#eBPF-an-example" class="headerlink" title="eBPF: an example"></a>eBPF: an example</h2><p>Linux内核源代码包含几个eBPF示例。 它们可以 <a href="https://github.com/torvalds/linux/tree/v4.19/samples/bpf" target="_blank" rel="noopener">samples/bpf/</a>获得。 要编译这些示例，只需键入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo make samples/bpf/</span><br></pre></td></tr></table></figure><p>我将重新使用 samples/bpf/中可用的一个例子，而不是编写新的eBPF示例。 我将介绍代码的某些部分并解释它是如何工作的。 我选择的例子是tracex4程序。</p><p>通常，<code>samples/bpf/</code>的所有示例都包含2个文件。 这是一个例子：</p><ol><li><code>tracex4_kern.c</code>，包含要在内核中作为eBPF字节码执行的源代码。</li><li><code>tracex4_user.c</code>，包含用户空间程序。</li></ol><p>我们需要将tracex4_kern.c编译为eBPF字节码。 此时，gcc缺少eBPF的后端。 幸运的是，clang可以产生eBPF字节码。 Makefile使用clang将tracex4_kern.c编译为目标文件。</p><p>我之前评论过，eBPF最有趣的功能之一是Maps。 Maps是键/值存储，允许在用户空间和内核空间程序之间交换数据。 tracex4_kern定义了一个Maps：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct pair &#123;</span><br><span class="line">    u64 val;</span><br><span class="line">    u64 ip;</span><br><span class="line">&#125;;  </span><br><span class="line"></span><br><span class="line">struct bpf_map_def SEC(&quot;maps&quot;) my_map = &#123;</span><br><span class="line">    .type = BPF_MAP_TYPE_HASH,</span><br><span class="line">    .key_size = sizeof(long),</span><br><span class="line">    .value_size = sizeof(struct pair),</span><br><span class="line">    .max_entries = 1000000,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>BPF_MAP_TYPE_HASH是eBPF提供的众多Maps类型之一。 在这种情况下，它只是一个哈希表。 您可能也注意到<code>SEC(&quot;Maps&quot;)</code>声明。 SEC是一个用于在二进制文件中创建新section的宏。 实际上tracex4_kern示例还定义了两个section：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">SEC(&quot;kprobe/kmem_cache_free&quot;)</span><br><span class="line">int bpf_prog1(struct pt_regs *ctx)</span><br><span class="line">&#123;   </span><br><span class="line">    long ptr = PT_REGS_PARM2(ctx);</span><br><span class="line"></span><br><span class="line">    bpf_map_delete_elem(&amp;my_map, &amp;ptr); </span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">SEC(&quot;kretprobe/kmem_cache_alloc_node&quot;) </span><br><span class="line">int bpf_prog2(struct pt_regs *ctx)</span><br><span class="line">&#123;</span><br><span class="line">    long ptr = PT_REGS_RC(ctx);</span><br><span class="line">    long ip = 0;</span><br><span class="line"></span><br><span class="line">    // get ip address of kmem_cache_alloc_node() caller</span><br><span class="line">    BPF_KRETPROBE_READ_RET_IP(ip, ctx);</span><br><span class="line"></span><br><span class="line">    struct pair v = &#123;</span><br><span class="line">        .val = bpf_ktime_get_ns(),</span><br><span class="line">        .ip = ip,</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    bpf_map_update_elem(&amp;my_map, &amp;ptr, &amp;v, BPF_ANY);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这两个函数将允许我们从Map中删除一个条目(kprobe/kmem_cache_free) 并向Map添加一个新条目(kretprobe/kmem_cache_alloc_node)。 所有以大写字母表示的函数调用实际上都是在bpf_helpers.h中定义的宏。</p><p>如果我转储目标文件的部分，我应该能够看到定义的这些新部分：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ objdump -h tracex4_kern.o</span><br><span class="line"></span><br><span class="line">tracex4_kern.o:     file format elf64-little</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA               LMA               File off  Algn</span><br><span class="line">  0 .text         00000000  0000000000000000  0000000000000000  00000040  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 kprobe/kmem_cache_free 00000048  0000000000000000  0000000000000000  00000040  2**3</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE</span><br><span class="line">  2 kretprobe/kmem_cache_alloc_node 000000c0  0000000000000000  0000000000000000  00000088  2**3</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE</span><br><span class="line">  3 maps          0000001c  0000000000000000  0000000000000000  00000148  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  4 license       00000004  0000000000000000  0000000000000000  00000164  2**0</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  5 version       00000004  0000000000000000  0000000000000000  00000168  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  6 .eh_frame     00000050  0000000000000000  0000000000000000  00000170  2**3</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA</span><br></pre></td></tr></table></figure><p>然后是主程序tracex4_user.c。 基本上，程序所做的是监听kmem_cache_alloc_node事件。 当该事件发生时，执行相应的eBPF代码。 代码将对象的IP属性存储到Map中，该地图在主程序中循环打印。 例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ./tracex4</span><br><span class="line">obj 0xffff8d6430f60a00 is  2sec old was allocated at ip ffffffff9891ad90</span><br><span class="line">obj 0xffff8d6062ca5e00 is 23sec old was allocated at ip ffffffff98090e8f</span><br><span class="line">obj 0xffff8d5f80161780 is  6sec old was allocated at ip ffffffff98090e8f</span><br></pre></td></tr></table></figure><p>用户空间程序和eBPF程序是如何连接的？ 在初始化时，tracex4_user.c使用load_bpf_file函数加载tracex4_kern.o对象文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">int main(int ac, char **argv)</span><br><span class="line">&#123;</span><br><span class="line">    struct rlimit r = &#123;RLIM_INFINITY, RLIM_INFINITY&#125;;</span><br><span class="line">    char filename[256];</span><br><span class="line">    int i;</span><br><span class="line"></span><br><span class="line">    snprintf(filename, sizeof(filename), &quot;%s_kern.o&quot;, argv[0]);</span><br><span class="line"></span><br><span class="line">    if (setrlimit(RLIMIT_MEMLOCK, &amp;r)) &#123;</span><br><span class="line">        perror(&quot;setrlimit(RLIMIT_MEMLOCK, RLIM_INFINITY)&quot;);</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (load_bpf_file(filename)) &#123;</span><br><span class="line">        printf(&quot;%s&quot;, bpf_log_buf);</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (i = 0; ; i++) &#123;</span><br><span class="line">        print_old_objects(map_fd[1]);</span><br><span class="line">        sleep(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行load_bpf_file时，eBPF文件中定义的探针将添加/sys/kernel/debug/tracing/kprobe_eventskprobe_events。 我们现在正在听那些事件，我们的程序可以在它们发生时做点什么。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cat /sys/kernel/debug/tracing/kprobe_events</span><br><span class="line">p:kprobes/kmem_cache_free kmem_cache_free</span><br><span class="line">r:kprobes/kmem_cache_alloc_node kmem_cache_alloc_node</span><br></pre></td></tr></table></figure><p>sample/bpf/ 中的所有其他程序都遵循类似的结构。 总有两个文件：</p><ol><li>XXX_kern.c: the eBPF program.</li><li>XXX_user.c: the main program.</li></ol><p>eBPF程序定义了连接到二进制部分的Maps和函数。 当内核发出某种类型的事件（例如，一个跟踪点）时，我们的钩子(hooks)将被执行。 Maps用于在内核程序和用户空间程序之间交换数据。</p><p>在本文中，我从高级视图中介绍了BPF和eBPF。 我知道现在有很多关于eBPF的资源和信息，但我觉得我需要用自己的话来解释它（查看建议读数列表以获取更多信息）。 在下一篇文章中，我将介绍XDP及其与eBPF的关系。</p><p>Recommended readings:</p><ul><li><a href="https://lwn.net/Articles/599755/" target="_blank" rel="noopener">BPF: the universal in-kernel virtual machine</a> by Jonathan Corbet. An introduction to BPF and its evolution towards eBPF.</li><li><a href="https://lwn.net/Articles/740157/" target="_blank" rel="noopener">A thorough introduction to eBPF</a> by Brendan Gregg. Article by LWN.net. Brendan tweets often about eBPF and maintains a list of resources in his <a href="http://www.brendangregg.com/" target="_blank" rel="noopener">personal blog</a>.</li><li><a href="https://jvns.ca/blog/2017/06/28/notes-on-bpf---ebpf/" target="_blank" rel="noopener">Notes on BPF &amp; eBPF</a> by Julia Evans. Notes on Suchakra Sharma’s presentation “The BSD Packet Filter: A New Architecture for User-level Packet Capture”. The notes are of good quality and really helpful to digest the slides.</li><li><a href="https://ferrisellis.com/posts/ebpf_past_present_future/" target="_blank" rel="noopener">eBPF, part1: Past, Present and Future</a> by Ferris Ellis. A long read, with a <a href="https://ferrisellis.com/posts/ebpf_syscall_and_maps/" target="_blank" rel="noopener">follow-up</a>, but time worth invested. One of the best articles I’ve read so far about eBPF.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;eBPF-入门1-Introduction-to-xdp-and-
      
    
    </summary>
    
      <category term="eBPF" scheme="https://wwyf.github.io/categories/eBPF/"/>
    
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
      <category term="eBPG" scheme="https://wwyf.github.io/tags/eBPG/"/>
    
  </entry>
  
  <entry>
    <title>docker 配置nextcloud 并配置泛域名证书</title>
    <link href="https://wwyf.github.io/2019/07/19/2019-07-2019-07-19-%E9%85%8D%E7%BD%AEnextcloud/"/>
    <id>https://wwyf.github.io/2019/07/19/2019-07-2019-07-19-配置nextcloud/</id>
    <published>2019-07-19T03:11:44.000Z</published>
    <updated>2019-07-19T03:11:52.461Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="docker-配置nextcloud-并配置泛域名证书"><a href="#docker-配置nextcloud-并配置泛域名证书" class="headerlink" title="docker 配置nextcloud 并配置泛域名证书"></a>docker 配置nextcloud 并配置泛域名证书</h1><p>总结一下，配一个网站真的费时费力。不过说真的，用了docker已经好很多了……</p><p>配了一晚上，我完成了以下工作：</p><ol><li>使用docker安装了nginx，mysql，nextcloud。</li><li>三个容器间可使用容器名直接连接，避免了重启后容器ip可能改变的问题。</li><li>配置泛域名证书，并每个月自动更新，给nextcloud启动https。</li></ol><h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><p>这里挑选了旧版的mysql，是因为我发现用新版的话，可能由于mysql默认身份验证方式的改变而无法与nextcloud连接上。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">docker run \</span><br><span class="line">-v /data/docker/mysql:/var/lib/mysql \</span><br><span class="line">--name wyf-mysql \</span><br><span class="line">-e MYSQL_ROOT_PASSWORD="XXXXXXXX" \</span><br><span class="line">-e MYSQL_USER="username" \</span><br><span class="line">-e MYSQL_PASSWORD="XXXXXXXX" \</span><br><span class="line">-p 3306  -d mysql:5</span><br></pre></td></tr></table></figure><h2 id="安装nextcloud"><a href="#安装nextcloud" class="headerlink" title="安装nextcloud"></a>安装nextcloud</h2><p>说实在的，有了docker，真的给服务部署简化了不少。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">docker run -d \</span><br><span class="line">-v /data/docker/nextcloud:/var/www/html \</span><br><span class="line">--name wyf-nextcloud \</span><br><span class="line">-p 80 \</span><br><span class="line">--link wyf-mysql:wyf-mysql \</span><br><span class="line">nextcloud</span><br></pre></td></tr></table></figure><p>这个时候使用docker ps 命令看看目前nextcloud的端口是哪一个，然后去访问即可。</p><p>初始页面中设置管理员账户还有数据库信息，注意这里数据库的host直接写 wyf-mysql 就可以了。</p><p>这里我发现好像只能用root账户？nextcloud需要创建数据库的权限，想来，一个更好的操作可能是在mysql中创建一个nextcloud的专用账户会更好。</p><p>emmm我为了方便直接就使用了root账户来初始化。</p><h2 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h2><p>本来nginx直接在物理机装就好，弄成docker的原因是我想在nginx.conf里面能够直接写容器名，而不写易变的容器IP。这样子我就不用经常修改nginx.conf</p><p>注意到我这里挂在了两个目录，并且设置为只读。<br>nginx目录就是放置nginx的配置文件的。<br>letsencrypt目录用于certbot存放https证书，后面会说明怎么生成https证书。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">docker run --name wyf-nginx \</span><br><span class="line">-v /etc/nginx:/etc/nginx:ro \</span><br><span class="line">-v /etc/letsencrypt:/etc/letsencrypt:ro \</span><br><span class="line">-d \</span><br><span class="line">-p 80:80 \</span><br><span class="line">-p 443:443 \</span><br><span class="line">--link wyf-mysql:wyf-mysql \</span><br><span class="line">--link wyf-nextcloud:wyf-nextcloud \</span><br><span class="line">nginx</span><br></pre></td></tr></table></figure><h2 id="配置泛域名证书与自动更新"><a href="#配置泛域名证书与自动更新" class="headerlink" title="配置泛域名证书与自动更新"></a>配置泛域名证书与自动更新</h2><p>安装如下包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S certbot certbot-nginx certbot-dns-cloudflare</span><br></pre></td></tr></table></figure><p>在arch安装的时候会莫名发现几个包找不到，在arch官网的包仓库里找到然后离线安装即可，例子如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#pacman -U /home/wyf/python-pbr-5.4.1-1-any.pkg.tar.xz</span><br></pre></td></tr></table></figure><p>然后我使用的是cloudflare的DNS，因此就在cloudflare上获取一个global api key 准备之后的操作。</p><p>创建文件  “/etc/certbot/certbot-dns-cloudflare/dns.ini”，里面填入以下信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dns_cloudflare_email = #cloudfalre的注册邮箱</span><br><span class="line">dns_cloudflare_api_key = #XXXX global api key</span><br></pre></td></tr></table></figure><p>安全起见，将该文件权限设置为 700</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 700 /etc/certbot/certbot-dns-cloudflare/dns.ini</span><br></pre></td></tr></table></figure><p>配置好这一个之后，certbot就具备了自动完成DNS验证的能力，我们就不需要手动在DNS上增加TXT条目了，为之后的自动更新做准备。</p><p>然后获取泛域名证书</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">certbot certonly  \</span><br><span class="line">--dns-cloudflare  \</span><br><span class="line">--dns-cloudflare-credentials /etc/certbot/certbot-dns-cloudflare/dns.ini   \ # 刚刚设置的配置文件路径</span><br><span class="line">--dns-cloudflare-propagation-seconds 60 \ # 等待60秒，等DNS记录更新上来</span><br><span class="line">-d *.sysu.wangyf.top # 泛域名</span><br></pre></td></tr></table></figure><p>此时泛域名证书会存放到 /etc/letsencrypt 下。</p><p>测试一下能否自动更新？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">certbot renew --dry-run</span><br></pre></td></tr></table></figure><p>如果这个操作没有问题的话，那就可以配置crontab自动更新了。<br>pacman -S cronie，安装crontab，使用crontab -e 命令，填入以下信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 3 1 * * /usr/bin/certbot renew</span><br></pre></td></tr></table></figure><p>这样子泛域名证书还有证书的自动更新就完成了，证书会在每个月1号的凌晨3点更新。</p><h2 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h2><p>最后就是配好nginx的代理还有ssl证书。以下是我的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    #listen       80;</span><br><span class="line">    server_name  pan.sysu.wangyf.top;</span><br><span class="line">    location / &#123;</span><br><span class="line">                  proxy_pass http://wyf-nextcloud:80/;</span><br><span class="line">                  proxy_http_version 1.1;</span><br><span class="line">                  proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">                  proxy_set_header Connection &apos;upgrade&apos;;</span><br><span class="line">                  proxy_set_header Host $host;</span><br><span class="line">                  proxy_cache_bypass $http_upgrade;</span><br><span class="line">        &#125;</span><br><span class="line">    listen 443 ssl; # managed by Certbot</span><br><span class="line">    # 泛域名证书</span><br><span class="line">    ssl_certificate /etc/letsencrypt/live/sysu.wangyf.top/fullchain.pem; # managed by Certbot</span><br><span class="line">    ssl_certificate_key /etc/letsencrypt/live/sysu.wangyf.top/privkey.pem; # managed by Certbot</span><br><span class="line">    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot</span><br><span class="line">    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot</span><br><span class="line">    # HSTS</span><br><span class="line">    add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains&quot; always;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">     if ($host = pan.sysu.wangyf.top) &#123;</span><br><span class="line">          return 301 https://$host$request_uri;</span><br><span class="line">     &#125; # managed by Certbot</span><br><span class="line">     listen       80;</span><br><span class="line">     server_name pan.sysu.wangyf.top;</span><br><span class="line">     return 404;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后重启一下nginx</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart wyf-nginx</span><br></pre></td></tr></table></figure><p>一切大功告成！</p><h2 id="可能存在的问题"><a href="#可能存在的问题" class="headerlink" title="可能存在的问题"></a>可能存在的问题</h2><p>nextcloud可能会不认识我们自己设置的域名，这个时候需要进入容器中修改 /var/www/html/config/config.php 文件。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;docker-配置nextcloud-并配置泛域名证书&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="try" scheme="https://wwyf.github.io/categories/try/"/>
    
    
      <category term="try" scheme="https://wwyf.github.io/tags/try/"/>
    
  </entry>
  
  <entry>
    <title>Travis CI 初入门</title>
    <link href="https://wwyf.github.io/2019/05/13/2019-05-2019-05-13-Travis-CI/"/>
    <id>https://wwyf.github.io/2019/05/13/2019-05-2019-05-13-Travis-CI/</id>
    <published>2019-05-13T13:41:44.000Z</published>
    <updated>2019-05-14T01:32:45.212Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Travis-CI-初入门"><a href="#Travis-CI-初入门" class="headerlink" title="Travis CI 初入门"></a>Travis CI 初入门</h1><p>准备做软工项目了！我和队友准备实现一个前后端分离的系统，今儿了解到Travis CI这个好东西，便马上来试用了！</p><p>我使用Travis CI的目的主要是：</p><ol><li>当我push代码后，Travis CI可以帮我自动配置环境，并运行脚本进行测试</li><li>还可以通过一些方法，在测试通过后帮我部署到真实服务器上</li></ol><p>也就是说，之后的开发中，我只需要一个push指令，就可以将测试，部署等东东全部自动完成！正所谓持续集成便是如此。</p><p>事不宜迟，马上来用。</p><h2 id="一个最简单的-例子"><a href="#一个最简单的-例子" class="headerlink" title="一个最简单的 例子"></a>一个最简单的 例子</h2><p>在我即将开始的项目中，我打算使用flask写一个后端，后端还没写，先把持续集成安排一下？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">language: python</span><br><span class="line">install:</span><br><span class="line">  - pip3 install flask</span><br><span class="line">script: </span><br><span class="line">  - python tests/test.py</span><br></pre></td></tr></table></figure><p>install：安装步骤，准备运行所需环境。</p><p>script：运行自己的测试脚本完成单元测试。</p><p>在 Travis CI 上看到这个build过程还是很开心的！</p><p><img src="https://i.imgur.com/VOW4zTe.png" alt=""></p><h2 id="自动部署"><a href="#自动部署" class="headerlink" title="自动部署"></a>自动部署</h2><p>TODO：</p><p>参考链接</p><p><a href="https://zhuanlan.zhihu.com/p/25066056" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25066056</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;Travis-CI-初入门&quot;&gt;&lt;a href=&quot;#Travis-C
      
    
    </summary>
    
      <category term="try" scheme="https://wwyf.github.io/categories/try/"/>
    
    
      <category term="try" scheme="https://wwyf.github.io/tags/try/"/>
    
  </entry>
  
  <entry>
    <title>Pinpoint-Problem Determination in Large, Dynamic Internet Services</title>
    <link href="https://wwyf.github.io/2019/02/19/2019-02-2019-02-19-Pinpoint/"/>
    <id>https://wwyf.github.io/2019/02/19/2019-02-2019-02-19-Pinpoint/</id>
    <published>2019-02-19T02:36:44.000Z</published>
    <updated>2019-02-19T03:22:52.152Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Pinpoint-Problem-Determination-in-Large-Dynamic-Internet-Services"><a href="#Pinpoint-Problem-Determination-in-Large-Dynamic-Internet-Services" class="headerlink" title="Pinpoint: Problem Determination in Large, Dynamic Internet Services"></a>Pinpoint: Problem Determination in Large, Dynamic Internet Services</h1><p>年份：2002</p><p>会议/期刊：IPDS</p><h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><ol><li><p>背景：在大规模，分布式且动态变化的系统中，依靠<strong>静态依赖关系</strong>来进行问题定位的方法已经遇到了瓶颈：</p><ol><li>is difficulty of generating and maintaining an accurate model of a constantly evolving Internet service.</li><li>only model a logical system, do not distinguish among replicated components.</li></ol></li><li><p>主要贡献</p><ol><li><p>提出了一种可行的，可动态分析系统中问题的方法</p></li><li><p>提出了一个可以分离错误检测和问题分析的框架</p></li><li><blockquote><p>1) a dynamic analysis approach to problem determination that works well and<br>2) a framework that enables separation of fault detection<br>and problem determination from application-level components.</p></blockquote></li></ol></li><li><p>In this paper, we present a dynamic analysis methodology that automates problem determination in these environments by </p><p>1) coarse-grained(粗粒度) tagging of numerous real client requests as they travel through the system</p><p>2) using <strong>data mining techniques</strong> to correlate the believed failures and successes of these requests to determine which components are most likely to be at fault.</p></li></ol><h2 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h2><p>Pinpoing的框架主要包含三个部件：</p><p><img src="https://i.imgur.com/ckM3ZEW.png" alt=""></p><ol><li>Client Request Traces<ol><li>在通讯层以及中间件中处理</li><li>目的：追踪某请求用到的所有部件</li></ol></li><li>Failure Detection<ol><li>Internal failure detection<ol><li>might be masked before becoming visible to users</li><li>assertions and exceptions</li></ol></li><li>External failure detection<ol><li>detect faults that will be bisible to the user</li></ol></li><li>detection subsystem logs this along with the ID of the client request</li></ol></li><li>Data Clustering Analysis<ol><li><img src="https://i.imgur.com/R0d5RI9.png" alt=""></li></ol></li></ol><h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><p>在论文3.3节中，作者提到了该框架中的聚类算法。</p><blockquote><p>In our implementation of Pinpoint, we use a hierarchical clustering method, an unweighted pair-group method using arithmetic averages (UPGMA), and calculate distances between components using the Jaccard similarity coefficient.</p></blockquote><p>该算法可以在维基百科<a href="https://en.wikipedia.org/wiki/UPGMA" target="_blank" rel="noopener">wiki</a>上找到相应介绍。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>实验结果的话主要分为两部分</p><ol><li><p>问题定位的准确性</p><ol><li>比另外两种方法准确（Simple Dependency Analysis， Detection Analysis）</li></ol></li><li><p>该系统对性能的影响</p><ol><li><blockquote><p>We measured a cold server with a warm file cache for three 5-minute runs, and found that the online overhead of Pinpoint to be 8.4%.</p></blockquote></li></ol></li></ol><h2 id="我的想法"><a href="#我的想法" class="headerlink" title="我的想法"></a>我的想法</h2><p>这一种tracing的方法在现在看起来，tracing的信息少之又少，在追踪的过程中，系统只需要获取两种信息：该请求调用过的所有部件，以及该请求成功/失败与否。</p><p>这种方法虽然简单，不过在一些特定的系统中我想是行之有效的，并且这种方法也的确比以前的方法有了很大的进步。</p><p>这种通过聚类找到问题根因的思想，了解一下吧。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>Pinpoint: Problem Determination in Large, Dynamic Internet Services</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;Pinpoint-Problem-Determination-in
      
    
    </summary>
    
      <category term="Paper" scheme="https://wwyf.github.io/categories/Paper/"/>
    
    
      <category term="Paper" scheme="https://wwyf.github.io/tags/Paper/"/>
    
      <category term="Tracing" scheme="https://wwyf.github.io/tags/Tracing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习4-OpenMP</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A04-OpenMP/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习4-OpenMP/</id>
    <published>2019-01-15T13:44:24.000Z</published>
    <updated>2019-01-15T13:48:00.257Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习4-OpenMP"><a href="#HPC复习4-OpenMP" class="headerlink" title="HPC复习4-OpenMP"></a>HPC复习4-OpenMP</h1><ol><li>OpenMP简介</li><li>OpenMP编译制导</li><li>OpenMP库函数</li><li>OpenMP环境变量</li><li>OpenMP示例–性能改善</li></ol><a id="more"></a><h2 id="OpenMP简介"><a href="#OpenMP简介" class="headerlink" title="OpenMP简介"></a>OpenMP简介</h2><ol><li>是一种基于线程的并行编程模型<ol><li>编译制导</li><li>运行库函数</li><li>环境变量</li></ol></li><li>采用<strong>Fork-Join</strong>并行执行方式<ol><li>OpenMP程序开始于一个单独的主线程（Master Thread），然后主线程一直串行执行，直到遇见第一个并行域(Parallel Region)，然后开始并行执行并行域。并行域代码执行完后再回到主线程，直到遇到下一个并行域，以此类推，直至程序运行结束。</li><li><img src="https://lh3.googleusercontent.com/-2y771w5Yl0Y/XD3UJrbnJDI/AAAAAAAAN1A/sj3jk-OsMMYb-x7sjX6OEqeoPdSZ0EmaACHMYCw/s0/Acrobat_2019-01-15_20-37-57.png" alt=""></li></ol></li></ol><h2 id="OpenMP-编译制导"><a href="#OpenMP-编译制导" class="headerlink" title="OpenMP 编译制导"></a>OpenMP 编译制导</h2><p>编译制导语句格式：<strong>制导标识符 制导名称 [Cluase,…]</strong></p><h3 id="并行域制导"><a href="#并行域制导" class="headerlink" title="并行域制导"></a>并行域制导</h3><blockquote><p>一个并行域就是一个能被多个线程并行执行的程序段</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> ompparallel [clauses]</span></span><br><span class="line">&#123;</span><br><span class="line">BLOCK</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>在并行域结尾有一个隐式同步（barrier）。</li><li>子句（clause）用来说明并行域的附加信息。</li><li>在C/C++中，子句间用空格分开。（Fortran语言中，子句间用逗号或空格分隔）</li></ol><p><img src="https://lh3.googleusercontent.com/-CvLoMA9lHL0/XD3h6muXSmI/AAAAAAAAN1M/mu9RelbjSocH1CzKVCmrsuxTsTSGf9mpACHMYCw/s0/Acrobat_2019-01-15_21-36-40.png" alt=""></p><h3 id="数据访问相关子句"><a href="#数据访问相关子句" class="headerlink" title="数据访问相关子句"></a>数据访问相关子句</h3><p><img src="https://lh3.googleusercontent.com/-0QjMf3-Fjjk/XD3iFQgDyrI/AAAAAAAAN1Q/5yFImqC7IDkjChF_xy5GmiZ227IFTUtcwCHMYCw/s0/Acrobat_2019-01-15_21-37-20.png" alt=""></p><blockquote><p>如何决定哪些变量是共享哪些是私有？</p><ol><li>通常循环变量、临时变量、写变量一般是私有的；</li><li>数组变量、仅用于读的变量通常是共享的。默认时为公有</li></ol></blockquote><h3 id="并行域结构：reduction子句"><a href="#并行域结构：reduction子句" class="headerlink" title="并行域结构：reduction子句"></a>并行域结构：reduction子句</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">inti,myid,n; <span class="keyword">double</span> a[][];</span><br><span class="line"><span class="keyword">double</span> sum;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel reduction(+: sum), private(i, myid)</span></span><br><span class="line">&#123;</span><br><span class="line">    myid=omp_get_thread_num();</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;n;i++)</span><br><span class="line">    sum=sum+a[i][myid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>特别说明：要理解reduction操作</p><ol><li>在reduction子句中，编译器为每个线程创建变量sum的私有副本。当循环完成后，将这些值加在一起并把结果放到原始的变量sum中;</li><li>Reduction中的op操作必须满足算术结合律和交换律。</li></ol></blockquote><p>剩下的，详细可见总结或文档。</p><h3 id="任务划分并行制导"><a href="#任务划分并行制导" class="headerlink" title="任务划分并行制导"></a>任务划分并行制导</h3><ol><li>并行for循环制导<ol><li>schedule 调度子句<ol><li>static</li><li>dynamic</li><li>guided</li><li>runtime</li></ol></li></ol></li><li>并行sections制导</li><li>single和master制导</li><li>其他制导</li></ol><h3 id="同步制导"><a href="#同步制导" class="headerlink" title="同步制导"></a>同步制导</h3><ol><li>barrier制导</li><li>nowait制导</li><li>critical制导</li><li>atomic制导</li><li>lock例程</li><li>flush制导：高速缓存会刷新恢复到内存，影响性能</li></ol><h2 id="OpenMP库函数"><a href="#OpenMP库函数" class="headerlink" title="OpenMP库函数"></a>OpenMP库函数</h2><table><thead><tr><th>函数名</th><th>作用</th></tr></thead><tbody><tr><td><code>int omp_get_num_threads()</code></td><td>得到线程队列中的线程数</td></tr><tr><td><code>int omp_get_thread_num()</code></td><td>得到执行线程的线程号：</td></tr><tr><td><code>void omp_set_num_threads(4)</code></td><td>设定执行线程的数量为4</td></tr><tr><td><code>double omp_get_wtime(void)</code></td><td>返回挂钟“自过去任意时刻以来”经过的时间（秒）</td></tr><tr><td><code>double omp_get_wtick(void);</code></td><td>返回连续时钟滴答声之间的秒数。</td></tr></tbody></table><h2 id="OpenMP环境变量"><a href="#OpenMP环境变量" class="headerlink" title="OpenMP环境变量"></a>OpenMP环境变量</h2><table><thead><tr><th>环境变量名称</th><th>作用</th></tr></thead><tbody><tr><td>OMP_NUM_THREADS</td><td>设定最大线程数</td></tr><tr><td>OMP_SCHEDULE</td><td>调度方式 “DYNAMIC,4”</td></tr><tr><td>OMP_DYNAMIC</td><td>是否动态设定并行域执行的线程数</td></tr><tr><td>OMP_NESTED</td><td>确定是否可以并行嵌套</td></tr></tbody></table><h2 id="OpenMP示例–性能改善"><a href="#OpenMP示例–性能改善" class="headerlink" title="OpenMP示例–性能改善"></a>OpenMP示例–性能改善</h2><h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><p>如何处理循环中存在的依赖关系？例子如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)</span><br><span class="line"><span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">a[i][j]=<span class="number">2.0</span>*a[i<span class="number">-1</span>][j];</span><br></pre></td></tr></table></figure><p>可以变为(交换循环位置)；</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)</span><br><span class="line">a[i][j]=<span class="number">2.0</span>*a[i<span class="number">-1</span>][j];</span><br></pre></td></tr></table></figure><h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><p>下面这一个循环是存在循环依赖的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">2</span>;i&lt;<span class="number">20</span>;i++)</span><br><span class="line">a[i]=a[i<span class="number">-2</span>]+<span class="number">4</span> ;</span><br></pre></td></tr></table></figure><p>不过我们可以将这一个循环分解为多个循环，这多个循环间不存在依赖关系</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">2</span>;i&lt;<span class="number">20</span>;i=i+<span class="number">2</span>)</span><br><span class="line">a[i]=a[i<span class="number">-2</span>]+<span class="number">4</span> ;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">3</span>;i&lt;<span class="number">20</span>;i=i+<span class="number">2</span>)</span><br><span class="line">a[i]=a[i<span class="number">-2</span>]+<span class="number">4</span> ;</span><br></pre></td></tr></table></figure><h2 id="制导指令总结"><a href="#制导指令总结" class="headerlink" title="制导指令总结"></a>制导指令总结</h2><h3 id="并行域指令"><a href="#并行域指令" class="headerlink" title="并行域指令"></a>并行域指令</h3><p><img src="https://lh3.googleusercontent.com/-Qq6sgKD2ji0/XD3i5oH9VvI/AAAAAAAAN1c/Ry8Ay8PLx0ICJfQERdUhafUk00ta3cIZwCHMYCw/s0/Acrobat_2019-01-15_21-40-53.png" alt=""></p><h3 id="工作共享指令"><a href="#工作共享指令" class="headerlink" title="工作共享指令"></a>工作共享指令</h3><p><img src="https://lh3.googleusercontent.com/-JhjPfP392W0/XD3i8nOBkoI/AAAAAAAAN1g/b0rFfhaRdXE7qo4bSY36EMmF0PoL8DCDQCHMYCw/s0/Acrobat_2019-01-15_21-41-06.png" alt=""></p><h3 id="并行域与工作共享指令的结合"><a href="#并行域与工作共享指令的结合" class="headerlink" title="并行域与工作共享指令的结合"></a>并行域与工作共享指令的结合</h3><p><img src="https://lh3.googleusercontent.com/-y7KBSiWaDl4/XD3i_TPH8OI/AAAAAAAAN1k/Q3pjVu3MC-YArhkz1VxhLnJFlenauZjhgCHMYCw/s0/Acrobat_2019-01-15_21-41-17.png" alt=""></p><h3 id="同步指令"><a href="#同步指令" class="headerlink" title="同步指令"></a>同步指令</h3><p><img src="https://lh3.googleusercontent.com/-y7KBSiWaDl4/XD3i_TPH8OI/AAAAAAAAN1k/Q3pjVu3MC-YArhkz1VxhLnJFlenauZjhgCHMYCw/s0/Acrobat_2019-01-15_21-41-17.png" alt=""></p><h3 id="数据环境指令"><a href="#数据环境指令" class="headerlink" title="数据环境指令"></a>数据环境指令</h3><p><img src="https://lh3.googleusercontent.com/-Ccf5agIIOL8/XD3jFewuXmI/AAAAAAAAN1s/825ZKEyguzkYXD8gA7sOIZjctwbZf9CdwCHMYCw/s0/Acrobat_2019-01-15_21-41-39.png" alt=""></p><h2 id="OpenMP子句总结"><a href="#OpenMP子句总结" class="headerlink" title="OpenMP子句总结"></a>OpenMP子句总结</h2><h3 id="数据作用域属性子句"><a href="#数据作用域属性子句" class="headerlink" title="数据作用域属性子句"></a>数据作用域属性子句</h3><p><img src="https://lh3.googleusercontent.com/-JQovoZ2MIzk/XD3jWTZcajI/AAAAAAAAN2A/jrZd8dFECb4lNtCWV3poWFlnx2709pZOACHMYCw/s0/Acrobat_2019-01-15_21-42-48.png" alt=""></p><p><img src="https://lh3.googleusercontent.com/-RY1UDZes6Q4/XD3jZY1-7PI/AAAAAAAAN2E/1-F2Y4dXSngZLhY54tNDClmQt-uVcFF-ACHMYCw/s0/Acrobat_2019-01-15_21-43-01.png" alt=""></p><h3 id="其他子句"><a href="#其他子句" class="headerlink" title="其他子句"></a>其他子句</h3><p><img src="https://lh3.googleusercontent.com/-sfXhe5-b9qg/XD3jcESZ9CI/AAAAAAAAN2I/tN-9ENQk29AezWKTJLkPA9IcBcboBEHHQCHMYCw/s0/Acrobat_2019-01-15_21-43-12.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习4-OpenMP&quot;&gt;&lt;a href=&quot;#HPC复习4-OpenMP&quot; class=&quot;headerlink&quot; title=&quot;HPC复习4-OpenMP&quot;&gt;&lt;/a&gt;HPC复习4-OpenMP&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;OpenMP简介&lt;/li&gt;
&lt;li&gt;OpenMP编译制导&lt;/li&gt;
&lt;li&gt;OpenMP库函数&lt;/li&gt;
&lt;li&gt;OpenMP环境变量&lt;/li&gt;
&lt;li&gt;OpenMP示例–性能改善&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.4-归约操作优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-4-%E5%BD%92%E7%BA%A6%E6%93%8D%E4%BD%9C%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-4-归约操作优化/</id>
    <published>2019-01-15T12:02:10.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-4-并行归约优化"><a href="#HPC复习7-4-并行归约优化" class="headerlink" title="HPC复习7.4-并行归约优化"></a>HPC复习7.4-并行归约优化</h1><p>这里会有归约操作的7种优化版本。</p><p><img src="https://lh3.googleusercontent.com/-8rV-AMsd_Rw/XD2sO0WhFPI/AAAAAAAANzs/dR5OQxmXKt4l3HpoRmnq4Oh9VAf-hN7twCHMYCw/s0/Acrobat_2019-01-15_17-47-39.png" alt=""></p><p>7种方法的加速情况如下：</p><p><img src="https://lh3.googleusercontent.com/-ZARtsyKmBik/XD2s_jh4RUI/AAAAAAAANz0/ZVLxWOhn41MEkuP9fTrLlLwKSkEGc22awCHMYCw/s0/Acrobat_2019-01-15_17-50-54.png" alt=""></p><a id="more"></a><h2 id="Interleaved-Addressing-with-divergent-branching"><a href="#Interleaved-Addressing-with-divergent-branching" class="headerlink" title="Interleaved Addressing with divergent branching"></a>Interleaved Addressing with divergent branching</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reduce0</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata)</span> </span>&#123;</span><br><span class="line"><span class="keyword">extern</span> __shared__ <span class="keyword">int</span> sdata[];</span><br><span class="line">    <span class="comment">// each thread loads one element from global to shared mem</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">    sdata[tid] = g_idata[i]; <span class="comment">// 合并访存，读取一个block的数据到share memory中</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="comment">// do reduction in shared mem</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> s=<span class="number">1</span>; s &lt; blockDim.x; s *= <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid % (<span class="number">2</span>*s) == <span class="number">0</span>) &#123;</span><br><span class="line">            sdata[tid] += sdata[tid + s];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// write result for this block to global mem</span></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) g_odata[blockIdx.x] = sdata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://lh3.googleusercontent.com/-hfUJjKZ4Ksw/XD2vIHV9BzI/AAAAAAAAN0A/gLS3oE0NzqEKGI1O8hjvAI_0jFSTe3wKQCHMYCw/s0/Acrobat_2019-01-15_17-59-59.png" alt=""></p><h3 id="存在的问题："><a href="#存在的问题：" class="headerlink" title="存在的问题："></a>存在的问题：</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">unsigned</span> <span class="keyword">int</span> s=<span class="number">1</span>; s &lt; blockDim.x; s *= <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (tid % (<span class="number">2</span>*s) == <span class="number">0</span>) &#123; <span class="comment">// 以warp的运行想一想，就会发现，这个是发散的</span></span><br><span class="line">        sdata[tid] += sdata[tid + s];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Interleaved-address-with-bank-conflict"><a href="#Interleaved-address-with-bank-conflict" class="headerlink" title="Interleaved address with bank conflict"></a>Interleaved address with bank conflict</h2><p>对上面的问题进行优化，将对应的for循环改成下面的循环：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">unsigned</span> <span class="keyword">int</span> s=<span class="number">1</span>; s &lt; blockDim.x; s *= <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> index = <span class="number">2</span> * s * tid;</span><br><span class="line">    <span class="keyword">if</span> (index &lt; blockDim.x) &#123;</span><br><span class="line">    sdata[index] += sdata[index + s];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看了老半天终于看懂了</p><p>第一次循环：</p><p>indexs:0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32，取其中的</p><p>0,2,4,6,8,10,12,14，也就是前8个线程去计算</p><p>第二次循环</p><p>indexs:0,4,8,12,16,….，取前四个线程去计算</p><p><img src="https://lh3.googleusercontent.com/-mB5VGBUtzb4/XD2w5t6nmEI/AAAAAAAAN0M/dzqs-ASHP2syD1k7QFzuprgHYpv0fHjwACHMYCw/s0/Acrobat_2019-01-15_18-07-34.png" alt=""></p><h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><p>数组可能是很大的，考虑到有16个bank，这里在归约的时候，都是以2的倍数在增加，及其容易发生bank冲突。</p><p>如，在第二次循环中，会去读取这些index对应的数据</p><p>0,4,8,12,16,20,24,28,32，。。。就会发生bank冲突了。</p><h2 id="Sequential-Addressing"><a href="#Sequential-Addressing" class="headerlink" title="Sequential Addressing"></a>Sequential Addressing</h2><p>这一个优化就好多啦,不会发生bank冲突，因为一定是顺序写shared memory，看一看示意图，很容易懂！</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">unsigned</span> <span class="keyword">int</span> s=blockDim.x/<span class="number">2</span>; s&gt;<span class="number">0</span>; s&gt;&gt;=<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; s) &#123;</span><br><span class="line">        sdata[tid] += sdata[tid + s];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://lh3.googleusercontent.com/-fIBj8uEKW8I/XD2yyRsUFcI/AAAAAAAAN0c/xi3CeNJWtXs9Uvgg14Yrsxhx228gx3LcQCHMYCw/s0/Acrobat_2019-01-15_18-15-38.png" alt=""></p><h2 id="First-Add-During-Load"><a href="#First-Add-During-Load" class="headerlink" title="First Add During Load"></a>First Add During Load</h2><p>关键：在装入shared memory时做第一次加法</p><p>从代码中可以看出思路：在读取数组中的值时，原本是以一个blockDim.x为单位读取，每个block读取与blockDim.x相当的元素，放到shared memory中，现在每个block会读取两个blockDim.x大小的数组，然后在写进shared memory的时候就做一次加法。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// perform first level of reduction,</span></span><br><span class="line"><span class="comment">// reading from global memory, writing to shared memory</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*(blockDim.x*<span class="number">2</span>) + threadIdx.x;</span><br><span class="line">sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure><h3 id="存在的问题：-1"><a href="#存在的问题：-1" class="headerlink" title="存在的问题："></a>存在的问题：</h3><p>可能在指令的吞吐量上，有瓶颈：</p><p>尝试循环展开</p><h2 id="Unrolling-the-Last-Warp"><a href="#Unrolling-the-Last-Warp" class="headerlink" title="Unrolling the Last Warp"></a>Unrolling the Last Warp</h2><p>这里主要尝试这样的做法：</p><ol><li>当归约到只剩下32个线程需要计算的时候（也就是说只剩下一个warp了）</li><li>显式的将剩下的32个线程所需要做的事情通过循环展开的方式来完成</li></ol><p>优化主要体现在两点：</p><ol><li>节省了所有的warp的额外开销<ol><li>想想其他的warp怎么会有开销呢？当只剩下一个warp需要进行实质的工作的时候，其他warp仍然在执行循环。</li><li>这个额外开销指的是维护循环变量，检查循环条件等</li></ol></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">unsigned</span> <span class="keyword">int</span> s=blockDim.x/<span class="number">2</span>; s&gt;<span class="number">32</span>; s&gt;&gt;=<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; s)</span><br><span class="line">        sdata[tid] += sdata[tid + s];</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">32</span>)</span><br><span class="line">&#123;</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">32</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">16</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">8</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">4</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">2</span>];</span><br><span class="line">    sdata[tid] += sdata[tid + <span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="存在的问题-1"><a href="#存在的问题-1" class="headerlink" title="存在的问题"></a>存在的问题</h3><p>这里仅仅展开了最后的一个warp，能否完全展开呢？</p><h2 id="Completely-Unrolled"><a href="#Completely-Unrolled" class="headerlink" title="Completely Unrolled"></a>Completely Unrolled</h2><p>由于编译期就可以知道迭代的<code>blockDim.x</code>，因此可以通过模板的方式生成循环展开的相关代码</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (blockSize &gt;= <span class="number">512</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">256</span>) &#123; sdata[tid] += sdata[tid + <span class="number">256</span>]; &#125; __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (blockSize &gt;= <span class="number">256</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">128</span>) &#123; sdata[tid] += sdata[tid + <span class="number">128</span>]; &#125; __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (blockSize &gt;= <span class="number">128</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">64</span>) &#123; sdata[tid] += sdata[tid + <span class="number">64</span>]; &#125; __syncthreads();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (tid &lt; <span class="number">32</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">64</span>) sdata[tid] += sdata[tid + <span class="number">32</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>) sdata[tid] += sdata[tid + <span class="number">16</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>) sdata[tid] += sdata[tid + <span class="number">8</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>) sdata[tid] += sdata[tid + <span class="number">4</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>) sdata[tid] += sdata[tid + <span class="number">2</span>];</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>) sdata[tid] += sdata[tid + <span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的blockSize是个模板参数</p><h2 id="Multiple-Adds-Thread"><a href="#Multiple-Adds-Thread" class="headerlink" title="Multiple Adds/Thread"></a>Multiple Adds/Thread</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>combine sequential and parallel reduction</p><p>原理有点不懂。</p><p>Algorithm Cascading（算法级联）</p><p>它具体的做法是这样子的（我猜）：</p><ol><li>申请的线程可以少一些，推荐申请$O(N/logN)$个线程</li><li>在算法开始的时候，先使用串行求和，（也就是下面那一串代码），这样子就可以将问题规模缩小到与线程数的情况</li><li>后面都一样</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*(blockSize*<span class="number">2</span>) + threadIdx.x;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> gridSize = blockSize*<span class="number">2</span>*gridDim.x;</span><br><span class="line">sdata[tid] = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i &lt; n) &#123;</span><br><span class="line">    sdata[tid] += g_idata[i] + g_idata[i+blockSize];</span><br><span class="line">    i += gridSize;</span><br><span class="line">&#125;</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>前面的优化都其实特别有意思，特别是最后一个</p><p>最后一个优化应该说在理论层面的推导会稍微多一点，所以就不容易发现。</p><p>而正因为此吧，我觉得我需要弄清楚什么是“算法级联”，如何计算并行算法的复杂度。</p><p>如何推导出来怎样的“算法级联”能够给程序加速。</p><p>最后优化的程序如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">unsigned</span> <span class="keyword">int</span> blockSize&gt;</span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">reduce6</span><span class="params">(<span class="keyword">int</span> *g_idata, <span class="keyword">int</span> *g_odata, <span class="keyword">unsigned</span> <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">int</span> sdata[];</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> i = blockIdx.x*(blockSize*<span class="number">2</span>) + tid;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> gridSize = blockSize*<span class="number">2</span>*gridDim.x;</span><br><span class="line">    sdata[tid] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">do</span> &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize; &#125; <span class="keyword">while</span> (i &lt; n);</span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">512</span>) &#123; </span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">256</span>) &#123; sdata[tid] += sdata[tid + <span class="number">256</span>]; &#125; __syncthreads(); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">256</span>) &#123; </span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">128</span>) &#123; sdata[tid] += sdata[tid + <span class="number">128</span>]; &#125; __syncthreads(); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (blockSize &gt;= <span class="number">128</span>) &#123; </span><br><span class="line">        <span class="keyword">if</span> (tid &lt; <span class="number">64</span>) &#123; sdata[tid] += sdata[tid + <span class="number">64</span>]; &#125; __syncthreads(); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; <span class="number">32</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">64</span>) sdata[tid] += sdata[tid + <span class="number">32</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">32</span>) sdata[tid] += sdata[tid + <span class="number">16</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">16</span>) sdata[tid] += sdata[tid + <span class="number">8</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">8</span>) sdata[tid] += sdata[tid + <span class="number">4</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">4</span>) sdata[tid] += sdata[tid + <span class="number">2</span>];</span><br><span class="line">        <span class="keyword">if</span> (blockSize &gt;= <span class="number">2</span>) sdata[tid] += sdata[tid + <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) g_odata[blockIdx.x] = sdata[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>优化的结果可见：</p><p><img src="https://lh3.googleusercontent.com/-bnSz_ewThXc/XD3KsyUzD9I/AAAAAAAAN0w/cTjEcJ9zFb4k_SKLLmMwUIPyAh1TANfDgCHMYCw/s0/Acrobat_2019-01-15_19-57-36.png" alt=""></p><h2 id="相关博客"><a href="#相关博客" class="headerlink" title="相关博客"></a>相关博客</h2><ol><li><a href="http://wattlebird.github.io/2013/07/20/%E5%85%B3%E4%BA%8E-CUDA-%E4%B8%AD-reduction-%E8%BF%90%E7%AE%97%E7%9A%84%E4%BC%98%E5%8C%96/" target="_blank" rel="noopener">关于 CUDA 中 reduction 运算的优化</a></li><li><a href="https://en.wikipedia.org/wiki/Analysis_of_parallel_algorithms" target="_blank" rel="noopener">Brent’s theorem</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习7-4-并行归约优化&quot;&gt;&lt;a href=&quot;#HPC复习7-4-并行归约优化&quot; class=&quot;headerlink&quot; title=&quot;HPC复习7.4-并行归约优化&quot;&gt;&lt;/a&gt;HPC复习7.4-并行归约优化&lt;/h1&gt;&lt;p&gt;这里会有归约操作的7种优化版本。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-8rV-AMsd_Rw/XD2sO0WhFPI/AAAAAAAANzs/dR5OQxmXKt4l3HpoRmnq4Oh9VAf-hN7twCHMYCw/s0/Acrobat_2019-01-15_17-47-39.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;7种方法的加速情况如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-ZARtsyKmBik/XD2s_jh4RUI/AAAAAAAANz0/ZVLxWOhn41MEkuP9fTrLlLwKSkEGc22awCHMYCw/s0/Acrobat_2019-01-15_17-50-54.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.3-矩阵转置优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-3-%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-3-矩阵转置优化/</id>
    <published>2019-01-15T12:01:04.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-3-矩阵转置优化"><a href="#HPC复习7-3-矩阵转置优化" class="headerlink" title="HPC复习7.3-矩阵转置优化"></a>HPC复习7.3-矩阵转置优化</h1><p>这一个例子使用了以下几种技巧优化了矩阵转置：</p><ol><li><p>合并访问</p></li><li><p>避免共享内存的bank conflict</p><p><img src="https://lh3.googleusercontent.com/-KenoHV2uZck/XD2rzKYgx9I/AAAAAAAANzk/fSipGdSUZRgZEL5HDX_I0JVWik5ZZOfnwCHMYCw/s0/Acrobat_2019-01-15_17-45-49.png" alt=""></p></li></ol><a id="more"></a><h2 id="NAIVE"><a href="#NAIVE" class="headerlink" title="NAIVE"></a>NAIVE</h2><p>原始的矩阵转置可见</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">transpose_naive</span><span class="params">(<span class="keyword">float</span> *odata, <span class="keyword">float</span> *idata, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> xIndex = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> yIndex = blockDim.y * blockIdx.y + threadIdx.y;</span><br><span class="line">    <span class="comment">// //这里xIndex对应矩阵的列号，yIndex对应矩阵的行号</span></span><br><span class="line">    <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_in = xIndex + width * yIndex;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_out = yIndex + height * xIndex;</span><br><span class="line">        odata[index_out] = idata[index_in];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// //warp的排列：按threadIdx.x优先的次序</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="合并访存优化"><a href="#合并访存优化" class="headerlink" title="合并访存优化"></a>合并访存优化</h2><p>在原始的版本里，关键问题在于：</p><p><code>odata[index_out]</code>写的时候，无法合并访存：</p><p><img src="https://lh3.googleusercontent.com/-Ji3U1csOcqw/XD2mimdstWI/AAAAAAAANzA/2Ssh9Fc9_W4LrIp9VCK0KkxurBf5Q5IOgCHMYCw/s0/Acrobat_2019-01-15_17-23-22.png" alt=""></p><h3 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h3><ol><li>关键思想：使用合并访存技巧，读取一个块到shared memory中<ol><li><img src="https://lh3.googleusercontent.com/-e2xir8DtlLw/XD2rL1J5cgI/AAAAAAAANzM/IRKaftgFzF4yk62GpzPVBY_Yb7F_BEfoACHMYCw/s0/Acrobat_2019-01-15_17-43-10.png" alt=""></li></ol></li><li>在shared memory中，通过调换读取的索引，实现合并访存写回内存中<ol><li><img src="https://lh3.googleusercontent.com/-NPJTmLUBZio/XD2rWEhYLmI/AAAAAAAANzQ/je5sVWS75IIU8RL0rfLO0uHNNIzN_q02wCHMYCw/s0/Acrobat_2019-01-15_17-43-52.png" alt=""></li></ol></li></ol><h2 id="解决bank冲突"><a href="#解决bank冲突" class="headerlink" title="解决bank冲突"></a>解决bank冲突</h2><p>在上面读取shared memory中，会发生bank冲突导致读取串行化的问题。</p><p><img src="https://lh3.googleusercontent.com/-MM2-kYkf_qI/XD2rfV1YaBI/AAAAAAAANzY/8wKHxHvatQ8iPcHgw34uhA30DSJJoCXAgCHMYCw/s0/Acrobat_2019-01-15_17-44-29.png" alt=""></p><h2 id="代码实现："><a href="#代码实现：" class="headerlink" title="代码实现："></a>代码实现：</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">transpose</span><span class="params">(<span class="keyword">float</span> *odata, <span class="keyword">float</span> *idata, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __shared__ <span class="keyword">float</span> block[(BLOCK_DIM+<span class="number">1</span>)*BLOCK_DIM];</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> xBlock = __mul24(blockDim.x, blockIdx.x);</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> yBlock = __mul24(blockDim.y, blockIdx.y);</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> xIndex = xBlock + threadIdx.x;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> yIndex = yBlock + threadIdx.y;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> index_out, index_transpose;</span><br><span class="line">    <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_in = __mul24(width, yIndex) + xIndex;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> index_block = __mul24(threadIdx.y, BLOCK_DIM+<span class="number">1</span>) + threadIdx.x;</span><br><span class="line">        block[index_block] = idata[index_in];</span><br><span class="line">        index_transpose = __mul24(threadIdx.x, BLOCK_DIM+<span class="number">1</span>) + threadIdx.y;</span><br><span class="line">        index_out = __mul24(height, xBlock + threadIdx.y) + yBlock + threadIdx.x;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    <span class="keyword">if</span> (xIndex &lt; width &amp;&amp; yIndex &lt; height)</span><br><span class="line">    odata[index_out] = block[index_transpose];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习7-3-矩阵转置优化&quot;&gt;&lt;a href=&quot;#HPC复习7-3-矩阵转置优化&quot; class=&quot;headerlink&quot; title=&quot;HPC复习7.3-矩阵转置优化&quot;&gt;&lt;/a&gt;HPC复习7.3-矩阵转置优化&lt;/h1&gt;&lt;p&gt;这一个例子使用了以下几种技巧优化了矩阵转置：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;合并访问&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;避免共享内存的bank conflict&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-KenoHV2uZck/XD2rzKYgx9I/AAAAAAAANzk/fSipGdSUZRgZEL5HDX_I0JVWik5ZZOfnwCHMYCw/s0/Acrobat_2019-01-15_17-45-49.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.2-cuda矩阵向量乘法优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-2-cuda%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-2-cuda矩阵向量乘法优化/</id>
    <published>2019-01-15T11:59:38.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-2-矩阵向量乘法优化"><a href="#HPC复习7-2-矩阵向量乘法优化" class="headerlink" title="HPC复习7.2-矩阵向量乘法优化"></a>HPC复习7.2-矩阵向量乘法优化</h1><blockquote><p>这里描述了从CPU到GPU的优化步骤，步步渐进，最终收敛于使用cuda的标准数学库。</p></blockquote><p>对于CUDA程序开发来说，优化往往是整个开发过程的核心，不同算法，不同存储器组织的程序性能往往差几十倍，本讲通过一个简单的例子来展示CUDA开发中一些重要的因素对性能的影响。</p><p>最后的优化结果可见</p><p><img src="https://lh3.googleusercontent.com/-eO3K2LRIf3Q/XD2cyoaQgII/AAAAAAAANyo/CwokcPDNYRkX3mZo8UqcINMGXtAgpmxOwCHMYCw/s0/Acrobat_2019-01-15_16-41-45.png" alt=""></p><h2 id="原始版本：串行C版本"><a href="#原始版本：串行C版本" class="headerlink" title="原始版本：串行C版本"></a>原始版本：串行C版本</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mxv</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> rowSize, <span class="keyword">const</span> <span class="keyword">int</span> columnSize,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">float</span> *matrix, <span class="keyword">const</span> <span class="keyword">float</span> *v, <span class="keyword">float</span> *r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)&#123;</span><br><span class="line">        <span class="keyword">float</span> re = <span class="number">0.0f</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columnSize; j++)&#123;</span><br><span class="line">        re += matrix[i*columnSize+j]*v[j];</span><br><span class="line">        &#125;</span><br><span class="line">        r[i] = re;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="CPU上的优化"><a href="#CPU上的优化" class="headerlink" title="CPU上的优化"></a>CPU上的优化</h2><p>在cpu上的优化我就不详细说了吧</p><ol><li><p>使用sse指令来计算</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mxvSSE</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> rowSize, <span class="keyword">const</span> <span class="keyword">int</span> columnSize, <span class="keyword">const</span> <span class="keyword">float</span> *matrix, <span class="keyword">const</span> <span class="keyword">float</span> *v, <span class="keyword">float</span> *r)</span></span>&#123;</span><br><span class="line">    __m128 *mv = (__m128*)v;</span><br><span class="line">    __m128 *mm = (__m128*)matrix;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)&#123;</span><br><span class="line">        __m128 re = _mm_set_ps(<span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columnSize/<span class="number">4</span>; j++)&#123;</span><br><span class="line">            re = _mm_add_ps(re, _mm_mul_ps(mm[i*columnSize/<span class="number">4</span>+j], mv[j]));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">float</span> __attribute((aligned(<span class="number">16</span>))) a[<span class="number">4</span>];</span><br><span class="line">        _mm_store_ps(a, re);</span><br><span class="line">        r[i] = a[<span class="number">0</span>] + a[<span class="number">1</span>] + a[<span class="number">2</span>] + a[<span class="number">3</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>使用sse+openmp来优化</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mxvSSEOpenmp</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> rowSize, <span class="keyword">const</span> <span class="keyword">int</span> columnSize, <span class="keyword">float</span> *matrix, <span class="keyword">float</span> *vec, <span class="keyword">float</span> *r)</span></span>&#123;</span><br><span class="line">    __m128 *mv = (__m128*)v;</span><br><span class="line">    __m128 *mm = (__m128*)matrix;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for num_threads(2)</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)&#123;</span><br><span class="line">        __m128 re = _mm_set_ps(<span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columnSize/<span class="number">4</span>; j++)&#123;</span><br><span class="line">        re = _mm_add_ps(re, _mm_mul_ps(mm[i*columnSize/<span class="number">4</span>+j], mv[j]));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">float</span> __attribute((aligned(<span class="number">16</span>))) a[<span class="number">4</span>];</span><br><span class="line">    _mm_store_ps(a, re);</span><br><span class="line">    r[i] = a[<span class="number">0</span>] + a[<span class="number">1</span>] + a[<span class="number">2</span>] + a[<span class="number">3</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol><h2 id="使用CUDA的注意事项"><a href="#使用CUDA的注意事项" class="headerlink" title="使用CUDA的注意事项"></a>使用CUDA的注意事项</h2><p>几个原则需要尽可能保证</p><ol><li>保持SM尽可能忙碌<ol><li>加大数据量或者减小线程块大小</li></ol></li><li>优化存储器的使用<ol><li>全局存储器合并访问</li><li>使用constant或shared memory</li></ol></li><li>对齐分配空间<ol><li>关于<a href="https://www.ibm.com/developerworks/library/pa-dalign/" target="_blank" rel="noopener">为什么</a></li></ol></li></ol><h2 id="CUDA-naive的优化"><a href="#CUDA-naive的优化" class="headerlink" title="CUDA naive的优化"></a>CUDA naive的优化</h2><p>关键在于：理解这里为什么要使用转置矩阵来达到合并访存的目的</p><h3 id="第一步-cuda-naive"><a href="#第一步-cuda-naive" class="headerlink" title="第一步-cuda naive"></a>第一步-cuda naive</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvNaive</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> columnPitch, <span class="keyword">const</span> <span class="keyword">float</span> *d_matrix, <span class="keyword">const</span> <span class="keyword">float</span> *d_vec, <span class="keyword">float</span> *d_r)</span></span>&#123;</span><br><span class="line">    uint id = blockDim.x*blockIdx.x+ threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(rowSize&lt;= id) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i= <span class="number">0</span>; i&lt; columnSize; i++)&#123;</span><br><span class="line">    temp += d_matrix[id*columnPitch+i]*d_vec[i]; </span><br><span class="line">        <span class="comment">// d_matrix[id*columnPitch+i]这里存在不能合并访存的问题</span></span><br><span class="line">    &#125;</span><br><span class="line">    d_r[id] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="第二步-发现合并访存的问题"><a href="#第二步-发现合并访存的问题" class="headerlink" title="第二步-发现合并访存的问题"></a>第二步-发现合并访存的问题</h3><p><img src="https://lh3.googleusercontent.com/-hTGicVs9O-g/XD2gvBT9DHI/AAAAAAAANy0/OecalPhUJ9Al47t8fZrVLgkejFgThupkQCHMYCw/s0/Acrobat_2019-01-15_16-58-36.png" alt=""></p><p>解决方法：先将矩阵转置，就可以达到合并访存的要求了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 转置后的for循环</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i= <span class="number">0</span>; i&lt; rowSize; i++)&#123;</span><br><span class="line">temp += d_matrix[i*columnPitch+id]*d_vec[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="访存优化"><a href="#访存优化" class="headerlink" title="访存优化"></a>访存优化</h2><p>关注到<code>d_vec</code>数组是不会改变的，因此考虑使用constant或者shared memory进行优化</p><h3 id="使用constant-memory优化"><a href="#使用constant-memory优化" class="headerlink" title="使用constant memory优化"></a>使用constant memory优化</h3><ol><li><p>将一整个向量都放进constant memory中，得到以下代码：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvNaiveTransposeConstant</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> columnPitch, <span class="keyword">const</span> <span class="keyword">float</span> *d_matrix, <span class="keyword">const</span> <span class="keyword">int</span> start, <span class="keyword">float</span> *d_r)</span></span>&#123;</span><br><span class="line">    uint id = blockDim.x*blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(columnSize &lt;= id) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">int</span> end = start+CONSTANTSIZE &gt; rowSize ? rowSize : start+CONSTANTSIZE;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = start; i &lt; end; i++)&#123;</span><br><span class="line">    temp += d_matrix[i*columnPitch+id]*c_v[i-start];</span><br><span class="line">    &#125;</span><br><span class="line">d_r[id] += temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>如果向量超过了constant memory的上限，那就</p><ol><li>分批，多次传输，启动内核。</li></ol></li></ol><h3 id="使用shared-memory优化"><a href="#使用shared-memory优化" class="headerlink" title="使用shared memory优化"></a>使用shared memory优化</h3><ol><li><p>关注到：可以在一个block内共享向量$v$，考虑使用shared memory</p></li><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvNaiveTransposeShared</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> columnPitch, <span class="keyword">const</span> <span class="keyword">float</span> *d_matrix, <span class="keyword">const</span> <span class="keyword">float</span> *d_v, <span class="keyword">const</span> <span class="keyword">int</span> sharedSize, <span class="keyword">float</span> *d_r)</span></span>&#123;</span><br><span class="line">    uint id = blockDim.x*blockIdx.x+ threadIdx.x;</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">float</span> s_v[];</span><br><span class="line">    <span class="comment">// 外层循环，每次加载一段大小为sharedsize的向量v进行计算</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> start = <span class="number">0</span>; start &lt; rowSize; start += sharedSize)&#123;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        <span class="meta">#<span class="meta-keyword">pragma</span> unroll 4</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i= threadIdx.x; i&lt; sharedSize&amp;&amp;i+start&lt;rowSize; i+= blockDim.x)&#123;</span><br><span class="line">        s_v[i] = d_v[start+i]; <span class="comment">// 关键在于这里加载shared memory</span></span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        <span class="keyword">if</span>(columnSize&lt;= id) <span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">int</span> end = start+sharedSize&gt; rowSize? rowSize: start+sharedSize;</span><br><span class="line">        <span class="meta">#<span class="meta-keyword">pragma</span> unroll 8</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = start; i &lt; end; i++)&#123;</span><br><span class="line">            <span class="comment">// 使用shared memory 访存得到极大提升</span></span><br><span class="line">        temp += d_matrix[i*columnPitch+id]*s_v[i-start];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(id &lt; columnSize)</span><br><span class="line">    d_r[id] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="block模式与warp模式"><a href="#block模式与warp模式" class="headerlink" title="block模式与warp模式"></a>block模式与warp模式</h2><p>问题：如果不转置矩阵如何计算？</p><h3 id="block模式"><a href="#block模式" class="headerlink" title="block模式"></a>block模式</h3><p>关键：一个block处理矩阵的一行和向量乘积，其中block中的每个线程处理该行中的一个与对应向量元素的乘积,然后归约。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __<span class="function">global__ <span class="title">mxvBlock</span><span class="params">(<span class="keyword">int</span> rowSize, <span class="keyword">int</span> columnSize, <span class="keyword">int</span> pitchItem, <span class="keyword">const</span> <span class="keyword">float</span>* __restrict__ d_matrix,constfloat* __restrict__ d_vec, <span class="keyword">float</span>* __restrict__ d_r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tid= threadIdx.x;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">float</span> s_r[];</span><br><span class="line">    <span class="keyword">float</span> temp = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i= tid; i&lt; columnSize; i+= blockDim.x)&#123;</span><br><span class="line">    temp += d_matrix[blockIdx.x*pitchItem+i]*d_vec[i];</span><br><span class="line">    &#125;</span><br><span class="line">    s_r[tid] = temp; __syncthreads();</span><br><span class="line">    ……<span class="comment">//省略归约代码</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="warp模式"><a href="#warp模式" class="headerlink" title="warp模式"></a>warp模式</h3><p>具体的计算和block模式差不多,只是使用一个warp线程计算矩阵的一行与向量的乘积,在我的测试中发现,这个算法对于行数大于列数的矩阵效果很好,很多时候性能是block的两倍以上。</p><h2 id="使用cuBlas包"><a href="#使用cuBlas包" class="headerlink" title="使用cuBlas包"></a>使用cuBlas包</h2><p>成为调包侠：</p><p>函数: cublasSgemv——cuBlas包的矩阵向量乘法</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后的优化结果可见</p><p><img src="https://lh3.googleusercontent.com/-eO3K2LRIf3Q/XD2cyoaQgII/AAAAAAAANyo/CwokcPDNYRkX3mZo8UqcINMGXtAgpmxOwCHMYCw/s0/Acrobat_2019-01-15_16-41-45.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;HPC复习7-2-矩阵向量乘法优化&quot;&gt;&lt;a href=&quot;#HPC复
      
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习7.1-cuda矩阵乘法优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-1-cuda%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习7-1-cuda矩阵乘法优化/</id>
    <published>2019-01-15T11:58:43.000Z</published>
    <updated>2019-01-15T12:02:39.602Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习7-1-矩阵乘法优化"><a href="#HPC复习7-1-矩阵乘法优化" class="headerlink" title="HPC复习7.1-矩阵乘法优化"></a>HPC复习7.1-矩阵乘法优化</h1><h2 id="naive实现"><a href="#naive实现" class="headerlink" title="naive实现"></a>naive实现</h2><p>具体思路就很简单了，仅使用一个块，然后块中每一个线程计算矩阵的一个元素。</p><p>算法图示可见<img src="https://lh3.googleusercontent.com/-hk3rnSa5zm4/XD2a5NgdiSI/AAAAAAAANyc/HDkg-4FY4icQgSXBtHLzhZ7XQ8PliUd3gCHMYCw/s0/Snipaste_2019-01-15_16-33-36.png" alt=""></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 矩阵乘法的内核函数——每个线程都要执行的代码</span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">MatrixMulKernel</span><span class="params">(<span class="keyword">float</span>* Md, <span class="keyword">float</span>* Nd, <span class="keyword">float</span>* Pd, intWidth)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 2维的线程ID号</span></span><br><span class="line">    inttx= threadIdx.x;</span><br><span class="line">    intty= threadIdx.y;</span><br><span class="line">    <span class="comment">// Pvalue用来保存被每个线程计算完成后的矩阵的元素</span></span><br><span class="line">    <span class="keyword">float</span> Pvalue= <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//每个线程计算一个元素</span></span><br><span class="line">    <span class="keyword">for</span> (intk = <span class="number">0</span>; k &lt; Width; ++k)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">float</span> Melement= Md[ty* Width + k];</span><br><span class="line">        <span class="keyword">float</span> Nelement= Nd[k * Width + tx];</span><br><span class="line">        Pvalue += Melement* Nelement;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将计算结果写入设备存储器中</span></span><br><span class="line">    Pd[ty* Width + tx] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>这样的实现是有问题的：</p><ol><li>计算的时间与访存时间比例相当，受存储器延迟的影响很大。</li><li>矩阵的大小收到线程块所能容纳的最大线程数的限制。</li></ol></blockquote><h2 id="处理任意大小的方形矩阵"><a href="#处理任意大小的方形矩阵" class="headerlink" title="处理任意大小的方形矩阵"></a>处理任意大小的方形矩阵</h2><p>解决了在上面的实现中，无法处理任意大小的方形矩阵的问题。</p><p>关键思想：</p><ol><li>将矩阵分块，每一个线程块block计算其中的一个子矩阵</li><li>如果矩阵块的数量大于最大的上限时，需要在内核附近设置一个循环（一个已经用过的技巧，我会的啦）</li></ol><blockquote><p>问题：每一个线程都要访问global memory获取矩阵的一整行和一整列元素</p><p>访存带宽成为了计算的瓶颈</p></blockquote><h2 id="分片矩阵乘法"><a href="#分片矩阵乘法" class="headerlink" title="分片矩阵乘法"></a>分片矩阵乘法</h2><p>使用高带宽的片上存储器”shared memory”缓解了访存瓶颈</p><p>关键思想：重用数据，原来的矩阵乘法实现中，每一个区域都有多个线程多次访问，如果数据可以重用，可以大大降低计算所需的带宽。</p><p>分片矩阵乘法-算法关键：</p><ol><li>代价估计：<code>浮点操作：全局存储器读出操作＝16: 1</code>，说明访存代价占比不高</li><li><img src="figure/1545275255554.png" alt="1545275255554"></li><li>算法细节<ol><li>逐个子矩阵块，依次计算，求和到结果矩阵上</li><li>进行子矩阵块的运算前，先将子矩阵块复制到<code>shared memory</code>上<ol><li>一个合并访存(访问global memory)的技巧：每一个线程读取一个值，然后使用同步原语保证同步</li></ol></li><li>每一个线程计算完子矩阵块的一个结果后，合并访存的技巧依然使用，写位于global memory的矩阵<ol><li>每一个线程仅写回自己计算的值，合并访存，然后使用同步原语</li></ol></li></ol></li></ol><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//每个线程块有TILE_WIDTH2个线程</span></span><br><span class="line"><span class="function">dim3 <span class="title">dimBlock</span><span class="params">(TILE_WIDTH, TILE_WIDTH)</span></span>;</span><br><span class="line"><span class="comment">//有(Width/TILE_WIDTH)2个线程块</span></span><br><span class="line"><span class="function">dim3 <span class="title">dimGrid</span><span class="params">(Width/TILE_WIDTH, Width/TILE_WIDTH)</span></span>;</span><br><span class="line"><span class="comment">//调用内核函数</span></span><br><span class="line">MatrixMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(Md, Nd, Pd，Width);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下是内核函数</span></span><br><span class="line"><span class="comment">// part 1 将数据从global memory加载到shared memory上</span></span><br><span class="line"><span class="comment">//获得线程块号</span></span><br><span class="line">intbx= blockIdx.x;</span><br><span class="line">intby = blockIdx.y;</span><br><span class="line"><span class="comment">//获得块内的线程号</span></span><br><span class="line">inttx= threadIdx.x;</span><br><span class="line">intty= threadIdx.y;</span><br><span class="line"><span class="comment">//Pvalue：线程计算完成后的子矩阵元素——自动变量</span></span><br><span class="line"><span class="keyword">float</span> Pvalue= <span class="number">0</span>;</span><br><span class="line"><span class="comment">//循环，遍历M和N的所有子矩阵</span></span><br><span class="line"><span class="keyword">for</span> (intm = <span class="number">0</span>; m &lt; Width/TILE_WIDTH; ++m) &#123;</span><br><span class="line">    <span class="comment">// 获取指向当前矩阵M子矩阵的指针Msub</span></span><br><span class="line">    Float* Mdsub= GetSubMatrix(Md, m, by, Width);</span><br><span class="line">    <span class="comment">//获取指向当前矩阵N的子矩阵的指针Nsub</span></span><br><span class="line">    Float* Ndsub= GetSubMatrix(Nd, bx, m, Width);</span><br><span class="line">    <span class="comment">//共享存储器空间声明</span></span><br><span class="line">    __shared__floatMds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    __shared__floatNds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    <span class="comment">// 每个线程载入M的子矩阵的一个元素</span></span><br><span class="line">    Mds[ty][tx] = GetMatrixElement(Mdsub, tx, ty);</span><br><span class="line">    <span class="comment">//每个线程载入N的子矩阵的一个元素</span></span><br><span class="line">    Nds[ty][tx] = GetMatrixElement(Ndsub, tx, ty);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// part 2 每个线程计算一个值结果</span></span><br><span class="line"><span class="comment">//同步，在计算之前，确保子矩阵所有的元素都已载入共享存储器中</span></span><br><span class="line">__syncthreads();</span><br><span class="line"><span class="comment">//每个线程计算线程块内子矩阵中的一个元素</span></span><br><span class="line"><span class="keyword">for</span> (intk = <span class="number">0</span>; k &lt; TILE_WIDTH; ++k)</span><br><span class="line">Pvalue+= Mds[ty][k] * Nds[k][tx];</span><br><span class="line"><span class="comment">//同步，确保重新载入新的M和N子矩阵数据前，上述计算操作已全部完成</span></span><br><span class="line">__syncthreads();</span><br><span class="line"></span><br><span class="line"><span class="comment">// part 3 合并访存 写回</span></span><br><span class="line"><span class="comment">// 获取指向矩阵P的子矩阵的指针</span></span><br><span class="line">Matrix Psub= GetSubMatrix(P, bx, by);</span><br><span class="line"><span class="comment">//向全局存储器写入线程块计算后的结果子矩阵</span></span><br><span class="line"><span class="comment">//每个线程写入一个元素</span></span><br><span class="line">SetMatrixElement(Psub, tx, ty, Pvalue);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;HPC复习7-1-矩阵乘法优化&quot;&gt;&lt;a href=&quot;#HPC复习7
      
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习6-CUDA优化</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A06-CUDA%E4%BC%98%E5%8C%96/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习6-CUDA优化/</id>
    <published>2019-01-15T08:13:09.000Z</published>
    <updated>2019-01-15T08:13:49.733Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习6-cuda优化"><a href="#HPC复习6-cuda优化" class="headerlink" title="HPC复习6-cuda优化"></a>HPC复习6-cuda优化</h1><p>在cuda程序的优化中，需要考虑以下几个问题</p><ol><li>了解SM核中所提供的资源，并合理分配。</li><li>确定kernel的启动参数，以尽可能提高cuda程序的性能。</li><li>理解warp隐藏延时的作用，知道为什么warp越多越能隐藏延时。</li><li>通过数据预读取隐藏访存延时。</li><li>了解不同指令的吞吐量，并优化之。</li></ol><a id="more"></a><h2 id="SM资源分割"><a href="#SM资源分割" class="headerlink" title="SM资源分割"></a>SM资源分割</h2><h3 id="需要确定的值"><a href="#需要确定的值" class="headerlink" title="需要确定的值"></a>需要确定的值</h3><ol><li>block的数量</li><li>thread的数量</li></ol><h3 id="与分配资源有关的参数"><a href="#与分配资源有关的参数" class="headerlink" title="与分配资源有关的参数"></a>与分配资源有关的参数</h3><ol><li>线程块槽数量（thread block slot）：block数量的上限</li><li>线程槽数量（thread slot）</li><li>寄存器的数量</li><li>shared memory的大小</li></ol><h3 id="分配资源的数量，与哪些因素有关"><a href="#分配资源的数量，与哪些因素有关" class="headerlink" title="分配资源的数量，与哪些因素有关"></a>分配资源的数量，与哪些因素有关</h3><ol><li>原则一：单个SM核上分配的线程数（block*每个block具有的线程数）越大，线程级别的并行越大（前提与sm核实际运行的状况有关，需要想清楚）<ol><li>线程越多，warp越多，可运行的用来隐藏访存时间的warp就越多，因此就可以尽可能让GPU达到满负荷工作，不会由于访存延迟使得gpu空闲。</li></ol></li><li>原则二：单个SM核上的所有寄存器，平均分配给各个线程，因此，线程数量越多，单个线程可用的寄存器越少<ol><li>性能悬崖警惕：减少1/3的线程（并行度），仅仅让每一个线程增加了1个寄存器，除非由于寄存器不足导致了较大的访存开销，否则小心调整。</li></ol></li><li>原则三：对block的数量需要注意，尽量让每一个SM核上都具有多个block，这样子如果一个block在等待同步，可以启动另一个block<ol><li>需要知道SM核的数量</li></ol></li><li>原则五：『关于shared memory』<ol><li>shared memory按block分割，block过多可能会让单个block所具有的shared memory脱销</li></ol></li></ol><h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><p>对G80而言，与分配相关的参数可见：</p><p><img src="https://lh3.googleusercontent.com/-kTJQHo2890Y/XD2P6Ak0g2I/AAAAAAAANx4/HmgaxgQefeAXjfCrvVLuaHq1WeG4QGtAwCHMYCw/s0/Acrobat_2019-01-15_15-46-48.png" alt=""></p><p>有这样的一个情景，在每个block都含256个线程的情况下，一个SM核可能有以下两种情况：</p><p><img src="https://lh3.googleusercontent.com/-lbe-eNMWhP0/XD2PuXTO_aI/AAAAAAAANx0/Z0Grw8p5d0sLkhYhQM5eEafxGO_6aMF8ACHMYCw/s0/Acrobat_2019-01-15_15-46-01.png" alt=""></p><p>这里就可以发现，每个线程多了一个寄存器，但是带来的影响是，总的可以运行的线程的数量变为原来的2/3，也就是说，并行度是原来的2/3了。</p><p>这个可以给我一个启示：除非为了隐藏global memory访存延迟，否则尽可能不要为了增加寄存器数量而降低并行性。</p><h2 id="Kernel启动参数配置"><a href="#Kernel启动参数配置" class="headerlink" title="Kernel启动参数配置"></a>Kernel启动参数配置</h2><h3 id="需要确定以下参数"><a href="#需要确定以下参数" class="headerlink" title="需要确定以下参数"></a>需要确定以下参数</h3><ol><li><p>grid（block的数量）：主要看$\frac{blocks}{sm}$</p><ol><li>大于1：每个SM至少有一个block在执行</li><li>大于2：多个block可以在SM核上并发执行，如果一个block在等待同步，可以启动另一个block</li><li>大于100：对未来设备有很好的伸缩性</li></ol></li><li><p>block（thread的数量）</p><ol><li><p>块大小必须为32的倍数</p></li><li><p>warp尽可能多，隐藏延时</p></li><li><p>64,128,256 等等，试一下，经验成分比较多</p></li></ol></li></ol><h2 id="隐藏延时-相关计算"><a href="#隐藏延时-相关计算" class="headerlink" title="隐藏延时-相关计算"></a>隐藏延时-相关计算</h2><p>问题：需要使用多少个warp来隐藏某操作的延时，此时占用率多大？</p><blockquote><p>占用率：激活warp与最大可容纳warp数目的比值</p><p>最大warp数目: 32 in Tesla, 48 in Fermi</p></blockquote><h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><p><img src="https://lh3.googleusercontent.com/-_DlX9mCbLX8/XD2Sz8Y7WRI/AAAAAAAANyI/clacnlWedsAqyV5mozO0HiLdBlBAskVVwCHMYCw/s0/Acrobat_2019-01-15_15-59-11.png" alt=""></p><h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><p><img src="https://lh3.googleusercontent.com/-pgQYXjs0hrU/XD2S4yZQCiI/AAAAAAAANyM/rwa9BCsy02EMvIOUSQZmUg4dURBSj05LACHMYCw/s0/Acrobat_2019-01-15_15-59-31.png" alt=""></p><h2 id="数据预读"><a href="#数据预读" class="headerlink" title="数据预读"></a>数据预读</h2><blockquote><p>数据预读：在某global memroy变量的读操作，与该变量的实际使用语句之间，插入与该数据无关的独立指令，可以隐藏访存延迟</p></blockquote><p>例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> m = Md[i];</span><br><span class="line"><span class="keyword">float</span> f = a*b + c*d; <span class="comment">// 无关指令，隐藏访存延时</span></span><br><span class="line"><span class="keyword">float</span> f2 = m * f;</span><br></pre></td></tr></table></figure><h3 id="如何在矩阵乘法中使用预读操作进行优化"><a href="#如何在矩阵乘法中使用预读操作进行优化" class="headerlink" title="如何在矩阵乘法中使用预读操作进行优化"></a>如何在矩阵乘法中使用预读操作进行优化</h3><p>代码模板如下，</p><p>注意到中间的预读在计算点积前面，这样子中间的点积在运算时便可以隐藏预读内存产生的误差了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Load first tile into registers</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="comment">/* ... */</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// Deposit registers into shared memory</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Load next tile into registers</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Accumulate dot product</span></span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="指令吞吐量优化"><a href="#指令吞吐量优化" class="headerlink" title="指令吞吐量优化"></a>指令吞吐量优化</h2><p>了解每一种指令的吞吐量，减少使用昂贵的指令。</p><h3 id="一些指令的吞吐量"><a href="#一些指令的吞吐量" class="headerlink" title="一些指令的吞吐量"></a>一些指令的吞吐量</h3><table><thead><tr><th>int &amp; fp32</th><th>2 cycles</th></tr></thead><tbody><tr><td>fp64:</td><td>2 cycles</td></tr><tr><td>fp32 transendental</td><td>8 cycles</td></tr><tr><td>int devide/modulo</td><td>expensive</td></tr></tbody></table><blockquote><p>优化建议：</p><ol><li>与<code>2^n</code>运算，尽量使用位运算，如<code>&gt;&gt; n``&lt;&lt; n</code></li><li>在float常量中添加f，（缺省是double，会导致隐式的类型转换）</li></ol></blockquote><h3 id="数学函数的吞吐量提高"><a href="#数学函数的吞吐量提高" class="headerlink" title="数学函数的吞吐量提高"></a>数学函数的吞吐量提高</h3><ol><li>cuda中两种类型的运行时数学函数<ol><li>func()</li><li>__func()：使用硬件加速，SFU，精度低</li></ol></li><li><code>--use-fast-math</code>编译指令，强制使用硬件加速的数学函数</li></ol><h3 id="循环展开"><a href="#循环展开" class="headerlink" title="循环展开"></a>循环展开</h3><blockquote><p>原理：循环中除了循环体，还有更新计数器，判断条件，计算地址等指令，减少这些无关指令的运算可以加速</p></blockquote><p>例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k =<span class="number">0</span>;k &lt; <span class="number">16</span>;++k)</span><br><span class="line">&#123;</span><br><span class="line">Pvalue +=Ms[ty][k]*Ns[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这其中含有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2条浮点运算</span><br><span class="line">1条循环分支</span><br><span class="line">2条地址运算</span><br><span class="line">1条循环计数器自增</span><br></pre></td></tr></table></figure><p><strong>仅1/3是浮点计算！！！</strong></p><p>做以下改动：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Pvalue += </span><br><span class="line">    Ms[ty][<span class="number">0</span>] * Ns[<span class="number">0</span>][tx] + </span><br><span class="line">    Ms[ty][<span class="number">1</span>] * Ns[<span class="number">1</span>][tx] + </span><br><span class="line">    ...</span><br><span class="line">    Ms[ty][<span class="number">15</span>] * Ns[<span class="number">15</span>][tx];</span><br></pre></td></tr></table></figure><p>从而减少了循环分支，自增，同时地址运算也可以减少。</p><p>自动完成循环展开：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> unroll 16</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k =<span class="number">0</span>;k &lt; <span class="number">16</span>;++k)</span><br><span class="line">&#123;</span><br><span class="line">Pvalue +=Ms[ty][k]*Ns[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>由于展开能够消除分支以及一些管理归纳变量的代码，因此可以摊销一些分支开销。<br>展开可以积极调度（或管道化）循环以掩盖一些延迟。如果有足够的空闲寄存器使变量保持活动状态，因为通过展开相关性链展露了关键路径，这将非常有用。</p></blockquote><p>但</p><blockquote><p>展开过度或展开非常大的循环时，可能导致代码篇幅增加。如果展开后的循环不能再放入跟踪缓存 (TC)，这将有害无益。</p><p>展开循环体中包含分支的循环时，会增加对 BTB 容量的需求。如果展开后循环的迭代次数是 16 或更少，则分支预测应该能正确预测循环体中改变方向的分支。</p></blockquote><h2 id="课上提醒"><a href="#课上提醒" class="headerlink" title="课上提醒"></a>课上提醒</h2><ol><li>如果一整个warp没有指令要执行，不会占住SP，一上来就下去，但只要warp中有一个线程要执行，那就一定会占住SP</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习6-cuda优化&quot;&gt;&lt;a href=&quot;#HPC复习6-cuda优化&quot; class=&quot;headerlink&quot; title=&quot;HPC复习6-cuda优化&quot;&gt;&lt;/a&gt;HPC复习6-cuda优化&lt;/h1&gt;&lt;p&gt;在cuda程序的优化中，需要考虑以下几个问题&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;了解SM核中所提供的资源，并合理分配。&lt;/li&gt;
&lt;li&gt;确定kernel的启动参数，以尽可能提高cuda程序的性能。&lt;/li&gt;
&lt;li&gt;理解warp隐藏延时的作用，知道为什么warp越多越能隐藏延时。&lt;/li&gt;
&lt;li&gt;通过数据预读取隐藏访存延时。&lt;/li&gt;
&lt;li&gt;了解不同指令的吞吐量，并优化之。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.3-CUDA线程</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-3-CUDA%E7%BA%BF%E7%A8%8B/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-3-CUDA线程/</id>
    <published>2019-01-15T07:21:22.000Z</published>
    <updated>2019-01-17T07:19:21.240Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-3-CUDA线程"><a href="#HPC复习5-3-CUDA线程" class="headerlink" title="HPC复习5.3-CUDA线程"></a>HPC复习5.3-CUDA线程</h1><p>这里主要想想明白一个事：</p><p>已知的是，会有多个block，分配到SM核上来执行。</p><p>也知道，单一时间上，SM核仅有一个warp在运行。</p><p>问题是：</p><ol><li>SM核内部的结构是如何的？</li><li>warp的实际执行情况是如何的？</li><li>warp的并发执行是否会引发一些问题？如何解决？</li></ol><a id="more"></a><h2 id="SM核架构"><a href="#SM核架构" class="headerlink" title="SM核架构"></a>SM核架构</h2><p>对SM核的架构该如何理解？</p><ol><li>2个warp调度器与2个指令分派单元能够将2个warp同时进行发射和执行:</li><li>双warp调度器先选择两个warp，然后从每个warp发射一条指令到一个十六核心的组，或是十六个读写单元或是四个SFU。</li></ol><p><img src="figure/Acrobat_2019-01-15_15-18-20.png" alt=""></p><h2 id="Single-Warp"><a href="#Single-Warp" class="headerlink" title="Single Warp"></a>Single Warp</h2><p>对于单个warp内部的并行执行，可能会遇到以下的一些问题：</p><h3 id="单个warp上可能发生的访存冲突"><a href="#单个warp上可能发生的访存冲突" class="headerlink" title="单个warp上可能发生的访存冲突"></a>单个warp上可能发生的访存冲突</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (warpIdx == <span class="number">0</span>) &#123;</span><br><span class="line">    __shared__ <span class="keyword">int</span> v;</span><br><span class="line">    v = <span class="number">0</span>;</span><br><span class="line">    ++v;</span><br><span class="line">    v == ?</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>注意到share memory在一个block内是能够共享的，因此这一段代码由于会导致错误。</li><li>解决这一个问题可以使用<code>atomicAdd(&amp;v, 1);</code>来实现。</li><li>注意到CUDA不支持临界区。</li></ol><p><img src="https://lh3.googleusercontent.com/-nSO5ewSSqtw/XD15aShcuWI/AAAAAAAANvw/b4Vgwb5THG0NvN8vTR011C3KATyKXZ1IgCHMYCw/s0/Acrobat_2019-01-15_14-10-49.png" alt=""></p><h3 id="warp如何处理分支指令？"><a href="#warp如何处理分支指令？" class="headerlink" title="warp如何处理分支指令？"></a>warp如何处理分支指令？</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> warpIdx = threadIdx.x / <span class="number">32</span>;</span><br><span class="line"><span class="keyword">int</span> laneIdx = threadIdx.x % <span class="number">32</span>;</span><br><span class="line"><span class="keyword">if</span> (warpIdx == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (laneIdx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">    doA();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    doB();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>事实上，warp线程在执行上面代码的时候，图示可见如下：</p><p><img src="https://lh3.googleusercontent.com/-iMVFZM74Hxk/XD16kGp5FmI/AAAAAAAANv4/A4cKphyGtmAWbN00g02kvXHckXrIUbW8ACHMYCw/s0/Acrobat_2019-01-15_14-15-43.png" alt=""></p><ol><li>有很多branch的代码是低效的。</li><li>复杂的控制流，如break，continue，会导致代码低效，可能会出现bug。</li></ol><h3 id="Warp-functions"><a href="#Warp-functions" class="headerlink" title="Warp functions"></a>Warp functions</h3><ol><li><code>__all(predicate);</code><ol><li>return 1 if and only if predicate evaluates to non-zero for all of them.</li></ol></li><li><code>__any(predicate);</code><ol><li>return 1 if and only if predicate evaluates to non-zero for any of them.</li></ol></li><li><img src="https://lh3.googleusercontent.com/-vw2oRXY0li8/XD176bbVsSI/AAAAAAAANwE/YbZ0jpSYt-sFHT40WYokkHGAJeXx60SkACHMYCw/s0/Acrobat_2019-01-15_14-21-29.png" alt=""></li><li><code>__ballot(predicate);</code><ol><li>return an integer whose Nth bit is set if and only if predicate evaluates to non-zero for the Nth thread of the warp and the Nth thread is active.</li><li><img src="https://lh3.googleusercontent.com/-ueHU6gtByjg/XD18A5HFrwI/AAAAAAAANwI/p8mfYDejS8ch_4Uv6nWAmGBPhbzYTmPawCHMYCw/s0/Acrobat_2019-01-15_14-21-56.png" alt=""></li></ol></li></ol><h2 id="Multi-Warp"><a href="#Multi-Warp" class="headerlink" title="Multi Warp"></a>Multi Warp</h2><p>多个warp并发执行，可能会导致一些问题。</p><ol><li>多个warp之间的并发执行顺序不定，这会带来一些问题（联想：多线程可能会带来的问题）</li><li>warp内分支也可能会带来问题，导致性能损失。</li></ol><h3 id="warp之间无序的并发执行会带来哪些问题？"><a href="#warp之间无序的并发执行会带来哪些问题？" class="headerlink" title="warp之间无序的并发执行会带来哪些问题？"></a>warp之间无序的并发执行会带来哪些问题？</h3><ol><li>RaW（read after write）<ol><li>如果先写后读，由于后面读的时候，不知道其他warp写了没，可能会导致问题。</li><li><img src="https://lh3.googleusercontent.com/-uZj9SMP3wek/XD2FvMI87DI/AAAAAAAANwY/Q9uTD9MADB8MWDfVfsvAa2TUKIudidUWQCHMYCw/s0/Acrobat_2019-01-15_15-03-24.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-yt2kMUSQDq0/XD2FySx5pXI/AAAAAAAANwc/LeaX4scfJho6PhzfKyFJdsdAx5BbvfUrwCHMYCw/s0/Acrobat_2019-01-15_15-03-38.png" alt=""></li></ol></li><li>WaR（write after read）<ol><li>读后写，同样的写的时候，不知道前面读的值是否是最新的</li><li><img src="https://lh3.googleusercontent.com/-VJn672ZJxe8/XD2F4RJLBHI/AAAAAAAANwg/9y8nqyw1vE4Mge5Z4juJzuFSQK_7nu1FwCHMYCw/s0/Acrobat_2019-01-15_15-04-01.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-iV8FnRM_3eU/XD2F8DrVM9I/AAAAAAAANwk/Ym3R5o17uIMJglDNqYgX1uN--2SU0ikaQCHMYCw/s0/Acrobat_2019-01-15_15-04-17.png" alt=""></li></ol></li><li>WaW（write after write）<ol><li>写后写，同样的，不同的warp之间的写语句，可能运行的相对顺序不一样。</li><li><img src="https://lh3.googleusercontent.com/-yOpBk_JMEj4/XD2GCgXNvkI/AAAAAAAANws/C2i1Fn7EUSga1XeiHh0QbVy7RsPI_ck2ACHMYCw/s0/Acrobat_2019-01-15_15-04-42.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-b3Q1lYpBoVY/XD2GHe4prVI/AAAAAAAANww/iU36UTs-t5ARlM2uFWfZGrQFYgP2SCl2wCHMYCw/s0/Acrobat_2019-01-15_15-05-01.png" alt=""></li></ol></li><li>如何解决：使用<code>__syncthreads()</code>函数<ol><li><img src="https://lh3.googleusercontent.com/-iEnKp2ahX90/XD2GqKA7g6I/AAAAAAAANxA/1TkcMbml8LkK_9l9UVX-HesqNxjL-3O5gCHMYCw/s0/Acrobat_2019-01-15_15-07-20.png" alt=""></li></ol></li></ol><h3 id="branch如何影响多个warp运行的性能？"><a href="#branch如何影响多个warp运行的性能？" class="headerlink" title="branch如何影响多个warp运行的性能？"></a>branch如何影响多个warp运行的性能？</h3><p>对代码段：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (laneIdx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">doA();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">doB();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>结论：</p><ol><li>如果一个warp内的线程有的运行<code>doA</code>，有的运行<code>doB</code>，那么这一个warp必须两部分都运行</li><li>如果一个warp内的线程仅运行其中一个函数，那么该分支语句就不会带来影响</li></ol></li><li><p>以下分三种情况分别观察情况</p><ol><li>（warp-divergent）一个warp内，有的需要运行<code>doA</code>，有的需要运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-G68TmtaLlMA/XD2Hc6NgCPI/AAAAAAAANxM/VwoZls0KjzMr-s9XCHH451eYMx3XBRKVQCHMYCw/s0/Acrobat_2019-01-15_15-10-43.png" alt=""></li></ol></li><li>(warp-uniform)在同一个block内，有的warp运行<code>doA</code>，有的warp运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-1kdv3JnV8eg/XD2Hj5fN6JI/AAAAAAAANxQ/pLe-5ghYggQ70bhXCeU5ips2MG02p_8WwCHMYCw/s0/Acrobat_2019-01-15_15-11-11.png" alt=""></li></ol></li><li>(block-uniform)不同的block，有的block运行<code>doA</code>，有的block运行<code>doB</code><ol><li><img src="https://lh3.googleusercontent.com/-441QzpylRK0/XD2HowdmwLI/AAAAAAAANxU/0nkBL7fTwycSth6o5VV7swq4K9JT_RXUQCHMYCw/s0/Acrobat_2019-01-15_15-11-32.png" alt=""></li></ol></li><li>总结：block-uniform方式能够更好的减少性能损失</li></ol></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这幅图我觉得很好地将之前讲过的很多东西都联系了在一起，那就放上来慢慢观赏吧。</p><p><img src="https://lh3.googleusercontent.com/-8wO_TbAmW08/XD2IhLEAcTI/AAAAAAAANxg/vga83BRrlc4Nk8ebfYTnoOy1FLbJIA6zACHMYCw/s0/Acrobat_2019-01-15_15-15-16.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-3-CUDA线程&quot;&gt;&lt;a href=&quot;#HPC复习5-3-CUDA线程&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.3-CUDA线程&quot;&gt;&lt;/a&gt;HPC复习5.3-CUDA线程&lt;/h1&gt;&lt;p&gt;这里主要想想明白一个事：&lt;/p&gt;
&lt;p&gt;已知的是，会有多个block，分配到SM核上来执行。&lt;/p&gt;
&lt;p&gt;也知道，单一时间上，SM核仅有一个warp在运行。&lt;/p&gt;
&lt;p&gt;问题是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SM核内部的结构是如何的？&lt;/li&gt;
&lt;li&gt;warp的实际执行情况是如何的？&lt;/li&gt;
&lt;li&gt;warp的并发执行是否会引发一些问题？如何解决？&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.2-CUDA访存</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-2-CUDA%E8%AE%BF%E5%AD%98/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-2-CUDA访存/</id>
    <published>2019-01-15T05:30:18.000Z</published>
    <updated>2019-01-15T05:33:09.302Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-2-CUDA访存"><a href="#HPC复习5-2-CUDA访存" class="headerlink" title="HPC复习5.2-CUDA访存"></a>HPC复习5.2-CUDA访存</h1><p>这里就主要对cuda中的访存模式进行比较详细地说明吧。</p><ol><li>GPU中，5种不同存储部件的特性及使用方式</li><li>GPU中，如何使用合并访存加速</li><li>下图是GPU中的存储设备的大图</li></ol><p><img src="https://lh3.googleusercontent.com/-FME8Iu_B5cI/XD1D5vIEeaI/AAAAAAAANsE/9ObTV12e34ArBzh9o90oEjCsNBJ_X1LZQCHMYCw/s0/Acrobat_2019-01-15_10-22-29.png" alt=""></p><a id="more"></a><h2 id="GPU中的存储部件"><a href="#GPU中的存储部件" class="headerlink" title="GPU中的存储部件"></a>GPU中的存储部件</h2><h3 id="如何使用global-memory"><a href="#如何使用global-memory" class="headerlink" title="如何使用global memory?"></a>如何使用global memory?</h3><p>有两种方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="title">add4f</span><span class="params">(<span class="keyword">float</span>* u, <span class="keyword">float</span>* v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i=threadIdx.x;</span><br><span class="line">    u[i]+=v[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> hostU[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span> hostV[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span>* devU, devV;</span><br><span class="line">    <span class="keyword">size_t</span> size = <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*<span class="number">4</span>;</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;devU, size);</span><br><span class="line">    cudaMalloc(&amp;devV, size);</span><br><span class="line">    </span><br><span class="line">    cudaMemcpy(devU, hostU, size, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(devV, hostV, size, cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    add4f&lt;&lt;&lt;<span class="number">1</span>,<span class="number">4</span>&gt;&gt;&gt;(devU, devV);</span><br><span class="line">    cudaMemcpy(hostU, devU, size, cudaMemcpyDeviceToHost);</span><br><span class="line">    </span><br><span class="line">    cudaFree(devV);</span><br><span class="line">    cudaFree(devU);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二种方式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__device__ <span class="keyword">float</span> devU[<span class="number">4</span>];</span><br><span class="line">__device__ <span class="keyword">float</span> devV[<span class="number">4</span>];</span><br><span class="line">__<span class="function">global__ <span class="title">addUV</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i=threadIdx.x;</span><br><span class="line">    devU[i]+=devV[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> hostU[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">float</span> hostV[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">size_t</span> size = <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*<span class="number">4</span>;</span><br><span class="line">    cudaMemcpyToSymbol(devU, hostU, size, <span class="number">0</span>, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpyToSymbol(devV, hostV, size, <span class="number">0</span>, cudaMemcpyHostToDevice);</span><br><span class="line">    addUV&lt;&lt;&lt;<span class="number">1</span>,<span class="number">4</span>&gt;&gt;&gt;();</span><br><span class="line">    cudaMemcpyFromSymbol(hostU, devU, size, <span class="number">0</span>, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>一点点小疑问</p><p>cudaMemcpyToSymbol和cudaMemcpy的区别，可见<a href="https://blog.csdn.net/litdaguang/article/details/45047015" target="_blank" rel="noopener">link</a></p></blockquote><h3 id="如何使用constant-cache？该种存储空间有什么特点？"><a href="#如何使用constant-cache？该种存储空间有什么特点？" class="headerlink" title="如何使用constant cache？该种存储空间有什么特点？"></a>如何使用constant cache？该种存储空间有什么特点？</h3><ol><li><p>这样使用：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">__constant__ <span class="keyword">int</span> devVar</span><br><span class="line"></span><br><span class="line">cudaMemcpyToSymbol(</span><br><span class="line">    devVar, &amp;hostVar, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), <span class="number">0</span>,</span><br><span class="line">    cudaMemcpyHostToDevice</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cudaMemcpyFromSymbol(</span><br><span class="line">    &amp;hostVar, devVar, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), <span class="number">0</span>,</span><br><span class="line">    cudaMemcpyDeviceToHost</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>注意到，这种类型的使用，不需要显式的free</p></li></ol></li><li><p>constant cache的特点？</p><ol><li>空间大小上限为4KB</li><li>不依赖于threadIdx</li></ol></li></ol><h3 id="如何使用shared-memory？"><a href="#如何使用shared-memory？" class="headerlink" title="如何使用shared memory？"></a>如何使用shared memory？</h3><ol><li><p>有两种方式来使用：静态分配与动态分配</p><ol><li><p>静态分配如下设置：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="keyword">int</span> shArr[<span class="number">4</span>];</span><br></pre></td></tr></table></figure></li></ol></li><li><p>动态分配可以这样设置：</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="keyword">int</span> shArr[];</span><br><span class="line">kernel&lt;&lt;&lt;grid,block,<span class="keyword">sizeof</span>(<span class="keyword">int</span>)*<span class="number">4</span>&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure></li></ol></li></ol></li><li><p>这种memory 的特点？</p><ol><li><img src="https://lh3.googleusercontent.com/-0wOJ6oyRp14/XD1KCIF0C8I/AAAAAAAANsQ/Q44B4ty6zoce_X5HtgdGZDs48e8oKGE6wCHMYCw/s0/Acrobat_2019-01-15_10-48-40.png" alt=""></li><li>L1cache与shared Memory共用一块存储空间（直接说明速度很快）</li><li>大小有限制</li></ol></li></ol><h3 id="什么是local-memory？在什么情况下变量会存在local-memory中？"><a href="#什么是local-memory？在什么情况下变量会存在local-memory中？" class="headerlink" title="什么是local memory？在什么情况下变量会存在local memory中？"></a>什么是local memory？在什么情况下变量会存在local memory中？</h3><ol><li>local memory是线程中某些变量存储的空间，实质上是global memory中分配给线程的一块内存空间。<ol><li>实质上就是global memory</li></ol></li><li>local memory的特点：<ol><li>线程内私有</li><li>速度很慢（在global memory中）</li></ol></li><li>在这些情况下变量会存在local memory而不存在寄存器中<ol><li>当单个线程中的寄存器不够用的情况下，需要使用local memory存储变量。<ol><li>需要了解单个线程中能够使用的寄存器数量。</li><li><img src="https://lh3.googleusercontent.com/-qquc9S_qCr0/XD1LBKycwvI/AAAAAAAANsc/0QbLFST183gUhJI2FWFgp_d42NWb0dZxACHMYCw/s0/Acrobat_2019-01-15_10-52-52.png" alt=""></li></ol></li><li>如果变量使用到了地址，变量就会存在local memory中。<ol><li><img src="https://lh3.googleusercontent.com/-ZWqsNGN9Kn4/XD1LTH5bTjI/AAAAAAAANso/p4HIh0AdS_ktdH3vwk9rnbb0AAMcY294gCHMYCw/s0/Acrobat_2019-01-15_10-54-05.png" alt=""></li></ol></li><li>使用了递归函数，寄存器显然不够用，当然也会使用local memory</li></ol></li></ol><h3 id="texture-cache"><a href="#texture-cache" class="headerlink" title="texture cache"></a>texture cache</h3><p>TODO:</p><p>对这个没有什么兴趣，就先不看吧。</p><h2 id="GPU中的存储访问模式"><a href="#GPU中的存储访问模式" class="headerlink" title="GPU中的存储访问模式"></a>GPU中的存储访问模式</h2><p>问题：怎样的存储访问模式，效率更高？</p><h3 id="如何确定访问过程中对Global-Memory的访问长度"><a href="#如何确定访问过程中对Global-Memory的访问长度" class="headerlink" title="如何确定访问过程中对Global Memory的访问长度"></a>如何确定访问过程中对Global Memory的访问长度</h3><ol><li><p>基于这样的特性：</p><ol><li>对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节</li></ol></li><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>找出最小编号活动线程寻址的存储器片段。段的长度由线程访问的字的长度决定：</span><br><span class="line">    * <span class="number">1</span>字节的字<span class="number">32</span>字节</span><br><span class="line">    * <span class="number">2</span>字节的字<span class="number">64</span>字节</span><br><span class="line">    * <span class="number">4</span>，<span class="number">8</span>，<span class="number">16</span>字节的字<span class="number">128</span>字节</span><br><span class="line"><span class="number">2.</span>找出其它地址在同一段内的活动线程</span><br><span class="line"><span class="number">3.</span>减小事务长度，如果可能：</span><br><span class="line">    * 如果事务是<span class="number">128</span>字节且只有下半部分或上半部分被使用，减小事务到<span class="number">64</span>字节；</span><br><span class="line">    * 如果事务是<span class="number">64</span>字节（原始的或者从<span class="number">128</span>字节减小后的）且只有上半部分或下</span><br><span class="line"><span class="number">4.</span>执行事务且标记已访问数据的线程为非活动的。</span><br></pre></td></tr></table></figure></li></ol><h3 id="Global-Memory中，怎样访存效率更高？"><a href="#Global-Memory中，怎样访存效率更高？" class="headerlink" title="Global Memory中，怎样访存效率更高？"></a>Global Memory中，怎样访存效率更高？</h3><ol><li>cuda访存的特性<ol><li>对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节</li></ol></li><li>根据特性，判断不同访存方式的效率区别(<ol><li>图中例子为：遍历访问数组的32个int元素（32*Bytes=128Bytes）。</li><li>对齐且顺序：<ol><li><img src="https://lh3.googleusercontent.com/-hivZZjGGfi8/XD1PT_H5jRI/AAAAAAAANtA/Jyp5zvfIxyou6Epbh3d0XFTV0Fta6mDCgCHMYCw/s0/Acrobat_2019-01-15_11-11-11.png" alt=""></li></ol></li><li>对齐，但交叉次序访问，注意到对该情况的优化在不同的计算能力下不同。<ol><li>发现1.0的时候，完全不支持交叉次序访问的并行<ol><li>每个int读取一次，32次读取每次读取单位为32B</li></ol></li><li><img src="https://lh3.googleusercontent.com/-8do7xPatAfQ/XD1PgsjTPuI/AAAAAAAANtE/ywf_tP6vUiYlChN0xGN1pzx99kevZeBbQCHMYCw/s0/Acrobat_2019-01-15_11-12-02.png" alt=""></li></ol></li><li>未对齐，但顺序访问<ol><li><img src="https://lh3.googleusercontent.com/-UDvD96XD-Vw/XD1Qa2WOBBI/AAAAAAAANtQ/KiFbNr6zvto_TO4hnaahHwZpzwSHEISxACHMYCw/s0/Acrobat_2019-01-15_11-15-55.png" alt=""></li><li><img src="https://lh3.googleusercontent.com/-wuvaBvFBL04/XD1ST3z6tkI/AAAAAAAANts/LLtskN0255wkfZopm6VnnbL2EvdgPm_iQCHMYCw/s0/Acrobat_2019-01-15_11-23-58.png" alt=""></li></ol></li><li>即使对齐了，但是如果乘上一个系数<ol><li><img src="https://lh3.googleusercontent.com/-yGL6OLkxFsA/XD1QfeEWqFI/AAAAAAAANtU/3xmBtQvVAxMfOlW-EA_UxqEoiWl0aKA2ACHMYCw/s0/Acrobat_2019-01-15_11-16-14.png" alt=""></li></ol></li><li>随机访问<ol><li><img src="https://lh3.googleusercontent.com/-rCGJm6lllIs/XD1Qrdz7GbI/AAAAAAAANtc/EyEVB2TTgko4nkQ0ciJ35v3VjZfYNNE7wCHMYCw/s0/Acrobat_2019-01-15_11-17-01.png" alt=""></li></ol></li></ol></li><li>结论：尽可能对齐且顺序访问</li></ol><h3 id="Constant-Memory中，如何访存效率更高？"><a href="#Constant-Memory中，如何访存效率更高？" class="headerlink" title="Constant Memory中，如何访存效率更高？"></a>Constant Memory中，如何访存效率更高？</h3><ol><li>特点：<ol><li>片外存储器，速度虽然比shared满，但是具有缓存</li><li>只读</li><li>无需考虑冲突问题</li></ol></li><li>访问优化：<ol><li>关键：如果half-warp中的线程访问的不是同一个地址，那么各个线程的访问将会串行化。<img src="https://lh3.googleusercontent.com/-yYJUOX-zNgk/XD1TgLgRnyI/AAAAAAAANt4/jB6R5v6BWuA3RcIbegH_yCq33uPjxdJPACHMYCw/s0/Acrobat_2019-01-15_11-29-05.png" alt=""></li><li>例子：<img src="https://lh3.googleusercontent.com/-cXQbxBAYxWA/XD1TdHGWvJI/AAAAAAAANt0/i-ImhB4Jn98B3IPZObx9llbtihPgvRZdQCHMYCw/s0/Acrobat_2019-01-15_11-28-52.png" alt=""></li></ol></li></ol><h3 id="Shared-Memory中如何访存效率更高？"><a href="#Shared-Memory中如何访存效率更高？" class="headerlink" title="Shared Memory中如何访存效率更高？"></a>Shared Memory中如何访存效率更高？</h3><ol><li><p>特点：</p><ol><li>速度极快（毕竟在L1 cache上）</li><li>如果发生bank冲突，可能会使访存串行化</li></ol></li><li><p>shared memory的硬件结构特点与bank</p><ol><li>参考下图<ol><li>线性编址</li></ol></li><li>（以下图为例的话），地址<code>0008</code>，<code>0048</code>，<code>0088</code>在同一个bank上，无法在一个时钟周期内访问，必须串行访问。例如下图：同一个时间里，half-warp发出的访存请求，如果访问同一个bank上的地址，会导致访存串行化<ol><li><img src="https://lh3.googleusercontent.com/-SA4qmGTqTyM/XD1VSMTUETI/AAAAAAAANuI/FDzh1lkWp04cF8K-eT_yKmE2CKOI3K7xQCHMYCw/s0/Acrobat_2019-01-15_11-36-35.png" alt=""></li></ol></li><li>地址<code>0000</code>，<code>0004</code>，<code>0008</code>，等，在同一个bank上，多个线程可以在同一个时钟周期访问，因此实现了并行访存<ol><li><img src="https://lh3.googleusercontent.com/-Njk-efGNx5M/XD1Vb6wjVtI/AAAAAAAANuM/G6tcHtm7i8cz0KITIjuWuOOH07q2eGaBQCHMYCw/s0/Acrobat_2019-01-15_11-37-17.png" alt=""></li></ol></li></ol></li><li><p>关键优化需要特性</p><ol><li>一个half-warp中的线程，在没有发生bank冲突的情况下，可以在一个时钟周期内访问16个不同的地址。</li><li>一个half-warp中的所有线程如果都访问同一个地址，通过广播机制，可以在同一个时钟周期内完成访问。<img src="https://lh3.googleusercontent.com/-whTB6O25Bz8/XD1Ww8ozsKI/AAAAAAAANuc/I7fX9lzV3ioWMGs93a3-w3-P51tgUgalACHMYCw/s0/Acrobat_2019-01-15_11-42-59.png" alt=""></li></ol></li><li><p>访存例子：</p><ol><li><p><code>v = arr[ threadIdx.x ]</code></p><ol><li>连续的16个元素可以通过一个时钟周期一次访问。</li><li><img src="https://lh3.googleusercontent.com/-d7AP5GuL2ns/XD1YgQ30h5I/AAAAAAAANuo/jGCLvbPigYQHcNE9eJ2h9mMBS9b5K3IJQCHMYCw/s0/Acrobat_2019-01-15_11-50-25.png" alt=""></li></ol></li><li><p><code>v = arr[ threadIdx.x+2 ]</code></p><ol><li>没有发生bank冲突，连续的16个值依然可以通过一个时钟周期一次完成访问。</li><li><img src="https://lh3.googleusercontent.com/-NwTzxZl9Nbc/XD1YsH6m5WI/AAAAAAAANus/fAW7EWnFt2EaKdavF_-lrcCNJ5AFqi1IgCHMYCw/s0/Acrobat_2019-01-15_11-51-13.png" alt=""></li></ol></li><li><code>v = arr[2*threadIdx.x]</code>      <ol><li>连续的16个值，前8个可以一次访问，后8个由于与前8个发生了bank冲突，需要等到下一个时钟周期，需要两个时钟周期</li><li><img src="https://lh3.googleusercontent.com/-XH1ZOdJzB4Y/XD1ZBpizwpI/AAAAAAAANu4/WX7e_gTepj8a7_sWcTEKN69YVmUgWUwjwCHMYCw/s0/Acrobat_2019-01-15_11-52-39.png" alt=""></li></ol></li><li><code>v = arr2[threadIdx.x].x</code><ol><li>注意到arr2数组是由int2类型的结构体（int x, int y）组成的，因此在实际访存中，这个语句有着与上面那个类似的效果。</li><li><img src="https://lh3.googleusercontent.com/-PSr-FTdqRlw/XD1Zqeo80mI/AAAAAAAANvA/HyZcNu2u-mM5N_8ugMuuqYKzpFGKejdhACHMYCw/s0/Acrobat_2019-01-15_11-55-21.png" alt=""></li></ol></li><li><code>v = arr[3*threadIdx.x]</code><ol><li>发现很神奇的是，乘上3，就不会发生冲突了。<ol><li>(3与16互素，x $\in [0,15]$是16的一个剩余系，那么3*x能够遍历16的剩余系)</li></ol></li><li><img src="https://lh3.googleusercontent.com/-UBKhzjGNwco/XD1Z2oL1nZI/AAAAAAAANvE/ZIoh-iVj6ms5LXzrq_jD8Dj1IuzuxXQhwCHMYCw/s0/Acrobat_2019-01-15_11-56-10.png" alt=""></li></ol></li><li><code>v = arr[random]</code><ol><li><img src="https://lh3.googleusercontent.com/-_YfC9QLNbVA/XD1rxZMXNII/AAAAAAAANvY/kp120Lh9CnMiCuAP-wbwn44bSi_QYiVywCHMYCw/s0/Acrobat_2019-01-15_13-12-36.png" alt=""></li></ol></li></ol></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://lh3.googleusercontent.com/-hXWKX0lEAvM/XD1wcULablI/AAAAAAAANvk/auzOo_Af5dAKzdR5htukmRwdnKq15TYyQCHMYCw/s0/Acrobat_2019-01-15_13-32-33.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-2-CUDA访存&quot;&gt;&lt;a href=&quot;#HPC复习5-2-CUDA访存&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.2-CUDA访存&quot;&gt;&lt;/a&gt;HPC复习5.2-CUDA访存&lt;/h1&gt;&lt;p&gt;这里就主要对cuda中的访存模式进行比较详细地说明吧。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;GPU中，5种不同存储部件的特性及使用方式&lt;/li&gt;
&lt;li&gt;GPU中，如何使用合并访存加速&lt;/li&gt;
&lt;li&gt;下图是GPU中的存储设备的大图&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-FME8Iu_B5cI/XD1D5vIEeaI/AAAAAAAANsE/9ObTV12e34ArBzh9o90oEjCsNBJ_X1LZQCHMYCw/s0/Acrobat_2019-01-15_10-22-29.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习5.1-CUDA基础</title>
    <link href="https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-1-CUDA%E5%9F%BA%E7%A1%80/"/>
    <id>https://wwyf.github.io/2019/01/15/2019-01-2019-01-15-高性能计算基础-复习5-1-CUDA基础/</id>
    <published>2019-01-15T02:03:26.000Z</published>
    <updated>2019-01-15T02:04:25.938Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习5-1-CUDA基础"><a href="#HPC复习5-1-CUDA基础" class="headerlink" title="HPC复习5.1-CUDA基础"></a>HPC复习5.1-CUDA基础</h1><p>复习了一下cuda，主要以自问自答的方式，整理了一下知识点。</p><ol><li>相关背景：前言</li><li>逻辑上的cuda架构大概是怎样的？</li><li>gpu上实际的硬件情况</li><li>cuda架构与硬件之间的关系</li><li>一个简单实例：矩阵相乘的简单实现</li></ol><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="为什么需要gpu？"><a href="#为什么需要gpu？" class="headerlink" title="为什么需要gpu？"></a>为什么需要gpu？</h3><ol><li>CPU处理能力不断强大，但在进入3D时代后，人们发现庞大的3D图像处理数据计算使得CPU越来越不堪重荷，并且远远超出其计算能力；</li><li>图形计算需求日益增多，作为计算机的显示芯片也飞速发展。图形，图像计算等计算的功能被脱离出来，单独设计为一块芯片——GPU （也就是显卡）。</li></ol><h3 id="gpu与cpu的主要区别在？"><a href="#gpu与cpu的主要区别在？" class="headerlink" title="gpu与cpu的主要区别在？"></a>gpu与cpu的主要区别在？</h3><ol><li>gpu采用了大量的执行单元，并且一个控制单元可以同时控制多个执行单元进行计算，实现类似于SIMD的加速。</li><li><img src="https://lh3.googleusercontent.com/-U6dLqQSsc_U/XD0vGdcz0oI/AAAAAAAANqg/skeMgQgw4NMZnsCU87OTm8bNWqoBnac0ACHMYCw/s0/Acrobat_2019-01-15_08-53-44.png" alt=""></li></ol><h3 id="cuda是什么？"><a href="#cuda是什么？" class="headerlink" title="cuda是什么？"></a>cuda是什么？</h3><ol><li>是一种专门针对GPU的开发工具，可以使用类C语言进行通用计算。</li><li>用于编写host+device异构并行C应用程序</li><li><img src="https://lh3.googleusercontent.com/-FlqXBhfrtAQ/XD0vjzixC7I/AAAAAAAANqo/F_57eojX4nAF3CnPqXjbN-gl2nDc0mk0wCHMYCw/s0/Acrobat_2019-01-15_08-55-43.png" alt=""></li></ol><h2 id="CUDA-架构（逻辑上）"><a href="#CUDA-架构（逻辑上）" class="headerlink" title="CUDA 架构（逻辑上）"></a>CUDA 架构（逻辑上）</h2><h3 id="CUDA中线程的组织方式？"><a href="#CUDA中线程的组织方式？" class="headerlink" title="CUDA中线程的组织方式？"></a>CUDA中线程的组织方式？</h3><ol><li>三级：Grid-Block-Thread<ol><li>Thread ：单个线程，是并行的基本单位</li><li>Block：互相合作的线程组</li><li>Grid：一组Block</li></ol></li><li>需要关注到，一个kernel对应一个Grid</li><li><img src="https://lh3.googleusercontent.com/-4LwbA1Aj2MQ/XD0v2jCDuHI/AAAAAAAANq0/64pcOu7Onqc837_4Q79DnfvvoSzWXocaQCHMYCw/s0/Acrobat_2019-01-15_08-56-58.png" alt=""></li></ol><h3 id="CUDA中的访存模式？"><a href="#CUDA中的访存模式？" class="headerlink" title="CUDA中的访存模式？"></a>CUDA中的访存模式？</h3><p>线程可以访问以下空间</p><ol><li>以线程为单位的<ol><li>线程有内部的<strong>寄存器</strong></li><li>在寄存器不够用的情况下，可以在<strong>Global Memory</strong>中申请一块内存空间作为<strong>Local Memory</strong></li></ol></li><li>以Block为单位的<ol><li>单个block中的线程共享<strong>Shared Memory</strong></li></ol></li><li>以Grid为单位的<ol><li>一个Grid中的所有线程共享<strong>Glocal Memory</strong></li><li>特殊的，一个Grid中的所有线程共享<strong>只读的</strong> <strong>constant memory</strong>(常量存储器),<strong>texture memory</strong>(纹理存储器)</li></ol></li><li>图示如下：<img src="https://lh3.googleusercontent.com/-7Id_bAjJjD4/XD0xXYp4HTI/AAAAAAAANrA/g7kkEfzz_Zgxa6JaHZhGRdDckKAqbXEfACHMYCw/s0/Acrobat_2019-01-15_09-03-24.png" alt=""></li></ol><h2 id="cuda与硬件的关系"><a href="#cuda与硬件的关系" class="headerlink" title="cuda与硬件的关系"></a>cuda与硬件的关系</h2><h3 id="cuda中有哪些硬件？是如何组织的？"><a href="#cuda中有哪些硬件？是如何组织的？" class="headerlink" title="cuda中有哪些硬件？是如何组织的？"></a>cuda中有哪些硬件？是如何组织的？</h3><p>由低到高分别是：</p><ol><li>SP：流处理器</li><li>SM：流多处理器</li><li>TPC：线程处理集群</li><li>SPA：流处理器阵列</li></ol><p><img src="https://lh3.googleusercontent.com/-qmYboKb3JQM/XD0xsCp_K6I/AAAAAAAANrI/Hkgu4X-fusoYYnf2q3B-DWv1BcjVEPLYQCHMYCw/s0/Acrobat_2019-01-15_09-04-49.png" alt=""></p><h3 id="cuda架构与实际硬件的关系？"><a href="#cuda架构与实际硬件的关系？" class="headerlink" title="cuda架构与实际硬件的关系？"></a>cuda架构与实际硬件的关系？</h3><ol><li>Grid：运行在SPA上</li><li>Block的执行方式：<ol><li>一般的cuda应用程序具有多个Block组成的线程组，这些Block会分配到多个SM核上分别执行。</li><li>怎么分配？见下图：<img src="https://lh3.googleusercontent.com/-Plh4mq88QdE/XD0y2ywS9aI/AAAAAAAANrU/w50XC5epme4HVSkv4vKG0C-aRc06ujnmwCHMYCw/s0/Acrobat_2019-01-15_09-09-46.png" alt=""></li><li>注意到这里的分配，会受到以下两个限制的影响：<ol><li>一个SM核上分配的Blcok数量是有限制，G80中的SM核最多8个block</li><li>G80中的SM核最多768个线程。</li></ol></li></ol></li><li>SM核上具有多个Block需要运行后，这些线程更具体的，是如何执行的呢？<ol><li>一个SM核上的多个Block，每个block会分成多个Warp（32个线程）</li><li>这些Warp会在SM核上并发地执行，由于一个Warp有32个线程，而一个SM核上仅有8个SP，因此一个Warp运行4个Clock cycles</li></ol></li></ol><h3 id="Warp的调度具有开销吗？"><a href="#Warp的调度具有开销吗？" class="headerlink" title="Warp的调度具有开销吗？"></a>Warp的调度具有开销吗？</h3><ol><li>（联想）cpu中的硬件多线程之间的调度是几乎没有开销的，原因？是因为CPU中已经有了多个可以用于存储线程context的区域，每次调度切换线程的时候，切换context是在CPU硬件内完成的，不是由操作系统完成的，不需要访存，因此几乎0开销。</li><li>GPU中的warp调度，类似的，也是0开销的。</li></ol><h3 id="怎样的Warp会被调度出来执行？"><a href="#怎样的Warp会被调度出来执行？" class="headerlink" title="怎样的Warp会被调度出来执行？"></a>怎样的Warp会被调度出来执行？</h3><ol><li>很明显的，每一个时刻，都会有很多个Warp在等待被GPU调度执行，那么问题是：满足什么条件的Warp，会被调度出来执行？<ol><li>Warp中没有线程被阻塞的（如访存等）</li><li>合适的Warp挑出来优先执行。</li></ol></li></ol><h3 id="为什么要设计成warp的并发执行？"><a href="#为什么要设计成warp的并发执行？" class="headerlink" title="为什么要设计成warp的并发执行？"></a>为什么要设计成warp的并发执行？</h3><ol><li>结论：Warp的并发执行，能够很好的隐藏访存时间（原理类似于cpu中的硬件多线程）</li><li>简单例子：<ol><li><img src="https://lh3.googleusercontent.com/-M9QwhzmB0pI/XD02cA_ftZI/AAAAAAAANrg/NpkbQH9Eo2I7kq1FcXk2uzkxt10DuWbUgCHMYCw/s0/Acrobat_2019-01-15_09-25-04.png" alt=""></li><li>上图中，一个单位长度为一个warp的执行（实际上其实是4个时钟周期，这里简化成了1个）。</li><li>可以发现，每当一个Warp由于访存阻塞了，GPU会马上从调度其他可用的Warp来执行，从而保证GPU中的计算负载保持在100%，这个Warp的访存时间就被别的Warp的执行隐藏掉了</li></ol></li><li>复杂例子：如何计算完全隐藏访存时间所需要的Warp的数量。<ol><li>假设：<ol><li>运行一次一个Warp中的所有线程需要4个clock cycles</li><li>每n个指令需要一次全局内存访问（200个时钟周期）</li></ol></li><li>解答：<ol><li>假设每个指令都需要访存，访存的这一段时间里，可以使用$200/4=50$个warp的执行来隐藏。<ol><li>隐藏假设：单个Warp一次运行仅使用了4个clock cycles就被阻塞了</li></ol></li><li>由于是每n个指令访存一次，因此实际上，单个warp执行了$4*n$后才会被阻塞</li><li>因此，需要$200/(4*n)+1$个warp。</li></ol></li></ol></li></ol><h3 id="SM核上具有的存储空间及分配情况？"><a href="#SM核上具有的存储空间及分配情况？" class="headerlink" title="SM核上具有的存储空间及分配情况？"></a>SM核上具有的存储空间及分配情况？</h3><ol><li>SM核上拥有16KB的shared memory(有些GPU是48KB)</li><li>基于前面，一个SM核上分配多个Block的前提<ol><li>多个block分享一个SM核上的shared memory。</li></ol></li><li>由于单个block可能会要求shared memory至少多大，而一个SM核上的shared memory是有限制的，所以，block要看情况，不能分配太多，不然shared memory就不够用了。<ol><li>Shared Memory也会限制Block的分配</li></ol></li></ol><h2 id="cuda的软件接口"><a href="#cuda的软件接口" class="headerlink" title="cuda的软件接口"></a>cuda的软件接口</h2><p>写了这么多，终于写到要写一个真正的cuda程序了。</p><h3 id="cuda编程中的函数声明"><a href="#cuda编程中的函数声明" class="headerlink" title="cuda编程中的函数声明"></a>cuda编程中的函数声明</h3><ol><li>在cuda编程中，当然既要写在gpu上运行的函数又要写在cpu上运行的函数了，那么如何区分呢？</li><li><img src="https://lh3.googleusercontent.com/-Frw4biWiTdw/XD063lkpXrI/AAAAAAAANrs/2FySYbhR3EsgK3TcHH6cPOlsy7x_zxzTQCHMYCw/s0/Acrobat_2019-01-15_09-43-58.png" alt=""></li><li>好吧，之前我没有好好想<code>__device__</code>还有<code>__global__</code>的区别，所以这里要特地给自己强调一下。</li></ol><h3 id="cuda中的5个内建设备变量"><a href="#cuda中的5个内建设备变量" class="headerlink" title="cuda中的5个内建设备变量"></a>cuda中的5个内建设备变量</h3><ol><li><code>gridDim</code></li><li><code>blockDim</code></li><li><code>blockIdx</code></li><li><code>threadIdx</code></li><li><code>warpSize</code></li></ol><h3 id="cuda中的各种各样的内存操作"><a href="#cuda中的各种各样的内存操作" class="headerlink" title="cuda中的各种各样的内存操作"></a>cuda中的各种各样的内存操作</h3><p><code>cudaMemcpy(void * dst, void * src, size_t nbytes, enum cudaMemcpyType direction);</code></p><p><code>cudaMalloc</code></p><p><code>cudaFree</code></p><h3 id="cuda中的同步操作"><a href="#cuda中的同步操作" class="headerlink" title="cuda中的同步操作"></a>cuda中的同步操作</h3><p><code>__syncThreads()</code>：同步一个block里面的所有线程，作用相当于一个Barrier</p><h2 id="实例：very-simple的矩阵相乘"><a href="#实例：very-simple的矩阵相乘" class="headerlink" title="实例：very simple的矩阵相乘"></a>实例：very simple的矩阵相乘</h2><p>可以看我的<a href="https://gitee.com/wwyf/class_hpc/blob/master/e6/code/multi.cu" target="_blank" rel="noopener">git仓库</a>（我具体的实现可能没有这么naive）</p><p>具体思路是：</p><p><img src="https://lh3.googleusercontent.com/-3jJ-qYk5SD8/XD09D8JLBTI/AAAAAAAANr4/HjWn0Aj36A4S0xuZEoZ70EqhyJ6waYYGwCHMYCw/s0/Acrobat_2019-01-15_09-53-19.png" alt=""></p><p>对该程序优化的思考</p><ol><li>性能问题：<ol><li>每计算一次，访问两次内存（如从矩阵Md中取一个数，以及从Nd中取一个数，然后只做了一次加法）</li><li>访存限制</li></ol></li><li>矩阵的大小受到一个block大小的限制。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习5-1-CUDA基础&quot;&gt;&lt;a href=&quot;#HPC复习5-1-CUDA基础&quot; class=&quot;headerlink&quot; title=&quot;HPC复习5.1-CUDA基础&quot;&gt;&lt;/a&gt;HPC复习5.1-CUDA基础&lt;/h1&gt;&lt;p&gt;复习了一下cuda，主要以自问自答的方式，整理了一下知识点。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;相关背景：前言&lt;/li&gt;
&lt;li&gt;逻辑上的cuda架构大概是怎样的？&lt;/li&gt;
&lt;li&gt;gpu上实际的硬件情况&lt;/li&gt;
&lt;li&gt;cuda架构与硬件之间的关系&lt;/li&gt;
&lt;li&gt;一个简单实例：矩阵相乘的简单实现&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习3-pthread</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A03-pthread/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习3-pthread/</id>
    <published>2019-01-14T13:38:29.000Z</published>
    <updated>2019-01-16T01:15:19.718Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习3-pthread"><a href="#HPC复习3-pthread" class="headerlink" title="HPC复习3-pthread"></a>HPC复习3-pthread</h1><p><a href="https://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html" target="_blank" rel="noopener">toturial</a></p><p>这里是高性能计算课程-pthread部分的复习笔记，大概会有以下内容：</p><ol><li>pthread中的hello,world</li><li>pthread中的临界区</li><li>忙等待</li><li>互斥量</li><li>生产者-消费者同步与信号量</li><li>实现路障</li><li>读写锁与链表</li><li>pthread中的缓存一致性</li></ol><a id="more"></a><h2 id="进程、线程和pthread"><a href="#进程、线程和pthread" class="headerlink" title="进程、线程和pthread"></a>进程、线程和pthread</h2><ol><li>pthread:一种共享内存编程模型</li></ol><h2 id="Hello-world"><a href="#Hello-world" class="headerlink" title="Hello,world"></a>Hello,world</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">print_message_function</span><span class="params">( <span class="keyword">void</span> *ptr )</span></span>;</span><br><span class="line"></span><br><span class="line">main()</span><br><span class="line">&#123;</span><br><span class="line">     <span class="keyword">pthread_t</span> thread1, thread2;</span><br><span class="line">     <span class="keyword">char</span> *message1 = <span class="string">"Thread 1"</span>;</span><br><span class="line">     <span class="keyword">char</span> *message2 = <span class="string">"Thread 2"</span>;</span><br><span class="line">     <span class="keyword">int</span>  iret1, iret2;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Create independent threads each of which will execute function */</span></span><br><span class="line"></span><br><span class="line">     iret1 = pthread_create( &amp;thread1, <span class="literal">NULL</span>, print_message_function, (<span class="keyword">void</span>*) message1);</span><br><span class="line">     iret2 = pthread_create( &amp;thread2, <span class="literal">NULL</span>, print_message_function, (<span class="keyword">void</span>*) message2);</span><br><span class="line"></span><br><span class="line">     <span class="comment">/* Wait till threads are complete before main continues. Unless we  */</span></span><br><span class="line">     <span class="comment">/* wait we run the risk of executing an exit which will terminate   */</span></span><br><span class="line">     <span class="comment">/* the process and all threads before the threads have completed.   */</span></span><br><span class="line"></span><br><span class="line">     pthread_join( thread1, <span class="literal">NULL</span>);</span><br><span class="line">     pthread_join( thread2, <span class="literal">NULL</span>); </span><br><span class="line"></span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Thread 1 returns: %d\n"</span>,iret1);</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Thread 2 returns: %d\n"</span>,iret2);</span><br><span class="line">     <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">print_message_function</span><span class="params">( <span class="keyword">void</span> *ptr )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="keyword">char</span> *message;</span><br><span class="line">     message = (<span class="keyword">char</span> *) ptr;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"%s \n"</span>, message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="pthread中的临界区"><a href="#pthread中的临界区" class="headerlink" title="pthread中的临界区"></a>pthread中的临界区</h2><ol><li>课本上使用多个线程并行计算$\pi$会出问题<ol><li>多个线程尝试更新同一个共享变量时，会出问题。</li></ol></li><li>多个线程尝试更新一个共享资源，结果可能是无法预测的，这些访问可能会导致某种错误，我们称之为<strong>竞争条件</strong></li><li><strong>临界区</strong>：更新共享资源的代码段</li></ol><h2 id="忙等待"><a href="#忙等待" class="headerlink" title="忙等待"></a>忙等待</h2><ol><li>可以使用忙等待实现“严格按照线程号，单个线程进入临界区”。</li><li>注意，可能会由于发生了编译优化导致该忙等待失效（该忙等待语句可能会调度到其他指令前后）<ol><li>可以通过<code>volitile</code>关键字来解决</li></ol></li><li>缺点：<ol><li>忙等待：浪费CPU周期</li></ol></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initialize</span></span><br><span class="line">flag = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// .... some code</span></span><br><span class="line"><span class="keyword">while</span>(flag != my_rank);</span><br><span class="line"><span class="comment">// critical area</span></span><br><span class="line">flag = (flag + <span class="number">1</span>)% thread_count;<span class="comment">// 保证在所有进程都已到达后，flag恢复成0</span></span><br></pre></td></tr></table></figure><h2 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h2><ol><li>改善忙等待的缺点：互斥量，互斥锁</li><li>设计函数接口<ol><li><code>pthread_mutex_init( pthread_mutex_t *, const pthread_mutexattr_t *)</code></li><li><code>int pthread_mutex_destroy(pthread_mutex_t* )</code></li><li><code>int pthread_mutex_lock(pthread_mutex_t *)</code></li><li><code>int pthread_mutex_unlock(pthread_mutex_t *)</code></li></ol></li></ol><h2 id="生产者-消费者同步和信号量"><a href="#生产者-消费者同步和信号量" class="headerlink" title="生产者-消费者同步和信号量"></a>生产者-消费者同步和信号量</h2><p>TODO:</p><h2 id="路障和条件变量"><a href="#路障和条件变量" class="headerlink" title="路障和条件变量"></a>路障和条件变量</h2><ol><li><p>问题：如何保证所有线程在程序中处于同一位置来同步线程（即实现路障）</p></li><li><p>忙等待和互斥量实现路障</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> counter;</span><br><span class="line"><span class="keyword">int</span> thread_count;</span><br><span class="line"><span class="keyword">pthread_mutex_t</span> barier_mutex;</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> * <span class="title">Threa_word</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    pthread_mutex_lock(&amp;barier_mutex);</span><br><span class="line">    counter++；</span><br><span class="line">    pthread_mutex_unlock(&amp;barrier_mutex);</span><br><span class="line">    <span class="keyword">while</span>(counter &lt; thread_count);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>信号量实现路障</p><ol><li><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> counter;</span><br><span class="line"><span class="keyword">sem_t</span> count_sem;</span><br><span class="line"><span class="keyword">sem_t</span> barrier_sem;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">Thread_work</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    <span class="comment">// 先获得计数器的信号量</span></span><br><span class="line">    sem_wait(&amp;count_sem);</span><br><span class="line">    <span class="keyword">if</span> (counter == thread_count<span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="comment">// 最后一个到达路障的线程负责初始化counter以及释放其他线程</span></span><br><span class="line">        counter = <span class="number">0</span>;</span><br><span class="line">        sem_post(&amp;count_sem);</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; thread_count<span class="number">-1</span>; j++)</span><br><span class="line">            sem_post(&amp;barrier_sem);</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        counter++;</span><br><span class="line">        sem_postq(&amp;count_sem);</span><br><span class="line">        sem_wait(&amp;barrier_sem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>该路障的重用可能会导致竞争条件</p></li></ol></li><li><p>使用条件变量实现路障</p><ol><li><p>条件变量是：允许线程在某个特定条件或事前发生前都处于挂起状态。当事件发生时，另一个线程可以通过信号来唤醒挂起的线程。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> * <span class="title">Thread_work</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ....</span><br><span class="line">    <span class="comment">/* barrier */</span></span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    counter++;</span><br><span class="line">    <span class="keyword">if</span> (counter == thread_count)&#123;</span><br><span class="line">        counter = <span class="number">0</span>;</span><br><span class="line">        pthread_cond_broadcast(&amp;cond_var);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">while</span>(pthread_cond_wait(&amp;cond_var, &amp;mutex) != <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);    </span><br><span class="line">    ....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol><h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>使用读写锁，实现多线程共享的链表怎么实现？不难。</p><p><img src="https://lh3.googleusercontent.com/-jm61UeXUUc4/XD6AbNTejpI/AAAAAAAAN2k/AHGevmv9O5kY5oRH6DnqEail-W6a8NiIgCHMYCw/s0/Acrobat_2019-01-16_08-53-00.png" alt=""></p><p>一个结论：在Insert，Delete操作十分少的时候，使用读写锁的性能更好。</p><p><img src="https://lh3.googleusercontent.com/-BgLlpcl5A-k/XD6ATQaRnAI/AAAAAAAAN2g/DlvaYc1Cp5kLj6O4rNPIOQtAL_rVe-nigCHMYCw/s0/Acrobat_2019-01-16_08-52-27.png" alt=""></p><h2 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h2><p>书本拿了矩阵-向量乘法的例子，说明了缓存对程序性能的影响</p><ol><li>对于8*8000000的矩阵，伪共享带来了很大的影响<ol><li>关键：$y[0]-y[7]$在同一个缓存行中</li></ol></li></ol><p><img src="https://lh3.googleusercontent.com/-LJMIfdNhooo/XDyQgxv4XJI/AAAAAAAANqI/8lBb1o5SPBUV1Gn6uK0sRuGp0bH87hCJQCHMYCw/s0/Typora_2019-01-14_21-37-07.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习3-pthread&quot;&gt;&lt;a href=&quot;#HPC复习3-pthread&quot; class=&quot;headerlink&quot; title=&quot;HPC复习3-pthread&quot;&gt;&lt;/a&gt;HPC复习3-pthread&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.cs.cmu.edu/afs/cs/academic/class/15492-f07/www/pthreads.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;toturial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里是高性能计算课程-pthread部分的复习笔记，大概会有以下内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pthread中的hello,world&lt;/li&gt;
&lt;li&gt;pthread中的临界区&lt;/li&gt;
&lt;li&gt;忙等待&lt;/li&gt;
&lt;li&gt;互斥量&lt;/li&gt;
&lt;li&gt;生产者-消费者同步与信号量&lt;/li&gt;
&lt;li&gt;实现路障&lt;/li&gt;
&lt;li&gt;读写锁与链表&lt;/li&gt;
&lt;li&gt;pthread中的缓存一致性&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习2-MPI</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A02-MPI/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习2-MPI/</id>
    <published>2019-01-14T12:26:23.000Z</published>
    <updated>2019-01-14T13:39:25.530Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习2-MPI"><a href="#HPC复习2-MPI" class="headerlink" title="HPC复习2-MPI"></a>HPC复习2-MPI</h1><p><a href="https://www.open-mpi.org/doc/current/" target="_blank" rel="noopener">OpenMPI 官方文档</a></p><p><a href="http://www.mpich.org/static/docs/latest/" target="_blank" rel="noopener">mpich官方文档</a></p><p>这里是高性能计算课程-MPI部分的复习笔记，大概会有以下内容：</p><ol><li>MPI中的Hello world</li><li>常见的MPI函数</li><li>使用MPI实现梯形积分法</li><li>中级：MPI中的集合通信</li><li>中级：MPI中的派生数据类型</li><li>中级：MPI中的计时方法</li><li>算法：奇偶并行排序算法</li><li>算法：并行正则采样排序</li></ol><a id="more"></a><h2 id="MPI中的hello-world"><a href="#MPI中的hello-world" class="headerlink" title="MPI中的hello world"></a>MPI中的hello world</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_STRING = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> greeting[MAX_STRING];</span><br><span class="line">    <span class="keyword">int</span> comm_sz;</span><br><span class="line">    <span class="keyword">int</span> my_rank;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Initialize the MPI environment</span></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">// Get the number of processes</span></span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line">    <span class="comment">// Get the rank of the process</span></span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (my_rank != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">sprintf</span>(greeting, <span class="string">"Greetings from process %d of %d!"</span>, my_rank, comm_sz);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Hello world from ank %d\n"</span>,my_rank);</span><br><span class="line">        MPI_Send(</span><br><span class="line">            greeting,</span><br><span class="line">            <span class="comment">// strlen(greeting)+1,</span></span><br><span class="line">            <span class="comment">// strlen(greeting),</span></span><br><span class="line">            MAX_STRING,</span><br><span class="line">            MPI_CHAR,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            <span class="number">0</span>,</span><br><span class="line">            MPI_COMM_WORLD</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Greetings from process %d of %d!\n"</span>, my_rank, comm_sz);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> q = <span class="number">1</span>; q &lt; comm_sz; q++)&#123;</span><br><span class="line">            MPI_Recv(</span><br><span class="line">                greeting,</span><br><span class="line">                MAX_STRING,</span><br><span class="line">                MPI_CHAR,</span><br><span class="line">                q,</span><br><span class="line">                <span class="number">0</span>,</span><br><span class="line">                MPI_COMM_WORLD,</span><br><span class="line">                MPI_STATUS_IGNORE</span><br><span class="line">            );</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%s in %d\n"</span>, greeting, my_rank);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Finalize the MPI environment.</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见的MPI函数"><a href="#常见的MPI函数" class="headerlink" title="常见的MPI函数"></a>常见的MPI函数</h2><p>这6个MPI函数，可以完成一切任务</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Init</span><span class="params">(<span class="keyword">int</span> *argc, <span class="keyword">char</span> **argv[])</span></span>;</span><br><span class="line"><span class="comment">// 进入MPI环境并完成所有的初始化工作</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Finalize</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="comment">// 从MPI环境中退出</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_rank</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *rank)</span></span>;</span><br><span class="line"><span class="comment">// 获得当前进程在指定通信域中的编号</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_size</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *size)</span></span>;</span><br><span class="line"><span class="comment">// 获得指定通信域中的进程数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> dest, <span class="keyword">int</span> tag, MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 发送消息到目标进程</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Recv</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> source, <span class="keyword">int</span> tag, MPI_Comm comm,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Status * status_p</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 从指定进程接受一个消息</span></span></span><br></pre></td></tr></table></figure><h2 id="使用MPI实现梯形积分法"><a href="#使用MPI实现梯形积分法" class="headerlink" title="使用MPI实现梯形积分法"></a>使用MPI实现梯形积分法</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 对这一个函数进行积分</span></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">f</span><span class="params">(<span class="keyword">double</span> x)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x*x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">Trap</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> left_endpt,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> right_endpt,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> trap_count,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> base_len</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="comment">/**</span></span></span><br><span class="line"><span class="function"><span class="comment"> * @brief 梯形积分法的串行实现</span></span></span><br><span class="line"><span class="function"><span class="comment"> * </span></span></span><br><span class="line"><span class="function"><span class="comment"> * @param base_len 就是left_endpt与right_endpt之间分成trap_count份后，每一份的长度</span></span></span><br><span class="line"><span class="function"><span class="comment"> * </span></span></span><br><span class="line"><span class="function"><span class="comment"> */</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> estimate, x;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    estimate = (f(left_endpt) + f(right_endpt))/<span class="number">2.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= trap_count<span class="number">-1</span>; i++)&#123;</span><br><span class="line">        x = left_endpt + i*base_len;</span><br><span class="line">        estimate += f(x);</span><br><span class="line">    &#125;</span><br><span class="line">    estimate = estimate*base_len;</span><br><span class="line">    <span class="keyword">return</span> estimate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Get_input</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> my_rank,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> comm_sz,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> * a_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">double</span> * b_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>* n_p</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> dest;</span><br><span class="line">    <span class="keyword">if</span> (my_rank == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Enter a,b,and n\n"</span>);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%lf %lf %d"</span>, a_p, b_p, n_p);</span><br><span class="line">        <span class="keyword">for</span> (dest = <span class="number">1</span>; dest &lt; comm_sz; dest++)&#123;</span><br><span class="line">            MPI_Send(a_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(b_p, <span class="number">1</span>, MPI_DOUBLE, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">            MPI_Send(n_p, <span class="number">1</span>, MPI_INT, dest, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        MPI_Recv(a_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(b_p, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">        MPI_Recv(n_p, <span class="number">1</span>, MPI_INT, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD,MPI_STATUS_IGNORE);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"in trap %lf, %lf, %d\n"</span>, *a_p, *b_p, *n_p);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> my_rank, comm_sz, n=<span class="number">1024</span>, local_n;</span><br><span class="line">    <span class="keyword">double</span> a = <span class="number">0.0</span>, b = <span class="number">3.0</span>, h, local_a, local_b;</span><br><span class="line">    <span class="keyword">double</span> local_int, total_int;</span><br><span class="line">    <span class="keyword">int</span> source;</span><br><span class="line"></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz);</span><br><span class="line"></span><br><span class="line">    Get_input(my_rank, comm_sz, &amp;a, &amp;b, &amp;n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"in main %lf, %lf, %d\n"</span>, a, b, n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">    <span class="comment">// 将积分区间分成n份</span></span><br><span class="line">    h = (b-a)/n;</span><br><span class="line">    <span class="comment">// 将n分区间，分到comm_sz个进程里，每个进程分到local_n个区间</span></span><br><span class="line">    local_n = n/comm_sz;</span><br><span class="line"></span><br><span class="line">    local_a = a+my_rank*local_n*h;</span><br><span class="line">    local_b = local_a+local_n*h;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> DEBUG</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"local_a : %lf, local_b : %lf, local_n : %d"</span>, local_a, local_b, local_n);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// DEBUG</span></span></span><br><span class="line">    local_int = Trap(local_a, local_b, local_n, h);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (my_rank != <span class="number">0</span>)&#123;</span><br><span class="line">        MPI_Send(&amp;local_int, <span class="number">1</span>, MPI_DOUBLE, <span class="number">0</span>, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        total_int = local_int;</span><br><span class="line">        <span class="keyword">for</span> (source = <span class="number">1</span>; source &lt; comm_sz; source++)&#123;</span><br><span class="line">            MPI_Recv(&amp;local_int, <span class="number">1</span>, MPI_DOUBLE, source, <span class="number">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">            total_int += local_int;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(my_rank == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"With n = %d trapezoids, out estimate\n"</span>, n);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"of the integral from %f to %f = %.15e\n"</span>,a,b,total_int);</span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的阻塞与非阻塞通信"><a href="#中级：MPI中的阻塞与非阻塞通信" class="headerlink" title="中级：MPI中的阻塞与非阻塞通信"></a>中级：MPI中的阻塞与非阻塞通信</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MPI_Send</span><br><span class="line"><span class="comment">// normal send</span></span><br><span class="line">MPI_Isend</span><br><span class="line"><span class="comment">// begin a nonblocking send</span></span><br><span class="line">MPI_Ssend</span><br><span class="line"><span class="comment">// Blocking synchronous send</span></span><br><span class="line"></span><br><span class="line">MPI_Bsend</span><br><span class="line"><span class="comment">// send message wich user-provided buffering</span></span><br><span class="line">MPI_Issend</span><br><span class="line"><span class="comment">// Starts a nonblocking synchronous send</span></span><br><span class="line">MPI_Ibsend</span><br><span class="line"><span class="comment">// Starts a nonblocking buffered send</span></span><br><span class="line">MPI_Rsend</span><br><span class="line"><span class="comment">// Blocking ready send</span></span><br><span class="line">MPI_Irsend</span><br><span class="line"><span class="comment">// Starts a nonblocking ready send</span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Irecv</span><br><span class="line"><span class="comment">// Begins a nonblocking receive</span></span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的集合通信"><a href="#中级：MPI中的集合通信" class="headerlink" title="中级：MPI中的集合通信"></a>中级：MPI中的集合通信</h2><p>涉及通信子中所有进程的通信函数成为集合通信（与点对点通信区分开）</p><p>MPI中的集合通信，在树中介绍的主要有以下几个函数：</p><table><thead><tr><th>函数名</th><th>作用</th></tr></thead><tbody><tr><td>MPI_Reduce</td><td>归约（可以用来求和等等,支持交换律和结合律的运算）</td></tr><tr><td>MPI_Allreduce</td><td>所有进程都可以得到全局求和的结果</td></tr><tr><td>MPI_Bcast</td><td>广播，顾名思义</td></tr><tr><td>MPI_Scatter</td><td>0号进程读入整个向量，但只将分量发送给需要分量的其他进程</td></tr><tr><td>MPI_Gather</td><td>将其他进程的分量都收集到0号进程</td></tr><tr><td>MPI_Allgather</td><td>将每个进程desend_buf_p内容串联起来，存储到每个进程的recv_buf_p参数中</td></tr></tbody></table><p>下面一个一个函数分别说明其参数情况。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Reduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Op op,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allreduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Op op,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Bcast</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buffer, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Scatter</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Gather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allgather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="keyword">void</span> *sendbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> sendcount,  <span class="comment">// local_n</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *recvbuf, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> recvcount, <span class="comment">// local_n</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recvtype, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure><h2 id="中级：MPI中的派生数据类型"><a href="#中级：MPI中的派生数据类型" class="headerlink" title="中级：MPI中的派生数据类型"></a>中级：MPI中的派生数据类型</h2><blockquote><p>在MPI中，通过同时存储数据项的类型以及他们在内存中的相对位置，派生数据类型可以表示内存中数据项的任意集合。</p></blockquote><p>在书本中，派生数据类型用在了，减少通信量上。</p><p>一般创建一个新的派生数据类型，需要进行以下的步骤：</p><ol><li>调用<code>MPI_Type_create_struct</code>函数，创建派生数据类型<ol><li>可使用<code>MPI_Get_address</code>辅助得到相对地址</li></ol></li><li>调用<code>MPI_Type_commit</code>函数，允许MPI实现为了在通信函数内使用这一数据类型，优化数据类型的内部表示</li><li>使用结束后，调用<code>MPI_Type_free</code>函数释放额外的存储空间</li></ol><h3 id="函数原型"><a href="#函数原型" class="headerlink" title="函数原型"></a>函数原型</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_create_struct</span><span class="params">(<span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> <span class="keyword">int</span> array_of_blocklengths[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> MPI_Aint array_of_displacements[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">const</span> MPI_Datatype array_of_types[],</span></span></span><br><span class="line"><span class="function"><span class="params">                           MPI_Datatype * newtype</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_commit</span><span class="params">(MPI_Datatype * datatype_p)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_free</span><span class="params">(MPI_Datatype * datatype)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p><img src="https://lh3.googleusercontent.com/-ZQmKH0alUZ4/XDx4AZvqyiI/AAAAAAAANps/UnqSTxTMGJ4OO2Nq86kZFBMXJCN_YKBEQCHMYCw/s0/Acrobat_2019-01-14_19-52-35.png" alt=""></p><h2 id="中级：MPI中的计时方法"><a href="#中级：MPI中的计时方法" class="headerlink" title="中级：MPI中的计时方法"></a>中级：MPI中的计时方法</h2><ol><li><code>MPI_Wtime</code></li><li><code>MPI_Barrier</code></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MPI_Barrier(comm);</span><br><span class="line">local_start = MPI_Wtime();</span><br><span class="line"></span><br><span class="line">....</span><br><span class="line">    </span><br><span class="line">local_finish = MPI_Wtime();</span><br><span class="line">local_elapsed = local_finish - local_start;</span><br></pre></td></tr></table></figure><h2 id="算法：并行奇偶交换排序"><a href="#算法：并行奇偶交换排序" class="headerlink" title="算法：并行奇偶交换排序"></a>算法：并行奇偶交换排序</h2><h3 id="奇偶交换排序"><a href="#奇偶交换排序" class="headerlink" title="奇偶交换排序"></a>奇偶交换排序</h3><p>关键思想：去耦的比较-交换</p><ol><li>偶数阶段：以下数对进行比较-交换<ol><li>$(a[0], a[1]), (a[2],a[3]), (a[4],a[5]),…$</li></ol></li><li>奇数阶段：以下数对进行比较-交换<ol><li>$(a[1], a[2]), (a[3],a[4]), (a[5],a[6]),…$</li></ol></li><li>定理：n个值的列表，经过n个阶段后，该列表一定能够排好序。</li></ol><h3 id="并行化"><a href="#并行化" class="headerlink" title="并行化"></a>并行化</h3><p>步骤：</p><ol><li>将数据分到不同的进程之后，先本地进行一个qsort排个序</li><li>偶数阶段：进程0,1，进程2,3进行比较-交换数据</li><li>奇数阶段：进程1,2， 进程3,4进行比较-交换数据</li></ol><p><img src="https://lh3.googleusercontent.com/-eZA5pXZnybQ/XDx7VnZQdDI/AAAAAAAANp4/DVSafASPAYgRV2LWJXEz1F-a4z06JGiHQCHMYCw/s0/Acrobat_2019-01-14_20-06-48.png" alt=""></p><h2 id="算法：并行正则采样排序"><a href="#算法：并行正则采样排序" class="headerlink" title="算法：并行正则采样排序"></a>算法：并行正则采样排序</h2><ol><li>数据初始化阶段：每个进程根据进程号与数据量，计算得到本进程所读取的数据范围，并从文件中直接读取。由于读取数据的步骤不需要进行通信分发，提高了程序运行的效率。</li><li>每一个进程对其本地的无序数据,长度为$local_n$的$local_buffer$数组进行串行快速排序，从而在每个处理器上都得到一个有序的序列$local_buffer$。</li><li>在每一个处理器上选取代表元素：每一个处理器从局部有序序列中选取第$w$，第$2<em>w$，第$3</em>w$,第$(comm_sz-1)w$共$p-1$个代表元素，其中$w=comm_sz/(p*p)$。</li><li>进程0收集每一个进程中得到的代表元素，从而具有了$(p-1)<em>(p-1)$个代表元素，然后进程0对所有代表元素进行排序，选取第$comm_sz-1$，第$2</em>(comm_sz-1)$，第$3<em>(comm_sz-1)\ \cdots (comm_sz-1)</em>(comm_sz-1)$个元素，这$comm_sz-1$个元素作为主元。</li><li>进程0将上一步中得到的$comm_sz-1$个主元$pivot_values$，分发到其余所有处理器上。</li><li>局部有序序列划分：每一个处理器根据这$comm_sz-1$个主元，将本地的$local_buffer$划分成$comm_sz$段。</li><li>有序序列的分发：在上一个步骤中的$comm_sz$段序列中，每一个处理器将本地的第$i$段发送给第$i$个处理器，最终处理器$i$拥有所有处理器的第$i$段。</li><li>最终排序：每个处理器对上一步中得到的$comm_sz$段有序序列进行排序，即为最终结果。</li></ol><h2 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h2><h3 id="向量求和"><a href="#向量求和" class="headerlink" title="向量求和"></a>向量求和</h3><ol><li>块划分:简单的将连续N个分量所构成的块，分配到每个进程中。</li><li>循环划分:采用轮转的方式去分配向量分量</li><li>块-循环划分:用一个循环来分发向量分量所构成的块，而不是分发单个向量分量。</li></ol><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol><li>在什么场景下必须使用消息标签？<ol><li><img src="https://lh3.googleusercontent.com/-ac7MTJh3T3s/XDxVtBXjiPI/AAAAAAAANpI/VWRc8sgUPlIUJBJHvgJjXZCqcIUp9PzJgCHMYCw/s0/Acrobat_2019-01-14_17-26-13.png" alt=""></li><li>这段代码打算传送A的前32个字节进入X,传送B的前16个字节进入Y.但是,如果消息B尽管后发送但先到达进程Q,就会被第一个recv()接收在X中，使用标签就可以避免这种情况</li><li><img src="https://lh3.googleusercontent.com/-9IwMxoVBf2k/XDxV13-N1SI/AAAAAAAANpM/rZe2IYt1JLIzwqtUtfsiS1QiGPCRFt_qgCHMYCw/s0/Acrobat_2019-01-14_17-26-49.png" alt=""></li></ol></li><li>MPI_Send与MPI_Recv的问题<ol><li>Send的精确行为是由MPI实现决定的，MPI_Send可能有不同大小的缓冲区，在发送消息的时候，是使用缓冲区，还是直接阻塞等待发送完成，由“消息截止大小”决定。</li><li>启示：了解实际执行情况，不要做假设。</li></ol></li><li>关于MPI_Reduce调用顺序<ol><li><img src="https://lh3.googleusercontent.com/-yu7mVk_1EZE/XDxuhZnZycI/AAAAAAAANpg/6efvirvvmQc1TStPAXBgC2ryDgv-cMwHgCHMYCw/s0/Acrobat_2019-01-14_19-12-06.png" alt=""></li><li>内存单元的名字与MPI_Reduce的调用匹配无关，函数调用的顺序决定了匹配方式。</li><li>！！不可预测，可能b中存储的值将是$1+2+1=4$，而d中为$2+1+2=5$</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习2-MPI&quot;&gt;&lt;a href=&quot;#HPC复习2-MPI&quot; class=&quot;headerlink&quot; title=&quot;HPC复习2-MPI&quot;&gt;&lt;/a&gt;HPC复习2-MPI&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.open-mpi.org/doc/current/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;OpenMPI 官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.mpich.org/static/docs/latest/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;mpich官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里是高性能计算课程-MPI部分的复习笔记，大概会有以下内容：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MPI中的Hello world&lt;/li&gt;
&lt;li&gt;常见的MPI函数&lt;/li&gt;
&lt;li&gt;使用MPI实现梯形积分法&lt;/li&gt;
&lt;li&gt;中级：MPI中的集合通信&lt;/li&gt;
&lt;li&gt;中级：MPI中的派生数据类型&lt;/li&gt;
&lt;li&gt;中级：MPI中的计时方法&lt;/li&gt;
&lt;li&gt;算法：奇偶并行排序算法&lt;/li&gt;
&lt;li&gt;算法：并行正则采样排序&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>高性能计算基础-复习1-并行硬件与并行软件</title>
    <link href="https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A01-%E5%B9%B6%E8%A1%8C%E7%A1%AC%E4%BB%B6%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%BD%AF%E4%BB%B6/"/>
    <id>https://wwyf.github.io/2019/01/14/2019-01-2019-01-14-高性能计算基础-复习1-并行硬件与并行软件/</id>
    <published>2019-01-14T08:33:45.000Z</published>
    <updated>2019-01-15T05:38:38.926Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="HPC复习1-并行硬件与并行软件"><a href="#HPC复习1-并行硬件与并行软件" class="headerlink" title="HPC复习1-并行硬件与并行软件"></a>HPC复习1-并行硬件与并行软件</h1><p>主要分为四部分：</p><ol><li>背景介绍</li><li>超算硬件</li><li>超算软件</li><li>编写并行程序</li></ol><a id="more"></a><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><ol><li>冯·诺依曼结构</li><li>进程、多任务和线程</li><li>冯·诺依曼结构的发展</li></ol><h3 id="冯·诺依曼结构"><a href="#冯·诺依曼结构" class="headerlink" title="冯·诺依曼结构"></a>冯·诺依曼结构</h3><ol><li>包括主存，中央处理单元（控制单元，算术逻辑单元ALU），以及主存和CPU之间的互连结构</li><li>冯若依曼瓶颈：主存和CPU之间的分离</li></ol><p><img src="https://lh3.googleusercontent.com/-1a3WDll47y4/XDw4ZfJw_RI/AAAAAAAANnw/o5l-qRgC4zwyRuVTEYDXURYwzhuJsKPHQCHMYCw/s0/Acrobat_2019-01-14_15-21-10.png" alt=""></p><h3 id="进程、多任务和线程"><a href="#进程、多任务和线程" class="headerlink" title="进程、多任务和线程"></a>进程、多任务和线程</h3><ol><li><strong>进程</strong>：是运行着的程序的一个实例</li><li><strong>多任务</strong>：对同时运行多个程序的支持，可真并行，也可时间片轮转</li></ol><h3 id="冯诺依曼结构的发展"><a href="#冯诺依曼结构的发展" class="headerlink" title="冯诺依曼结构的发展"></a>冯诺依曼结构的发展</h3><ol><li>高速缓存：<ol><li>是一片读写极快但是空间很小的存储区域</li><li>根据程序执行与数据访问行为的局部性，存储部分数据</li><li>目的：让数据存取的速度适应CPU的处理速度（简而言之就是加快存取速度）</li><li><img src="https://lh3.googleusercontent.com/-ng0exR_kQ68/XDw66GtmfJI/AAAAAAAANn8/FXjZR74AmNI-Jm1AZjYJ4MMw34-zdtOPwCHMYCw/s0/Acrobat_2019-01-14_15-31-52.png" alt=""></li></ol></li><li>虚拟内存<ol><li>是一种内存管理技术</li><li>解决：所需内存超过物理内存下程序无法执行的问题，以及其他直接使用物理内存可能带来的问题</li></ol></li><li>指令集并行：单处理器上的细粒度并行<ol><li>流水线技术</li><li>多发射技术</li></ol></li><li>硬件多线程<ol><li>在处理器中多开辟几仹线程状态，当线程发生切换时，处理器切换到对应的线程状态执行，在瞬间即可完成，这种方式叫做硬件多线程</li><li>多种粒度的硬件多线程，可以了解一下<ol><li>粗粒度：遇到长时间中断，切换线程</li><li>细粒度：逐个CPU周期轮流切换线程</li><li>同时多线程：多个线程的指令能够被同时发射</li><li><img src="https://lh3.googleusercontent.com/-N8o9Xm48f08/XDw73TB4n_I/AAAAAAAANoE/jIAbyujdxncxl4hMJo7yPu8y_Ptch8fzQCHMYCw/s0/Acrobat_2019-01-14_15-35-58.png" alt=""></li></ol></li></ol></li></ol><h2 id="超算硬件"><a href="#超算硬件" class="headerlink" title="超算硬件"></a>超算硬件</h2><p>主要有以下内容：</p><ol><li>两类并行系统：SIMD，MIMD</li><li>互联网络</li><li>缓存一致性</li></ol><h3 id="两类并行系统"><a href="#两类并行系统" class="headerlink" title="两类并行系统"></a>两类并行系统</h3><ol><li>Flynn 分类法<ol><li>根据指令流和数据流的概念对计算机的体系结构进行分类</li><li><img src="https://lh3.googleusercontent.com/-VqI58B-Y0RA/XDw8xAmCI7I/AAAAAAAANoQ/O9qHhKvwSMsZfN3gFs6CzSaKEyQmLNPfACHMYCw/s0/Acrobat_2019-01-14_15-39-48.png" alt=""></li></ol></li><li>SIMD 与MIMD 的最大区别<ol><li>SMID 使用一个控制器来控制多个处理器，而MIMD系统使用多个控制器异步地控制多个处理器</li><li>SIMD 中所有进程/线程执行完全相同的指令操作，而MIMD系统使用不同进程/线程执行不同的指令</li></ol></li><li>MIMD<ol><li>共享内存<ol><li>UMA结构（Uniform Memory Access）</li><li>NUMA结构（Non-Uniform Memory Access）</li><li>COMA结构（Cache-only Memory Access）</li></ol></li><li>分布内存</li></ol></li></ol><h3 id="互联网络"><a href="#互联网络" class="headerlink" title="互联网络"></a>互联网络</h3><ol><li>互联网络是：连接所有节点组成并行计算机的高速网络</li><li>两种互联网络：<ol><li>共享内存的互联网络（CPU通过互联网络与所需的Memory相连）<ol><li>总线（Buses）</li><li>交叉开关（Crossbars）</li></ol></li><li>分布内存的互联网络<ol><li>直接互联网络（两个节点直接相连）<ol><li>环</li><li>环绕网络</li><li>超立方</li></ol></li><li>间接互联网络（由开关网络负责处理节点之间的相连）<ol><li>交叉开关（Crossbars）</li><li>$\Omega$ 网络</li></ol></li></ol></li></ol></li><li>参数：<ol><li>延迟：是消息源开始収送消息到消息目的地接收到第一个字节的时间段。</li><li>带宽：是消息目的地接收第一个字节开始到完成数据接收，接收数据的速率。</li><li>理解：使用水龙头出水的时间来理解<ol><li>延迟：打开水龙头到出水的时延</li><li>带宽：水龙头口的大小</li></ol></li></ol></li></ol><h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><ol><li>概念<ol><li>指在含有多个Cache的并行系统中，数据的多个副本（因为没有同步更新）而造成的丌一致问题。</li></ol></li><li>更新缓存所需协议（二选一）<ol><li>写无效策略</li><li>写更新策略</li></ol></li><li>缓存一致性协议（二选一）<ol><li>监听总线协议</li><li>基于目录的协议</li></ol></li><li>伪共享<ol><li>现象：两个处理器上的线程，分别读取的两个不同的变量在同一个cache line里。</li><li><img src="https://lh3.googleusercontent.com/-KiiHq4K34Go/XDxANFBQAyI/AAAAAAAANoc/coRh3XIr92o-DRICB9c8857nFRItevs6gCHMYCw/s0/Acrobat_2019-01-14_15-54-29.png" alt=""></li></ol></li></ol><h2 id="超算软件"><a href="#超算软件" class="headerlink" title="超算软件"></a>超算软件</h2><p>主要有以下内容：</p><ol><li>共享内存如何协调？</li><li>分布内存如何协调？</li><li>混合编程</li></ol><h3 id="协调共享内存"><a href="#协调共享内存" class="headerlink" title="协调共享内存"></a>协调共享内存</h3><ol><li>动态线程，静态线程</li><li>不确定性</li><li>需要使用一些方法解决不确定性<ol><li>互斥锁</li><li>忙碌等待</li><li>信号量</li><li>等等</li></ol></li><li>线程安全<ol><li>代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。</li><li>例子：<code>strtok</code>函数</li></ol></li></ol><h3 id="协调分布内存"><a href="#协调分布内存" class="headerlink" title="协调分布内存"></a>协调分布内存</h3><ol><li>消息传递<ol><li><img src="https://lh3.googleusercontent.com/-qwebtN8Zvrg/XDxCVtr7avI/AAAAAAAANoo/8SFS1EwYUroyKg8HGGtJxk1UOGVZizb7wCHMYCw/s0/Acrobat_2019-01-14_16-03-35.png" alt=""></li></ol></li><li>单向通信（或称 远程内存访问）<ol><li>消息传递中，一个进程必须调用一个发送函数，并且必须与另一个进程调用的接受函数相匹配</li><li>问题：任何通信都需要两个进程的显式参与</li><li>解决：单向通信中，单个进程调用一个函数，可从其他进程中得到对应的值来更新局部内存，或者使用自己的值更新远端内存。这种通信，只需要一个进程的参与计科。</li><li><img src="https://lh3.googleusercontent.com/-jN2bOlWAYro/XDxC7MdwgiI/AAAAAAAANow/V0-wOHcfsGskmxmjA9dhv1j-Ve7vz3_TwCHMYCw/s0/Acrobat_2019-01-14_16-06-06.png" alt=""></li></ol></li><li>分区的全局地址空间<ol><li><img src="https://lh3.googleusercontent.com/-bSmqC6yOmMo/XDxDOvWazbI/AAAAAAAANo4/kBCUSEZV8PI70uGj9ZB3h7b-5I8gF62-gCHMYCw/s0/Acrobat_2019-01-14_16-07-23.png" alt=""></li></ol></li></ol><h2 id="编写并行程序"><a href="#编写并行程序" class="headerlink" title="编写并行程序"></a>编写并行程序</h2><p>主要有以下内容：</p><ol><li>一般步骤<ol><li>划分：大任务划分为小任务，使小任务可以并行执行。</li><li>通信：确定划分得到的小任务需要的通信。</li><li>集聚：如果小任务间有依赖关系，就把它们合并为一个任务。</li><li>映射：把小任务映射到丌同的迚程中，使得进程通信量最小且负载均衡。</li></ol></li><li>并行程序设计</li><li>编辑运行</li><li>输入输出</li><li>性能</li></ol><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><ol><li>计时<ol><li>需要关注CPU时间与真实运行时间的差异。</li></ol></li><li>加速比，效率<ol><li>加速比：串行计算时间与并行计算时间的比值<ol><li>$ \frac{T<em>{serial}}{T</em>{parallel}} ​$</li><li>线性加速比：计算速度随进程线程数的增加呈线性增长</li></ol></li><li>效率：加速比与进程数的比值<ol><li>$ E = \frac{S}{P} = \frac{T<em>{serial}}{p * T</em>{parallel}} $</li></ol></li><li>需要了解到，并行是有额外开销的</li></ol></li><li>阿姆达尔定律<ol><li>加速比是有上限的，无论如何增大处理器数目，加速比也无法高于某个数</li><li>$T_{serial} = W_s + W_p$</li><li>$T_{parallel} = W_s + W_p/p$</li><li>$S = \frac{W_s + W_p}{W_s + W_p/p}$<ol><li>当$p \rightarrow $正无穷的时候，上式具有极限</li></ol></li></ol></li><li>可扩展性<ol><li>同时增加问题规模和进程/线程数，并行程序的效率能基本保持丌变，就说这个程序是可扩展的。</li><li><strong>强可扩展</strong>：增加进程/线程数，为了维持效率而增加的问题规模不大</li><li><strong>弱可扩展</strong>：问题规模的增加的比率与进程/线程数增加比率一致（为了维持效率不变）</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HPC复习1-并行硬件与并行软件&quot;&gt;&lt;a href=&quot;#HPC复习1-并行硬件与并行软件&quot; class=&quot;headerlink&quot; title=&quot;HPC复习1-并行硬件与并行软件&quot;&gt;&lt;/a&gt;HPC复习1-并行硬件与并行软件&lt;/h1&gt;&lt;p&gt;主要分为四部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;背景介绍&lt;/li&gt;
&lt;li&gt;超算硬件&lt;/li&gt;
&lt;li&gt;超算软件&lt;/li&gt;
&lt;li&gt;编写并行程序&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/categories/High-Performance-Computing/"/>
    
    
      <category term="High Performance Computing" scheme="https://wwyf.github.io/tags/High-Performance-Computing/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统中的无层次命名</title>
    <link href="https://wwyf.github.io/2019/01/12/2019-01-2019-01-12-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E6%97%A0%E5%B1%82%E6%AC%A1%E5%91%BD%E5%90%8D/"/>
    <id>https://wwyf.github.io/2019/01/12/2019-01-2019-01-12-分布式系统中的无层次命名/</id>
    <published>2019-01-12T09:49:37.000Z</published>
    <updated>2019-01-12T09:57:41.499Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="分布式系统中的无层次命名"><a href="#分布式系统中的无层次命名" class="headerlink" title="分布式系统中的无层次命名"></a>分布式系统中的无层次命名</h1><p>今天整理了一下笔记，打算将无层次命名这一部分的笔记重新编辑一下，放到这里分享给大家。</p><h2 id="命名系统-基本概念"><a href="#命名系统-基本概念" class="headerlink" title="命名系统-基本概念"></a>命名系统-基本概念</h2><p>在分布式系统中，命名系统起着名称解析的作用，即，允许进程访问对应命名的实体。关于命名系统中的一些概念，这里需要弄清楚：</p><ol><li>实体与访问点的关系<ol><li>访问点是一个特殊的实体</li><li>通过访问点访问实体</li><li>实体可能具有多个访问点</li><li>实体的访问点可能会改变</li></ol></li><li><strong>名称</strong>：用于指向一个实体<ol><li><strong>位置无关</strong>的名称：独立于实体地址</li></ol></li><li><strong>地址</strong>：实体对应的某个<strong>访问点</strong>的名称</li><li><strong>标识符</strong>：用于唯一标识实体，实体与标识符是一对一的关系，且不可重用</li><li><strong>用户友好的名称</strong>：一般是字符串</li></ol><p>为了解决：把名称和标识符解析成地址 的问题，需要：</p><p><strong>名称到地址的绑定</strong></p><h2 id="无层次命名"><a href="#无层次命名" class="headerlink" title="无层次命名"></a>无层次命名</h2><blockquote><p>无层次命名是一种与实体空间位置无关的，扁平化的一种命名方法，一般用做实体的<strong>标识符</strong>。</p><p>名称解析：只给定实体的标识符（常用标识符做非结构化或无层次的名称），定位该实体。</p></blockquote><p>大体有四种方法：</p><ol><li><p>简单方法</p><ol><li>广播和多播<ol><li>包含该实体所用标识符的消息会通过广播发送到所有机器上，请求每一套机器检查它是否拥有该实体（实例：ARP 地址解析协议）</li></ol></li><li>转发指针（<strong>移动实体定位</strong>）<ol><li>每个转发指针都已（客户端存根，服务器存根）对的形式实现，当对象从地址空间A移动到地址空间B时，它会将一个客户存根留在A中，并且在B安装一个应用它的服务器存根。移动的细节对客户是透明的，客户可以顺着转发指针形成的链来查找实体对应的当前地址。</li><li>两种策略：<ol><li>直接向起始客户存根发送相应</li><li>按照转发指针的相反方向发送响应</li></ol></li></ol></li></ol></li><li><p>基于宿主位置</p><ol><li>所有与某主机地址的通信一开始都被转发到移动主机的宿主代理中。对移动主机来说，如果要转移到另一个网络，会获得一个新的地址，该<strong>转交地址</strong>要在宿主代理中注册<ol><li><img src="1547286768306.png" alt="1547286768306"></li></ol></li></ol></li><li><p>分布式散列表</p><ol><li><p>主要解决问题：m位的标识符$k$，解析为$succ(k)$的地址</p></li><li><p>如何高效解决：在每一个节点上维护一个指状表</p><ol><li><p><img src="1546940003091.png" alt="1546940003091"></p></li><li><p><img src="1546940017315.png" alt="1546940017315"></p></li></ol></li><li><p>加入与退出：</p><ol><li>节点p加入很简单，只需要请求$succ(p+1)$即可</li><li>更新指状表会比较复杂</li></ol></li></ol></li><li><p>分层方法</p><ol><li>目录节点：维护目录下的域所有实体的位置记录</li><li>低级的只有低级域的位置记录，高级域有多个低级域的位置记录</li><li>查询实体：自底向上，如果目录节点没有某记录，那转发到父节点继续查询</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;分布式系统中的无层次命名&quot;&gt;&lt;a href=&quot;#分布式系统中的无层
      
    
    </summary>
    
      <category term="Distributed System" scheme="https://wwyf.github.io/categories/Distributed-System/"/>
    
    
      <category term="Distributed System" scheme="https://wwyf.github.io/tags/Distributed-System/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://wwyf.github.io/2019/01/12/test-2018-hello-world/"/>
    <id>https://wwyf.github.io/2019/01/12/test-2018-hello-world/</id>
    <published>2019-01-12T07:36:03.302Z</published>
    <updated>2019-01-12T07:36:03.302Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="test"><a href="#test" class="headerlink" title="test"></a>test</h1><h2 id="test-imag"><a href="#test-imag" class="headerlink" title="test imag"></a>test imag</h2><p><img src="https://i.loli.net/2018/01/24/5a6875a4acc53.png" alt="这是使用公共图床上传的图片"></p><!-- ![](figure/2018-04-21-16-26-20.png) --><img src="/2019/01/12/test-2018-hello-world/2018-04-21-16-26-20.png" title="test"><h2 id="test-math"><a href="#test-math" class="headerlink" title="test math"></a>test math</h2><p>$$ a^2 = b $$</p><h2 id="test-chinese"><a href="#test-chinese" class="headerlink" title="test chinese"></a>test chinese</h2><p>这是中文。</p><h2 id="换了个头像"><a href="#换了个头像" class="headerlink" title="换了个头像"></a>换了个头像</h2><p><img src="http://blog.wwyf.top/logo.jpg" alt=""></p><h2 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h2><p>可以在<code>_posts</code>文件夹下创建自己的文件夹，然后hexo是不会管你的文件夹的！<br>继续测试。</p><p><img src="2018-05-05-11-31-29.png" alt="测试文件夹下放图片"></p><p>使用 typora的话，设置图片根目录后可以很方便的复制粘贴图片。</p><p><img src="1525494633350.png" alt="1525494633350"></p><h2 id="写好了一个脚本"><a href="#写好了一个脚本" class="headerlink" title="写好了一个脚本"></a>写好了一个脚本</h2><p>这个脚本用来自动创建一个新页面，并且填写yml模板信息</p><h2 id="测试脚注"><a href="#测试脚注" class="headerlink" title="测试脚注"></a>测试脚注</h2><p>脚注是<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="用来测试的脚注">[1]</span></a></sup></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">用来测试的脚注<a href="#fnref:1" rev="footnote"> ↩</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;test&quot;&gt;&lt;a href=&quot;#test&quot; class=&quot;head
      
    
    </summary>
    
      <category term="test" scheme="https://wwyf.github.io/categories/test/"/>
    
    
      <category term="test" scheme="https://wwyf.github.io/tags/test/"/>
    
  </entry>
  
</feed>
