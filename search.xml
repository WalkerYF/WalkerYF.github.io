<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[高性能计算基础-复习4-OpenMP]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A04-OpenMP%2F</url>
    <content type="text"><![CDATA[HPC复习4-OpenMP OpenMP简介 OpenMP编译制导 OpenMP库函数 OpenMP环境变量 OpenMP示例–性能改善 OpenMP简介 是一种基于线程的并行编程模型 编译制导 运行库函数 环境变量 采用Fork-Join并行执行方式 OpenMP程序开始于一个单独的主线程（Master Thread），然后主线程一直串行执行，直到遇见第一个并行域(Parallel Region)，然后开始并行执行并行域。并行域代码执行完后再回到主线程，直到遇到下一个并行域，以此类推，直至程序运行结束。 OpenMP 编译制导编译制导语句格式：制导标识符 制导名称 [Cluase,…] 并行域制导 一个并行域就是一个能被多个线程并行执行的程序段 1234#pragma ompparallel [clauses]&#123; BLOCK&#125; 在并行域结尾有一个隐式同步（barrier）。 子句（clause）用来说明并行域的附加信息。 在C/C++中，子句间用空格分开。（Fortran语言中，子句间用逗号或空格分隔） 数据访问相关子句 如何决定哪些变量是共享哪些是私有？ 通常循环变量、临时变量、写变量一般是私有的； 数组变量、仅用于读的变量通常是共享的。默认时为公有 并行域结构：reduction子句12345678inti,myid,n; double a[][];double sum;#pragma omp parallel reduction(+: sum), private(i, myid)&#123; myid=omp_get_thread_num(); for(i=1;i&lt;n;i++) sum=sum+a[i][myid];&#125; 特别说明：要理解reduction操作 在reduction子句中，编译器为每个线程创建变量sum的私有副本。当循环完成后，将这些值加在一起并把结果放到原始的变量sum中; Reduction中的op操作必须满足算术结合律和交换律。 剩下的，详细可见总结或文档。 任务划分并行制导 并行for循环制导 schedule 调度子句 static dynamic guided runtime 并行sections制导 single和master制导 其他制导 同步制导 barrier制导 nowait制导 critical制导 atomic制导 lock例程 flush制导：高速缓存会刷新恢复到内存，影响性能 OpenMP库函数 函数名 作用 int omp_get_num_threads() 得到线程队列中的线程数 int omp_get_thread_num() 得到执行线程的线程号： void omp_set_num_threads(4) 设定执行线程的数量为4 double omp_get_wtime(void) 返回挂钟“自过去任意时刻以来”经过的时间（秒） double omp_get_wtick(void); 返回连续时钟滴答声之间的秒数。 OpenMP环境变量 环境变量名称 作用 OMP_NUM_THREADS 设定最大线程数 OMP_SCHEDULE 调度方式 “DYNAMIC,4” OMP_DYNAMIC 是否动态设定并行域执行的线程数 OMP_NESTED 确定是否可以并行嵌套 OpenMP示例–性能改善例子1如何处理循环中存在的依赖关系？例子如下： 123for(i=1;i&lt;m;i++) for(j=0;j&lt;n;j++) a[i][j]=2.0*a[i-1][j]; 可以变为(交换循环位置)； 123for(j=0;j&lt;n;j++) for(i=1;i&lt;m;i++) a[i][j]=2.0*a[i-1][j]; 例子2下面这一个循环是存在循环依赖的。 12for(i=2;i&lt;20;i++) a[i]=a[i-2]+4 ; 不过我们可以将这一个循环分解为多个循环，这多个循环间不存在依赖关系 1234for(i=2;i&lt;20;i=i+2) a[i]=a[i-2]+4 ;for(i=3;i&lt;20;i=i+2) a[i]=a[i-2]+4 ; 制导指令总结并行域指令 工作共享指令 并行域与工作共享指令的结合 同步指令 数据环境指令 OpenMP子句总结数据作用域属性子句 其他子句]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习7.4-归约操作优化]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-4-%E5%BD%92%E7%BA%A6%E6%93%8D%E4%BD%9C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[HPC复习7.4-并行归约优化这里会有归约操作的7种优化版本。 7种方法的加速情况如下： Interleaved Addressing with divergent branching1234567891011121314151617__global__ void reduce0(int *g_idata, int *g_odata) &#123; extern __shared__ int sdata[]; // each thread loads one element from global to shared mem unsigned int tid = threadIdx.x; unsigned int i = blockIdx.x*blockDim.x + threadIdx.x; sdata[tid] = g_idata[i]; // 合并访存，读取一个block的数据到share memory中 __syncthreads(); // do reduction in shared mem for(unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123; if (tid % (2*s) == 0) &#123; sdata[tid] += sdata[tid + s]; &#125; __syncthreads(); &#125; // write result for this block to global mem if (tid == 0) g_odata[blockIdx.x] = sdata[0];&#125; 存在的问题：123456for(unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123; if (tid % (2*s) == 0) &#123; // 以warp的运行想一想，就会发现，这个是发散的 sdata[tid] += sdata[tid + s]; &#125; __syncthreads();&#125; Interleaved address with bank conflict对上面的问题进行优化，将对应的for循环改成下面的循环： 1234567for (unsigned int s=1; s &lt; blockDim.x; s *= 2) &#123; int index = 2 * s * tid; if (index &lt; blockDim.x) &#123; sdata[index] += sdata[index + s]; &#125; __syncthreads();&#125; 看了老半天终于看懂了 第一次循环： indexs:0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32，取其中的 0,2,4,6,8,10,12,14，也就是前8个线程去计算 第二次循环 indexs:0,4,8,12,16,….，取前四个线程去计算 存在的问题数组可能是很大的，考虑到有16个bank，这里在归约的时候，都是以2的倍数在增加，及其容易发生bank冲突。 如，在第二次循环中，会去读取这些index对应的数据 0,4,8,12,16,20,24,28,32，。。。就会发生bank冲突了。 Sequential Addressing这一个优化就好多啦,不会发生bank冲突，因为一定是顺序写shared memory，看一看示意图，很容易懂！ 123456for (unsigned int s=blockDim.x/2; s&gt;0; s&gt;&gt;=1) &#123; if (tid &lt; s) &#123; sdata[tid] += sdata[tid + s]; &#125; __syncthreads();&#125; First Add During Load关键：在装入shared memory时做第一次加法 从代码中可以看出思路：在读取数组中的值时，原本是以一个blockDim.x为单位读取，每个block读取与blockDim.x相当的元素，放到shared memory中，现在每个block会读取两个blockDim.x大小的数组，然后在写进shared memory的时候就做一次加法。 123456// perform first level of reduction,// reading from global memory, writing to shared memoryunsigned int tid = threadIdx.x;unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];__syncthreads(); 存在的问题：可能在指令的吞吐量上，有瓶颈： 尝试循环展开 Unrolling the Last Warp这里主要尝试这样的做法： 当归约到只剩下32个线程需要计算的时候（也就是说只剩下一个warp了） 显式的将剩下的32个线程所需要做的事情通过循环展开的方式来完成 优化主要体现在两点： 节省了所有的warp的额外开销 想想其他的warp怎么会有开销呢？当只剩下一个warp需要进行实质的工作的时候，其他warp仍然在执行循环。 这个额外开销指的是维护循环变量，检查循环条件等 123456789101112131415for (unsigned int s=blockDim.x/2; s&gt;32; s&gt;&gt;=1)&#123; if (tid &lt; s) sdata[tid] += sdata[tid + s]; __syncthreads();&#125;if (tid &lt; 32)&#123; sdata[tid] += sdata[tid + 32]; sdata[tid] += sdata[tid + 16]; sdata[tid] += sdata[tid + 8]; sdata[tid] += sdata[tid + 4]; sdata[tid] += sdata[tid + 2]; sdata[tid] += sdata[tid + 1];&#125; 存在的问题这里仅仅展开了最后的一个warp，能否完全展开呢？ Completely Unrolled由于编译期就可以知道迭代的blockDim.x，因此可以通过模板的方式生成循环展开的相关代码 1234567891011121314151617if (blockSize &gt;= 512) &#123; if (tid &lt; 256) &#123; sdata[tid] += sdata[tid + 256]; &#125; __syncthreads();&#125;if (blockSize &gt;= 256) &#123; if (tid &lt; 128) &#123; sdata[tid] += sdata[tid + 128]; &#125; __syncthreads();&#125;if (blockSize &gt;= 128) &#123; if (tid &lt; 64) &#123; sdata[tid] += sdata[tid + 64]; &#125; __syncthreads();&#125;if (tid &lt; 32) &#123; if (blockSize &gt;= 64) sdata[tid] += sdata[tid + 32]; if (blockSize &gt;= 32) sdata[tid] += sdata[tid + 16]; if (blockSize &gt;= 16) sdata[tid] += sdata[tid + 8]; if (blockSize &gt;= 8) sdata[tid] += sdata[tid + 4]; if (blockSize &gt;= 4) sdata[tid] += sdata[tid + 2]; if (blockSize &gt;= 2) sdata[tid] += sdata[tid + 1];&#125; 上面的blockSize是个模板参数 Multiple Adds/Thread原理combine sequential and parallel reduction 原理有点不懂。 Algorithm Cascading（算法级联） 它具体的做法是这样子的（我猜）： 申请的线程可以少一些，推荐申请$O(N/logN)$个线程 在算法开始的时候，先使用串行求和，（也就是下面那一串代码），这样子就可以将问题规模缩小到与线程数的情况 后面都一样 123456789unsigned int tid = threadIdx.x;unsigned int i = blockIdx.x*(blockSize*2) + threadIdx.x;unsigned int gridSize = blockSize*2*gridDim.x;sdata[tid] = 0;while (i &lt; n) &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize;&#125;__syncthreads(); 总结前面的优化都其实特别有意思，特别是最后一个 最后一个优化应该说在理论层面的推导会稍微多一点，所以就不容易发现。 而正因为此吧，我觉得我需要弄清楚什么是“算法级联”，如何计算并行算法的复杂度。 如何推导出来怎样的“算法级联”能够给程序加速。 最后优化的程序如下： 1234567891011121314151617181920212223242526272829template &lt;unsigned int blockSize&gt;__global__ void reduce6(int *g_idata, int *g_odata, unsigned int n)&#123; extern __shared__ int sdata[]; unsigned int tid = threadIdx.x; unsigned int i = blockIdx.x*(blockSize*2) + tid; unsigned int gridSize = blockSize*2*gridDim.x; sdata[tid] = 0; do &#123; sdata[tid] += g_idata[i] + g_idata[i+blockSize]; i += gridSize; &#125; while (i &lt; n); __syncthreads(); if (blockSize &gt;= 512) &#123; if (tid &lt; 256) &#123; sdata[tid] += sdata[tid + 256]; &#125; __syncthreads(); &#125; if (blockSize &gt;= 256) &#123; if (tid &lt; 128) &#123; sdata[tid] += sdata[tid + 128]; &#125; __syncthreads(); &#125; if (blockSize &gt;= 128) &#123; if (tid &lt; 64) &#123; sdata[tid] += sdata[tid + 64]; &#125; __syncthreads(); &#125; if (tid &lt; 32) &#123; if (blockSize &gt;= 64) sdata[tid] += sdata[tid + 32]; if (blockSize &gt;= 32) sdata[tid] += sdata[tid + 16]; if (blockSize &gt;= 16) sdata[tid] += sdata[tid + 8]; if (blockSize &gt;= 8) sdata[tid] += sdata[tid + 4]; if (blockSize &gt;= 4) sdata[tid] += sdata[tid + 2]; if (blockSize &gt;= 2) sdata[tid] += sdata[tid + 1]; &#125; if (tid == 0) g_odata[blockIdx.x] = sdata[0];&#125; 优化的结果可见： 相关博客 关于 CUDA 中 reduction 运算的优化 Brent’s theorem]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习7.3-矩阵转置优化]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-3-%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[HPC复习7.3-矩阵转置优化这一个例子使用了以下几种技巧优化了矩阵转置： 合并访问 避免共享内存的bank conflict NAIVE原始的矩阵转置可见 12345678910111213__global__ void transpose_naive(float *odata, float *idata, int width, int height)&#123; unsigned int xIndex = blockDim.x * blockIdx.x + threadIdx.x; unsigned int yIndex = blockDim.y * blockIdx.y + threadIdx.y; // //这里xIndex对应矩阵的列号，yIndex对应矩阵的行号 if (xIndex &lt; width &amp;&amp; yIndex &lt; height) &#123; unsigned int index_in = xIndex + width * yIndex; unsigned int index_out = yIndex + height * xIndex; odata[index_out] = idata[index_in]; &#125; // //warp的排列：按threadIdx.x优先的次序&#125; 合并访存优化在原始的版本里，关键问题在于： odata[index_out]写的时候，无法合并访存： 解决方案： 关键思想：使用合并访存技巧，读取一个块到shared memory中 在shared memory中，通过调换读取的索引，实现合并访存写回内存中 解决bank冲突在上面读取shared memory中，会发生bank冲突导致读取串行化的问题。 代码实现：1234567891011121314151617181920__global__ void transpose(float *odata, float *idata, int width, int height)&#123; __shared__ float block[(BLOCK_DIM+1)*BLOCK_DIM]; unsigned int xBlock = __mul24(blockDim.x, blockIdx.x); unsigned int yBlock = __mul24(blockDim.y, blockIdx.y); unsigned int xIndex = xBlock + threadIdx.x; unsigned int yIndex = yBlock + threadIdx.y; unsigned int index_out, index_transpose; if (xIndex &lt; width &amp;&amp; yIndex &lt; height) &#123; unsigned int index_in = __mul24(width, yIndex) + xIndex; unsigned int index_block = __mul24(threadIdx.y, BLOCK_DIM+1) + threadIdx.x; block[index_block] = idata[index_in]; index_transpose = __mul24(threadIdx.x, BLOCK_DIM+1) + threadIdx.y; index_out = __mul24(height, xBlock + threadIdx.y) + yBlock + threadIdx.x; &#125; __syncthreads(); if (xIndex &lt; width &amp;&amp; yIndex &lt; height) odata[index_out] = block[index_transpose];&#125;]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习7.2-cuda矩阵向量乘法优化]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-2-cuda%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[HPC复习7.2-矩阵向量乘法优化 这里描述了从CPU到GPU的优化步骤，步步渐进，最终收敛于使用cuda的标准数学库。 对于CUDA程序开发来说，优化往往是整个开发过程的核心，不同算法，不同存储器组织的程序性能往往差几十倍，本讲通过一个简单的例子来展示CUDA开发中一些重要的因素对性能的影响。 最后的优化结果可见 原始版本：串行C版本12345678910void mxv(const int rowSize, const int columnSize, const float *matrix, const float *v, float *r)&#123; for(int i = 0; i &lt; rowSize; i++)&#123; float re = 0.0f; for(int j = 0; j &lt; columnSize; j++)&#123; re += matrix[i*columnSize+j]*v[j]; &#125; r[i] = re; &#125;&#125; CPU上的优化在cpu上的优化我就不详细说了吧 使用sse指令来计算 12345678910111213void mxvSSE(const int rowSize, const int columnSize, const float *matrix, const float *v, float *r)&#123; __m128 *mv = (__m128*)v; __m128 *mm = (__m128*)matrix; for(int i = 0; i &lt; rowSize; i++)&#123; __m128 re = _mm_set_ps(0.0f, 0.0f, 0.0f, 0.0f); for(int j = 0; j &lt; columnSize/4; j++)&#123; re = _mm_add_ps(re, _mm_mul_ps(mm[i*columnSize/4+j], mv[j])); &#125; float __attribute((aligned(16))) a[4]; _mm_store_ps(a, re); r[i] = a[0] + a[1] + a[2] + a[3]; &#125;&#125; 使用sse+openmp来优化 12345678910111213void mxvSSEOpenmp(const int rowSize, const int columnSize, float *matrix, float *vec, float *r)&#123; __m128 *mv = (__m128*)v; __m128 *mm = (__m128*)matrix; #pragma omp parallel for num_threads(2) for(int i = 0; i &lt; rowSize; i++)&#123; __m128 re = _mm_set_ps(0.0f, 0.0f, 0.0f, 0.0f); for(int j = 0; j &lt; columnSize/4; j++)&#123; re = _mm_add_ps(re, _mm_mul_ps(mm[i*columnSize/4+j], mv[j])); &#125; float __attribute((aligned(16))) a[4]; _mm_store_ps(a, re); r[i] = a[0] + a[1] + a[2] + a[3];&#125; 使用CUDA的注意事项几个原则需要尽可能保证 保持SM尽可能忙碌 加大数据量或者减小线程块大小 优化存储器的使用 全局存储器合并访问 使用constant或shared memory 对齐分配空间 关于为什么 CUDA naive的优化关键在于：理解这里为什么要使用转置矩阵来达到合并访存的目的 第一步-cuda naive12345678910static void __global__ mxvNaive(int rowSize, int columnSize, int columnPitch, const float *d_matrix, const float *d_vec, float *d_r)&#123; uint id = blockDim.x*blockIdx.x+ threadIdx.x; if(rowSize&lt;= id) return; float temp = 0.0f; for(int i= 0; i&lt; columnSize; i++)&#123; temp += d_matrix[id*columnPitch+i]*d_vec[i]; // d_matrix[id*columnPitch+i]这里存在不能合并访存的问题 &#125; d_r[id] = temp;&#125; 第二步-发现合并访存的问题 解决方法：先将矩阵转置，就可以达到合并访存的要求了。 1234// 转置后的for循环for(int i= 0; i&lt; rowSize; i++)&#123; temp += d_matrix[i*columnPitch+id]*d_vec[i];&#125; 访存优化关注到d_vec数组是不会改变的，因此考虑使用constant或者shared memory进行优化 使用constant memory优化 将一整个向量都放进constant memory中，得到以下代码： 12345678910static void __global__ mxvNaiveTransposeConstant(int rowSize, int columnSize, int columnPitch, const float *d_matrix, const int start, float *d_r)&#123; uint id = blockDim.x*blockIdx.x + threadIdx.x; if(columnSize &lt;= id) return; float temp = 0.0f; int end = start+CONSTANTSIZE &gt; rowSize ? rowSize : start+CONSTANTSIZE; for(int i = start; i &lt; end; i++)&#123; temp += d_matrix[i*columnPitch+id]*c_v[i-start]; &#125; d_r[id] += temp;&#125; 如果向量超过了constant memory的上限，那就 分批，多次传输，启动内核。 使用shared memory优化 关注到：可以在一个block内共享向量$v$，考虑使用shared memory 1234567891011121314151617181920212223static void __global__ mxvNaiveTransposeShared(int rowSize, int columnSize, int columnPitch, const float *d_matrix, const float *d_v, const int sharedSize, float *d_r)&#123; uint id = blockDim.x*blockIdx.x+ threadIdx.x; float temp = 0.0f; extern __shared__ float s_v[]; // 外层循环，每次加载一段大小为sharedsize的向量v进行计算 for(int start = 0; start &lt; rowSize; start += sharedSize)&#123; __syncthreads(); #pragma unroll 4 for(int i= threadIdx.x; i&lt; sharedSize&amp;&amp;i+start&lt;rowSize; i+= blockDim.x)&#123; s_v[i] = d_v[start+i]; // 关键在于这里加载shared memory &#125; __syncthreads(); if(columnSize&lt;= id) continue; int end = start+sharedSize&gt; rowSize? rowSize: start+sharedSize; #pragma unroll 8 for(int i = start; i &lt; end; i++)&#123; // 使用shared memory 访存得到极大提升 temp += d_matrix[i*columnPitch+id]*s_v[i-start]; &#125; &#125; if(id &lt; columnSize) d_r[id] = temp;&#125; block模式与warp模式问题：如果不转置矩阵如何计算？ block模式关键：一个block处理矩阵的一行和向量乘积，其中block中的每个线程处理该行中的一个与对应向量元素的乘积,然后归约。 1234567891011static void __global__ mxvBlock(int rowSize, int columnSize, int pitchItem, const float* __restrict__ d_matrix,constfloat* __restrict__ d_vec, float* __restrict__ d_r)&#123; unsigned int tid= threadIdx.x; extern __shared__ float s_r[]; float temp = 0.0f; for(int i= tid; i&lt; columnSize; i+= blockDim.x)&#123; temp += d_matrix[blockIdx.x*pitchItem+i]*d_vec[i]; &#125; s_r[tid] = temp; __syncthreads(); ……//省略归约代码 &#125;&#125; warp模式具体的计算和block模式差不多,只是使用一个warp线程计算矩阵的一行与向量的乘积,在我的测试中发现,这个算法对于行数大于列数的矩阵效果很好,很多时候性能是block的两倍以上。 使用cuBlas包成为调包侠： 函数: cublasSgemv——cuBlas包的矩阵向量乘法 总结最后的优化结果可见]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习7.1-cuda矩阵乘法优化]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A07-1-cuda%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[HPC复习7.1-矩阵乘法优化naive实现具体思路就很简单了，仅使用一个块，然后块中每一个线程计算矩阵的一个元素。 算法图示可见 123456789101112131415161718// 矩阵乘法的内核函数——每个线程都要执行的代码__global__ void MatrixMulKernel(float* Md, float* Nd, float* Pd, intWidth)&#123; // 2维的线程ID号 inttx= threadIdx.x; intty= threadIdx.y; // Pvalue用来保存被每个线程计算完成后的矩阵的元素 float Pvalue= 0; //每个线程计算一个元素 for (intk = 0; k &lt; Width; ++k) &#123; float Melement= Md[ty* Width + k]; float Nelement= Nd[k * Width + tx]; Pvalue += Melement* Nelement; &#125; // 将计算结果写入设备存储器中 Pd[ty* Width + tx] = Pvalue;&#125; 这样的实现是有问题的： 计算的时间与访存时间比例相当，受存储器延迟的影响很大。 矩阵的大小收到线程块所能容纳的最大线程数的限制。 处理任意大小的方形矩阵解决了在上面的实现中，无法处理任意大小的方形矩阵的问题。 关键思想： 将矩阵分块，每一个线程块block计算其中的一个子矩阵 如果矩阵块的数量大于最大的上限时，需要在内核附近设置一个循环（一个已经用过的技巧，我会的啦） 问题：每一个线程都要访问global memory获取矩阵的一整行和一整列元素 访存带宽成为了计算的瓶颈 分片矩阵乘法使用高带宽的片上存储器”shared memory”缓解了访存瓶颈 关键思想：重用数据，原来的矩阵乘法实现中，每一个区域都有多个线程多次访问，如果数据可以重用，可以大大降低计算所需的带宽。 分片矩阵乘法-算法关键： 代价估计：浮点操作：全局存储器读出操作＝16: 1，说明访存代价占比不高 算法细节 逐个子矩阵块，依次计算，求和到结果矩阵上 进行子矩阵块的运算前，先将子矩阵块复制到shared memory上 一个合并访存(访问global memory)的技巧：每一个线程读取一个值，然后使用同步原语保证同步 每一个线程计算完子矩阵块的一个结果后，合并访存的技巧依然使用，写位于global memory的矩阵 每一个线程仅写回自己计算的值，合并访存，然后使用同步原语 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//每个线程块有TILE_WIDTH2个线程dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);//有(Width/TILE_WIDTH)2个线程块dim3 dimGrid(Width/TILE_WIDTH, Width/TILE_WIDTH);//调用内核函数MatrixMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(Md, Nd, Pd，Width);// 以下是内核函数// part 1 将数据从global memory加载到shared memory上//获得线程块号intbx= blockIdx.x;intby = blockIdx.y;//获得块内的线程号inttx= threadIdx.x;intty= threadIdx.y;//Pvalue：线程计算完成后的子矩阵元素——自动变量float Pvalue= 0;//循环，遍历M和N的所有子矩阵for (intm = 0; m &lt; Width/TILE_WIDTH; ++m) &#123; // 获取指向当前矩阵M子矩阵的指针Msub Float* Mdsub= GetSubMatrix(Md, m, by, Width); //获取指向当前矩阵N的子矩阵的指针Nsub Float* Ndsub= GetSubMatrix(Nd, bx, m, Width); //共享存储器空间声明 __shared__floatMds[TILE_WIDTH][TILE_WIDTH]; __shared__floatNds[TILE_WIDTH][TILE_WIDTH]; // 每个线程载入M的子矩阵的一个元素 Mds[ty][tx] = GetMatrixElement(Mdsub, tx, ty); //每个线程载入N的子矩阵的一个元素 Nds[ty][tx] = GetMatrixElement(Ndsub, tx, ty);&#125;;// part 2 每个线程计算一个值结果//同步，在计算之前，确保子矩阵所有的元素都已载入共享存储器中__syncthreads();//每个线程计算线程块内子矩阵中的一个元素for (intk = 0; k &lt; TILE_WIDTH; ++k) Pvalue+= Mds[ty][k] * Nds[k][tx];//同步，确保重新载入新的M和N子矩阵数据前，上述计算操作已全部完成__syncthreads();// part 3 合并访存 写回// 获取指向矩阵P的子矩阵的指针Matrix Psub= GetSubMatrix(P, bx, by);//向全局存储器写入线程块计算后的结果子矩阵//每个线程写入一个元素SetMatrixElement(Psub, tx, ty, Pvalue);]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习6-CUDA优化]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A06-CUDA%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[HPC复习6-cuda优化在cuda程序的优化中，需要考虑以下几个问题 了解SM核中所提供的资源，并合理分配。 确定kernel的启动参数，以尽可能提高cuda程序的性能。 理解warp隐藏延时的作用，知道为什么warp越多越能隐藏延时。 通过数据预读取隐藏访存延时。 了解不同指令的吞吐量，并优化之。 SM资源分割需要确定的值 block的数量 thread的数量 与分配资源有关的参数 线程块槽数量（thread block slot）：block数量的上限 线程槽数量（thread slot） 寄存器的数量 shared memory的大小 分配资源的数量，与哪些因素有关 原则一：单个SM核上分配的线程数（block*每个block具有的线程数）越大，线程级别的并行越大（前提与sm核实际运行的状况有关，需要想清楚） 线程越多，warp越多，可运行的用来隐藏访存时间的warp就越多，因此就可以尽可能让GPU达到满负荷工作，不会由于访存延迟使得gpu空闲。 原则二：单个SM核上的所有寄存器，平均分配给各个线程，因此，线程数量越多，单个线程可用的寄存器越少 性能悬崖警惕：减少1/3的线程（并行度），仅仅让每一个线程增加了1个寄存器，除非由于寄存器不足导致了较大的访存开销，否则小心调整。 原则三：对block的数量需要注意，尽量让每一个SM核上都具有多个block，这样子如果一个block在等待同步，可以启动另一个block 需要知道SM核的数量 原则五：『关于shared memory』 shared memory按block分割，block过多可能会让单个block所具有的shared memory脱销 例子：对G80而言，与分配相关的参数可见： 有这样的一个情景，在每个block都含256个线程的情况下，一个SM核可能有以下两种情况： 这里就可以发现，每个线程多了一个寄存器，但是带来的影响是，总的可以运行的线程的数量变为原来的2/3，也就是说，并行度是原来的2/3了。 这个可以给我一个启示：除非为了隐藏global memory访存延迟，否则尽可能不要为了增加寄存器数量而降低并行性。 Kernel启动参数配置需要确定以下参数 grid（block的数量）：主要看$\frac{blocks}{sm}$ 大于1：每个SM至少有一个block在执行 大于2：多个block可以在SM核上并发执行，如果一个block在等待同步，可以启动另一个block 大于100：对未来设备有很好的伸缩性 block（thread的数量） 块大小必须为32的倍数 warp尽可能多，隐藏延时 64,128,256 等等，试一下，经验成分比较多 隐藏延时-相关计算问题：需要使用多少个warp来隐藏某操作的延时，此时占用率多大？ 占用率：激活warp与最大可容纳warp数目的比值 最大warp数目: 32 in Tesla, 48 in Fermi 例子1 例子2 数据预读 数据预读：在某global memroy变量的读操作，与该变量的实际使用语句之间，插入与该数据无关的独立指令，可以隐藏访存延迟 例子： 123float m = Md[i];float f = a*b + c*d; // 无关指令，隐藏访存延时float f2 = m * f; 如何在矩阵乘法中使用预读操作进行优化代码模板如下， 注意到中间的预读在计算点积前面，这样子中间的点积在运算时便可以隐藏预读内存产生的误差了。 123456789101112// Load first tile into registersfor(/* ... */)&#123; // Deposit registers into shared memory __syncthreads(); // Load next tile into registers // Accumulate dot product __syncthreads();&#125; 指令吞吐量优化了解每一种指令的吞吐量，减少使用昂贵的指令。 一些指令的吞吐量 int &amp; fp32 2 cycles fp64: 2 cycles fp32 transendental 8 cycles int devide/modulo expensive 优化建议： 与2^n运算，尽量使用位运算，如&gt;&gt; n``&lt;&lt; n 在float常量中添加f，（缺省是double，会导致隐式的类型转换） 数学函数的吞吐量提高 cuda中两种类型的运行时数学函数 func() __func()：使用硬件加速，SFU，精度低 --use-fast-math编译指令，强制使用硬件加速的数学函数 循环展开 原理：循环中除了循环体，还有更新计数器，判断条件，计算地址等指令，减少这些无关指令的运算可以加速 例子： 1234for(int k =0;k &lt; 16;++k)&#123; Pvalue +=Ms[ty][k]*Ns[k][tx];&#125; 这其中含有 12342条浮点运算1条循环分支2条地址运算1条循环计数器自增 仅1/3是浮点计算！！！ 做以下改动： 12345Pvalue += Ms[ty][0] * Ns[0][tx] + Ms[ty][1] * Ns[1][tx] + ... Ms[ty][15] * Ns[15][tx]; 从而减少了循环分支，自增，同时地址运算也可以减少。 自动完成循环展开： 12345#pragma unroll 16for(int k =0;k &lt; 16;++k)&#123; Pvalue +=Ms[ty][k]*Ns[k][tx];&#125; 由于展开能够消除分支以及一些管理归纳变量的代码，因此可以摊销一些分支开销。展开可以积极调度（或管道化）循环以掩盖一些延迟。如果有足够的空闲寄存器使变量保持活动状态，因为通过展开相关性链展露了关键路径，这将非常有用。 但 展开过度或展开非常大的循环时，可能导致代码篇幅增加。如果展开后的循环不能再放入跟踪缓存 (TC)，这将有害无益。 展开循环体中包含分支的循环时，会增加对 BTB 容量的需求。如果展开后循环的迭代次数是 16 或更少，则分支预测应该能正确预测循环体中改变方向的分支。 课上提醒 如果一整个warp没有指令要执行，不会占住SP，一上来就下去，但只要warp中有一个线程要执行，那就一定会占住SP]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习5.3-CUDA线程]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-3-CUDA%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[HPC复习5.3-CUDA线程这里主要想想明白一个事： 已知的是，会有多个block，分配到SM核上来执行。 也知道，单一时间上，SM核仅有一个warp在运行。 问题是： SM核内部的结构是如何的？ warp的实际执行情况是如何的？ warp的并发执行是否会引发一些问题？如何解决？ SM核架构对SM核的架构该如何理解？ 2个warp调度器与2个指令分派单元能够将2个warp同时进行发射和执行: 双warp调度器先选择两个warp，然后从每个warp发射一条指令到一个十六核心的组，或是十六个读写单元或是四个SFU。 Single Warp对于单个warp内部的并行执行，可能会遇到以下的一些问题： 单个warp上可能发生的访存冲突123456if (warpIdx == 0) &#123; __shared__ int v; v = 0; ++v; v == ?&#125; 注意到share memory在一个block内是能够共享的，因此这一段代码由于会导致错误。 解决这一个问题可以使用atomicAdd(&amp;v, 1);来实现。 注意到CUDA不支持临界区。 warp如何处理分支指令？123456789int warpIdx = threadIdx.x / 32;int laneIdx = threadIdx.x % 32;if (warpIdx == 0) &#123; if (laneIdx % 2 == 0) &#123; doA(); &#125; else &#123; doB(); &#125;&#125; 事实上，warp线程在执行上面代码的时候，图示可见如下： 有很多branch的代码是低效的。 复杂的控制流，如break，continue，会导致代码低效，可能会出现bug。 Warp functions __all(predicate); return 1 if and only if predicate evaluates to non-zero for all of them. __any(predicate); return 1 if and only if predicate evaluates to non-zero for any of them. __ballot(predicate); return an integer whose Nth bit is set if and only if predicate evaluates to non-zero for the Nth thread of the warp and the Nth thread is active. Multi Warp多个warp并发执行，可能会导致一些问题。 多个warp之间的并发执行顺序不定，这会带来一些问题（联想：多线程可能会带来的问题） warp内分支也可能会带来问题，导致性能损失。 warp之间无序的并发执行会带来哪些问题？ RaW（read after write） 如果先写后读，由于后面读的时候，不知道其他warp写了没，可能会导致问题。 WaR（write after read） 读后写，同样的写的时候，不知道前面读的值是否是最新的 WaW（write after write） 写后写，同样的，不同的warp之间的写语句，可能运行的相对顺序不一样。 如何解决：使用__syncthreads()函数 branch如何影响多个warp运行的性能？对代码段： 12345if (laneIdx % 2 == 0) &#123; doA();&#125; else &#123; doB();&#125; 结论： 如果一个warp内的线程有的运行doA，有的运行doB，那么这一个warp必须两部分都运行 如果一个warp内的线程仅运行其中一个函数，那么该分支语句就不会带来影响 以下分三种情况分别观察情况 （warp-divergent）一个warp内，有的需要运行doA，有的需要运行doB (warp-uniform)在同一个block内，有的warp运行doA，有的warp运行doB (block-uniform)不同的block，有的block运行doA，有的block运行doB 总结：block-uniform方式能够更好的减少性能损失 总结这幅图我觉得很好地将之前讲过的很多东西都联系了在一起，那就放上来慢慢观赏吧。]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习5.2-CUDA访存]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-2-CUDA%E8%AE%BF%E5%AD%98%2F</url>
    <content type="text"><![CDATA[HPC复习5.2-CUDA访存这里就主要对cuda中的访存模式进行比较详细地说明吧。 GPU中，5种不同存储部件的特性及使用方式 GPU中，如何使用合并访存加速 下图是GPU中的存储设备的大图 GPU中的存储部件如何使用global memory?有两种方式： 1234567891011121314151617181920212223__global__ add4f(float* u, float* v) &#123; int i=threadIdx.x; u[i]+=v[i];&#125;int main() &#123; float hostU[4] = &#123;1, 2, 3, 4&#125;; float hostV[4] = &#123;1, 2, 3, 4&#125;; float* devU, devV; size_t size = sizeof(float)*4; cudaMalloc(&amp;devU, size); cudaMalloc(&amp;devV, size); cudaMemcpy(devU, hostU, size, cudaMemcpyHostToDevice); cudaMemcpy(devV, hostV, size, cudaMemcpyHostToDevice); add4f&lt;&lt;&lt;1,4&gt;&gt;&gt;(devU, devV); cudaMemcpy(hostU, devU, size, cudaMemcpyDeviceToHost); cudaFree(devV); cudaFree(devU); return 0;&#125; 第二种方式： 12345678910111213141516__device__ float devU[4];__device__ float devV[4];__global__ addUV() &#123; int i=threadIdx.x; devU[i]+=devV[i];&#125;int main() &#123; float hostU[4] = &#123;1, 2, 3, 4&#125;; float hostV[4] = &#123;1, 2, 3, 4&#125;; size_t size = sizeof(float)*4; cudaMemcpyToSymbol(devU, hostU, size, 0, cudaMemcpyHostToDevice); cudaMemcpyToSymbol(devV, hostV, size, 0, cudaMemcpyHostToDevice); addUV&lt;&lt;&lt;1,4&gt;&gt;&gt;(); cudaMemcpyFromSymbol(hostU, devU, size, 0, cudaMemcpyDeviceToHost); return 0;&#125; 一点点小疑问 cudaMemcpyToSymbol和cudaMemcpy的区别，可见link 如何使用constant cache？该种存储空间有什么特点？ 这样使用： 1234567891011__constant__ int devVarcudaMemcpyToSymbol( devVar, &amp;hostVar, sizeof(int), 0, cudaMemcpyHostToDevice)cudaMemcpyFromSymbol( &amp;hostVar, devVar, sizeof(int), 0, cudaMemcpyDeviceToHost) 注意到，这种类型的使用，不需要显式的free constant cache的特点？ 空间大小上限为4KB 不依赖于threadIdx 如何使用shared memory？ 有两种方式来使用：静态分配与动态分配 静态分配如下设置： 1__shared__ int shArr[4]; 动态分配可以这样设置： 12extern __shared__ int shArr[];kernel&lt;&lt;&lt;grid,block,sizeof(int)*4&gt;&gt;&gt;(); 这种memory 的特点？ L1cache与shared Memory共用一块存储空间（直接说明速度很快） 大小有限制 什么是local memory？在什么情况下变量会存在local memory中？ local memory是线程中某些变量存储的空间，实质上是global memory中分配给线程的一块内存空间。 实质上就是global memory local memory的特点： 线程内私有 速度很慢（在global memory中） 在这些情况下变量会存在local memory而不存在寄存器中 当单个线程中的寄存器不够用的情况下，需要使用local memory存储变量。 需要了解单个线程中能够使用的寄存器数量。 如果变量使用到了地址，变量就会存在local memory中。 使用了递归函数，寄存器显然不够用，当然也会使用local memory texture cacheTODO: 对这个没有什么兴趣，就先不看吧。 GPU中的存储访问模式问题：怎样的存储访问模式，效率更高？ 如何确定访问过程中对Global Memory的访问长度 基于这样的特性： 对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节 1234567891.找出最小编号活动线程寻址的存储器片段。段的长度由线程访问的字的长度决定： * 1字节的字32字节 * 2字节的字64字节 * 4，8，16字节的字128字节2.找出其它地址在同一段内的活动线程3.减小事务长度，如果可能： * 如果事务是128字节且只有下半部分或上半部分被使用，减小事务到64字节； * 如果事务是64字节（原始的或者从128字节减小后的）且只有上半部分或下4.执行事务且标记已访问数据的线程为非活动的。 Global Memory中，怎样访存效率更高？ cuda访存的特性 对全局存储总是按32B，64B，128B的大小对齐访问，即使只需要一个字节 根据特性，判断不同访存方式的效率区别( 图中例子为：遍历访问数组的32个int元素（32*Bytes=128Bytes）。 对齐且顺序： 对齐，但交叉次序访问，注意到对该情况的优化在不同的计算能力下不同。 发现1.0的时候，完全不支持交叉次序访问的并行 每个int读取一次，32次读取每次读取单位为32B 未对齐，但顺序访问 即使对齐了，但是如果乘上一个系数 随机访问 结论：尽可能对齐且顺序访问 Constant Memory中，如何访存效率更高？ 特点： 片外存储器，速度虽然比shared满，但是具有缓存 只读 无需考虑冲突问题 访问优化： 关键：如果half-warp中的线程访问的不是同一个地址，那么各个线程的访问将会串行化。 例子： Shared Memory中如何访存效率更高？ 特点： 速度极快（毕竟在L1 cache上） 如果发生bank冲突，可能会使访存串行化 shared memory的硬件结构特点与bank 参考下图 线性编址 （以下图为例的话），地址0008，0048，0088在同一个bank上，无法在一个时钟周期内访问，必须串行访问。例如下图：同一个时间里，half-warp发出的访存请求，如果访问同一个bank上的地址，会导致访存串行化 地址0000，0004，0008，等，在同一个bank上，多个线程可以在同一个时钟周期访问，因此实现了并行访存 关键优化需要特性 一个half-warp中的线程，在没有发生bank冲突的情况下，可以在一个时钟周期内访问16个不同的地址。 一个half-warp中的所有线程如果都访问同一个地址，通过广播机制，可以在同一个时钟周期内完成访问。 访存例子： v = arr[ threadIdx.x ] 连续的16个元素可以通过一个时钟周期一次访问。 v = arr[ threadIdx.x+2 ] 没有发生bank冲突，连续的16个值依然可以通过一个时钟周期一次完成访问。 v = arr[2*threadIdx.x] 连续的16个值，前8个可以一次访问，后8个由于与前8个发生了bank冲突，需要等到下一个时钟周期，需要两个时钟周期 v = arr2[threadIdx.x].x 注意到arr2数组是由int2类型的结构体（int x, int y）组成的，因此在实际访存中，这个语句有着与上面那个类似的效果。 v = arr[3*threadIdx.x] 发现很神奇的是，乘上3，就不会发生冲突了。 (3与16互素，x $\in [0,15]$是16的一个剩余系，那么3*x能够遍历16的剩余系) v = arr[random] 总结]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习5.1-CUDA基础]]></title>
    <url>%2F2019%2F01%2F15%2F2019-01-2019-01-15-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A05-1-CUDA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[HPC复习5.1-CUDA基础复习了一下cuda，主要以自问自答的方式，整理了一下知识点。 相关背景：前言 逻辑上的cuda架构大概是怎样的？ gpu上实际的硬件情况 cuda架构与硬件之间的关系 一个简单实例：矩阵相乘的简单实现 前言为什么需要gpu？ CPU处理能力不断强大，但在进入3D时代后，人们发现庞大的3D图像处理数据计算使得CPU越来越不堪重荷，并且远远超出其计算能力； 图形计算需求日益增多，作为计算机的显示芯片也飞速发展。图形，图像计算等计算的功能被脱离出来，单独设计为一块芯片——GPU （也就是显卡）。 gpu与cpu的主要区别在？ gpu采用了大量的执行单元，并且一个控制单元可以同时控制多个执行单元进行计算，实现类似于SIMD的加速。 cuda是什么？ 是一种专门针对GPU的开发工具，可以使用类C语言进行通用计算。 用于编写host+device异构并行C应用程序 CUDA 架构（逻辑上）CUDA中线程的组织方式？ 三级：Grid-Block-Thread Thread ：单个线程，是并行的基本单位 Block：互相合作的线程组 Grid：一组Block 需要关注到，一个kernel对应一个Grid CUDA中的访存模式？线程可以访问以下空间 以线程为单位的 线程有内部的寄存器 在寄存器不够用的情况下，可以在Global Memory中申请一块内存空间作为Local Memory 以Block为单位的 单个block中的线程共享Shared Memory 以Grid为单位的 一个Grid中的所有线程共享Glocal Memory 特殊的，一个Grid中的所有线程共享只读的 constant memory(常量存储器),texture memory(纹理存储器) 图示如下： cuda与硬件的关系cuda中有哪些硬件？是如何组织的？由低到高分别是： SP：流处理器 SM：流多处理器 TPC：线程处理集群 SPA：流处理器阵列 cuda架构与实际硬件的关系？ Grid：运行在SPA上 Block的执行方式： 一般的cuda应用程序具有多个Block组成的线程组，这些Block会分配到多个SM核上分别执行。 怎么分配？见下图： 注意到这里的分配，会受到以下两个限制的影响： 一个SM核上分配的Blcok数量是有限制，G80中的SM核最多8个block G80中的SM核最多768个线程。 SM核上具有多个Block需要运行后，这些线程更具体的，是如何执行的呢？ 一个SM核上的多个Block，每个block会分成多个Warp（32个线程） 这些Warp会在SM核上并发地执行，由于一个Warp有32个线程，而一个SM核上仅有8个SP，因此一个Warp运行4个Clock cycles Warp的调度具有开销吗？ （联想）cpu中的硬件多线程之间的调度是几乎没有开销的，原因？是因为CPU中已经有了多个可以用于存储线程context的区域，每次调度切换线程的时候，切换context是在CPU硬件内完成的，不是由操作系统完成的，不需要访存，因此几乎0开销。 GPU中的warp调度，类似的，也是0开销的。 怎样的Warp会被调度出来执行？ 很明显的，每一个时刻，都会有很多个Warp在等待被GPU调度执行，那么问题是：满足什么条件的Warp，会被调度出来执行？ Warp中没有线程被阻塞的（如访存等） 合适的Warp挑出来优先执行。 为什么要设计成warp的并发执行？ 结论：Warp的并发执行，能够很好的隐藏访存时间（原理类似于cpu中的硬件多线程） 简单例子： 上图中，一个单位长度为一个warp的执行（实际上其实是4个时钟周期，这里简化成了1个）。 可以发现，每当一个Warp由于访存阻塞了，GPU会马上从调度其他可用的Warp来执行，从而保证GPU中的计算负载保持在100%，这个Warp的访存时间就被别的Warp的执行隐藏掉了 复杂例子：如何计算完全隐藏访存时间所需要的Warp的数量。 假设： 运行一次一个Warp中的所有线程需要4个clock cycles 每n个指令需要一次全局内存访问（200个时钟周期） 解答： 假设每个指令都需要访存，访存的这一段时间里，可以使用$200/4=50$个warp的执行来隐藏。 隐藏假设：单个Warp一次运行仅使用了4个clock cycles就被阻塞了 由于是每n个指令访存一次，因此实际上，单个warp执行了$4*n$后才会被阻塞 因此，需要$200/(4*n)+1$个warp。 SM核上具有的存储空间及分配情况？ SM核上拥有16KB的shared memory(有些GPU是48KB) 基于前面，一个SM核上分配多个Block的前提 多个block分享一个SM核上的shared memory。 由于单个block可能会要求shared memory至少多大，而一个SM核上的shared memory是有限制的，所以，block要看情况，不能分配太多，不然shared memory就不够用了。 Shared Memory也会限制Block的分配 cuda的软件接口写了这么多，终于写到要写一个真正的cuda程序了。 cuda编程中的函数声明 在cuda编程中，当然既要写在gpu上运行的函数又要写在cpu上运行的函数了，那么如何区分呢？ 好吧，之前我没有好好想__device__还有__global__的区别，所以这里要特地给自己强调一下。 cuda中的5个内建设备变量 gridDim blockDim blockIdx threadIdx warpSize cuda中的各种各样的内存操作cudaMemcpy(void * dst, void * src, size_t nbytes, enum cudaMemcpyType direction); cudaMalloc cudaFree cuda中的同步操作__syncThreads()：同步一个block里面的所有线程，作用相当于一个Barrier 实例：very simple的矩阵相乘可以看我的git仓库（我具体的实现可能没有这么naive） 具体思路是： 对该程序优化的思考 性能问题： 每计算一次，访问两次内存（如从矩阵Md中取一个数，以及从Nd中取一个数，然后只做了一次加法） 访存限制 矩阵的大小受到一个block大小的限制。]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习3-pthread]]></title>
    <url>%2F2019%2F01%2F14%2F2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A03-pthread%2F</url>
    <content type="text"><![CDATA[HPC复习3-pthreadtoturial 这里是高性能计算课程-pthread部分的复习笔记，大概会有以下内容： pthread中的hello,world pthread中的临界区 忙等待 互斥量 生产者-消费者同步与信号量 实现路障 读写锁与链表 pthread中的缓存一致性 进程、线程和pthread pthread:一种共享内存编程模型 Hello,world12345678910111213141516171819202122232425262728293031323334#include &lt;pthread.h&gt;void *print_message_function( void *ptr );main()&#123; pthread_t thread1, thread2; char *message1 = "Thread 1"; char *message2 = "Thread 2"; int iret1, iret2; /* Create independent threads each of which will execute function */ iret1 = pthread_create( &amp;thread1, NULL, print_message_function, (void*) message1); iret2 = pthread_create( &amp;thread2, NULL, print_message_function, (void*) message2); /* Wait till threads are complete before main continues. Unless we */ /* wait we run the risk of executing an exit which will terminate */ /* the process and all threads before the threads have completed. */ pthread_join( thread1, NULL); pthread_join( thread2, NULL); printf("Thread 1 returns: %d\n",iret1); printf("Thread 2 returns: %d\n",iret2); exit(0);&#125;void *print_message_function( void *ptr )&#123; char *message; message = (char *) ptr; printf("%s \n", message);&#125; pthread中的临界区 课本上使用多个线程并行计算$\pi$会出问题 多个线程尝试更新同一个共享变量时，会出问题。 多个线程尝试更新一个共享资源，结果可能是无法预测的，这些访问可能会导致某种错误，我们称之为竞争条件 临界区：更新共享资源的代码段 忙等待 可以使用忙等待实现“严格按照线程号，单个线程进入临界区”。 注意，可能会由于发生了编译优化导致该忙等待失效（该忙等待语句可能会调度到其他指令前后） 可以通过volitile关键字来解决 缺点： 忙等待：浪费CPU周期 123456// initializeflag = 0;// .... some codewhile(flag != my_rank);// critical areaflag = (flag + 1)% thread_count;// 保证在所有进程都已到达后，flag恢复成0 互斥量 改善忙等待的缺点：互斥量，互斥锁 设计函数接口 pthread_mutex_init( pthread_mutex_t *, const pthread_mutexattr_t *) int pthread_mutex_destroy(pthread_mutex_t* ) int pthread_mutex_lock(pthread_mutex_t *) int pthread_mutex_unlock(pthread_mutex_t *) 生产者-消费者同步和信号量TODO: 路障和条件变量 问题：如何保证所有线程在程序中处于同一位置来同步线程（即实现路障） 忙等待和互斥量实现路障 1234567891011121314int counter;int thread_count;pthread_mutex_t barier_mutex;//....void * Threa_word(...)&#123; ... /* barrier */ pthread_mutex_lock(&amp;barier_mutex); counter++； pthread_mutex_unlock(&amp;barrier_mutex); while(counter &lt; thread_count); ...&#125; 信号量实现路障 123456789101112131415161718192021int counter;sem_t count_sem;sem_t barrier_sem;void* Thread_work(...)&#123; ... /* barrier */ // 先获得计数器的信号量 sem_wait(&amp;count_sem); if (counter == thread_count-1)&#123; // 最后一个到达路障的线程负责初始化counter以及释放其他线程 counter = 0; sem_post(&amp;count_sem); for(j = 0; j &lt; thread_count-1; j++) sem_post(&amp;barrier_sem); &#125;else&#123; counter++; sem_postq(&amp;count_sem); sem_wait(&amp;barrier_sem); &#125;&#125; 该路障的重用可能会导致竞争条件 使用条件变量实现路障 条件变量是：允许线程在某个特定条件或事前发生前都处于挂起状态。当事件发生时，另一个线程可以通过信号来唤醒挂起的线程。 123456789101112131415void * Thread_work(...)&#123; .... /* barrier */ pthread_mutex_lock(&amp;mutex); counter++; if (counter == thread_count)&#123; counter = 0; pthread_cond_broadcast(&amp;cond_var); &#125; else &#123; while(pthread_cond_wait(&amp;cond_var, &amp;mutex) != 0); &#125; pthread_mutex_unlock(&amp;mutex); ....&#125; 读写锁使用读写锁，实现多线程共享的链表怎么实现？不难。 一个结论：在Insert，Delete操作十分少的时候，使用读写锁的性能更好。 缓存一致性书本拿了矩阵-向量乘法的例子，说明了缓存对程序性能的影响 对于8*8000000的矩阵，伪共享带来了很大的影响 关键：$y[0]-y[7]$在同一个缓存行中]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习2-MPI]]></title>
    <url>%2F2019%2F01%2F14%2F2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A02-MPI%2F</url>
    <content type="text"><![CDATA[HPC复习2-MPIOpenMPI 官方文档 mpich官方文档 这里是高性能计算课程-MPI部分的复习笔记，大概会有以下内容： MPI中的Hello world 常见的MPI函数 使用MPI实现梯形积分法 中级：MPI中的集合通信 中级：MPI中的派生数据类型 中级：MPI中的计时方法 算法：奇偶并行排序算法 算法：并行正则采样排序 MPI中的hello world12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;mpi.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;const int MAX_STRING = 100;int main(int argc, char** argv) &#123; char greeting[MAX_STRING]; int comm_sz; int my_rank; // Initialize the MPI environment MPI_Init(NULL, NULL); // Get the number of processes MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz); // Get the rank of the process MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank); if (my_rank != 0)&#123; sprintf(greeting, "Greetings from process %d of %d!", my_rank, comm_sz); printf("Hello world from ank %d\n",my_rank); MPI_Send( greeting, // strlen(greeting)+1, // strlen(greeting), MAX_STRING, MPI_CHAR, 0, 0, MPI_COMM_WORLD ); &#125; else &#123; printf("Greetings from process %d of %d!\n", my_rank, comm_sz); for (int q = 1; q &lt; comm_sz; q++)&#123; MPI_Recv( greeting, MAX_STRING, MPI_CHAR, q, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE ); printf("%s in %d\n", greeting, my_rank); &#125; &#125; // Finalize the MPI environment. MPI_Finalize(); return 0;&#125; 常见的MPI函数这6个MPI函数，可以完成一切任务 123456789101112131415161718192021222324int MPI_Init(int *argc, char **argv[]);// 进入MPI环境并完成所有的初始化工作int MPI_Finalize(void);// 从MPI环境中退出int MPI_Comm_rank(MPI_Comm comm, int *rank);// 获得当前进程在指定通信域中的编号int MPI_Comm_size(MPI_Comm comm, int *size);// 获得指定通信域中的进程数int MPI_Send( void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)// 发送消息到目标进程int MPI_Recv( void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status * status_p)// 从指定进程接受一个消息 使用MPI实现梯形积分法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include &lt;mpi.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;// 对这一个函数进行积分double f(double x)&#123; return x*x;&#125;double Trap( double left_endpt, double right_endpt, int trap_count, double base_len)/** * @brief 梯形积分法的串行实现 * * @param base_len 就是left_endpt与right_endpt之间分成trap_count份后，每一份的长度 * */&#123; double estimate, x; int i; estimate = (f(left_endpt) + f(right_endpt))/2.0; for (int i = 1; i &lt;= trap_count-1; i++)&#123; x = left_endpt + i*base_len; estimate += f(x); &#125; estimate = estimate*base_len; return estimate;&#125;void Get_input( int my_rank, int comm_sz, double * a_p, double * b_p, int* n_p)&#123; int dest; if (my_rank == 0)&#123; printf("Enter a,b,and n\n"); scanf("%lf %lf %d", a_p, b_p, n_p); for (dest = 1; dest &lt; comm_sz; dest++)&#123; MPI_Send(a_p, 1, MPI_DOUBLE, dest, 0, MPI_COMM_WORLD); MPI_Send(b_p, 1, MPI_DOUBLE, dest, 0, MPI_COMM_WORLD); MPI_Send(n_p, 1, MPI_INT, dest, 0, MPI_COMM_WORLD); &#125; &#125; else &#123; MPI_Recv(a_p, 1, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD,MPI_STATUS_IGNORE); MPI_Recv(b_p, 1, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD,MPI_STATUS_IGNORE); MPI_Recv(n_p, 1, MPI_INT, 0, 0, MPI_COMM_WORLD,MPI_STATUS_IGNORE); &#125;#ifdef DEBUG printf("in trap %lf, %lf, %d\n", *a_p, *b_p, *n_p);#endif // DEBUG&#125;int main(void)&#123; int my_rank, comm_sz, n=1024, local_n; double a = 0.0, b = 3.0, h, local_a, local_b; double local_int, total_int; int source; MPI_Init(NULL, NULL); MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank); MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_sz); Get_input(my_rank, comm_sz, &amp;a, &amp;b, &amp;n);#ifdef DEBUG printf("in main %lf, %lf, %d\n", a, b, n);#endif // DEBUG // 将积分区间分成n份 h = (b-a)/n; // 将n分区间，分到comm_sz个进程里，每个进程分到local_n个区间 local_n = n/comm_sz; local_a = a+my_rank*local_n*h; local_b = local_a+local_n*h;#ifdef DEBUG printf("local_a : %lf, local_b : %lf, local_n : %d", local_a, local_b, local_n);#endif // DEBUG local_int = Trap(local_a, local_b, local_n, h); if (my_rank != 0)&#123; MPI_Send(&amp;local_int, 1, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); &#125; else&#123; total_int = local_int; for (source = 1; source &lt; comm_sz; source++)&#123; MPI_Recv(&amp;local_int, 1, MPI_DOUBLE, source, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); total_int += local_int; &#125; &#125; if(my_rank == 0)&#123; printf("With n = %d trapezoids, out estimate\n", n); printf("of the integral from %f to %f = %.15e\n",a,b,total_int); &#125; MPI_Finalize();&#125; 中级：MPI中的阻塞与非阻塞通信1234567891011121314151617MPI_Send// normal sendMPI_Isend// begin a nonblocking sendMPI_Ssend// Blocking synchronous sendMPI_Bsend// send message wich user-provided bufferingMPI_Issend// Starts a nonblocking synchronous sendMPI_Ibsend// Starts a nonblocking buffered sendMPI_Rsend// Blocking ready sendMPI_Irsend// Starts a nonblocking ready send 12MPI_Irecv// Begins a nonblocking receive 中级：MPI中的集合通信涉及通信子中所有进程的通信函数成为集合通信（与点对点通信区分开） MPI中的集合通信，在树中介绍的主要有以下几个函数： 函数名 作用 MPI_Reduce 归约（可以用来求和等等,支持交换律和结合律的运算） MPI_Allreduce 所有进程都可以得到全局求和的结果 MPI_Bcast 广播，顾名思义 MPI_Scatter 0号进程读入整个向量，但只将分量发送给需要分量的其他进程 MPI_Gather 将其他进程的分量都收集到0号进程 MPI_Allgather 将每个进程desend_buf_p内容串联起来，存储到每个进程的recv_buf_p参数中 下面一个一个函数分别说明其参数情况。 123456789int MPI_Reduce( const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm); 12345678int MPI_Allreduce( const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, MPI_Comm comm) 1234567int MPI_Bcast( void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm) 12345678910int MPI_Scatter( const void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm) 12345678910int MPI_Gather( const void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm) 123456789int MPI_Allgather( const void *sendbuf, int sendcount, // local_n MPI_Datatype sendtype, void *recvbuf, int recvcount, // local_n MPI_Datatype recvtype, MPI_Comm comm) 中级：MPI中的派生数据类型 在MPI中，通过同时存储数据项的类型以及他们在内存中的相对位置，派生数据类型可以表示内存中数据项的任意集合。 在书本中，派生数据类型用在了，减少通信量上。 一般创建一个新的派生数据类型，需要进行以下的步骤： 调用MPI_Type_create_struct函数，创建派生数据类型 可使用MPI_Get_address辅助得到相对地址 调用MPI_Type_commit函数，允许MPI实现为了在通信函数内使用这一数据类型，优化数据类型的内部表示 使用结束后，调用MPI_Type_free函数释放额外的存储空间 函数原型12345678910int MPI_Type_create_struct(int count, const int array_of_blocklengths[], const MPI_Aint array_of_displacements[], const MPI_Datatype array_of_types[], MPI_Datatype * newtype);int MPI_Type_commit(MPI_Datatype * datatype_p);int MPI_Type_free(MPI_Datatype * datatype); 实例 中级：MPI中的计时方法 MPI_Wtime MPI_Barrier 1234567MPI_Barrier(comm);local_start = MPI_Wtime();.... local_finish = MPI_Wtime();local_elapsed = local_finish - local_start; 算法：并行奇偶交换排序奇偶交换排序关键思想：去耦的比较-交换 偶数阶段：以下数对进行比较-交换 $(a[0], a[1]), (a[2],a[3]), (a[4],a[5]),…$ 奇数阶段：以下数对进行比较-交换 $(a[1], a[2]), (a[3],a[4]), (a[5],a[6]),…$ 定理：n个值的列表，经过n个阶段后，该列表一定能够排好序。 并行化步骤： 将数据分到不同的进程之后，先本地进行一个qsort排个序 偶数阶段：进程0,1，进程2,3进行比较-交换数据 奇数阶段：进程1,2， 进程3,4进行比较-交换数据 算法：并行正则采样排序 数据初始化阶段：每个进程根据进程号与数据量，计算得到本进程所读取的数据范围，并从文件中直接读取。由于读取数据的步骤不需要进行通信分发，提高了程序运行的效率。 每一个进程对其本地的无序数据,长度为$local_n$的$local_buffer$数组进行串行快速排序，从而在每个处理器上都得到一个有序的序列$local_buffer$。 在每一个处理器上选取代表元素：每一个处理器从局部有序序列中选取第$w$，第$2w$，第$3w$,第$(comm_sz-1)w$共$p-1$个代表元素，其中$w=comm_sz/(p*p)$。 进程0收集每一个进程中得到的代表元素，从而具有了$(p-1)(p-1)$个代表元素，然后进程0对所有代表元素进行排序，选取第$comm_sz-1$，第$2(comm_sz-1)$，第$3(comm_sz-1)\ \cdots (comm_sz-1)(comm_sz-1)$个元素，这$comm_sz-1$个元素作为主元。 进程0将上一步中得到的$comm_sz-1$个主元$pivot_values$，分发到其余所有处理器上。 局部有序序列划分：每一个处理器根据这$comm_sz-1$个主元，将本地的$local_buffer$划分成$comm_sz$段。 有序序列的分发：在上一个步骤中的$comm_sz$段序列中，每一个处理器将本地的第$i$段发送给第$i$个处理器，最终处理器$i$拥有所有处理器的第$i$段。 最终排序：每个处理器对上一步中得到的$comm_sz$段有序序列进行排序，即为最终结果。 实例向量求和 块划分:简单的将连续N个分量所构成的块，分配到每个进程中。 循环划分:采用轮转的方式去分配向量分量 块-循环划分:用一个循环来分发向量分量所构成的块，而不是分发单个向量分量。 其他 在什么场景下必须使用消息标签？ 这段代码打算传送A的前32个字节进入X,传送B的前16个字节进入Y.但是,如果消息B尽管后发送但先到达进程Q,就会被第一个recv()接收在X中，使用标签就可以避免这种情况 MPI_Send与MPI_Recv的问题 Send的精确行为是由MPI实现决定的，MPI_Send可能有不同大小的缓冲区，在发送消息的时候，是使用缓冲区，还是直接阻塞等待发送完成，由“消息截止大小”决定。 启示：了解实际执行情况，不要做假设。 关于MPI_Reduce调用顺序 内存单元的名字与MPI_Reduce的调用匹配无关，函数调用的顺序决定了匹配方式。 ！！不可预测，可能b中存储的值将是$1+2+1=4$，而d中为$2+1+2=5$]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能计算基础-复习1-并行硬件与并行软件]]></title>
    <url>%2F2019%2F01%2F14%2F2019-01-2019-01-14-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80-%E5%A4%8D%E4%B9%A01-%E5%B9%B6%E8%A1%8C%E7%A1%AC%E4%BB%B6%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[HPC复习1-并行硬件与并行软件主要分为四部分： 背景介绍 超算硬件 超算软件 编写并行程序 背景介绍 冯·诺依曼结构 进程、多任务和线程 冯·诺依曼结构的发展 冯·诺依曼结构 包括主存，中央处理单元（控制单元，算术逻辑单元ALU），以及主存和CPU之间的互连结构 冯若依曼瓶颈：主存和CPU之间的分离 进程、多任务和线程 进程：是运行着的程序的一个实例 多任务：对同时运行多个程序的支持，可真并行，也可时间片轮转 冯诺依曼结构的发展 高速缓存： 是一片读写极快但是空间很小的存储区域 根据程序执行与数据访问行为的局部性，存储部分数据 目的：让数据存取的速度适应CPU的处理速度（简而言之就是加快存取速度） 虚拟内存 是一种内存管理技术 解决：所需内存超过物理内存下程序无法执行的问题，以及其他直接使用物理内存可能带来的问题 指令集并行：单处理器上的细粒度并行 流水线技术 多发射技术 硬件多线程 在处理器中多开辟几仹线程状态，当线程发生切换时，处理器切换到对应的线程状态执行，在瞬间即可完成，这种方式叫做硬件多线程 多种粒度的硬件多线程，可以了解一下 粗粒度：遇到长时间中断，切换线程 细粒度：逐个CPU周期轮流切换线程 同时多线程：多个线程的指令能够被同时发射 超算硬件主要有以下内容： 两类并行系统：SIMD，MIMD 互联网络 缓存一致性 两类并行系统 Flynn 分类法 根据指令流和数据流的概念对计算机的体系结构进行分类 SIMD 与MIMD 的最大区别 SMID 使用一个控制器来控制多个处理器，而MIMD系统使用多个控制器异步地控制多个处理器 SIMD 中所有进程/线程执行完全相同的指令操作，而MIMD系统使用不同进程/线程执行不同的指令 MIMD 共享内存 UMA结构（Uniform Memory Access） NUMA结构（Non-Uniform Memory Access） COMA结构（Cache-only Memory Access） 分布内存 互联网络 互联网络是：连接所有节点组成并行计算机的高速网络 两种互联网络： 共享内存的互联网络（CPU通过互联网络与所需的Memory相连） 总线（Buses） 交叉开关（Crossbars） 分布内存的互联网络 直接互联网络（两个节点直接相连） 环 环绕网络 超立方 间接互联网络（由开关网络负责处理节点之间的相连） 交叉开关（Crossbars） $\Omega$ 网络 参数： 延迟：是消息源开始収送消息到消息目的地接收到第一个字节的时间段。 带宽：是消息目的地接收第一个字节开始到完成数据接收，接收数据的速率。 理解：使用水龙头出水的时间来理解 延迟：打开水龙头到出水的时延 带宽：水龙头口的大小 缓存一致性 概念 指在含有多个Cache的并行系统中，数据的多个副本（因为没有同步更新）而造成的丌一致问题。 更新缓存所需协议（二选一） 写无效策略 写更新策略 缓存一致性协议（二选一） 监听总线协议 基于目录的协议 伪共享 现象：两个处理器上的线程，分别读取的两个不同的变量在同一个cache line里。 超算软件主要有以下内容： 共享内存如何协调？ 分布内存如何协调？ 混合编程 协调共享内存 动态线程，静态线程 不确定性 需要使用一些方法解决不确定性 互斥锁 忙碌等待 信号量 等等 线程安全 代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。 例子：strtok函数 协调分布内存 消息传递 单向通信（或称 远程内存访问） 消息传递中，一个进程必须调用一个发送函数，并且必须与另一个进程调用的接受函数相匹配 问题：任何通信都需要两个进程的显式参与 解决：单向通信中，单个进程调用一个函数，可从其他进程中得到对应的值来更新局部内存，或者使用自己的值更新远端内存。这种通信，只需要一个进程的参与计科。 分区的全局地址空间 编写并行程序主要有以下内容： 一般步骤 划分：大任务划分为小任务，使小任务可以并行执行。 通信：确定划分得到的小任务需要的通信。 集聚：如果小任务间有依赖关系，就把它们合并为一个任务。 映射：把小任务映射到丌同的迚程中，使得进程通信量最小且负载均衡。 并行程序设计 编辑运行 输入输出 性能 性能 计时 需要关注CPU时间与真实运行时间的差异。 加速比，效率 加速比：串行计算时间与并行计算时间的比值 $ \frac{T{serial}}{T{parallel}} ​$ 线性加速比：计算速度随进程线程数的增加呈线性增长 效率：加速比与进程数的比值 $ E = \frac{S}{P} = \frac{T{serial}}{p * T{parallel}} $ 需要了解到，并行是有额外开销的 阿姆达尔定律 加速比是有上限的，无论如何增大处理器数目，加速比也无法高于某个数 $T_{serial} = W_s + W_p$ $T_{parallel} = W_s + W_p/p$ $S = \frac{W_s + W_p}{W_s + W_p/p}$ 当$p \rightarrow $正无穷的时候，上式具有极限 可扩展性 同时增加问题规模和进程/线程数，并行程序的效率能基本保持丌变，就说这个程序是可扩展的。 强可扩展：增加进程/线程数，为了维持效率而增加的问题规模不大 弱可扩展：问题规模的增加的比率与进程/线程数增加比率一致（为了维持效率不变）]]></content>
      <categories>
        <category>High Performance Computing</category>
      </categories>
      <tags>
        <tag>High Performance Computing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统中的无层次命名]]></title>
    <url>%2F2019%2F01%2F12%2F2019-01-2019-01-12-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E6%97%A0%E5%B1%82%E6%AC%A1%E5%91%BD%E5%90%8D%2F</url>
    <content type="text"><![CDATA[分布式系统中的无层次命名今天整理了一下笔记，打算将无层次命名这一部分的笔记重新编辑一下，放到这里分享给大家。 命名系统-基本概念在分布式系统中，命名系统起着名称解析的作用，即，允许进程访问对应命名的实体。关于命名系统中的一些概念，这里需要弄清楚： 实体与访问点的关系 访问点是一个特殊的实体 通过访问点访问实体 实体可能具有多个访问点 实体的访问点可能会改变 名称：用于指向一个实体 位置无关的名称：独立于实体地址 地址：实体对应的某个访问点的名称 标识符：用于唯一标识实体，实体与标识符是一对一的关系，且不可重用 用户友好的名称：一般是字符串 为了解决：把名称和标识符解析成地址 的问题，需要： 名称到地址的绑定 无层次命名 无层次命名是一种与实体空间位置无关的，扁平化的一种命名方法，一般用做实体的标识符。 名称解析：只给定实体的标识符（常用标识符做非结构化或无层次的名称），定位该实体。 大体有四种方法： 简单方法 广播和多播 包含该实体所用标识符的消息会通过广播发送到所有机器上，请求每一套机器检查它是否拥有该实体（实例：ARP 地址解析协议） 转发指针（移动实体定位） 每个转发指针都已（客户端存根，服务器存根）对的形式实现，当对象从地址空间A移动到地址空间B时，它会将一个客户存根留在A中，并且在B安装一个应用它的服务器存根。移动的细节对客户是透明的，客户可以顺着转发指针形成的链来查找实体对应的当前地址。 两种策略： 直接向起始客户存根发送相应 按照转发指针的相反方向发送响应 基于宿主位置 所有与某主机地址的通信一开始都被转发到移动主机的宿主代理中。对移动主机来说，如果要转移到另一个网络，会获得一个新的地址，该转交地址要在宿主代理中注册 分布式散列表 主要解决问题：m位的标识符$k$，解析为$succ(k)$的地址 如何高效解决：在每一个节点上维护一个指状表 加入与退出： 节点p加入很简单，只需要请求$succ(p+1)$即可 更新指状表会比较复杂 分层方法 目录节点：维护目录下的域所有实体的位置记录 低级的只有低级域的位置记录，高级域有多个低级域的位置记录 查询实体：自底向上，如果目录节点没有某记录，那转发到父节点继续查询]]></content>
      <categories>
        <category>Distributed System</category>
      </categories>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F12%2Ftest-2018-hello-world%2F</url>
    <content type="text"><![CDATA[testtest imag test math$$ a^2 = b $$ test chinese这是中文。 换了个头像 发现可以在_posts文件夹下创建自己的文件夹，然后hexo是不会管你的文件夹的！继续测试。 使用 typora的话，设置图片根目录后可以很方便的复制粘贴图片。 写好了一个脚本这个脚本用来自动创建一个新页面，并且填写yml模板信息 测试脚注脚注是[1] 1.用来测试的脚注 ↩]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置博客]]></title>
    <url>%2F2019%2F01%2F12%2F2019-01-2019-01-12-%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[今天配置了一下博客。 本地仅维护markdown文件 通过git push，将markdown文件push到腾讯云服务器 云服务器中的远程git仓库触发hooks，cd到服务器的博客文件中，拉取最新博客文件，并执行hexo g -d 生成博客文件并发布 最重要的一个改变在于：本地不需要存储博客的配置文件，仅需维护内容即可，一切配置文件都存放在了云服务器上，而且网页静态文件的生成也放在了云服务器上。]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo配置评论系统]]></title>
    <url>%2F2019%2F01%2F12%2F2018-05-2018-05-06-hexo%E9%85%8D%E7%BD%AE%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[hexo 评论系统有这样的想法，为自己的博客弄一个评论系统。 不过由于时间精力的缘故，还没有去弄。 先放一下要弄评论系统可能需要的一些资料。 第三方的评论系统似乎都不太好使，打算自建 http://www.candura.us/posts/post-348/ https://wzfou.com/hashover/ https://zhuanlan.zhihu.com/p/26955370]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo中的评论系统]]></title>
    <url>%2F2019%2F01%2F11%2F2019-01-2019-01-11-hexo%E4%B8%AD%E7%9A%84%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[关于hexo的评论系统这里要推荐一个极简无后端的评论系统！！！ Valine 诞生于2017年8月7日，是一款基于Leancloud的快速、简洁且高效的无后端评论系统。理论上支持但不限于静态博客，目前已有Hexo、Jekyll、Typecho、Hugo 等博客程序在使用Valine。 官网是这一个：https://valine.js.org/ 使用感受到leancloud上创建一个应用，然后找到把appid和appkey填到hexo的config里就好了！别的什么都不用怎么配置，哇比其他的方便多了，特别是之前那一个已经没有人维护的gitment。 引用几个博客的链接： https://blog.csdn.net/esa_dsq/article/details/78626509https://xiaotiandi.github.io/publicBlog/2018-09-19-d196c9ad.html]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[立一个flag]]></title>
    <url>%2F2019%2F01%2F11%2F2019-01-2019-01-11-%E7%AB%8B%E4%B8%80%E4%B8%AAflag%2F</url>
    <content type="text"><![CDATA[test 目录就是让我用来随便测试的吧。 吐槽一下，现在考试进度 6/8，加油吧~ 我想测试一个图片]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BCNF与4NF]]></title>
    <url>%2F2018%2F11%2F01%2F2018-11-2018-11-01-BCNF%E4%B8%8E4NF%2F</url>
    <content type="text"><![CDATA[数据库关系模式的BCNF分解与4NF分解这两种分解看得我云里雾里，今早好不容易觉得看懂了，觉得要写成一篇blog记下来，不然以后回来再看的时候可能又要看半天才能看懂了o(╥﹏╥)o。 书本上说的会比较抽象，虽然这保证了定义和方法的准确性，但是要去理解实在是有点困难，我想，将我解答题目的过程放上来能帮助这几种分解的理解。 BCNF分解实例题目有这样的关系模式$r(A,B,C,D,E,F)$，其中该关系模式需要满足以下函数依赖： $ A \rightarrow BCD $ $ BC \rightarrow DE $ $ B \rightarrow D $ $ D \rightarrow A $ 分析原理 如何判断一个关系模式是否满足BCNF模式 书本P196最上面：一个最简单的判定方法，但不可用于分解后的关系模式的判定 书本P196中间：可用于分解后的关系模式的判定 这两种方法，我觉得后者会相对比较难理解，但是在实际题目中还是的确能够使用上的。 具体的定义书本上就有，这里也照抄一份： 第一种方法： 第二种方法： 实际操作就，按顺序一个函数依赖一个函数依赖的看就好了。 第一步分解目前的关系模式$r$还没有分解，就使用第一种方法来进行分析： 对于函数依赖$A \rightarrow BCD$来说，根据第一种方法，我先计算$A^{+} = ABCDE$，发现$A^{+}$并没有包含关系$r$中的所有属性（$ABCDEF$，少了个$F$），因此$A$不是关系模式$r$的超码。 这样子，我就根据函数依赖$A \rightarrow BCD$说明了关系模式$r$不属于BCNF，因此将原有的关系模式$r$分解为$ (r-BCD) \cup (A,BCD) $ 因此此步分解得到以下关系模式： $ r_1(A,B,C,D) $$ r_2(A,E,F) $ 检验第一步分解结果在第二步分解结果前，需要检验第一步的分解结果是否满足BCNF条件，注意到这两个关系模式是分解后产生的，原先的第一种用来判断关系模式是否属于BCNF的方法不能够再使用，后面均使用第二种方法。 先看关系模式$r_1(A,B,C,D)$。 第二种方法要求$r_1$中属性的每一个子集$\alpha$，确保$\alpha^{+}$（F下$\alpha$的属性闭包）要么不包含$r-\alpha$的任何属性，要么包含$r_1$的所有属性。 这里为遍历$r_1$中属性子集的过程对于属性$A$，$A^{+} = ABCDE$，包含了$r_1$的所有属性对于属性$B$，$B^{+} = ABCDE$，包含了$r_1$的所有属性对于属性$C$，$C^{+} = C$，不包含$r_1 - C$的任何属性对于属性$D$，$D^{+} = ABCDE$,包含了$r_1$的所有属性对于属性$E$，$E^{+} = E$，不包含$r_1 - E$的任何属性对于属性子集$AB，AC，AD，AE，BC，BD，BE，CD，DE$，属性闭包均为$ABCDE$，包含了$r_1$的所有属性对于属性子集$CD$，$CD^{+} = CD$，不包含$r_1 - C$的任何属性对于三个属性以上的属性子集，属性闭包均为$ABCDE$，包含了$r_1$的所有属性 综上，$r_1$满足BCNF条件。 再看关系模式$r_2(A,E,F)$: 这里为遍历$r_2$属性子集的过程对于属性$A$，$A^{+} = ABCDE$，而$r_2 - A = EF$，会发现$A^{+}$包含了$r_2 - A$中的属性$E$，且没有包含$r_2$的所有属性（如属性$F$） 找到了一个属性违反该条件，那么就可以证明有这样的一个函数依赖出现在$F^{+}$中： $$A \rightarrow (A^{+} - A) \cap r_2$$ 算一算，$A^{+} - A \cap r_2 = BCDE \cap AEF = E$ 因此便找到了这样的一个函数依赖$A \rightarrow E$，让$r_2$不满足BCNF 第二步分解上面找到了这样的一个函数依赖$A \rightarrow E$，让$r_2(A,E,F)$不满足BCNF，因此$r_2$可以这样子分解： $r_3(A, E)$ $r_4(A, F)$ 此步骤得到的分解结果为 $r_1(A,B,C,D)$$r_3(A, E)$$r_4(A, F)$ 检验第二步结果$r_1$上面已经检验过了，这里只需要检验$r_3$和$r_4$即可。 对于关系模式$r_3$： 对于属性$A$， $A^{+} = ABCDE$，包含了$r_3$的所有属性对于属性$E$，$E^{+} = E$，不包含$r_3 - E$的任何属性 对于关系模式$r_4$： 对于属性$A$，$A^{+} = ABCDE$，而$r_4 - A = F$，$A^{+}$不包含$r_4 - A$的所有属性对于属性$F$，$F^{+} = F$，不包含$r_3 - F$的任何属性 综上，关系模式$r_3$,$r_4$，都已经满足BCNF条件 最终结果已经检验过了，每一个关系模式都满足BCNF条件，因此，最终结果便是： $r_1(A,B,C,D)$$r_3(A, E)$$r_4(A, F)$ 3NF分解实例我觉得3NF比BCNF简单很多，不想写了hhh 4NF分解实例分解原理关于4NF，其实课本P201上已经说明了检验模式是否满足4NF的方法。 一种方法便是4NF的定义，定义可以好好看看书本，和BCNF的定义类似，但问题在于这一个定义无法用于分解后的关系模式中。 第二种方法可以用在分解后的关系模式，其实就是找到在分解后的关系模式上的限定$D_i$，然后对于该限定$D_i$里面的每一个依赖，都使用4NF的定义去检查是否满足条件。 题目$R = (A,B,C,G,H,I)$$F = {$$A \rightarrow\rightarrow B$,$B \rightarrow\rightarrow HI$,$CG \rightarrow\rightarrow H$$}$ 分解流程第一步分解使用第一种方法来判断，注意到多值依赖是一种比函数依赖更弱的依赖，因此这里我觉得较难判断关系模式$R$的超码，就暂且认为该关系模式中的每一个属性都不是超码。 因为$A \rightarrow\rightarrow B$满足，且$A$不是关系模式$R$的超码，因此分解$R$得到 $R_1(A,B)$$R_2(A,C,G,H,I)$ 判断第一步分解结果判断分解后的关系模式是否满足4NF条件，需要使用第二种方法，这里需要计算函数依赖和多值依赖的集合$D$在$R_1$和$R_2$上的限定。 判断1先判断关系模式$R_1(A,B)$，我通过如下方式寻找函数依赖和多值依赖的集合$D$在$R_1$上的限定$D_1$: $D^{+}$中所有只含有$R_1$中属性的函数依赖：无 所有形如$\alpha \rightarrow\rightarrow \beta \cap R_1$的多值依赖，其中$\alpha \in R_1$，且$\alpha \rightarrow\rightarrow \beta$ 属于$D^{+}$: 当$\alpha = A$，能够找到$A\rightarrow\rightarrow B$，还有$A\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后得到仅有$A\rightarrow\rightarrow B$在限定$D_1$中当$\alpha = B$，能够找到$B\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后发现没有多值依赖在限定$D_1$中 因此函数依赖和多值依赖的集合$D$在$R_1$上的限定$D_1$为${ (A\rightarrow\rightarrow B) }$。 接下来判断限定里面的依赖是否能够让关系模式$R_1$满足4NF条件。因为在关系模式$R_1$中仅有两个属性$A,B$，因此多值依赖$A\rightarrow\rightarrow B$是一个平凡的多值依赖。因此满足4NF条件。 判断2判断关系模式$R_2(A,C,G,H,I)$是否满足4NF条件。 同样是两个步骤，显示找到函数依赖和多值依赖的集合$D$在$R_2$上的限定$D_2$，然后在限定$D_2$中，遍历每一个依赖关系，寻找是否有使得$R_2$不满足条件的依赖关系，若有则不满足4NF条件，若无则该关系模式满足4NF条件。 在限定$D_2$中，我找到了这样的依赖关系$CG \rightarrow\rightarrow H$ 该依赖关系并不平凡，并且$CG$也不是$R_2$的一个超码 因此关系模式$R_2$不满足4NF条件，需要分解 第二步分解前面说到，根据依赖关系$CG \rightarrow\rightarrow H$，$R_2(A,C,G,H,I)$并不满足4NF条件。 因此进行分解得到以下关系模式 $R_3(C,G,H)$$R_4(A,C,G,I)$ 判断第二步分解结果是否满足4NF条件然后又需要判断$R_3$,$R_4$是否满足4NF条件。 判断$R_3$判断仍然是两步走，先寻找函数依赖和多值依赖的集合$D$在$R_3$上的限定$D_3$，然后遍历该限定$D_3$中的每一个依赖关系。 $D_3 = { (CG \rightarrow\rightarrow H) }$ $D_3$中仅有一个依赖关系，且$CG \rightarrow\rightarrow H$是一个平凡的多值依赖（因为$CG \cap H = R_3$），满足4NF条件 因此$R_3$满足4NF条件 判断$R_4$对$R_4(A,C,G,I)$一样的方法，寻找$D_4$,然后遍历$D_4$。这里我会更详细地说明限定$D_4$的计算方法 $D^{+}$中所有只含有$R_4(A,C,H,I)$中属性的函数依赖：无 所有形如$\alpha \rightarrow\rightarrow \beta \cap R_4$的多值依赖，其中$\alpha \in R_4$，且$\alpha \rightarrow\rightarrow \beta$ 属于$D^{+}$: 当$\alpha = A$，能够找到$A\rightarrow\rightarrow B$，还有$A\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后得到仅有$A\rightarrow\rightarrow I$在限定$D_4$中当$\alpha = C$，或$\alpha = H$ 或$\alpha = I$，均找不到符合条件的多值依赖当$\alpha = AC$,$\alpha = AH$,$\alpha = AI$,等等等，所有子集都找不到符合条件的多值依赖 因此$D_4 = { (A \rightarrow\rightarrow I) }$ 对着一个函数依赖我会发现，$A$并不是关系模式$R_4$的主键，因此该关系模式不符合4NF条件。 第三步分解上面找到了$A \rightarrow\rightarrow I$让关系模式$R_4$不满足4NF条件，因此分解成以下两个关系模式 $R_5(A,I)$ $R_6(A,C,G)$ 判断第三步结果是否符合4NF条件判断的过程依然是两步走 判断$R_5$计算得到$D_5 = { (A\rightarrow\rightarrow I) }$ 该依赖关系在$R_5$中是平凡的，因为$A \cap I = R_5$ 因此$R_5$满足4NF条件 判断$R_6$计算$D_6$: $D^{+}$中所有只含有$R_6(A,C,G)$中属性的函数依赖：无 所有形如$\alpha \rightarrow\rightarrow \beta \cap R_6$的多值依赖，其中$\alpha \in R_6$，且$\alpha \rightarrow\rightarrow \beta$ 属于$D^{+}$: 当$\alpha = A$，能够找到$A\rightarrow\rightarrow B$，还有$A\rightarrow\rightarrow HI$，使用$\beta \cap R_1$处理后得找不到符合条件的多值依赖当$\alpha = C$，或$\alpha = G$均找不到符合条件的多值依赖当$\alpha = AC$,$\alpha = AG$,$\alpha = CG$,等等等，能够找到$CG \rightarrow\rightarrow H$，但是在使用$\beta \cap R_6$后，依然是空集 因此，$D_6 = \emptyset$。 这个时候也可以说，对$D_6$中所有依赖，均满足4NF条件。 因此$R_6$满足4NF条件 最终分解的结果最终分解得到 $R_1(A,B)$$R_3(C,G,H)$$R_5(A,I)$$R_6(A,C,G)$ 感想总之就是严格按照课本定义，一点一点地推导和证明。 课本上的定义和方法实在是太过抽象了，我希望自己可以通过对这一些实例的详细探讨，对这一些分解方法有一个比较清晰的认识就好，昨天做作业的时候还是感觉自己迷迷糊糊的，现在就感觉，注意到了一些昨天没有注意到的细节，然后对书本这些理论的自洽性也有了一些比较深的理解，本来一些觉得诶好像证明不了的，回去一看看定义，哦原来是我对定义本身就不清楚……诸如此类的问题还是蛮多的.啊希望以后期末的时候对这一块的内容可以通过这篇博客更好地复习。]]></content>
      <categories>
        <category>Datebase</category>
      </categories>
      <tags>
        <tag>Datebase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于word-embedding的理解]]></title>
    <url>%2F2018%2F07%2F28%2F2018-07-2018-07-28-%E5%85%B3%E4%BA%8Eword-embedding%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[关于word-embedding的理解与pytorch实现在NLP中，计算机需要一种方法，表示一个单词。我们马上可以想到，可以直接使用ascii来保存呀，计算机也能够识别。 用ascii并不是不可以，但是，大家都知道，如果能够把单词表示成向量的形式，无论在怎样的数学处理中都会更加方便，即使是用ascii，最终也必须在计算机中有一种数学的方法表达，才能够完成后续的语义识别的工作。这种，为单词寻找到一种在计算机中表示的方法，可以称之为”Word embedding”(这里的定义是不完整的，后面继续补充。) 那么，什么办法可以表示一个单词呢？一种显而易见的办法是使用“one-hot encoding”,也就是说，每一个单词，在这样的一个向量中，都有一个独一不二的索引。对不同的词，便在不同的位置为1，其余的位置为0. 不妨将单词向量化后的那一个向量空间称之为单词空间？那么，对于单词空间中的每一个具有“one-hot encoding”性质的向量，我们都能够找到一个单词一一对应。 “one-hot encoding”已经解决了单词-单词空间向量的映射问题，但是，似乎不太好呢。大家都知道，每一个单词之间都有着或多或少的关联。one-hot encoding方法，将单词之间可能具有的关联信息全部都抛弃掉，只留下一一对应的性质，这样的单词嵌入方法，并不是特别的理想。 真正的word-embedding的定义摘自知乎 Embedding在数学上表示一个maping, f: X -&gt; Y， 也就是一个function，其中该函数是injective（就是我们所说的单射函数，每个Y只有唯一的X对应，反之亦然）和structure-preserving (结构保存，比如在X所属的空间上X1 &lt; X2,那么映射后在Y所属空间上同理 Y1 &lt; Y2)。那么对于word embedding，就是将单词word映射到另外一个空间，其中这个映射具有injective和structure-preserving的特点。 个人觉得这位网友说的还是很不错的。word embedding的关键在于两点 单射 结构保存（原本关联度较大的两个词，在新的向量空间中的相似度也应该较大？） word-embedding的输入输出输入：一个单词输出：这一个单词对应的向量 其中为了达到结构保存的目的，前期还需要很多的语料库进行训练。 pytorch中的word embeddingpytorch中预先已经提供了很多可用了“神经元层”，其中有一个nn.Embedding(a,b)就是专门用于完成“word embedding”工作的神经元层。该层的功能是：将一个具有$a$个单词的字典中的所有单词，映射到一个$b$维的向量空间中。 简单的代码如下： 1234567891011import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimtorch.manual_seed(1)word_to_ix = &#123;"hello": 0, "world": 1&#125;embeds = nn.Embedding(2, 5) # 2 words in vocab, 5 dimensional embeddingslookup_tensor = torch.tensor([word_to_ix["hello"]], dtype=torch.long)# print(lookup_tensor) # tensor([0])hello_embed = embeds(lookup_tensor) # 输入单词索引即可print(hello_embed) An Example: N-Gram Language Modeling([ word_i-2, word_i-1 ], target word) 官网上提供了一个根据上文预测下一个单词的神经网络以供参考。代码我就不放上来了。 参考 pytorch官方教程 https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html 一个知乎的回答：https://www.zhihu.com/question/32275069/answer/80188672]]></content>
      <categories>
        <category>Machine-Learning</category>
      </categories>
      <tags>
        <tag>Machine-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch初学感想]]></title>
    <url>%2F2018%2F07%2F27%2F2018-07-2018-07-27-pytorch%E5%88%9D%E5%AD%A6%E6%84%9F%E6%83%B3%2F</url>
    <content type="text"><![CDATA[pytorch初学感想一开始是通过莫烦的python教程来进行学习的。他的教程有一个特点，丰富的样例代码，加上对一些细节的讲解，让我能够很快的上手pytorch。不过，我看完，总觉得还缺点什么？有一些机制我始终没有想的特别明白，就像我对loss.backword() optimizer.step()， 这几个函数的作用始终一知半解，虽然大概知道一点，但是对使用pytorch实现的神经网络，还是有一些没法想清楚的地方。 官方教程pytorch的官方教程，有一篇我觉得写得特别好，可以说是给初学者稍微打开了pytorch背后封装的一些操作，让这一个黑盒，至少看起来不那么黑，自己写起代码来心中也有一些B数。 https://pytorch.org/tutorials/beginner/pytorch_with_examples.html 这个教程我最喜欢的一点，是它从一个使用numpy实现的两层神经网络（输入层不算一层）开始， 一点点改造成具有纯正“pytorch”风味的神经网络。这样子的教程，消除了我对pytorch封装的担心，内部的操作顿时清晰了很多。 使用numpy实现神经网络？当然可以了~ 下面把原教程的代码抄了过来，加上了自己的一点点注释。 1234567891011121314151617181920212223242526272829303132333435363738394041import numpy as np# N is batch size; D_in is input dimension;# H is hidden dimension; D_out is output dimension.N, D_in, H, D_out = 64, 1000, 100, 10# Create random input and output datax = np.random.randn(N, D_in)y = np.random.randn(N, D_out)# Randomly initialize weightsw1 = np.random.randn(D_in, H)w2 = np.random.randn(H, D_out)learning_rate = 1e-6for t in range(500): # Forward pass: compute predicted y # 这是矩阵相乘，(N行D_in列) * (D_in行H列)，算出来(N行，H列)的矩阵，其中第i行第j列的元素表示，第i个输入对应的第j个隐藏层神经元的输出 h = x.dot(w1) # 这里就是relu函数啦，相比起来我们喜闻乐见的relu函数，这里不过是用矩阵的方式，使用这个函数本身的定义来计算。查一下relu函数就清楚了 h_relu = np.maximum(h, 0) # 再一次矩阵线程，算出输出层神经元的输出值 y_pred = h_relu.dot(w2) # Compute and print loss # 差的平方再求和 loss = np.square(y_pred - y).sum() print(t, loss) # Backprop to compute gradients of w1 and w2 with respect to loss # 下面就是具体计算梯度的方法，这个计算方法如何得出来的，大概可以参考《机器学习》周志华书上的数学证明 P102-104 grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.T.dot(grad_y_pred) grad_h_relu = grad_y_pred.dot(w2.T) grad_h = grad_h_relu.copy() grad_h[h &lt; 0] = 0 grad_w1 = x.T.dot(grad_h) # Update weights w1 -= learning_rate * grad_w1 w2 -= learning_rate * grad_w2 如何将上面的神经网络pytorch化？pytorch为神经网络的编写，提供了一些方便的接口，用以替代上面的部分代码 numpy中的array不能够跑在GPU上计算，而与之功能类似的torch.tensor可以跑在GPU上 梯度的计算，pytorch中提供接口能够自动算 tensor中有一个grad成员用于存放梯度 tensor对象在进行运算的时候，会自动建造一张计算图（computational graph ） 在计算损失后，能够调用backwoard()，算出用于计算这个损失涉及到的有关tensor（requires_grad=True）的梯度，并存到对应的tensor的grad成员中。 优化器的选择：pytorch中提供了多种优化器，用以取代显式的使用梯度修改 神经网络模型的建立，能够通过高层接口，简单的增加层，而不用自己麻烦的定义参数矩阵再进行相乘 损失的计算：pytorch中同样提供了多种损失函数 以上每一个点，在原教程中都有对应的代码用来与原代码对比。最终，我们得到了下面的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import torch# N is batch size; D_in is input dimension;# H is hidden dimension; D_out is output dimension.N, D_in, H, D_out = 64, 1000, 100, 10# Create random Tensors to hold inputs and outputsx = torch.randn(N, D_in)y = torch.randn(N, D_out)# Use the nn package to define our model and loss function.model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out),)loss_fn = torch.nn.MSELoss(size_average=False)# Use the optim package to define an Optimizer that will update the weights of# the model for us. Here we will use Adam; the optim package contains many other# optimization algoriths. The first argument to the Adam constructor tells the# optimizer which Tensors it should update.learning_rate = 1e-4optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)for t in range(500): # Forward pass: compute predicted y by passing x to the model. y_pred = model(x) # Compute and print loss. loss = loss_fn(y_pred, y) print(t, loss.item()) # Before the backward pass, use the optimizer object to zero all of the # gradients for the variables it will update (which are the learnable # weights of the model). This is because by default, gradients are # accumulated in buffers( i.e, not overwritten) whenever .backward() # is called. Checkout docs of torch.autograd.backward for more details. optimizer.zero_grad() # Backward pass: compute gradient of the loss with respect to model # parameters loss.backward() # Calling the step function on an Optimizer makes an update to its # parameters optimizer.step() 代码其实少了很多，通过与原来numpy编写的神经网络对比，也更好的理解各个高层接口的作用。 我个人觉得，编写框架的人总是喜欢把高层接口控制得尽可能优雅，就如同现在我们所使用的pytorch一样，事实上，有了pytorch的优雅的高层接口 ，十多二十行足以编写一个可以玩一玩的神经网络。然而，作为初学者而言，我们总是很难把握高层接口的作用，在使用的时候总是很不踏实，可以说，对高层接口又爱又恨，万一出bug了呢，怎么改呀，高层接口帮我做了啥我也不知道呀。官方教程这样子从底层开始展示细节到使用高层接口替换的教程，恰巧将初学者在学习过程中的不安给打消了。不管怎么说，我觉得官方的教程写的棒棒哒！让我感觉自己在调用高层api的时候心安了不少:joy:。 自定义nn模块还有autograd函数？都可以都可以，我建议自己试多几把，这样子对这个框架也能够更加地熟悉。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch中的unsqueeze函数]]></title>
    <url>%2F2018%2F07%2F27%2F2018-07-2018-07-27-pytorch%E4%B8%AD%E7%9A%84unsqueeze%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[pytorch中的unsqueeze函数一直对pytorch中的unsqueeze不太理解，官方文档的解释是： Returns a new tensor with a dimension of size one inserted at the specified position. The returned tensor shares the same underlying data with this tensor. 其实说的已经很清楚了，但是在我搞懂这个问题前，一直没有看懂这段说明的意思，因此做了一些实验来验证自己的想法。将自己的感想放到博客上，以供以后忘记了再回看复习。 一句话解释这个函数的意思，就是 往原有的数据中，增加一个维度 增加的维度值，必须是1 实验验证随便弄了个这样的矩阵来进行实验 1234567891011arr = array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]], [[ 8, 9, 10, 11], [12, 13, 14, 15]]]) # In [53]: arr.shape# Out[53]: (3, 2, 4) 结果见下面的截图 对numpy中维度的理解https://flat2010.github.io/2017/05/31/Numpy%E6%95%B0%E7%BB%84%E8%A7%A3%E6%83%91/]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ftp服务器+内网穿透]]></title>
    <url>%2F2018%2F07%2F26%2F2018-07-2018-07-26-ftp%E6%9C%8D%E5%8A%A1%E5%99%A8-%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%2F</url>
    <content type="text"><![CDATA[花了一下下午时间，做了自己的ftp服务器。 配置具有多用户多权限多目录的ftp服务器 内网测试 买一个域名？绑定到云服务器上 使用frp完成内网穿透 几个比较重要的坑 必须使用被动模式 vsftpd的被动模式设置数据端口段，并使用frp进行转发 主要分为两个内容来记录一下这一次的配置。 配置多用户多权限多目录的ftp服务器考虑到自己需要去弄多个用户都可以登录并且还具有不同权限的ftp服务器，我在网上找到了这样的一个教程，然后自己在理解了这个教程的基础上，对一些指令进行了适当的改动。 http://forum.ubuntu.org.cn/viewtopic.php?t=368282 为了防止该网站gg，我记录一下。 我自己的配置我把有关用户的配置都放在了/etc/vsftpd里面，并且把一些重要的文件的权限设置为600，这样的话，就无法查看与数据库对应的用户名密码的文件。 还有一个坑vsftpd-500-oops-cannot-change-directory 关于这一个错误，可能有好几种原因。 我见过的有， 补上这一条指令，可能就可以了（ allow_writeable_chroot=YES 可能是对应的文件夹还没有创建（傻逼错误了这是） 内网穿透大概的配置其实还是挺简单的，frp本身就易用，然后我在这一次的配置中，使用到了supervisor对frp进程进行守护。 使用supervisor对frp进行守护https://diannaobos.com/post/535.html主要参考了这一篇博客来进行配置，注意到日志文件的输出也是在配置文件里面定义好的。 配置服务器端frps.ini 很贴心的提供了token，防止别人偷偷用自己的服务器做内网穿透 配置客户端注意客户端的token要和服务器端的一致就好 一个坑点在清楚ftp主动模式和被动模式之后，其实我们很容易发现，在使用一台外网服务器去做内网穿透后，我们如果使用主动模式访问ftp服务器，是会出问题的。 https://github.com/fatedier/frp/issues/219 主要参考了这一个issue解决了这个问题。 不过有一个显示，只能够使用被动模式访问ftp服务器，如果使用主动模式是完全行不通的。 访问注意了，如果使用域名访问的话只能够使用被动模式来访问，在命令行中，linux的ftp命令可以通过passive切换主被动模式，而window下好像没有被动模式？ 注意一点：使用域名的话，必须使用被动模式，而如果使用中大内网ip的话则必须使用主动模式，不能使用被动模式（原因有点复杂），不过中大内网速度飞快啊10mb/s]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[信号量应用实例]]></title>
    <url>%2F2018%2F07%2F13%2F2018-07-2018-07-13-%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[使用信号量解决这样的问题 某操作系统支持信号量机制，系统中有一组进程A、B、C、D和E共5个合作进程，它们中各有一个操作，分别记为a, b, c, d和e，这些操作需要按下面的时序推进：操作a完成后才可以开始操作b和操作c；操作b完成后才可以开始操作d，操作c和操作d完成后才能开始操作e。请在这5个进程的程序中描述如何利用信号量实现规定的同步，要求说明用到几个信号量，每个信号量的初值是什么。 一些说明使用信号量实现一些进程的按序执行，一般可以按照这样的做法。 若B进程必须等候A进程的进行，以下是简单的代码说明 123456789101112131415s a_finished = 0;void A()&#123; /* a */ V(a_finished);&#125;void B()&#123; P(a_finished); /* b */&#125; 这一道题使用到的信号量注意，使用的都是计数信号量 信号量名称 信号量作用 a_finished 将“a已完成任务”作为一种信号，给进程B，进程C领取 b_finished “b已完成任务”，告诉d进程 c_finished “c已完成任务”，告诉e进程 d_finished “d已完成任务”，告诉e进程 代码说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051s a_finished = 0;s b_finished = 0;s c_finished = 0;s d_finished = 0;s e_finished = 0;void A()&#123; /* a */ V(a_finished); V(a_finished);&#125;void B()&#123; P(a_finished); /* b */ V(b_finished);&#125;void C()&#123; P(a_finished); /* c */ V(c_finished);&#125;void D()&#123; P(b_finished); /* d */ V(d_finished);&#125;void E()&#123; P(d_finished); P(c_finished); /* e */&#125;void main()&#123; parbegin(A(),B(),C(),D(),E());&#125;]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用信号量解决互斥问题]]></title>
    <url>%2F2018%2F07%2F08%2F2018-07-2018-07-08-%E4%BD%BF%E7%94%A8%E4%BF%A1%E5%8F%B7%E9%87%8F%E8%A7%A3%E5%86%B3%E4%BA%92%E6%96%A5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[使用信号量解决同步问题信号量定义1234567891011121314151617struct semaphore&#123; //定义结构 int count; queueType *queue;&#125;s;void P(semaphore s) &#123; // P操作 s.count--; if (s.count&lt;0) Block(CurruntProcess, s.queue);&#125;void V(semaphore s) &#123;// V操作 s.count++; if (s.count&lt;=0) WakeUp(s.queue);&#125; 用信号量实现进程同步系统中的一些进程需要相互合作，共同完成一项任务。具体来说，一个进程运行到某一点时，要求另一伙伴进程为它提供消息，在未获得消息之前，该进程处于阻塞状态，获得消息后被唤醒进入就绪状态。 这里有一个例子是：司机与售票员之间的同步。只有当售票员关门了，司机才可以进行启动汽车，而且只有当司机到站停车了，售票员才能够开门。 信号量实现进程同步进程$P_I$将输入的数据写入缓冲区$B_1$,进程$P_C$读出$B_1$中的数据，完成计算，把结果写入缓冲区$B_2$进程$P_P$读出$B_2$中的结果，打印输出 这三个进程之间的同步要求有两点 先写后读（不能读空缓冲区） 未读完不能写（不能写非空缓冲区） 对于这个问题，使用信号量可以这样解决 12345678910111213141516171819202122232425262728293031semaphore empty1 = 1;semaphore full1 = 0;semaphore empry2 = 1;semaphore full2 = 0;// 对PI进程而言while (1)&#123; P(empty1); // 将数据写到B1 V(full1);&#125;//对PC进程而言while ( 1 ) &#123; P(full1); // 从B1中读取数据; V(empty1); // 计算; P(empty2); // 结果写到B2; V(full2);&#125; // 对PP进程而言while ( 1 ) &#123; P(full2); // 读取B2中的结果并输出到打印机; V(empty2);&#125; 生产者/消费者问题并发处理的最常见问题类型 问题描述 若干进程通过无限/有限的共享缓冲区交换数据 一组“生产者”进程不断写入 另一组“消费者”进程不断读出 共享缓冲区无限/共有N个 任何时刻只能有一个进程可对共享缓冲区进行操作 基于计数信号量的正确解决方案1234567891011121314151617181920212223242526272829semaphore n=0; /*缓冲区中的产品数*/semaphore s=1; /*互斥*/void producer() &#123; while (true) &#123; produce(); semWait(s); append(); semSignal(s); semSignal(n); &#125;&#125; void consumer() &#123; while (true) &#123; semWait(n); semWait(s); take(); semSignal(s); consume(); &#125;&#125; void main() &#123; parbegin(producer, consumer);&#125; 基于二元信号量的正确解决方案12345678910111213141516171819202122232425262728int n;Binary_semaphore s=1; // 用于控制缓冲区变量的互斥访问Binary_semaphore delay=0; // 用于确定能否访问缓冲区，如果缓冲区为空，阻塞消费者void producer() &#123; while (true) &#123; produce(); semWaitB(s); append(); n++; if (n==1) semSignalB(delay); semSignalB(s); &#125;&#125; void consumer() &#123; int m; semWaitB(delay); while (true) &#123; semWaitB(s); take(); n--; m=n; semSignalB(s); consume(); if (m==0) semWaitB(delay); &#125;&#125; 有限循环缓冲区的解决方案一种这样的思想：生产者在将产品放入缓冲区前，先申请一个空闲位置（空闲信号量-1），然后在将产品放入到缓冲区中，然后再申请增加一个产品。（感觉是一种比较保守的做法） 消费者也是采取了一种保守的做法。 1234567891011121314151617181920212223242526272829303132const int sizebuffer=Nsemaphore n=0; /*产品数*/semaphore s=1; /*互斥*/semaphore e=N; /*空闲数*/void producer() &#123; while (true) &#123; produce(); semWait(e); semWait(s); append(); semSignal(s); semSignal(n); &#125;&#125; void consumer() &#123; while (true) &#123; semWait(n); semWait(s); take(); semSignal(s); semSignal(e); consume(); &#125;&#125; void main() &#123; parbegin(producer, consumer);&#125; 写者/读者问题同步与并发机制设计的著名问题问题描述 有一个多个进程共享的数据区，有一些只读取这个数据区的进程(reader)和一些只往数据区中写数据的进程(writer) 必须满足下列条件： 任意多的读进程可以同时读这个数据区 一次只有一个写进程可以往数据区写 如果一个写进程正在往数据区中写，禁止任何读进程读数据区 读者优先信号量方案 一旦有一个读进程正在读，写进程就一直被阻塞 直到没有读进程在读了写进程才可以在写。 读者优先，写者可能饥饿 1234567891011121314151617181920212223242526272829303132/* program reader_and_writer */int readcount; semaphore x=1; // 用于保证readcount被正确更新semaphore wsem=1; // 用于实现互斥void reader() &#123; while(true) &#123; P(x); readcount++; // 如果本来没有进程在读，这是第一个进程，就需要防止该单元被写 if (readcount==1) P(wsem); V(x); READUNIT(); P(x); readcount--; // 如果没有进程在读了，这是最后一个进程，就需要释放这一个单元 if (readcount==0) V(wsem); V(x); &#125;&#125;void writer() &#123; while(true) &#123; P(wsem); WRITEUNIT(); V(wsem); &#125;&#125;void main() &#123; readcount=0; parbegin(reader(), writer());&#125; 写者优先信号量方案为了保证写进程优先，写进程声明想写时，不允许新的读进程访问该数据块。 一旦有一个写者要写，读者就无法读取，读者只能够等待所有写者写完才能够进行读取。 当写进程声明想写时，不允许有新的进程继续读 思路 读进程在一个队列上进行排队（信号量z） 信号量z初值设为1，这就意味着所有想要读的进程想要排队的时候，只有一个能够排到队头去获取读的权力 概括：通过信号量z，多个读者在队列中排队，并且每次只能够派出一名读者尝试获取读的权力 尝试获取读的权力（信号量rsem） rsem信号量，读者写者都在争取，写者获得了运行权限后，第一个写者会锁住“读的权力”rsem信号量，从而此时的读者无法获得读的权力，阻塞着 若此时仍有写者要来写，writecount的值会大于1，因此rsem不会被第一个写者立马释放。 实现了：一旦有一个写者要写，读者就无法读取，读者只能够等待所有写者写完才能够进行读取。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* program reader_and_writer */int readcount, writecount; semaphore x=1, y=1, z=1, rsem=1, wsem=1; /*信号量z：信号量x：控制readcount的更新-------------------------writecount：控制rsem的设置信号量rsem : 『读的权力』当有写进程准备访问数据区的时候，用于禁止所有的读进程信号量wsem：『写的权力』信号量y：控制writecount的更新*/void reader() &#123; while(true) &#123; // rsem表示『读的权力』，应该像一个二元信号量一样 // 有了z在rsem前面，那么rsem最多被读进程要一次，其他的进程都会在z上排队。 P(z); P(rsem); P(x); readcount++; if (readcount==1) P(wsem); V(x); V(rsem); V(z); READUNIT(); P(x); readcount--; if (readcount==0) V(wsem); V(x); &#125;&#125;void writer() &#123; while(true) &#123; P(y); writecount++; if (writecount==1) P(rsem); V(y); P(wsem); WRITEUNIT(); V(wsem); P(y); writecount--; if (writecount==0) V(rsem); V(y); &#125;&#125;void main() &#123; readcount = writecount = 0; parbegin(reader(), writer());&#125; 公平方案如何体现公平？ 读者/写者的公平方案是指：无论读者还是写者，都有可能获取到一个锁用以锁住文件访问权限。 12345678910111213141516171819202122232425262728293031323334void read-justice()&#123; while(1)&#123; p(q); p(rcountsem) if (rcount == 0) p(fsem) rcount++; r(rcountsem) v(q) ; // reading... p(rcountsem) rcount--; if (rcount == 0) v(fsem); v(rcountsem) &#125;&#125;void write_justice()&#123; p(q) ; p(fsem) ; v(q); // writing... v (fsem) ; &#125; 哲学家就餐问题信号量解决方案一这一种方案有死锁风险 123456789101112131415161718192021222324semaphore fork[5]=&#123;1,1,1,1,1&#125;;int i;void philosopher(int i) &#123; while (true) &#123; think(); P(fork[i]); P(fork[(i+1) mod 5]); eat(); V(fork[(i+1) mod 5]); V(fork[i]); &#125;&#125;void main() &#123; parbegin( philosopher(1), philosopher(2), philosopher(3), philosopher(4), philosopher(5) )&#125; 信号量解决方案二这里增加了一个服务员，这个服务员只允许四位哲学家同时进入餐厅。 123456789101112131415161718192021222324semaphore fork[5]=&#123;1,1,1,1,1&#125;;semaphore room=4;int i;void philosopher(int i) &#123; while (true) &#123; think(); P(room); P(fork[i]); P(fork[(i+1) mod 5]); eat(); V(fork[(i+1) mod 5]); V(fork[i]); V(room); &#125;&#125;void main() &#123; parbegin( philosopher(0), philosopher(1), philosopher(2), philosopher(3), philosopher(4) )&#125;]]></content>
      <categories>
        <category>Operating System</category>
      </categories>
      <tags>
        <tag>Operating System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scipy题目]]></title>
    <url>%2F2018%2F06%2F03%2F2018-06-2018-06-03-scipy%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[scipy题目（高级编程技术 week-13） 第一题 Least squares 关于这一道题，使用scipy库中的leastsq函数即可求解。 第一步：先生成可用的矩阵和向量在本题中，我需要先生成矩阵$A$，向量$b$，考虑到后期该问题需要有解，向量$b$不随机生成，而是先随机生成x，然后算出b。代码如下 123456789101112import scipy as spimport numpy as npimport matplotlib.pyplot as plt# 维数m = 20n = 10# 生成矩阵AA = np.random.normal(size=(m,n), scale=15, loc=10)# 生成假想的该问题应有的解xx = np.random.normal(size=n,scale=15, loc=10)# 生成该解对应的向量bb = np.dot(A, xx) 在生成了可用的数据后，便使用leastsq函数解决问题，代码如下 12345678910111213from scipy.optimize import leastsq# 问题求解初始向量x = np.ones(10)# 误差函数def error(xx): return np.dot(A, xx) - bx_result,cov_x = leastsq(error, x)print(x_result, cov_x)# 计算误差向量的范数norm_residual = np.linalg.norm(np.dot(A, x_result) - b)print(norm_residual) 运行以上代码后，可以得到下面的解： 第二题 Optimization求函数最大值，使用scipy自带的fmin函数即可，这里稍微转换一下，由于只有fmin这个函数可用，而我们找的又是最大值，我们就只需要给函数加个负数，就变成了求最小值，这样子就把问题转换过来了。下面是代码： 1234def func(x): return -(np.sin(x-2) * np.sin(x-2) * np.exp(-x**2))minimum = sp.optimize.fmin(func, 1)print(minimum) 求得的结果是 经过绘图检验，可见的确是在$x \approx 0.2162$左右这个点处取得最大值。 第三题 Pairwise distances 在scipy文档中，找到了这样的函数可以实现计算行之间的距离的功能：pdist 因此实现的代码如下： 1234567from scipy.spatial.distance import pdistm = 30n = 20X = np.random.normal(size=(n, m), scale=10, loc=10)Y = pdist(X, 'sqeuclidean')print(Y.shape)print(Y) 注意，这里需要说明的数，这里使用的是欧拉距离公式，因此在函数参数中有一个sqeuclidean的项。 文档内容可见 结果可见 经过检验，的确应该是190个数（毕竟 20 * 19 /2 )， 其余的结果也是正确的。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlibplot.pyplot的使用]]></title>
    <url>%2F2018%2F05%2F26%2F2018-05-2018-05-26-matlibplot-pyplot%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[matlibplot 相关题目在这节课中，老师给我们讲了python中matplotlib库的用法，基于这些，我完成了以下三道习题。 第一题 该题需要我们在$ [0,2] $这个区间内画出这个函数的图，并且增加一些适合的标签和题目。 1234567891011x = np.linspace(0,2,50)y = np.sin(x-2) * np.sin(x-2) * np.exp(-x**2)plt.figure(1)plt.xlabel("x")plt.ylabel("y")plt.ylim(-0.1, 1)plt.title(r"$f(x) = sin^2(x-2)e^&#123;-x^2&#125;$")plt.annotate('local max', xy=(0.22, 0.9), xytext=(0.13, 0.5), arrowprops=dict(facecolor='black', shrink=0.05))plt.plot(x,y)plt.show() 运行的结果可见下图 第二题这一道题的题目可见： 在这里，题目要求我们自己给出方程的$y = Xb+z$各个量的值，然后使用$X$和$y$去反过来估计出原来的$b$。 根据题目提示，此处为多元线性回归模型，使用最小二乘法即可，在scipy模块中有leastsq函数，可以用来寻找此种回归模型的解。于是我的代码如下： 1234567891011121314151617181920212223242526X = np.random.normal(loc=5,scale=5,size=(20,10))b = np.random.normal(loc=0,scale=5,size=10)z = np.random.normal(size=20)y = np.dot(X,b) + z# 初始向量b_e = np.ones(10)print(b_e)# 误差函数def error(p,xxx,yyy): return np.dot(xxx,p)-yyy# 最小二乘法b_e,cost=leastsq(error,b_e,args=(X,y)) plt.figure(2)plt.xlabel("index")plt.ylabel("value")plt.plot(b, 'rx', label="True coefficients")plt.plot(b_e, 'b', label="Estimated coefficients")plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)plt.axis([0,9,-10,10])plt.hlines(0,0,9 ,colors = "c", linestyles = "dashed")plt.show() 运行后，结果可见下图 第三题该题题面如下： 这一道题主要要求我们掌握关于直方图的绘制以及核函数密度估计的方法。 12345678data = np.random.normal(scale=100, size=10000)kernel = stats.gaussian_kde(data)full_data = np.linspace(-500,500,10000)est_data = kernel.evaluate(full_data)plt.figure(3)plt.hist(data, 30, density=True)plt.plot(full_data, est_data)plt.show() 运行的结果可见下图：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy实战]]></title>
    <url>%2F2018%2F05%2F20%2F2018-05-2018-05-20-Numpy%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[numpy实战（高级编程技术week 11）做题前 在这里，我使用了这样的代码来产生符合题目条件的矩阵 12345import numpy as npfrom scipy.linalg import toeplitzA = np.mat(np.random.normal(size=(200,500)))B = np.mat(toeplitz(np.random.normal(size=500),np.random.normal(size=500)))A,B 第一题 这里还是一些比较简单正常的计算，代码如下 12345a1 = A + Aa2 = A.dot(A.T)a3 = A.T.dot(A)a4 = A.dot(B)a1,a2,a3,a4 结果如下： 同时，根据题目要求，我还写了这样的一个函数，并且测试了一下。 123def t1(lamda): return A.dot(B-lamda*np.eye(500))t1(4) 结果如图所示 第二题 首先使用np.random.normal函数生成这样的向量，为了求解该方程，可以考虑方程左右两边同时乘上矩阵$B$的逆，即$x = B’b$。 123b = np.random.normal(size=(500,1))x = B.I.dot(b)x 结果如下 问题三：范数 这一道题主要考虑的是np.linalg.norm函数的使用。 查阅文档得知，该函数的原型为numpy.linalg.norm(x, ord=None, axis=None, keepdims=False)同时参数的功能如下表： 由此，可以写出这道题的代码 1234np.linalg.norm(A, ord='fro') # Frobenius normnp.linalg.norm(B, ord=np.inf) # infinity normnp.linalg.norm(B, ord=2) # biggest singular valuesnp.linalg.norm(B, ord=-2) # smallest singular values 结果可见 问题四 关于这个幂迭代法求解矩阵的特征向量，我使用了以下代码来实现。 12345678910111213141516def power_iteration(A, error): v_k = np.random.rand(A.shape[1]) v_k1 = np.random.rand(A.shape[1]) count = 0 while np.linalg.norm(v_k - v_k1) &gt;= error: v_k = v_k1 u_k1 = np.dot(A, v_k) m_k1 = np.max(u_k1) v_k1 = u_k1/m_k1 count += 1 return (np.max(u_k1), v_k1, count)power_iteration(np.array([[-4, 14, 0], [-5, 13, 0], [-1, 0, 2]]), 0.00000001)#Z = np.random.normal(size=(200,200))#power_iteration(Z, 0.000000001) 在进一步的测试中，验证了该程序的正确性。 我计算了$\begin{bmatrix} -4 &amp; 14 &amp; 0 \ -5 &amp; 13 &amp; 0 \ -1 &amp; 0 &amp; 2 \end{bmatrix} $该矩阵的特征值和特征向量，与自己算的值是一致的。见下图： 问题五 这里需要探寻$n$, $p$,还有最大奇异值之间的关系。从scipy的文档中找到关于求奇异值的函数：scipy.linalg.svd(C),其中第二个返回值就是奇异值列表。 12345678910111213141516171819202122from scipy import linalgdef get_singular_value(size, p): t = np.random.rand(size, size) &gt; p C = np.zeros((size,size)) C[t]=1 s_v = linalg.svd(C)[1] l_s_v = np.max(s_v) return l_s_vget_singular_valut(200,0.6)t = []for n in range(5,300): t.append(get_singular_value(n,0.6))plt.plot(range(5,300), t)t = []for n in np.linspace(0,1,30): t.append(get_singular_value(100,n))plt.plot(np.linspace(0,1,30),t)plt.show() 通过实验，得知，当n渐渐变大时，最大奇异值也在变大 当p变小的时候，最大奇异值变小，如下图 问题六 这里要写一个函数，去寻找数据A中最接近$z$的数，函数需要返回最接近的值，以下是代码实现。 12def find_nearest(A, z): return A[np.argmin(np.abs(A-z))] 以下是运行截图： 参考资料 wiki：https://en.wikipedia.org/wiki/Power_iteration numpy文档：https://www.numpy.org/devdocs/reference/]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git删除大文件]]></title>
    <url>%2F2018%2F05%2F19%2F2018-05-2018-05-19-git%E5%88%A0%E9%99%A4%E5%A4%A7%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[不作死就不会死，不应该，不应该把视频都放到git仓库中。 下面知乎中的命令给了我很大的帮助。 12345678910111213git filter-branch --force --index-filter 'git rm --cached --ignore-unmatch "这里是文件名匹配的地方！！" ' --prune-empty --tag-name-filter cat -- --allgit push origin --force --allgit push origin --force --tagsgit for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdingit reflog expire --expire=now --allgit gc --prune=nowgit count-objects -v https://www.zhihu.com/question/54419234]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ftp服务器的配置]]></title>
    <url>%2F2018%2F05%2F19%2F2018-05-2018-05-19-ftp%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[今天在自己的远程服务器上配置好了ftp服务器，有必要记录下来。 http://www.cnblogs.com/xiongpq/p/3384759.html 这个博客给了我很大的帮助。 注意有一个坑：配置文件每一行后面都不能够有空格，不然会发生读取配置文件错误的坑。]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F05%2F13%2F2018-05-2018-05-13-%E4%B8%AD%E5%BF%83%E6%8E%A7%E5%88%B6%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[中心控制的路由选择的实现 路由器 每一个路由器维护一个线程，这个线程用来与中心服务器维持连接 该线程定期发送本地链路信息给中心服务器 定期从中心服务器获取路由表，并用于替换本地路由表 服务器 服务器对每一个路由器的连接建立一个定时器 服务器上 主线程：定期从队列中取出链路信息，并更新路由表 链路信息：包括链路的存在，费用，以及某路由的下线 注意：主线程需要维护每一个路由器的路由表 有一个重点：邻接矩阵-&gt;某路由器路由表这个过程需要好好实现 其他线程： 维护一个与路由器的连接 定期发送路由表 将接收到的链路状态放入队列中供主线程使用用来更新路由表 如果一段时间没有接收到信息，将该路由器已下线的信息放入队列中 如何初始化路由器 配置文件里写好controller的ip 就行啦]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSPF协议]]></title>
    <url>%2F2018%2F05%2F13%2F2018-05-2018-05-13-OSPF%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[OSPF协议 http://www.cnblogs.com/sddai/p/5399482.html https://zh.wikipedia.org/wiki/%E5%BC%80%E6%94%BE%E5%BC%8F%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E4%BC%98%E5%85%88 https://www.qingsword.com/qing/596.html 线程1：维护与多个路由器之间的连接，并得知最新本地链路情况 线程2：接受包，判断是否需要转发和广播 维护 1. 与广播有关的信息，防止风暴 2. 网络拓扑数据库 报文类型 链路状态更新报文,广播 keepalive报文 全局拓扑数据交换报文？ 维护 拓扑数据库 1.类型1:Router LSA：每个路由器都将产生Router LSA，这种LSA只在本区域内传播，描述了路由器所有的链路和接口，状态和开销.]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RIP协议]]></title>
    <url>%2F2018%2F05%2F13%2F2018-05-2018-05-13-RIP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[最近在写路由选择协议相关的实现，这里放了一些有关RIP协议的细节。 RIP协议原理距离向量算法 https://wenku.baidu.com/view/09af0ecf5fbfc77da269b14f.html RIP报文格式]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[补充-物理层]]></title>
    <url>%2F2018%2F05%2F08%2F2018-05-2018-05-08-%E8%A1%A5%E5%85%85-%E7%89%A9%E7%90%86%E5%B1%82%2F</url>
    <content type="text"><![CDATA[这里主要放一些关于计算机网络-协议栈中物理层的相关笔记. 参考自谢希仁&lt;计算机网络&gt; 1 物理层的基本概念作用 在连接各种计算机的传输媒体上传输数据比特流. 屏蔽硬件的差异,使物理层上面的数据链路层感觉不到差异 特性 机械特性:指明接口所用接线器的形状和尺寸,引线数目和排列,固定和锁定转置等 电气特性:指明在接口电缆的各条线上出现的电压的范围。 功能特性:指明某条线上出现的某一电平的电压表示何种意义。 过程特性:指明对于不同功能的各种可能事件的出现顺序。 2 数据通信的基础知识2.1 数据通信系统的模型一个数据通信系统可划分为三大部分: 源系统 传输系统 目的系统 根据信号中代表消息的参数的取值方式不同,信号可分为两大类 模拟信号-代表消息的参数的趋势是连续的 数字信号-代表消息的参数的取值是离散的 使用时域中的波形表示数字信号时,代表不同离散数值的基本波形称为码元 2.2 信道的几个基本概念 信道:表示向某一个方向传送信息的媒体 带宽:信道最高信号频率-信道最低信号频率,单位是Hz 信道容量:信道能无错误传送的的最高比特率,bps 通信的双方信息交互的方式的分类 单向通信 双向交替通信 双向同时通信 基带信号需要通过带通调制,生成带通信号 来自信源的信号称为基带信号 基带信号往往含有较多的低频成分,许多信道是无法传输这种低频分量和直流分量的,于是就有了调制 调制的种类 基带调制(仅变换信号波形) 带通调制(使用载波,把基带信号的频率范围搬移到较高的频段,生成带通信号) 带通调制又分很多种:调幅,调频,调相,正交振幅调制 2.3 信道的极限容量数字通信优越性:接收端只需要从失真的波形识别出原来的信号,这种失真就对通信质量没有影响. 影响码元传输速率的因素 信道能够通过的频率范围 理想条件下(无噪声干扰),避免码间串扰,码元传输速率的上限值由奈氏准则得出 信噪比 带宽受限且有高斯白噪声干扰的信道的极限,无差错的信息传输速率由香农公式得出 3 物理层下面的传输媒体导引型传输媒体 双绞线 同轴电缆 光缆 多模光纤 单模光纤 非导引型传输媒体 短波通信 微波通信 4 信道复用技术频分复用,时分复用,统计时分复用波分复用码分复用重点掌握CDMA,码分多址技术TODO: 5 数字传播系统6 宽带接入技术6.1 ADSL6.2 光纤同轴混合网HFC6.3 FTTx 技术]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第五章链路层]]></title>
    <url>%2F2018%2F05%2F07%2F2018-05-2018-05-07-%E7%AC%AC%E4%BA%94%E7%AB%A0%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[《计算机网络》第五章 链路层笔记 链路层概述链路层提供的服务任一链路层的基本服务都是将数据报通过单一通信链路从一个节点移动到相邻接点。不过其提供的服务细节随着链路层协议的不同而变化。 成帧：链路层帧 链路接入：媒体访问控制协议（Medium Access Control）规定了帧在链路上传输的规则.TODO 可靠交付（可选） 差错检测和纠正 链路层在哪里实现？ 链路层是软件和硬件交接的地方。 差错检测和纠正技术 接收方的挑战是在：它只收到$D’$和$EDC’$的情况下，确定$D’$是否与初始的$D$相同. 差错检测和纠正技术使接收方有时但并总是检测出已经出现的比特差错,但还是可能会有未检出比特差错. 奇偶校验 单个奇偶校验位 二维奇偶校验TODO! TODO:前向纠错的优点 检验和方法因特网检验和(用于运输层) 循环冗余检测CRC编码的关键思想:发送方和接收方需要协商长度$r+1$的比特$G$(即生成多项式).对于一个给定的数据段$D$ 发送方要选择$r$个附加比特$R$,并将它们附加到D上,使得到的$d+r$比特用模2算术恰好能被$G$整除. 接收方用$G$去除接收到的$d+r$比特,如果余数为非零,就是出了差错,否则数据正确而被接受. 关键问题:发送方需要确定$R$,如何确定? $$\displaystyle R = remainder \frac{D \cdot 2^r}{G}$$ 注意都是模2算术 多路访问链路和协议有两种链路: 点对点链路,广播链路 多路访问协议的两个理想特性 当只有一个节点活跃时,该活跃节点具有$R$ bps的吞吐量 当有$M$个节点活跃时每个活跃节点的吞吐量接近$R/M$ bps 对于广播链路,需要解决多路访问问题. 通过多路访问协议规范多个节点在共享的广播信道上的传输行为 碰撞问题的解决. 信道划分协议 时分多路复用(TDM) 时间帧,时隙 频分多路复用(FDM) 码分多址(CDMA) 随机接入协议在随机接入协议中,一个传输节点总是以信道的全部速率(即$R$ bps)进行发送.当有碰撞时,设计碰撞的每个节点反复地重发它的帧,到该帧无碰撞为止.当一个节点经历一次碰撞时,它不必立即重发该帧,相反他再重发该帧之前等待一个随机时延. 时隙ALOHA书P299-P300 下面放一些较关键的内容. 假设:重点在于:节点是同步的,每个节点都知道时隙何时开始. 节点的行为 当节点有一个新帧需要发送时,它等到下一个时隙开始并在该时隙传输整个帧 如果没有碰撞,该节点成功地传输它的帧从而不需要考虑重传 如果有碰撞,会在时隙结束前检测到碰撞,并在后续的每个时隙中以概率$P$重传该帧,直到该帧无碰撞地传输出去. 效率的计算(注意思考推导过程)对于有N个活跃节点的局域网中: 计算任意一个节点成功传送的概率:$p*(1-p)^{N-1}$ 最大效率为:$Np*(1-p)^{N-1}$ $N$取极限,最大效率为$\frac{1}{e}$,如何证明就完全是数学问题了. 纯ALOHA与时隙ALOHA不同在于非时隙的,完全分散不同步的 最大效率的计算P301 载波侦听多路访问(CSMA)和下面的放在一起了 具有碰撞检测的载波侦听多路访问(CSMA/CD)特性 载波侦听:如果节点检测到信道有来自其他节点的帧正在传送,则等待一段时间在检测. 碰撞检测:节点在进行传输的时候仍然保持侦听,若检测到其他节点传输帧,则停止传输,等待随机时间量后再传输 等待随机时间量的确定:二进制指数后退 性能 信道传播时延:信号从一个节点传播到另一个节点所花费的时间 该传播时延越长,载波侦听节点不能真听到网络中另一个节点已经开始传输的机会就越大 CSMA/CD效率:当有大量的活跃节点,且每个节点都有大量的帧需要发送时,帧在信道中无碰撞地传输的那部分时间在长期运行时间中所占的份额.TODO: 轮流协议 轮询协议 主节点以循环的方式轮询每个结点,告诉每个结点可以传输的帧的最大数量 令牌传输协议 实例 DOCSISTODO: 交换局域网链路层寻址和ARPMAC地址 与局域网相连的每个接口都有一个唯一的MAC接口 适配器接收到一个帧时,将检查该帧的目的MAC地址是否与它自己的MAC地址匹配,如果匹配就提取数据包向上传递,如果不匹配就丢弃. 特例是MAC广播地址:48个连续的1组成的字符串 地址解析协议ARP作用:网络层地址(如IP地址)与链路层地址(MAC地址)之间的转换 书P310 发送一个IP包的时候,需要将其封装成一个链路层帧,这时候就需要对方的MAC地址 获取MAC地址 在ARP表中有对应项的时候,直接从ARP表中取 ARP表没有对应项的时候,发送方构造ARP分组并使用广播MAC地址封装成链路层帧广播之,等待一个响应ARP分组,从中取得并更新ARP表 需要注意的事情 查询ARP报文是在广播帧发送的,响应ARP报文是在一个标准帧中发送的 ARP分组中具有的字段: 发送数据报到子网外我觉得这个要自己学会分析. 以太网 以太网帧结构 以太网技术 链路层交换机交换机自身对于子网中的主机和路由器是透明的. 交换机转发和过滤 借助于交换机表 当一台交换机安装配置好之后，其工作过程如下： 收到某网段（设为A）MAC地址为X的计算机发给MAC地址为Y的计算机的数据包。交换机从而记下了MAC地址X在网段A。这称为学习（learning）。 交换机还不知道MAC地址Y在哪个网段上，于是向除了A以外的所有网段转发该数据包。这称为泛洪（flooding）。 MAC地址Y的计算机收到该数据包，向MAC地址X发出确认包。交换机收到该包后，从而记录下MAC地址Y所在的网段。 交换机向MAC地址X转发确认包。这称为转发（forwarding）。 交换机收到一个数据包，查表后发现该数据包的来源地址与目的地址属于同一网段。交换机将不处理该数据包。这称为过滤（filtering）。 交换机内部的MAC地址-网段查询表的每条记录采用时间戳记录最后一次访问的时间。早于某个阈值（用户可配置）的记录被清除。这称为老化（aging）。 https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E4%BA%A4%E6%8F%9B%E5%99%A8 虚拟局域网认识到以太网帧中新添加的802.1Q标签的作用. 链路虚拟化多协议标签交换MPLS:在基于分组交换的网络中实现的虚电路系统 数据中心网络 等级拓扑 全连通拓扑]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
      <tags>
        <tag>Computer Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas数据处理笔记]]></title>
    <url>%2F2018%2F05%2F06%2F2018-05-2018-05-06-Pandas%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Pandas 数据处理https://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook-merge 其实官网教程还是讲的很清楚的，下面就是放一些我一开始没有理解的特别好的地方，以提醒自己。 没理解好应该是因为我没有学过数据库吧emmmm。。。。 表格的合并merge()方法关于表格的合并这一块，一开始理解了蛮久才懂。下面先放一个例子吧。 1234567891011121314import pandas as pdimport numpy as npimport matplotlib.pyplot as pltdf = pd.DataFrame(data=&#123;'Area' : ['A'] * 5 + ['C'] * 2, 'Bins' : [110] * 2 + [160] * 3 + [40] * 2, 'Test_0' : [0, 1, 0, 1, 2, 0, 1], 'Data' : np.random.randn(7)&#125;)print(df)df['Test_1'] = df['Test_0'] - 1print(df)# df2 = pd.merge(df, df, left_on=['Test_0'], right_on=['Test_1'],suffixes=('_L','_R'))df2 = pd.merge(df, df, left_on=['Bins', 'Area','Test_0'], right_on=['Bins', 'Area','Test_1'],suffixes=('_L','_R'))print(df2) 通过理解这一个例子，我总算是明白了on : Columns (names) to join on.的意思，下面放分析过程吧。 第一个print，第二个print，相必都非常好理解。 对于第三个print，为什么输出了这样的表格呢？要理解这个，必须明白理解on参数的意思。 上面使用了left_on 和 right_on两个参数，指明了需要合并的列。 用这些列来合并两个表格，那其他的列便会作为需要合并的数据，分别在列名后加上后缀，将这些数据放到对应的index处。 问题在于：pandas如何知道这个数据该放到哪一行？ 如果将这个合并过程，看做重新创建一个表格，我们可以从确定表格的两个关键：索引，数据分别分析 合并后新的表格，每一个项应该准确的对应一个索引，这个索引的创建由on参数决定。上面中的left_on,right_on,其实我们可以这样想：在默认的inner模式下， 当right_on这些列中的元素与left_on这些列中的元素都相等，这些列中的元素便可以作为一个索引 那么这个索引对应的数据有哪些呢？数据从不做索引的列中取得。 使用这个索引，在原来的left的表中不做索引的列中找到对应的项，加到新表格该项的后面去 在right表中同理。 我觉得写得好像有点难理解？ on参数决定的是在合并过程中作为索引找到对应数据的项 最后一句话总结大概是这样吧，我总算是理解了on参数的意义。 建议多练习，多去改变参数试一下，心里就很清楚了。]]></content>
      <categories>
        <category>Data Analysis</category>
      </categories>
      <tags>
        <tag>Data Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test_git_hook]]></title>
    <url>%2F2018%2F05%2F06%2Ftest-2018-05-06-test-git-hook%2F</url>
    <content type="text"><![CDATA[测试一些githook test success! 当我push的时候，就会将网站自动部署到我宿舍的服务器中。 ! 可以直接push到我的服务器，不需要经过github 再试一下，ok 出现了一点小问题 我的主页的连接的链接没有更新 测试了一下，typora可以复制富文本中的图片，可以可以。 可以在_posts文件夹下创建自己的文件夹，然后hexo是不会管你的文件夹的！继续测试。]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas入门]]></title>
    <url>%2F2018%2F05%2F04%2F2018-05-2018-05-04-pandas%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[pandas 功能介绍以及入门材料指引pandas给我们提供了以下功能。 读取文件中的数据，并且支持常见的格式，如json，csv 灵活的行选择和列选择 列：有两种方法，一种是使用字符串索引，另一种是直接. 行：有数字索引和字符串索引，字符串索引有各种过滤器可设置。 对于表格中的值 支持一些过滤方法，用于将表格中满足特定条件的数据提取出来，生成新的表格 可以对值进行简单的处理，如value_counts()方法 groupby()方法：将一列中含有同样值的行合并起来，合并后其他行的处理方法有很多种（如min,max,mean,sum等） 封装了matplotlib的功能，支持常见的画图 入门材料本来想写一些入门材料，想到网上入门材料多的是，其实并没有这个必要。 直接放一些入门材料的链接总比自己写的入门材料靠谱。 也方便自己以后参考。 首先得看这个：https://github.com/jvns/pandas-cookbook 该代码仓库有代码还有对应的数据，可以边看教程边练习 该教程主要以实例练习为主，先提出一个需求（如要实现什么功能），然后再教程中穿插讲解各个函数的用法，最后实现功能 好评！ 当然是pandas 官方 document了，https://pandas.pydata.org/pandas-docs/stable/ pandas官方的document里面有一个 10 Minutes to pandas,如果看了上面那个教程对pandas有了初步的了解，就可以再看看这个，了解更多pandas的内置函数的用法 https://pandas.pydata.org/pandas-docs/stable/10min.html 这个也可以平时用作速查panda常用函数。 其他的我觉得需要用就再查文档就好。]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-565]]></title>
    <url>%2F2018%2F05%2F03%2F2018-05-2018-05-03-leetcode-565%2F</url>
    <content type="text"><![CDATA[leetcode 565题目链接可见https://leetcode.com/problems/array-nesting/description/ 题目A zero-indexed array A of length N contains all integers from 0 to N-1. Find and return the longest length of set S, where S[i] = {A[i], A[A[i]], A[A[A[i]]], … } subjected to the rule below. Suppose the first element in S starts with the selection of element A[i] of index = i, the next element in S should be A[A[i]], and then A[A[A[i]]]… By that analogy, we stop adding right before a duplicate element occurs in S. 12345678910111213Example 1:Input: A = [5,4,0,3,1,6,2]Output: 4Explanation: A[0] = 5, A[1] = 4, A[2] = 0, A[3] = 3, A[4] = 1, A[5] = 6, A[6] = 2.One of the longest S[K]:S[0] = &#123;A[0], A[5], A[6], A[2]&#125; = &#123;5, 6, 2, 0&#125;Note:N is an integer within the range [1, 20,000].The elements of A are all distinct.Each element of A is an integer within the range [0, N-1]. 题目分析这里题目要求的是：返回一个最大集合的长度。其中这个集合需要满足的条件如题目所示。 仔细分析这个集合的特点，若一个数字在这样的一个集合中，这个集合内的元素必然连成一个环。 如题目的示例，可构成这样的一个环 可知数组中的所有元素最后必定能够划分为独立的M个环，现在的问题就是求最大的环的长度了。 毫无疑问，我需要遍历每一个元素。 若这个元素所在的环我已经算过了，那我就直接返回这个环的长度 若这个元素所在的环我没有算过，那我就算一算 现在的问题是，对一个元素，我如何知道它所在的环被算过？知道被算过我又如何找到对应的环的长度？ 这就需要我先清楚使用什么数据结构来存储我的计算结果。 当一个元素我没有计算过的时候，我通过一个集合存放当前环的元素，循环将下一个元素放入集合中，直到下一个元素已经在集合中。此时我们便计算得出了一个环的长度，并且这个环里的所有元素我以集合的方式存储进来。 我使用一个额外的数组存放每一个数组对应的环的长度，在计算一个环的长度后，我可以将环内的所有元素在数组中对应的位置的值置为环的长度，此后我便可以通过直接访问该数组的方式来得到环的长度，若为0，表示没计算过，那就去算。 代码展示123456789101112131415161718192021222324252627class Solution: def arrayNesting(self, nums): """ :type nums: List[int] :rtype: int """ self.nums = nums self.lens = [0 for _ in range(len(nums))] max_len = 0 for i in range(len(nums)): cur_len = self.get_len(self.nums[i]) if max_len &lt; cur_len: max_len = cur_len return max_len def get_len(self, num): if self.lens[num]: return self.lens[num] loop = set() loop.add(num) cur_num = num while (self.nums[cur_num] not in loop): loop.add(self.nums[cur_num]) cur_num = self.nums[cur_num] for i in loop: self.lens[i] = len(loop) # print(loop) return len(loop) 这个方法似乎还不够快,其实想了一下，没有必要用集合。 优化这里放一个大神的代码参考，简洁，优雅。 123456789101112131415class Solution(object): def arrayNesting(self, nums): """ :type nums: List[int] :rtype: int """ ans, step, n = 0, 0, len(nums) seen = [False] * n for i in range(n): while not seen[i]: seen[i] = True i, step = nums[i], step + 1 ans = max(ans, step) step = 0 return ans 这个代码beat了84.44%的python3 solutions。]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode442]]></title>
    <url>%2F2018%2F05%2F03%2F2018-05-2018-05-03-leetcode442%2F</url>
    <content type="text"><![CDATA[leetcode 442(高级编程技术 week9-1)原题可见：https://leetcode.com/problems/find-all-duplicates-in-an-array/description/ 题目Given an array of integers, $1 ≤ a[i] ≤ n$ (n = size of array), some elements appear twice and others appear once. Find all the elements that appear twice in this array. Could you do it without extra space and in O(n) runtime? 123456Example:Input:[4,3,2,7,8,2,3,1]Output:[2,3] 题目分析仔细看题，会发现一个很明显的提示： $$1 &lt;= a[i] &lt;= n$$ 看到这个，基本就可以确定使用类似于桶排序的方式记录每一个元素的个数，又考虑到题目给的数组中的数字最多也只会出现两次，所以就设置为如果只要某一个桶大于1，就将该桶对应的数字放进答案中。 代码展示12345678910111213class Solution: def findDuplicates(self, nums): """ :type nums: List[int] :rtype: List[int] """ ans = [] tong = [0 for _ in range(len(nums))] for i in range(0,len(nums)): tong[nums[i]-1] += 1 if tong[nums[i]-1] &gt; 1: ans.append(nums[i]) return ans]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode665]]></title>
    <url>%2F2018%2F05%2F02%2F2018-05-2018-05-02-leetcode665%2F</url>
    <content type="text"><![CDATA[Leetcode 665题目描述Given an array with n integers, your task is to check if it could become non-decreasing by modifying at most 1 element. We define an array is non-decreasing if array[i] &lt;= array[i + 1] holds for every i (1 &lt;= i &lt; n). 题目分析我们要做的是：判断一个数组：能否至多只移动一个数字，就能够使得该数组变为不减数组。 来思考符合题目要求的数组应该具有怎样的特征？由于题目要求不降数组，我们可以先遍历数组，将每个数与它右侧的数进行比较，若发生了“降”，则记录降的次数加1。 首先，已经有序，不降的数组显然是满足题目要求的，此时数组中“降”的次数为0。（由于这一个一开始没有注意到，结果搞了半天都没有AC） 其次，如果这一个数组可以通过只移动一个数字的方式就能恢复成不降序列，该数组发生“降”的次数必然是1，如果不是1的话，假设是2，那么就有两个位置都发生了“降”的情况。这时候如果仅仅移动一个数字，只可能将一个“降”消去，但是另一个降是不可能消失的。 因此，我们先确认，满足这样的数组的一个必要条件是dec_time == 0，这个在代码中可以了解他的意思。 但是这样的条件还不够，我们仍然可以找到这样的数组，它满足dec_time == 0，但是仅移动一个数字是不能够将数组恢复成不降序列的。如下面的例子： $$[4,5,6,7,1,2,3,4]$$ 我们可以进一步思考符合题目要求的数组需要满足的特征。仅移动一个数组便能恢复，说明该数组只有一个数字是无序的，并且将这个数字从数组中拿出后，新的数组应该要保持有序不降。很显然，我们现在的必要条件，并不能保证新的数组仍能有序不降。 在计算dec_time时，我们可以找到数组中第一个降序的数对的位置。设这个数对中较大的数的索引为index。因为现在的条件，并不足以让我们判断失序的两个数中是哪一个数导致了数组的失序，这时候可以将这样的数组分成两类来讨论： 失序的数比周围的数大 失序的数比周围的数小 情况1：大对于失序的数比周围的数大的情况，那么这个时候，失序的数应该是索引index对应的数字，那么当我将这个数字从数组中拿出来时，这个数组应该是不降的，因此我们得到 $$array[index-1] &lt;= array[index+1]$$ 情况2：小对失序的数比周围的数小的情况，这时我们可以判断失序的数应该是索引index+1对应的数字。同样由于新数组是不降的，因此得到： $$arrry[index] &lt;= array[index+2]$$ 将以上的情况判断后，再将一些边界条件处理一下（如失序的数位于数组首尾的情况），就可以完成这一道题目了。 代码展示12345678910111213141516171819202122class Solution: def checkPossibility(self, nums): """ :type nums: List[int] :rtype: bool """ dec_time = 0 index = 0 for i in range(0, len(nums)-1): if nums[i] &gt; nums[i+1]: dec_time += 1 index = i if dec_time == 0: return True if dec_time == 1: if index == 0 or index == len(nums)-2: return True if nums[index-1]&lt;=nums[index+1]: return True if nums[index] &lt;= nums[index+2]: return True return False 感想卡了很久，后来发现自己没有处理数组原本就有序的情况，傻逼了。]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode561]]></title>
    <url>%2F2018%2F05%2F02%2F2018-05-2018-05-02-leetcode561%2F</url>
    <content type="text"><![CDATA[leetcode 561 习题解答原题网址见 https://leetcode.com/problems/array-partition-i/description/ 题目描述Given an array of $2n$ integers, your task is to group these integers into n pairs of integer, say ($a_1$, $b_1$), ($a_2$, $b_2$), …, ($a_n$, $b_n$) which makes sum of min($a_i$, $b_i$) for all i from 1 to n as large as possible. 题目分析这里要求对$2n$个数字进行配对，并且对每一对数字，取出他们中的最小者，并且对这些最小者进行求和得出最大的和。 求最大的和，这是这道题最关键的突破点。如何在两两取最小值的情况下得出尽可能大的和呢？ 注意到样例，1，3，4，2这四个数字中，我们来探究(1,2)(3,4)与(1,3)(2,4)这两种不同的组合的差别。 (1,3)之所以是比(1,2)这个组合要差，一个很重要的原因是在(1,3)中取最小值的时候，从3到1，损失了2，而相比起这个，(1,2)只损失了1。这里损失的减少，带来的直接好处就是最后和能尽可能大。 因此，为了和尽可能大，我们要做的是，每一对数中的两个数之间的差要尽可能小，这样子求和加起来的时候损失就能够达到最小，从而求和最大，而能够让两个数之间的差尽可能小的排列很明显，一定是按序排好的情况。 代码展示1234567891011class Solution: def arrayPairSum(self, nums): """ :type nums: List[int] :rtype: int """ sort_nums = sorted(nums) s = 0 for i in sort_nums[::2]: s += i return s 这里用到了一个切片的技巧，减少了很多代码量。sort_nums[::2]能够做到从原有的列表中隔一个取一个，这样子就必然能够取到每对数中最小的那一个数。]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openMP编程]]></title>
    <url>%2F2018%2F05%2F02%2F2018-05-2018-05-02-openMP%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[OpenMP编程模型简述如图所示 格式12345#pragma omp somedirective clause(value,othervalue) &#123; parallel statement 1; parallel statement 2; &#125; 并行模式说明在OpenMP中有两种并行模式 SPMD模型：创建一系列新的线程，这些线程执行的代码段相同 MIMP模型：为了完成一个任务，创建一系列新的线程，主线程将工作分配给这一系列新的线程（也就是说这些线程执行的代码段由OpenMP决定，并不一致） 并行模式之SPMD模型SPMD模型新建的线程会并行地运行下面花括号扩住的代码段，并且每一个线程运行的代码相同。1234#pragma omp parallel&#123; // this is executed by a team of threads&#125; 于是，在这里如何做任务分配呢？可以通过opm_get_thread_num获取线程号来判断自己应该运行的指令。例：使用三个线程计算 $result = f(x)+g(x)+h(x)$. 12345678double result,fresult,gresult,hresult;#pragma omp parallel&#123; int num = omp_get_thread_num(); if (num==0) fresult = f(x); else if (num==1) gresult = g(x); else if (num==2) hresult = h(x);&#125;result = fresult + gresult + hresult; 关于OpenMP在这过程中完成的工作，教程上讲的很详细，摘录一下。 This code corresponds to the model we just discussed: Immediately preceding the parallel block, one thread will be executing the code. In the main program this is the \emph{initial thread} . At the start of the block, a new team of threads is created, and the thread that was active before the block becomes the master thread of that team. After the block only the master thread is active. Inside the block there is team of threads: each thread in the team executes the body of the block, and it will have access to all variables of the surrounding environment. How many threads there are can be determined in a number of ways; we will get to that later. 并行模型之MIMD模型 take an amount of work and distribute it over the available threads in a parallel region. 这种模型下，OpenMP会完成给线程分配任务的工作，如下面的例子：123456789#pragma omp parallel&#123; int threadnum = omp_get_thread_num(), numthreads = omp_get_num_threads(); int low = N*threadnum/numthreads, high = N*(threadnum+1)/numthreads; for (i=low; i&lt;high; i++) // do something with i&#125; 在这个例子中，我们通过获取线程号的方式显式分配任务，在OpenMP中，为了完成这样的工作，有一种更加自然的语法12345#pragma omp parallel#pragma omp forfor (i=0; i&lt;N; i++) &#123; // do something with i&#125; 这种模式下需要注意的地方可用这种模型的for循环是有很多限制的，这一些限制在下面有说明。 There are some restrictions on the loop: basically, OpenMP needs to be able to determine in advance how many iterations there will be. The loop can not contains break , return , exit statements, or goto to a label outside the loop. The continue (C) or cycle (F) statement is allowed. The index update has to be an increment (or decrement) by a fixed amount. The loop index variable is automatically private, and not changes to it inside the loop are allowed. 并行模型的理解在上面两种基础的并行模型理解之后，我们可以看一看之后这一段代码，OpenMP将会如何去实现？ 123456789#pragma omp parallel&#123; code1();#pragma omp for for (i=1; i&lt;=4*N; i++) &#123; code2(); &#125; code3();&#125; 下面这一个图解释的很清楚了，每一个线程都会原封不动地完成code1()，然后将for中包含的任务分配给各个线程完成，最后等到每一个线程for块包含的任务都完成之后，每一个线程继续各干各的code3()。 其他需要注意的地方Nested parallelism在并行运行块中运行一个函数，而这个函数里又有并行运行块，openmp会如何实现这样的操作呢？在默认情况下，嵌套的并行操作块只会有一个线程执行（就像没有嵌套一样），可通过omp_set_nested(1)显式说明可以嵌套。 omp_set_nested(1) 123456789101112131415int main() &#123; ...#pragma omp parallel &#123; ... func(...) ... &#125;&#125; // end of mainvoid func(...) &#123;#pragma omp parallel &#123; ... &#125;&#125; 参考资料 http://pages.tacc.utexas.edu/~eijkhout/pcse/html/omp-basics.html]]></content>
      <categories>
        <category>Parallel Programing</category>
      </categories>
      <tags>
        <tag>OpenMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openGL配置]]></title>
    <url>%2F2018%2F04%2F30%2F2018-04-2018-04-30-openGL%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[配置OpenGL的笔记linux好不容易在Window下配置好OpenGL，在博客上记录一下。 12345sudo apt-get install mesa-common-dev libgl1-mesa-dev libglu1-mesa-devsudo apt-get install freeglut3-devsudo apt-get install build-essential gdb subversionsudo apt-get install automake autoconf libtoolsudo apt-get install libgtk2.0-dev libxmu-dev libxxf86vm-dev 在安装了参考资料里面的包之后，还另外安装了glfw,为了能够运行教程中的用到glfw代码的示例。 12sudo apt install libglfw3 libglfw3-devsudo apt install libassimp-dev 运行成功动图这个gif有点大，可能会加载的很慢（15mb) 小结这是在wsl上配置的，为了能够让wsl里面的程序在window运行图形界面，还另外装了VcXsrv作为Xwindow server。然后在启动VcXsrv时还修改了一些配置才运行的比较正常，如截图所示。 windowmingw直接装就好了，里面有libopengl32.a,libgdi32.a等库，都是等下需要的。 gifw 官网下载glfw（32） 将头文件放到项目文件夹下/includes中 将静态链接库房贷项目文件夹/lib中 获取glad.h glad.c 等文件，并将glad.c加入到项目中。 编写makefile 尝试运行示例代码 http://www.glfw.org/documentation.html 1234567891011121314151617181920# the ROOT dictionaryROOT = .# Target FileTARGET_FILE = triangle.cpp# compile optionCXX_FLAGS = -std=c++11 -g -Wall CXX_INCLUDES =-I$(ROOT)/include# 增加静态链接库的寻找目录CXX_LIB = -L$(ROOT)/libSTATIC_LINK_LIB = -lglfw3 -lopengl32 -lgdi32all:t.exe t.o ./t.exe make cleant.exe:t.o glad.o g++ $(CXX_FLAGS) t.o glad.o -o t.exe $(CXX_LIB) $(STATIC_LINK_LIB)t.o:t.cpp g++ $(CXX_INCLUDES) $(CXX_FLAGS) -o t.o -c $(TARGET_FILE)glad.o:glad.c g++ $(CXX_INCLUDES) $(CXX_FLAGS) -o glad.o -c glad.c 参考了这些资料 https://stackoverflow.com/questions/22008845/glfw-mingw-link-errorhttps://learnopengl-cn.github.io/01%20Getting%20started/02%20Creating%20a%20window/ freeglut如果不用glfw，用freeglut的话，也可以进行配置。 参考资料https://blog.csdn.net/evenness/article/details/9150351]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmux]]></title>
    <url>%2F2018%2F04%2F30%2F2018-04-2018-04-30-tmux%2F</url>
    <content type="text"><![CDATA[Tmux 终端复用工具满足需求： 一个终端窗口能够查看多个终端。 保存环境，恢复环境。 学习资料看了一部分资料，觉得这个已经讲得足够清楚，放在这里收藏着。 http://louiszhai.github.io/2017/09/30/tmux/]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[物理层]]></title>
    <url>%2F2018%2F04%2F28%2F2018-04-2018-04-28-%E7%89%A9%E7%90%86%E5%B1%82%2F</url>
    <content type="text"><![CDATA[物理层2.1 物理层的基本概念 机械特性 接线器的形状和尺寸，引线数目和排列，固定，锁定装置 电气特性 各条线的电压等 功能特性 某条线上出现的某一电平的电压表示的意义 过程特性 不同功能的各种可能事件的出现顺序 2.2 数据通信的基础知识2.2.1 数据通信系统的模型 两个关键过程：调制 解调 关于调制，解调过程重要性的理解。 信号的衰减在数据的传播过程中不可忽略。实例：使用十米的延长线连接电脑和移动硬盘，电脑无法识别。 为了解决这种问题，有专家发现高频的信号衰减较小，更加适合远距离传输。于是便有了调试解调的过程。 关于调制的理解模拟信号-&gt;数字信号两个步骤：1. 抽样 2. 量化抽样后，仅仅在时间本身做了离散化，样点能取到的值仍然是连续的因此需要量化进行将样点取到的值离散化， 如四舍五入等方法。 几个概念码元码元：数字通信中一个基带波形所对应的二进制玛组。 关于单极性和双极性的思考：单极性的码元容易出现误码，双极性会好很多。]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[OpenMP笔记]]></title>
    <url>%2F2018%2F04%2F27%2F2018-04-2018-04-27-Openmp%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[OpenMP笔记OpenMP 框架是使用 C、C++ 和 Fortran 进行并发编程的一种强大方法。GNU Compiler Collection (GCC) V4.2 支持 OpenMP 2.5 标准，而 GCC 4.4 支持最新的 OpenMP 3 标准。 Hello world程序的编写12345678910#include &lt;omp.h&gt;#include &lt;iostream&gt;int main()&#123; omp_set_num_threads(5); #pragma omp parallel &#123; std::cout &lt;&lt; "Hello World!\n"; &#125;&#125; 在本机运行的结果为 #pragma omp parallel 仅在您指定了 -fopenmp 编译器选项后才会发挥作用。在编译期间，GCC 会根据硬件和操作系统配置在运行时生成代码，创建尽可能多的线程。每个线程的起始例程为代码块中位于指令之后的代码。这种行为是 隐式的并行化，而 OpenMP 本质上由一组功能强大的编译指示组成，帮您省去了编写大量样本文件的工作。（为了进行比较，您需要了解使用 Portable Operating System Interface (POSIX) 线程 [pthreads] 实现您刚才的程序将会怎样）。 修改并行线程数默认的并行线程数由硬件决定。修改的时候有如下方法： #pragma omp parallel num_threads(5) omp_set_num_threads(5); 还可以通过修改外部环境变量来设置 在命令行中加入：export OMP_NUM_THREADS=6 OpenMP 的三个方面：编译指示、运行时 API 和环境变量。同时使用环境变量和运行时 API ,运行时 API 将获得更高的优先权。 继续深入，一个实例两个数组之间的运算如下代码所示。123456789int main( )&#123;int a[1000000], b[1000000]; // ... some initialization code for populating arrays a and b; int c[1000000];for (int i = 0; i &lt; 1000000; ++i) c[i] = a[i] * b[i] + a[i-1] * b[i+1];// ... now do some processing with array c&#125; 很明显，每一次循环之间并没有前后依赖关系，很容易并行化。 12345678910int main( )&#123;int a[1000000], b[1000000]; // ... some initialization code for populating arrays a and b; int c[1000000];#pragma omp parallel forfor (int i = 0; i &lt; 1000000; ++i) c[i] = a[i] * b[i] + a[i-1] * b[i+1];// ... now do some processing with array c&#125; 当加入了这一条编译指令之后，发生了什么呢？TODO:不清楚 计算线程运行时间123456789101112131415161718192021#include &lt;omp.h&gt;#include &lt;math.h&gt;#include &lt;time.h&gt;#include &lt;iostream&gt; int main(int argc, char *argv[]) &#123; int i, nthreads; clock_t clock_timer; double wall_timer; double c[1000000]; for (nthreads = 1; nthreads &lt;=8; ++nthreads) &#123; clock_timer = clock(); wall_timer = omp_get_wtime(); #pragma omp parallel for private(i) num_threads(nthreads) for (i = 0; i &lt; 1000000; i++) c[i] = sqrt(i * 4 + i * 2 + i); std::cout &lt;&lt; "threads: " &lt;&lt; nthreads &lt;&lt; " time on clock(): " &lt;&lt; (long double) (clock() - clock_timer) / CLOCKS_PER_SEC &lt;&lt; " time on wall: " &lt;&lt; omp_get_wtime() - wall_timer &lt;&lt; "\n"; &#125;&#125; 运行结果： 可以看到的结果是：随着运行的线程数不断增加，总运行时间渐渐减少，并行对程序运行的加速效果可见一斑。 需要注意的地方 #pragma parallel for private(i) 意味着循环向量 i 将被作为一个线程本地存储进行处理，每个线程有一个该向量的副本。线程本地向量未进行初始化。 omp_get_wtime API 从一些任意的但是一致的点返回已用去的时间（定义很拗口，不过wtime可以看做wall time 墙上时间，即实际时间），以秒为单位。因此，omp_get_wtime() - wall_timer 将返回运行 for 循环所用的真实时间。 (clock() - clock_timer)返回的是CPU时间，问题在于，并行会减少实际时间，但不会减少CPU时间，因此应该用上面的omp_get_wtime()函数测量时间。下面的三个链接，将一些相关的疑问解释得很清楚了。 关于omp_get_wtime函数的疑问，可见这个网站https://stackoverflow.com/questions/10673732/openmp-time-and-clock-calculates-two-different-resultshttps://gcc.gnu.org/onlinedocs/libgomp/omp_005fget_005fwtime.htmlCPU time与WALL timehttps://blog.csdn.net/qq_15514565/article/details/78220342 OpenMP 中对临界区的处理通过#pragma omp critical指令来对临界区进行处理。12345678910#pragma omp critical (section1)&#123;myhashtable.insert("key1", "value1");&#125; // ... other code follows#pragma omp critical (section1)&#123;myhashtable.insert("key2", "value2");&#125;// pragma omp critical 之后的代码只能由一个线程在给定时间运行。同样，optional section name 是一个全局标识符，在同一时间，两个线程不能使用相同的全局标识符名称运行临界区段。 在这一代码的基础上，您可以作出一个很安全的假设：永远不会出现两个散列表同时插入的情况，因为临界区段名是相同的。 OpenMP 中的锁与互斥OpenMP 提供了自己的互斥锁：omp_lock_t，它被定义为 omp.h 头文件的一部分。关于互斥锁的使用，需要了解以下 5 个 API： 注：以下API均需要传递锁的地址作为参数。 API 功能 omp_init_lock 此 API 必须是第一个访问 omp_lock_t 的 API，并且要使用它来完成初始化。注意，在完成初始化之后，锁被认为处于未设置状态 omp_destroy_lock 此 API 会破坏锁。在调用该 API 时，锁必须处于未设置状态，这意味着您无法调用 omp_set_lock 并随后发出调用来破坏这个锁。 omp_set_lock 此 API 设置 omp_lock_t，也就是说，将会获得互斥。如果一个线程无法设置锁，那么它将继续等待，直到能够执行锁操作。 omp_test_lock 此 API 将在锁可用时尝试执行锁操作，并在获得成功后返回 1，否则返回 0。这是一个非阻塞 API， 也就是说，该函数不需要线程等待就可以设置锁 omp_unset_lock 此 API 将会释放锁。 使用例子使用一个线程不安全的队列，扩展成线程安全的队列： 12345678910111213141516171819202122232425262728293031#include &lt;omp.h&gt; #include "myqueue.h"class omp_q : public myqueue&lt;int&gt; &#123; public: typedef myqueue&lt;int&gt; base; omp_q( ) &#123; // 构造函数，先初始化锁 omp_init_lock(&amp;lock); &#125; ~omp_q() &#123; omp_destroy_lock(&amp;lock); &#125; bool push(const int&amp; value) &#123; omp_set_lock(&amp;lock); bool result = this-&gt;base::push(value); omp_unset_lock(&amp;lock); return result; &#125; bool trypush(const int&amp; value) &#123; bool result = omp_test_lock(&amp;lock); if (result) &#123; result = result &amp;&amp; this-&gt;base::push(value); omp_unset_lock(&amp;lock); &#125; return result; &#125; // likewise for pop private: omp_lock_t lock;&#125;; 嵌套锁这个嵌套锁有点像信号量，内部会维护一个计数器，一旦使用cmp_set_nest_lock，与锁相关的计数量就会加1，不会阻塞。 API 功能 omp_init_nest_lock(omp_nest_lock_t* ) 此 API 将内部嵌套计数初始化为 0。 omp_destroy_nest_lock(omp_nest_lock_t* ) 此 API 将破坏锁。使用非零内部嵌套计数对某个锁调用此 API 将会导致出现未定义的行为。 omp_set_nest_lock(omp_nest_lock_t* ) 此 API 类似于 omp_set_lock，不同之处是线程可以在已持有锁的情况下多次调用这个函数。 omp_test_nest_lock(omp_nest_lock_t* ) 此 API 是 omp_set_nest_lock 的非阻塞版本。 omp_unset_nest_lock(omp_nest_lock_t* ) 此 API 将在内部计数器为 0 时释放锁。否则，计数器将在每次调用该方法时递减。 理解 firstprivate 和 lastprivate 指令firstprivate指令使用主线程的变量初始化自身。关于这个指令的作用，下面的链接解释得很清楚了。https://stackoverflow.com/questions/15304760/how-are-firstprivate-and-lastprivate-different-than-private-clauses-in-openmp 如果您准备将 firstprivate 用于您的 C++ 代码，那么还要注意，firstprivate 指令使用的变量是一个副本构造函数，用于从主线程的变量初始化自身，因此对您的类使用一个私有的副本构造函数肯定会产生不好的结果。 lastprivate指令目的在于解决这样的问题：一个全局变量被多个线程修改后，修改全局变量的线程是不确定的，每一次运行程序，多线程结束后全局变量的值都不同 再将问题具体化，可以看以下程序 1234567891011121314151617#include &lt;stdio.h&gt;#include &lt;omp.h&gt; int main()&#123; int idx = 100; int main_var = 2120; #pragma omp parallel for private(idx) lastprivate(main_var) for (idx = 0; idx &lt; 12; ++idx) &#123; main_var = idx * idx; printf("In thread %d idx = %d main_var = %d\n", omp_get_thread_num(), idx, main_var); &#125; printf("Back in main thread with main_var = %d\n", main_var);&#125; 如果我希望最后main_var的值是11*11，则必须要用lastprivate(main_var),否则当并行部分结束后main_var的值是不确定的。 参考资料 https://www.ibm.com/developerworks/cn/aix/library/au-aix-openmp-framework/]]></content>
      <categories>
        <category>Parallel Programing</category>
      </categories>
      <tags>
        <tag>OpenMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[the life of a web request]]></title>
    <url>%2F2018%2F04%2F25%2F2018-04-2018-04-25-the-life-of-a-web-request%2F</url>
    <content type="text"><![CDATA[一个web请求的例程]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[集线器，二层交换机，三层交换机的区别]]></title>
    <url>%2F2018%2F04%2F25%2F2018-04-2018-04-25-%E4%BA%A4%E6%8D%A2%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[集线器总线式的结构。一次只能够有一个用户占用总线发送消息。 二层交换机能够多用户同时发送，使用交换机。缺点：体积大，实现虚拟局域网复杂。 三层交换机三层交换技术：二层交换技术+三层转发技术 网段划分之后，网段中子网必须依赖路由器进行管理。三层交换机解决了传统路由器低速，复杂所造成的网络瓶颈问题。 二层交换引擎：实现同一个网段内的快速二层转发 三层路由引擎：实现跨网段的三层路由转发 基于流交换的三层交换技术有个不在同一个子网内的站点需要发送消息给另一个不在同一个子网的站点。 假设两个使用IP协议的站点A、B通过第三层交换机进行通信 发送站点A在开始发送时，把自己的IP地址与B站的IP地址比较，判断B站是否与自己在同一子网内。 若目的站B与发送站A在同一子网内，则进行二层的转发。 若两个站点不在同一子网内，发送站A要向“缺省网关”发出ARP(地址解析)封包，而“缺省网关”的IP地址其实是三层交换机的三层交换模块。 当发送站A对“缺省网关”的IP地址广播出一个ARP请求时，如果三层交换模块在以前的通信过程中已经知道B站的MAC地址，则向发送站A回复B的MAC地址。否则三层交换模块根据路由信息向B站广播一个ARP请求; B站得到此ARP请求后向三层交换模块回复其MAC地址; 三层交换模块保存此地址并回复给发送站A,同时将B站的MAC地址发送到二层交换引擎的MAC地址表中。 从这以后，当A向B发送的数据包便全部交给二层交换处理，信息得以高速交换。由于仅仅在路由过程中才需要三层处理，绝大部分数据都通过二层交换转发，因此三层交换机的速度很快，接近二层交换机的速度]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[source-insight]]></title>
    <url>%2F2018%2F04%2F24%2F2018-04-2018-04-24-source-insight%2F</url>
    <content type="text"><![CDATA[source insight 源代码阅读工具下面是我使用source insight 看minix源代码时的截图。 满足需求这个工具大概满足了使用者的这几点需求： 函数调用与被调用关系图的查看。 对函数定义，变量定义的迅速定位与查看，不需要程序员手动寻找。 小结暂时还不是很会用这个工具。对这个工具能提供的功能也还不是很清楚。暂时先放在这里，以后有什么使用的技巧的话再更新吧。]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown2ppt]]></title>
    <url>%2F2018%2F04%2F22%2F2018-04-2018-04-22-markdown2ppt%2F</url>
    <content type="text"><![CDATA[markdown 可以直接变成 ppt！今天发现了一个比较好用的工具，可以将自己书写的markdown直接变成可以展示的ppt，准确来讲应该是一个网页。 testtest! 参考资料 https://jk2k.com/2018/01/how-to-write-presentation-using-markdown/ https://sspai.com/post/40657]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test-auto-pull]]></title>
    <url>%2F2018%2F04%2F22%2Ftest-2018-04-22-test-auto-pull%2F</url>
    <content type="text"><![CDATA[今天试了一下，将博客部署在了公网上，并且在服务器端配置了自动pull。 参考资料： https://excaliburhan.com/post/add-webhooks-to-your-project.html 使用pm2 守护进程，守护服务器端监听的程序。]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广播与多播]]></title>
    <url>%2F2018%2F04%2F22%2F2018-04-2018-04-22-%E5%B9%BF%E6%92%AD%E4%B8%8E%E5%A4%9A%E6%92%AD%2F</url>
    <content type="text"><![CDATA[[toc] 简介广播路由选择：从一个源节点到网络中其他所有节点交付分组的服务. 多播路由选择：单个源节点能够向其他网络节点的一个子集发送分组的副本。 广播常见实现方法 N次单播 无控制泛洪 受控泛红 序号控制泛洪 反向路径转发 生成树广播 N次单播使用单播路由选择，向N个目的地传输N份副本。 优点 实现简单 缺点 效率低：每一个副本都需要重复经过同一段链路传播 缺陷：难以得到所有接收方的地址 无控制泛洪提高点某节点接受了一个广播分组后，复制该分组，并向其余所有邻居转发（除了从其接收分组的那个邻居） 优点解决了传播冗余副本的问题。 缺点若网络图具有圈，将导致广播风暴。 受控泛洪序号控制泛洪每个节点维护它已经收到的，复制的，转发的原地址和每个广播分组的序号列表。当结点接收到一个广播分组时，它先检查该分组是否在列表中，如果在，则丢弃，否则复制并转发。 反向路径转发当一台路由器接收到具有给定源地址的广播分组时，仅当该分组到达的链路正好是位于他自己返回其源的最短单播路径上，它才向所有出链路（除了它接收分组的那个）传输报文。 生成树广播通过某种分布式生成树算法（TODO:分布式生成树算法！记得吗？），结点能够得到它的哪些邻居位于生成树上，并只向这些邻居转发。 多播因特网中的网络层多播是由两个互补的组件组成的：IGMP和多播路由选择协议。 IGMP生效范围与作用 IGMP 并非在因特网范围内对所有多播组成员进行管理的协议。 IGMP 不知道IP 多播组包含的成员数，也不知道这些成员都分布在哪些网络上。 IGMP 协议是让连接在本地局域网上的多播路由器知道本局域网上是否有主机（严格讲，是主机上的某个进程）参加或退出了某个多播组。 IGMP报文类型 membership_query membership_report leave_group(optional) 另一种可选的退出多播组的方法是使用软状态机制 多播路由选择协议多播路由选择的目标：发现一颗链路的树，这些链路连接了所有具有该多播组的相连主机的路由器。由此，多播分组将能够沿着这棵树从发送方路由，发送到所有处于该多播树的主机。 一般的实现有两种方法： 使用一棵组共享树的多播路由选择 使用一棵基于源的树的多播路由选择 注意，一台接收到多播分组的多播路由器，如它没有加入到该组的相连主机，则它向上游路由器发送一个剪枝报文。 因特网中的多播路由选择协议无关的多播路由选择协议：明确辨识两种多播分发情形：稠密模式与稀疏模式。 可以参考因特网中的单播路由选择。对BGP的扩展，使得BGP能够为其他协议承载路由选择信息，包括多播信息。 小结对多播这一块的内容还没有完全消化。看了老师PPT，对硬件多播的内容还没看懂。下面放一个不懂的图。 不过多播的学习，我觉得可以参考单播。多播中的很多技术与单播是类似的，甚至可以说，是在单播的基础上，fork了一个分支出来，并且为了适应多播做了相应的修改。无论是在硬件层面，还是协议栈往上的几个协议，对于多播都有对应的协议来支持，并且这些协议的核心都来源于单播的实现算法。 还有个问题没有想清楚，多播路由协议是如何与传输层的协议合作的呢？ 参考资料 《计算机网络》第六版]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
      <tags>
        <tag>广播</tag>
        <tag>多播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP协议]]></title>
    <url>%2F2018%2F04%2F21%2F2018-04-2018-04-21-BGP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[BGP简介BGP全称是Border Gateway Protocol, 对应中文是边界网关协议。这个名字比较抽象，而维基中文的解释我觉得比较好（维基英文甚至都没有类似的解释）。BGP是互联网上一个核心的去中心化自治路由协议。从这个解释来看，首先这是一个用于互联网（Internet）上的路由协议。它的地位是核心的（目前是最重要的，互联网上唯一使用的路由协议），它的目的是去中心化，以达到各个网络自治。 这个协议，最终的结果，会反映到路由器的主路由表中，因此在发包寻路由的过程中，并不会有变动，变的，只是路由表的计算算法。 BGP协议环境前提BGP可以说是最复杂的路由协议。它是应用层协议，其传输层使用TCP，默认端口号是179。因为是应用层协议，可以认为它的连接是可靠的，并且不用考虑底层的工作，例如fragment，确认，重传等等。BGP是唯一使用TCP作为传输层的路由协议。 协议消息格式工作方式概述几个概念：BGP peer，BGP route 与距离向量算法类似，可以说是基于距离向量算法的实现。 BGP route指的是BGP自己维护的路由信息，区分于设备的主路由表，路由表项包括(列出部分) AS_PATH NEXT-HOP 时序 收到别的BGP实体发来的可达消息 AS_PATH通过该AS能够去到哪个子网，以什么路径去到 开始这一个路径的路由器接口:NEXT-HOP 通过本地的输入策略决定是否接受或者过滤该路由信息 接受这路由消息后，若本机拥有了新的可达对象，则构造新的消息，向其他的BGP实体发送 BGP更像是一个可达协议，可达信息传来传去，本地根据收到的信息判断决策，再应用到路由表。 关于策略经常使用人为指定的策略，控制数据流量的流向。如控制某AS防止帮别的BGP实体转发流量。如何控制呢？不告诉别的实体我可达其他子网。 BGP route 如何进入路由器的转发表书本P266 参考资料 https://zhuanlan.zhihu.com/p/25433049]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[因特网中的路由选择]]></title>
    <url>%2F2018%2F04%2F21%2F2018-04-2018-04-21-%E5%9B%A0%E7%89%B9%E7%BD%91%E4%B8%AD%E7%9A%84%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[路由选择在因特网下的问题在前面学习过，对于路由选择而言，有两种常用的算法：DV，LS算法。这些算法在比较小的网络规模中还是适用的，但是当网络规模开始膨胀（比如当今的因特网），这些算法会遇到下面的两个问题。 运行算法计算路径所需信息大小过大，路由器内存无法存下。 数据规模过大，路由器计算力跟不上 算法的正常运行，需要向网络广播或点对点发送运行路由选择算法所需的报文，而这会几乎占据所有带宽。 在这样的情况下，原先的算法不再适用，因特网中是如何做的呢？ 层次路由选择抽象总是能够解决问题，因特网的做法，也大概如此。在规模巨大的网络中，将一组通常处于相同管理控制下的路由器组成一个自治系统（AS），在自治系统内，路由的选择由自治系统内部路由选择协议（intra-autonomous system routing protocol）完成，在自治系统间，通过网关路由器实现自治系统之间的互连，对于自治系统间的路由寻址，由自治系统间路由选择协议（inter-autonomous system routing protocol)完成。 常见协议简介自治系统内部路由选择协议 RIP(核心：距离向量DV算法) OSPF(核心：Dijkstra最低费用路径算法) 自治系统间路由选择协议 BGP协议 参考资料 《计算机网络》第六版]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面包店算法（bakery）]]></title>
    <url>%2F2018%2F04%2F21%2F2018-04-2018-04-21-%E9%9D%A2%E5%8C%85%E5%BA%97%E7%AE%97%E6%B3%95%EF%BC%88bakery%EF%BC%89%2F</url>
    <content type="text"><![CDATA[面包店算法Lamport面包店算法是解决多个线程并发访问一个共享的单用户资源的互斥问题的算法。 来自《操作系统-精髓与设计原理》第五章课后习题5.7 算法描述面包店算法的基本思想来源于顾客在面包店购买面包时的排队原理。顾客进入面包店前，首先抓取一个号码，然后按号码从小到大的次序依次进入面包店购买面包，这里假定： (1)—面包店按由小到大的次序发放号码，且两个或两个以上的顾客有可能得到相同号码（要使顾客的号码不同，需互斥机制）； (2)—若多个顾客抓到相同号码，则按顾客名字的字典次序排序（假定顾客没有重名）。 计算机系统中，顾客相当于进程，每个进程有一个唯一的标识，用Pi表示，对于Pi和Pj，若有i&lt;j，即Pi先进入临界区，则先为Pi服务。 面包店算法的基本思想：首先设置一个发号器，按由小到大的次序发放号码。进程进入临界区前先抓取一个号码，然后按号码从小到大的次序依次进入临界区。若多个进程抓到相同的号码则按进程编号依次进入。 实现面包店算法所需的数据结构： 12int choosing[n]; //表示进程是否正在抓号，初值为0。若进程i正在抓号，则choosing[i]=1.int number[n]; //记录进程抓到的号码，初值为0。若number[i]=0，则进程i没有抓号 伪代码如下：123456789101112131415161718192021222324252627// declaration &amp; initial values of global variablesChoosing, Number: array [1..N] of integer = &#123;0&#125;;// logic used by each process...// where "(a, b)＜(c, d)"// means "(a＜c) or ((a == c) and (b＜d))"Process(i) &#123; //注意：此处测试的是进程Pi while (true) &#123; Choosing[i] = 1; Number[i] = 1 + max(Number[1],...,Number[N]); Choosing [i] = 0; for (j=1; j＜=N; ++j) &#123; while (Choosing[j] != 0) &#123;//保证编号较小的进程先进入临界区 // wait until process j receives its number &#125; while ((Number[j]!=0) &amp;&amp; ((Number[j],j) ＜(Number[i],i))) &#123; //进程Pj是其他线程 // wait until processes with smaller numbers // or with the same number, but with higher // priority, finish their work &#125; &#125; // critical section... Number[i] = 0; // non-critical section... &#125;&#125; 使用条件这个算法不需要基于硬件的原子(atomic)操作实现，即它可以纯软件实现。 直观理解每个线程只写它自己的Entering[i]、Number[i]，只读取其它线程的这两个数据项。 摘自wiki：使用Entering数组是必须的。假设不使用Entering数组，那么就可能会出现这种情况：设进程i的优先级高于进程j(即i&lt;j)，两个进程获得了相同的排队登记号(Number数组的元素值相等)。进程i在写Number[i]之前，被优先级低的进程j抢先获得了CPU时间片，这时进程j读取到的Number[i]为0，因此进程j进入了临界区. 随后进程i又获得CPU时间片，它读取到的Number[i]与Number[j]相等，且i&lt;j，因此进程i也进入了临界区。这样，两个进程同时在临界区内访问，可能会导致数据腐烂(data corruption)。算法使用了Entering数组变量，使得修改Number数组的元素值变得“原子化”，解决了上述问题。 严格证明证明：当有一个进程$i$已经处于临界区的时候，对于此时打算进入的进程$k$,始终有下面的关系式： $$( number[i], i ) &lt; ( number[k], k )$$ 书本答案 123456789101112Tw1 Pi reads choosing[k] for the last time, for j = k, in its first wait, so we have choosing[k] = false at Tw1.Tw2 Pi begins its final execution, for j = k, of the second while loop. Wetherefore have Tw1 &lt; Tw2.Tk1 Pk enters the beginning of the repeat loop.Tk2 Pk finishes calculating number[k].Tk3 Pk sets choosing[k] to false. We have Tk1 &lt; Tk2 &lt; Tk3.Since at Tw1, choosing[k] = false, we have either Tw1 &lt; Tk1 or Tk3 &lt; Tw1. In the first case, we have number[i] &lt; number[k], since Pi was assigned its number prior to Pk; this satisfies the condition of the lemma.In the second case, we have Tk2 &lt; Tk3 &lt; Tw1 &lt; Tw2, and therefore Tk2 &lt; Tw2.This means that at Tw2, Pi has read the current value of number[k]. Moreover, as Tw2 is the moment at which the final execution of the second while for j = k takes place, we have (number[i], i ) &lt; ( number[k], k), which completes the proof of the lemma.It is now easy to show the mutual exclusion is enforced. Assume that Pi is in its critical section and Pk is attempting to enter its critical section. Pk will be unable to enter its critical section, as it will find number[i] ≠ 0 and 参考资料 https://zh.wikipedia.org/wiki/Lamport%E9%9D%A2%E5%8C%85%E5%BA%97%E7%AE%97%E6%B3%95 https://blog.csdn.net/asce1885/article/details/5735565 《操作系统-精髓与设计原理》第七版 http://yoncise.com/assets/%E7%BB%8F%E5%85%B8%E4%BA%92%E6%96%A5%E7%AE%97%E6%B3%95.pdf]]></content>
      <categories>
        <category>Operating System</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统-精髓与设计原理-第五章]]></title>
    <url>%2F2018%2F04%2F21%2F2018-04-2018-04-21-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%B2%BE%E9%AB%93%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-%E7%AC%AC%E4%BA%94%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[操作系统-精髓与设计原理-第五章 读书笔记并发的原理擦偶偶系统中的进程交替执行，表现出一种并发执行的外部特征。在实现并发的过程中，会遇到很多问题，这个问题源于多道程序设计系统的一个基本特性：进程的相对执行速度不可预测。 操作系统关注并发的哪方面问题？ 操作系统必须能够跟踪不同的进程 操作系统必须为每个活跃进程分配和释放各种资源 操作系统必须保护每个进程的数据和物理资源 进程的功能和输出结果必须和执行速度无关。 互斥的要求最重要的是保证对临界资源的访问没有问题，一次只能有一个程序在临界区中。 进程之间的交互 进程间的资源竞争 进程间通过共享的合作 进程间通过通信的合作 竞争进程之间的交互面临的三个控制问题? 访问不可共享的资源（打印机）需要互斥 死锁 饥饿 互斥:硬件的支持 比较和交换指令 exchange指令 可使用忙等待(自旋等待)来实现互斥.(进程在得到临界区访问权限的时候,只能继续执行测试变量的指令来得到访问权限,除此之外不能做别的事情) 比较和交换指令 TODO:如何使用这两条指令实现互斥？P148 互斥:信号量信号量定义： 信号量可以初始化成非负数 semWait操作可以使信号量减1.若值为&lt;0,则执行semWait的进程被阻塞。 semSignal操作时信号量加1，若原本的值&lt;=0,则原恩被阻塞的一个进程被解除阻塞。 与二元信号量相关的一个概念是互斥量。两者的关键区别在于为互斥量加锁的进程和为互斥量解锁的进程必须是同一个进程信号量：可能由某个进程对二元信号量进行加锁操作，而由另一个进程解锁。 使用信号量解决消费者与生产者问题TODO:P154 信号量的实现12345struct semaphore&#123; int count; int flag; Queue q;&#125; TODO:信号量的实现，可以使用比较并交换，也可以使用exchange P158，目的是实现互斥，实现原子操作。 互斥:管程TODO:不想看了 互斥：消息传递发送消息有两种实现： 阻塞，直到目标进程接收到 不阻塞 收到消息有两种实现： 阻塞，直到等待的消息到达 不阻塞 消息传递模型中，一般实现的是：无阻塞send，阻塞receive 读者/写者问题TODO: 具体的解决？？？有点困 关于发送者与接受者之间的解耦合问题，可使用间接寻址：信箱。]]></content>
      <categories>
        <category>Operating System</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用wordpress建立自己的网站]]></title>
    <url>%2F2018%2F04%2F19%2F2018-04-2018-04-19-wordpress%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[参考资料 重点参考资料：https://blog.csdn.net/w_bu_neng_ku/article/details/79175479 http://blog.51cto.com/xpleaf/1903115]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http协议]]></title>
    <url>%2F2018%2F04%2F19%2F2018-04-2018-04-19-http%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[http协议 笔记HTTP协议作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。 HTTP（超文本传输协议）基于TCP/IP传输层协议传输数据。 参考资料 https://www.jianshu.com/p/80e25cb1d81a https://www.cnblogs.com/li0803/archive/2008/11/03/1324746.html http报头详解http://lvwenwen.iteye.com/blog/1570468 http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html]]></content>
      <categories>
        <category>Computer Network</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo + next 主题 博客安装与简单配置]]></title>
    <url>%2F2018%2F01%2F25%2Ftest-test-my-site%2F</url>
    <content type="text"><![CDATA[hexo + next 主题 博客安装与简单配置hexo 是一个快速、简洁且高效的博客框架。该框架使用markdown解析文章，并使用主题生成静态网页 hexo文档链接 安装hexo依赖 Node.js Git 安装确认已经安装依赖后，开始安装1npm install -g hexo-cli 建站建站过程中，建站所需的命令都是在站点初始化所在文件夹中进行的！ 初始化博客文件夹 hexo init &lt;folder&gt; 这条指令会在运行命令的目录下新建一个文件夹 之后各种配置站点都会在该文件夹中的 进入博客文件夹 cd &lt;folder&gt; 使用默认主题，生成网页静态文件 hexo g g 为 generate 的简写 启动服务器 hexo s s 为 server 的缩写 访问地址一般为：http://localhost:4000/ 将网站部署到github pages上 设置部署地址 ./_config.yml修改该配置文件 1234deploy: type: gitrepo: 这里填入你之前在GitHub上创建仓库的完整路径，记得加上 .gitbranch: master 安装git部署插件 npm install hexo-deployer-git --save 部署 hexo d github pages 简单说明只需要建一个仓库，该仓库命名为”用户名.github.io”这个仓库就可以存放静态页面，通过网址”用户名.github.io”即可访问 修改主题默认的主题其实蛮丑的。。修改主题可以这样子。 将主题对应的库clone到博客文件夹中themes文件夹下 1git clone https://github.com/iissnan/hexo-theme-next themes/next 修改站点的配置文件”./_config.yml” 12# Extensionstheme: next 修改主题的配置文件”./theme/_config.yml”next主题下有三种主题选择此步骤是为了选取更好看的主题我选的是Mist 1234# Schemes# scheme: Musescheme: Mist# scheme: Pisces 支持数学公式next主题本身就支持数学公式，只需要修改一下主题的配置文件就可以了 12345# MathJax Supportmathjax: enable: true # 修改此项为true即可 per_page: false cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML 总结暂时，一个简单的博客就配置完成了还有很多东西需要配置，这个就留到之后吧]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
</search>
